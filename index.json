[{"content":"Exploit Shell Code exploit은 파일 읽고 쓰기(open-read-write, orw), 셸 명령 실행(execve) 권한을 취득하는 것을 목표로 한다. Shell 권한을 획득하기 위한 어셈블리 코드들의 모음을 \u0026lsquo;Shell Code\u0026rsquo; 라 칭한다. ORW 파일을 열고 읽고 쓸 수 있도록 하는 shell code를 \u0026lsquo;ORW shell code\u0026rsquo; 라 칭한다. 시스템 콜들은 rax, rdi, rsi, rdx로 이루어 져 있음을 참고하여 shell code를 작성해 보자. rax : 시스템 콜에 대응되는 번호 rdi : 시스템 콜의 첫 번째 인자 rsi : 시스템 콜의 두 번째 인자 rdx : 시스템 콜의 세 번째 인자 open\n리눅스에서 open 명령은 open('FILE_PATH', flag, mode) 형태이다. 이를 어셈블리어로 분리하여 표현하면 \u0026lsquo;FILE_PATH\u0026rsquo; 을 stack에 담는다. 이때, stack에는 데이터가 8byte씩 올라가기 때문에 8byte 단위로 string을 끊어서 push한다. ex) \u0026ldquo;1234567890\u0026rdquo; 을 stack에 담을 때 \u0026ldquo;09\u0026rdquo; \u0026ldquo;87654321\u0026rdquo; 순으로 데이터를 push해야 한다. rsp를 rdi로 옮겨 rdi(첫번째 인자)가 \u0026lsquo;FILE_PATH\u0026rsquo;를 가리키도록 한다. 두 번째와 세 번째 인자에 맞게 각각 rsi와 rdx를 설정한다. open은 시스템 콜 번호 2에 해당하므로 rax를 2로 설정한다. ex) open (\u0026ldquo;1234567890\u0026rdquo;, O_RDONLY, NULL) 은 아래 어셈블리어로 치환된다. push 0x3039\rmov rax, 0x3837363534333231 ; to push 8byte\rpush rax\rmov rdi, rsp ; (1) rdi = \u0026#34;1234567890\u0026#34;\rxor rsi, rsi ; (3) rsi = 0 ; O_RDONLY\rxor rdx, rdx ; (3) rdx = 0 ; NULL\rmov rax, 2 ; (4) rax = 2 ; syscall_open\rsyscall ; open(\u0026#34;1234567890\u0026#34;, O_RDONLY, NULL) read\nread 명령은 read(FILE_DESCRIPTOR, buf, size) 형태이다. read 명령을 어셈블리어로 표현하면 open을 통해 열린 파일의 file descriptor는 rax 영역에 저장되므로, rax 값을 rdi 에 대입한다. 데이터를 저장할 길이를 고려하여 rsi에 값을 대입한다. size가 10이라면 rsp-10 값을 대입한다. rdx 에 size 값을 대입한다. rax 에 read에 해당하는 0 값을 대입한다. ex) read(fd, buf, 10) 은 아래 어셈블리어로 표현된다. mov rdi, rax ; (1) fd값을 rdi에 대입\rmov rsi, rsp\rsub rsi, 0x0A ; (2) rsi = rsp-10 ; buf\rmov rdx, 0x0A ; (3) rdx = 0x0A ; length\rmov rax, 0x0 ; (4) rax = 0 ; syscall_read\rsyscall ; read(fd, buf, 0x0A) write\nwrite 명령은 write(FILE_DESCRIPTOR, buf, size) 형태이다. write 명령을 어셈블리어로 표현하면 rdi 에 FILE_DESCRIPTOR 값을 대입한다. stdout으로 출력을 하려면 0x01을 적용한다. rsi 와 rdx 는 read 에서 사용한 값과 동일한 값을 적용한다. write 에 해당하는 시스템콜 번호 1을 rax 에 대입한다. ex) write(fd, buf, 10) 은 아래 어셈블리어로 표현된다. mov rdi, 1 ; (1) rdi = 1 ; fd = stdout\r; rsi rdx 값은 read와 동일한 값 사용, 별도 설정 안함\rmov rax, 0x1 ; (3) rax = 1 ; syscall_write\rsyscall ; write(fd, buf, 0x0A) shell code는 어셈블리 형태이므로 기계어로 컴파일 해서 사용 가능하지만, 실행될 기기의 os, cpu에 따라 다른 방법을 사용해야 한다. shell code를 동작시키기 위해 skeleton code에 shell code를 삽입하여 컴파일 하는 방법을 사용할 수 있다. skeleton code란, 아무런 동작도 하지 않는 어셈블리어로 작성된 코드로, 컴파일이 가능하다. 마치 C언어에서 void main(void) { return 0 } 를 컴파일 하는 것과 같다. C언어로 작성된 skeleton code의 예시는 아래와 같다. // 어셈블리어로 작성한 \u0026#39;assem_code\u0026#39; 함수를 실행시키는 파일\r__asm__(\r\u0026#34;.global assem_code\\n\u0026#34;\r\u0026#34;assem_code:\\n\u0026#34;\r# 여기에 원하는 assembly code를 집어넣는다.\r# 어셈블리 코드는 라인마다 마지막에 \u0026#39;\\n\u0026#39; 가 붙어야 함에 주의한다.\r\u0026#34;xor rdi, rdi # rdi = 0\\n\u0026#34;\r\u0026#34;mov rax, 0x3c\t# rax = sys_exit\\n\u0026#34;\r\u0026#34;syscall # exit(0)\u0026#34;\r);\rvoid assem_code();\rint main() { assem_code(); } execve execve() 는 Linux kernel 레벨의 함수로, 특정 프로그램을 실행시키는 함수이다. execve(\u0026quot;/bin/bash\u0026quot;, NULL, NULL) 을 실행할 수 있게 되면 쉘을 실행할 수 있는 권한을 얻은 것이다. execve는 execve(FILE_NAME, argv, envp) 형태로 실행되며, FILE_NAME은 실행할 프로그램 경로, argv는 인자, envp는 환경변수에 해당한다. execve를 어셈블리어로 표현하면 스택에 \u0026lsquo;/bin/bash\u0026rsquo; 를 넣고 rdi에 그 주소를 대입한다. rsi와 rdx는 NULL이므로 0을 대입한다. execve는 시스템콜 번호 0x3B에 해당하므로 rax는 0x3B가 적용된다. push 0x68\rmov rax, 0x7361622f6e69622f\rpush rax\rmov rdi, rsp ; (1) rdi = \u0026#34;/bin/bash\u0026#34;\rxor rsi, rsi ; (2) rsi = NULL\rxor rdx, rdx ; (2) rdx = NULL\rmov rax, 0x3b ; (3) rax = execve\rsyscall ; execve(\u0026#34;/bin/bash\u0026#34;, null, null) ","permalink":"https://aswinblue.github.io/post/systemhacking/exploit/","summary":"Exploit Shell Code exploit은 파일 읽고 쓰기(open-read-write, orw), 셸 명령 실행(execve) 권한을 취득하는 것을 목표로 한다. Shell 권한을 획득하기 위한 어셈블리 코드들의 모음을 \u0026lsquo;Shell Code\u0026rsquo; 라 칭한다. ORW 파일을 열고 읽고 쓸 수 있도록 하는 shell code를 \u0026lsquo;ORW shell code\u0026rsquo; 라 칭한다. 시스템 콜들은 rax, rdi, rsi, rdx로 이루어 져 있음을 참고하여 shell code를 작성해 보자. rax : 시스템 콜에 대응되는 번호 rdi : 시스템 콜의 첫 번째 인자 rsi : 시스템 콜의 두 번째 인자 rdx : 시스템 콜의 세 번째 인자 open","title":"Exploit"},{"content":"pwntool 시스템 해킹을 위해 제작된 파이썬 라이브러리 바이너리를 실행하고 특정 input을 집어넣어 해킹(exploit)을 할수 있게 한다. 설치 리눅스의 apt와 파이썬의 pip 명령으로 설치가 가능하다. $ apt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essential\r$ python3 -m pip install --upgrade pip\r$ python3 -m pip install --upgrade pwntools 공식 메뉴얼 사용법 from pwn import * 을 통해 모듈을 로딩한다. process / remote target = process(파일경로) 로 로컬 파일을 exploit 하기위한 대상으로 설정한다. 원격으로 접속한 목적지의 파일을 exploit 할 때는 remote를 사용한다. target = remote('목적지 ip', 목적지 port) 를 호출하면 해당 ip:port 에 연결된 소켓을 exploit target으로 설정한다. send process 혹은 remote 로 설정한 target 에 입력을 전달하는 함수 send의 파생으로 sendline, sendafter, sendlineafter 등이 있다. target.send(B) : target에 B를 입력 target.sendlineafter(A, B) : 출력으로 A가 감지되면 target에 B를 입력 recv target으로 부터 들어오는 출력 데이터를 수신하는 함수 파생으로 recvn, recvline, recvuntil, recvall 이 있다. result = target.recv(len): len만큼 데이터를 수신, len보다 길이가 짧으면 오류 반환 result = target.recvn(len): len만큼 데이터를 수신, 수신한 길이가 len보다 짧으면 무한 대기 result = target.recvline(): 개행문자를 만날 때 까지 데이터 수신 result = target.recvuntil(A): A 문자를 만날 때 까지 데이터 수신 result = target.recvall(): 프로세스가 종료될 때 까지 데이터 수신 packing / unpacking 리틀엔디안 / 빅엔디안 사이를 변환하는 함수 interactive exploint 중 표준 입력/출력으로 프로세스에 직접 입력을 주입하고 출력을 확인하고 싶은 경우 target.interactive() 를 설정하면 \u0026rsquo;target\u0026rsquo; 에 직접 관여할 수 있다. ELF ELF 파일 헤더를 참조할 때 사용 가능 elf = ELF(파일명) 형태로 참조하면 dictionary 형태의 데이터를 반환 받을 수 있다. elf.symbols[함수명] 으로 함수의 주소를 확인할 수 있다. context context.log_level context.log_level 을 설정하여 디버깅을 위한 로그 레벨을 설정 할 수 있다. context.arch exploit 대상의 아키텍처에 대한 정보를 설정할 수 있다. context.arch = \u0026quot;amd64\u0026quot; 형태로 설정 i386, arm, mips 등을 설정 할 수 있다. asm asm(CODE) 형태로 CODE에 어셈블리 라인을 string 형태로 기입시 바이너리 코드를 반환한다. ex) asm('mov eax, SYS_execve') =\u0026gt; b'\\xb8\\x0b\\x00\\x00\\x00' disasm disasm(BIN) 형태로 BIN에 바이너리 데이터를 입력시 어셈블리 명령어를 반환한다. ex) disasm(b'\\xb8\\x0b\\x00\\x00\\x00') =\u0026gt; 0: b8 0b 00 00 00 mov eax, 0xb' ","permalink":"https://aswinblue.github.io/post/systemhacking/pwntool/","summary":"pwntool 시스템 해킹을 위해 제작된 파이썬 라이브러리 바이너리를 실행하고 특정 input을 집어넣어 해킹(exploit)을 할수 있게 한다. 설치 리눅스의 apt와 파이썬의 pip 명령으로 설치가 가능하다. $ apt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essential\r$ python3 -m pip install --upgrade pip\r$ python3 -m pip install --upgrade pwntools 공식 메뉴얼 사용법 from pwn import * 을 통해 모듈을 로딩한다. process / remote target = process(파일경로) 로 로컬 파일을 exploit 하기위한 대상으로 설정한다.","title":"Pwntool"},{"content":"Assembly 기계어로 1대1 대응 가능한 언어로, human readable 한 언어 중 가장 기계어에 가까운 언어이다. 기계어로 컴파일 직전에 어셈블리어로 변환을 거친다. operation code(명령어) 와 operand(피연산자) 로 구성된다. 명령어는 데이터 이동, 산술연산, 논리연산, 비교, 분기, 스택, 프로시저, 시스템콜의 종류가 있다. 피연산자 자리에는 상수(Immediate Value), 레지스터(Register), 메모리(Memory)가 올 수 있다. 숫자를 넣으면 상수이다. [] 로 둘러싸인 숫자는 메모리이다. 메모리 피연산자 앞에는 메모리의 크기를 나타내는 크기 지정자(Size Directive)가 붙을 수 있다. WORD: 16bit DWORD: 32bit QWORD: 64bit 명령어 mov \u0026ldquo;값\u0026quot;을 레지스터리나 메모리에 저장하는 명령 mov dst, src : src 값을 dst에 덮어씀 dst = 레지스터, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 레지스터, src = 메모리 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 메모리 : 불가능 mov dst, [mem + 4] : mem + 4 주소에 저장된 값을 dst에 덮어씀 dst 값으로는 주소나 포인터가 올 수 있다. lea \u0026ldquo;주소\u0026quot;를 레지스터리나 메모리에 저장하는 명령 lea dst, src : src값을 dst에 덮어씀 (src는 주소값) lea dst, [mem + 4] : mem 값에 4를 더한 값을 dst에 덮어씀 add add dst, src : dst 에 있는 값에 src 값을 더해 dst에 덮어씀 dst는 주소, src는 값 sub sub dst, src: : dst 에 있는 값에 src 값을 빼고 dst 주소에 덮어씀 dst는 주소, src는 값 inc inc op : op 에 있는 값을 1 증가시킴 op는 주소 dec dec op : op 에 있는 값을 1 감소시킴 op는 주소 and and dst, src : src와 dst 값을 and 연산한 결과를 dst에 저장 or or dst, src : src와 dst 값을 or 연산한 결과를 dst에 저장 xor xor dst, src : src와 dst 값을 xor 연산한 결과를 dst에 저장 not not op : op 값을 not 연산한 값을 op에 저장 comp cmp rax, rbx : rax 값과 rbx 값을 비교한 후, 결과에 따라 플래그 설정 if rax == rbx: ZF = 1 test test rax, rbx : rax 값과 rbx 값을 and 연산 후, 결과에 따라 플래그 설정 jmp jmp addr : addr 주소로 rip를 이동한다. je je addr : 직전에 비교한 cmp rax rbx 연산에서 rax == rbx 라면 addr로 rip 를 이동한다. jg jg addr : 직전에 비교한 cmp rax rbx 연산에서 rax \u0026gt; rbx 라면 addr로 rip 를 이동한다. push push val : 스택의 최상단에 \u0026lsquo;val\u0026rsquo; 값을 집어넣는다. rsp 를 한칸 위로 옮기고, 그 위치에 \u0026lsquo;val\u0026rsquo;을 대입한다. rsp -= 8; [rsp] = val 동작과 동일하다. push val 형태로는 4byte 데이터밖에 주입할 수 없으므로, 4byte를 초과하는 데이터를 주입할 때는 값을 레지스터에 대입하고, 레지스터를 push한다. mov rax 0x0102030405060708\rpush rax pop pop rax : 스택의 최상단에 있는 값을 \u0026lsquo;rax\u0026rsquo; 주소에 대입한다. rsp 위치의 값을 반환하고, rsp 를 한칸 밑으로 옮긴다. rsp += 8; reg = [rsp-8] 동작과 동일하다. call call addr \u0026lsquo;addr\u0026rsquo; 위치의 프로시저를 호출 \u0026lsquo;push\u0026rsquo; 명령과 \u0026lsquo;jump\u0026rsquo; 명령으로 구현할 수 있다. 스택에 다음 실행 주소를 push한다. (push rip + 8) rip를 실행시키고 싶은 명령어가 적힌 주소로 이동한다. (jump) leave rsp를 rbp + 8 위치로 이동한다. rbp도 갱신한다. mov rsp, rbp; pop rbp 명령과 동일하다. ret rip를 rsp가 가리키는 스택의 주소에 담긴 값으로 이동한다. pop rip 명령과 동일하다. 시스템콜 운영체제는 하드웨어 및 소프트웨어를 총괄하며, 접근 권한을 제한하여 해킹으로부터 컴퓨터를 보호하기 위해 커널 모드와 유저 모드로 권한을 분리한다. 시스템 콜은 유저모드에서 시스템에게 커널 모드에서 실행할 수 있는 동작들을 요청하는 동작이다. 유저가 시스템 콜을 호출하면 커널은 이를 실행하고, 결과를 유저에게 반환한다. 레지스터 범용 레지스터 rsp : 스택의 최상단의 주소 rip : 현재 명령 실행 주소 rdi : 함수 실행시 첫 번째 인자의 주소 / 시스템 콜 실행시 첫 번째 인자의 주소 / (destination index) 데이터 이동시 목적지를 가리키는 주소 esi : 함수 실행시 두 번째 인자의 주소 rsi : 시스템 콜 실행시 두 번째 인자의 주소 / (source index) 데이터 이동시 원본을 가리키는 주소 rbp : (Base Register Pointer)스택 복귀 주소 SFP(Stack Frame Pointer) 라고도 부르며, 함수 호출시 호출자(caller)의 SFP를 stack에 넣고, 실행된 함수가 끝날 때 이를 pop하여 함수가 호출된 코드 라인으로 복귀할 수 있다. 즉, 함수 호출 시마다 push rbp 코드를 보게 될 것이다. rax : (Extended Accumulator Register)사칙연산에서 자동으로 피연산자로 사용되는 리턴 주소 시스템 콜의 실질적인 번호를 가리킴 시스템 콜의 반환값도 rax에 저장됨 rbx : (Extended Base register)메모리 주소를 저장하는 용도로 사용 rcx : (Extended Counter Register)CPU loop counter rdx : 시스템 콜 실행 시 세 번째 인자의 주소 / (Extended Data Register) eax : (Extended AX) 논리 연산(덧셈, 뺄셈 등)의 결과값이 저장되는 위치 피연산자와 별개로 데이터가 저장된다. rax 값에서 마지막 4byte 길이만 잘려서 저장된다. ax : eax가 사용되기 이전, CPU의 word가 16bit 일 때 사용되던 레지스터 큰 의미는 없지만 관습처럼 사용되며 eax에서 하위 2byte를 자른 값을 나타낸다. ax는 다시 ah와 al로 한 byte씩 나뉜다. ah : ax에서 상위 1byte al : ax에서 하위 1byte byte_4 byte_3 byte_2 byte_1 eax_4 eax_3 eax_2 eax_1 ax_2 ax_1 ah al 10. esp : 스택 최상단의 주소값 (Stack pointer register) PUSH , POP ,SUB , CALL 명령을 수행 할 때 마다 자동으로 변경된다. ebp : 스택 프레임 최하단의 주소값 (Base pointer register) 세그먼트 레지스터 cs, ss, ds, es, fs, gs 명령어 포인터 레지스터 Instruction Pointer Register, IP 플래그 레지스터 CF(Carry Flag) : 부호 없는 수의 연산 결과가 비트의 범위를 넘을 경우 1로 세팅 ZF(Zero Flag) : 연산의 결과가 0일 경우 1로 세팅 SF(Sign Flag) : 연산의 결과가 음수일 경우 1로 세팅 OF(Overflow Flag) : 부호 있는 수의 연산 결과가 비트 범위를 넘을 경우 1로 세팅 프로시저 특정 주소의 명령어를 실행하도록 하는 코드이다. 프로시저를 사용하면 가독성이 높아지고, 반복되는 코드를 절약할 수 있다. 스택프레임 각 함수들은 실행되면서 지역변수와 임시 값들을 저장해야 하는데, 이 값들은 스택 영역에 저장된다. 하지만 특정 함수가 사용하고 있는 스택 영역을 다른 함수가 침범하여 사용하지 못하게 하기 위해 함수별로 스택 프레임을 두고 스택 영역을 공용으로 사용하지 못하게 관리한다. rbp를 스택 프레임을 만드는 어셈블리는 아래와 같다. 스택에 현재 함수의 stack base pointer를 추가한다. 이후 rbp를 rsp와 동일하게 세팅한다. rsp를 원하는 값만큼(VALUE) 뺀다. 그러면 rbp와 rsp의 차이만큼 새로운 함수의 스택프레임이 형성된다. push rbp mov rbp, rsp\rsub rsp, VALUE .asm to bin .asm 파일을 바이트 코드로 변경하려면 \u0026ldquo;nasm\u0026rdquo; 이라는 모듈을 사용하면 된다. nasm -f elf YOUR_FILE.asm 명령으로 .o 파일을 생성할 수 있다. 만약 구동중인 컴퓨터가 x86-64 구조라면 elf 대신 elf64를 입력한다. 컴퓨터 구조별 명령은 nasm -fh 로 확인이 가능하다. 생성된 .o 파일은 objdump -d YOUR_OBJ.o 명령으로 내용 확인이 가능하다. 만약 assembly 파일 안에 main 함수를 정의하였다면 gcc YOUR_OBJ.o -o YOUR_OUT.out 명령어로 실행 가능한 ELF 파일을 생성할 수도 있다. objcopy --dump-section .YOUR_SECTION=YOUR_BIN.bin YOUR_OBJ.o 명령으로 .o 파일을 .bin 파일로 변환할 수 있다. section .text 로 어셈블리 영역이 시작된다면 YOUR_SECTION=text 가된다.\nex) test.asm 파일이 아래와 같은 경우,\nsection .text ; 아래에 text 라는 section을 정의한다.\rglobal main ; main 함수를 전역으로 선언한다.\rmain: ; main 함수의 내용을 구현한다.\rpush 0x00 ; 구현부\r... nasm -f elf64 test.asm 을 수행한 후, objcopy --dump-section .text=test.bin test.o 을 수행하면 test.bin 파일을 얻어낼 수 있다.\n생성한 바이너리 파일을 xxd YOUR_BIN.bin 명령으로 내용을 출력할 수 있다. 이는 objdump -s YOUR_OBJ.o 명령의 출력 형태와 동일하다\n","permalink":"https://aswinblue.github.io/post/assembly/assembly_basic/","summary":"Assembly 기계어로 1대1 대응 가능한 언어로, human readable 한 언어 중 가장 기계어에 가까운 언어이다. 기계어로 컴파일 직전에 어셈블리어로 변환을 거친다. operation code(명령어) 와 operand(피연산자) 로 구성된다. 명령어는 데이터 이동, 산술연산, 논리연산, 비교, 분기, 스택, 프로시저, 시스템콜의 종류가 있다. 피연산자 자리에는 상수(Immediate Value), 레지스터(Register), 메모리(Memory)가 올 수 있다. 숫자를 넣으면 상수이다. [] 로 둘러싸인 숫자는 메모리이다. 메모리 피연산자 앞에는 메모리의 크기를 나타내는 크기 지정자(Size Directive)가 붙을 수 있다. WORD: 16bit DWORD: 32bit QWORD: 64bit 명령어 mov \u0026ldquo;값\u0026quot;을 레지스터리나 메모리에 저장하는 명령 mov dst, src : src 값을 dst에 덮어씀 dst = 레지스터, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 레지스터, src = 메모리 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 메모리 : 불가능 mov dst, [mem + 4] : mem + 4 주소에 저장된 값을 dst에 덮어씀 dst 값으로는 주소나 포인터가 올 수 있다.","title":"Assembly_basic"},{"content":"Delver 시작날짜: March 18, 2023\n종료날짜: March 28, 2023\n목표 python 기반 웹 scrapping 및 결과를 slack 에 전송하는 slack bot\n요구사항 AWS lambda를 사용하여 동작 매 시간마다 동작하도록 설정 Web scrapper 작성 1. 구현 내용 beautiful soup를 사용하여 특정 web을 scrap (API 참조: https://beautiful-soup-4.readthedocs.io/en/latest/) 여러 사이트에 호환되도록 구조를 설정\n사이트별 속성을 json 형태로 기록\njson 형태를 읽어 코드 변경 없이 사이트 추가할 수 있는 구조로 작성\n2. 문제와 해결 Beautiful soup를 사용하여 특정 문자 찾기 find() 혹은 find_all() 에 string 인자를 넣어서 검색을 하면 반환 값으로html tag 배열이 아니라, string 배열이 온다.\n검색 결과에서 추가적으로 find를 해야할 경우 문자열을 따로 추출하여 검색을 하도록 한다.\nitem 안에 특정 문자열(keywords)이 있는지 확인하는 구문\n위와같이 find_all() 구문에 ‘string’ 파라미터를 넣으면 detected 는 string의 배열을 갖게 된다.\nAWS 배포 1. 구현 내용 python 코드가 배포될 때, 동작에 필요한 모듈들이 설치 되도록 dependency 설정\npip freeze 명령으로 설치된 모듈들을 확인한 후, 이를 requirements.txt 에 기입한다. 이후 pip install -r requirements.txt 명령어를 사용해 주면 설정된 의존성 파일들이 모두 설치된다. DockerFile을 설정하여 AWS에 docker 형태로 배포될 수 있도록 작성\nAWS 연동\n접속 계정 생성 IAM에서 AWS API 호출 시 인증에 사용 될 access key 를 발급 받는다. IAM → 사용자 → 보안 자격증명 → 액세스키 → 액세스 키 만들기 경로로 생성이 가능하다. 2) ECR 생성\r- [Amazon ECR](https://us-east-2.console.aws.amazon.com/ecr/get-started?region=us-east-2) → **리포지토리** 에 접속하여 ‘리포지토리 생성’ 버튼을 클릭한다.\r- 프라이빗 설정으로, 이름을 지정한다.\r- 태그는 리포지토리 마지막에 붙는 버전을 나타내는 postfix이다. 태그 변경 옵션은, 같은 이름의 태그를 덮어쓸 수 있는지 설정하는 항목이다.\r리포지터리 생성 화면\n3) Lambda 함수 생성\r- [Lambda](https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/) 에 접속하여 ‘함수생성’ 버튼을 클릭해 함수를 생성한다.\r- 생성된 ECR 을 실행하는 람다 함수를 생성한다. ‘컨테이너 이미지’ 를 동작시키도록 설정하여 생성하면 된다.\nGithub action을 작성하여 자동화 예시: https://github.com/AswinBlue/SlackBot/blob/master/.github/workflows/uploadECR.yml\n앞서 생성한 AWS 계정, ECR, lambda함수 정보가 모두 포함된다.\nAPI KEY 혹은 AWS 계정 정보와 같이 외부에 공개되면 안되는 정보들은 github 의 action secret 기능을 통해 코드와 분리된 채로 배포 시 추가될 수 있도록 한다. (참조: https://ji5485.github.io/post/2021-06-26/create-env-with-github-actions-secrets/)\n다른 사용자에게 공개되지 않는 비밀 변수를 생성할 수 있다.\nLambda 함수가 매일 실행되도록 AWS Cloud Watch (EventBridge) 세팅 설정 참조: https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html 시각 표시 규칙\n- 한국 시간 기준 매일 12시에 동작하도록 설정. 띄워 쓰기 기준으로, `cron(분 시 일 월 요일 해)` 를 뜻한다.\rEventBridge 설정 내용\nLambda 함수 설정 python code가 정상적으로 종료되었다는 것을 판단하는 조건 설정필요 lambda 함수는 실패한 경우 재시도를 수행하는데, 재시도 횟수를 설정할 수 있다. ( Lambda 함수 재시도 참조 : https://repost.aws/knowledge-center/lambda-function-retry-timeout-sdk) ![Untitled](%5BDelver%5D%F0%9F%94%A8%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%209862ea481974495d9bfa8b6b197b1ba8/Untitled%208.png)\r3) lambda 함수가 비동기로 실행되는 경우, 실행 완료까지 timeout을 설정할 수 있다. 너무 짧게 잡으면 실행이 완료되지 않아 정상 동작을 해도 실패로 처리될 수 있다.\r2. 문제와 해결 AWS lambda 를 통해 함수를 구동하려면, aws에서 제공하는 기본 python 환경의 모듈들만 사용 가능하다. 나는 slack과 beautifulsoup를 추가로 사용하고 있으므로, 별개의 이미지를 생성해야 한다. ECR(Elastic Container Registry) 를 생성하고 lambda 함수가 그 환경에서 동작하도록 한다. docker를 통해 ECR이 빌드될 수 있도록 DockerFile 및 requirements.txt을 세팅한다. AWS ECR 배포시 EOF 에러가 발생하였다. TRY 1: uses: docker/build-push-action@v2 를 사용하는 대신 run 을 이용하여 직접 docker 명령을 입력하였다. docker build 명령 시 docker build [123456789.dkr.ecr.us-east-1.amazonaws.com/](http://435370146413.dkr.ecr.us-east-2.amazonaws.com/)repo:latest . 와 같이 full repository name을 입력하여야 해당 이름으로 tag가 설정된다. (아니면, 빌드 후 docker tag 명령으로 직접 태그를 설정할 수도 있다.) TRY 2:\nIAM에서 사용자 권한을 변경하였다. AmazonEC2ContainerRegistryReadOnly 권한에 AmazonEC2ContainerRegistryPowerUser 를 추가로 부여하였다. AWS Lambda 함수 설정에도 403 에러가 발생하였다. 아래 권한을 추가로 부여하여 github action에서 uses: appleboy/lambda-action@master 을 호출하여 lambda 함수 설정이 가능하도록 하였다. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowLambdaFunctionUpload\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:GetFunctionConfiguration\u0026#34;, \u0026#34;lambda:UpdateFunctionCode\u0026#34;, \u0026#34;lambda:UpdateFunctionConfiguration\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:lambda:us-east-2:435370146413:function:Delver_webScrap\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowLambdaExecutionRole\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:GetFunctionConfiguration\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:ListFunctions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } 참조 Github 와 aws의 pipeline 을 통해 push시 자동으로 aws배포되도록 하는 방법도 있었으나, github action을 이용했다. AWS 설정 참조(https://docs.aws.amazon.com/codepipeline/latest/userguide/connections-github.html) Docker를 활용하여 ECR 생성 참조(https://www.youtube.com/watch?v=6O-7zb-igUs) ","permalink":"https://aswinblue.github.io/post/projects/delver/delver/","summary":"Delver 시작날짜: March 18, 2023\n종료날짜: March 28, 2023\n목표 python 기반 웹 scrapping 및 결과를 slack 에 전송하는 slack bot\n요구사항 AWS lambda를 사용하여 동작 매 시간마다 동작하도록 설정 Web scrapper 작성 1. 구현 내용 beautiful soup를 사용하여 특정 web을 scrap (API 참조: https://beautiful-soup-4.readthedocs.io/en/latest/) 여러 사이트에 호환되도록 구조를 설정\n사이트별 속성을 json 형태로 기록\njson 형태를 읽어 코드 변경 없이 사이트 추가할 수 있는 구조로 작성\n2. 문제와 해결 Beautiful soup를 사용하여 특정 문자 찾기 find() 혹은 find_all() 에 string 인자를 넣어서 검색을 하면 반환 값으로html tag 배열이 아니라, string 배열이 온다.","title":"Delver"},{"content":"Flick Through github: https://github.com/AswinBlue/FlickThrough\nLink : aswinblue.github.io/FlickThrough/\n시작날짜: August 21, 2023\n목표 텍스트 파일을 읽어 단어 단위로 슬라이드 쇼를 수행하는 앱 제작\n요구사항 텍스트 파일의 공백과 줄바꿈을 기준으로 단어를 나누고 이를 화면에 출력 출력은 한 단어씩 이루어 지며 분당 300개를 기본으로, 속도는 조절 가능 단어 자르는건 커스텀 가능 특정 문자마다 딜레이 다르게 줄 수 있도록 설정 스크린샷 혹은 클립보드의 내용도 사용할 수 있도록 함 기능 구현 1. 구현 내용 UI 구성 텍스트가 출력될 텍스트박스, 진행률 표시바, 시작/일시정지 버튼, 속도 조절 스크롤바, 파일 읽기 버튼을 구성\n파일 로드 기능\n파일 로드 버튼을 클릭해서 읽을 텍스트 파일 로드 파일을 단어 단위로 나누어 List 형태로 저장 재생 기능\n재생 버튼을 눌러 재생/일시정지 상태 변경 List형태로 저장된 단어들을 일정 시간 delay를 두고 화면에 순서대로 출력 진행률조절\n진행률 표시바를 클릭 혹은 드래그 하여 진행 위치를 조절 재생속도 조절\n재생 속도 설정 스크롤 바를 드래그 혹은 클릭하여 단어가 표시될 시간을 조절 클립보드 사용\n클립 보드를 사용할 수 있도록 Text Box 추가, dialog안의 text box에 내용을 채워넣으면 해당 내용으로 flick through 실행\nPaste from clip board 버튼을 추가\n버튼을 누르면 dialog 창이 발생하고, 여기서 confirm 을 누르면 해당 텍스트로 슬라이드 플레이 가능\n다개국어 기능\nintl, flutter_localizations 모듈을 사용하기 위해 pubsec.yml 파일에 필요한 모듈 및 속성들을 추가한다.\ndependencies: flutter: sdk: flutter intl: ^0.18.0 flutter_localizations: sdk: flutter ... dev_dependencies: build_runner: ^2.4.6 intl_translation: ^0.18.2 flutter: generate: true # 자동생성 활성화 StatelessWidget 에 flutter_localization 모듈 설정을 해주고, 필요한 모듈을 import 한다.\nimport \u0026#39;package:flutter_localizations/flutter_localizations.dart\u0026#39;; import \u0026#39;package:intl/intl.dart\u0026#39;; import \u0026#39;package:flutter_gen/gen_l10n/app_localizations.dart\u0026#39;; void main() { runApp(MyApp()); } class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( title: \u0026#39;Multi-Language App\u0026#39;, localizationsDelegates: const [ GlobalMaterialLocalizations.delegate, GlobalWidgetsLocalizations.delegate, GlobalCupertinoLocalizations.delegate, AppLocalizations.delegate, // 명령어로 생성할 AppLocations class도 delegate ], supportedLocales: AppLocalizations.supportedLocales, // AppLocalizations 생성시 자동으로 세팅되어 있음 home: MyHomePage(), ); } } l10n.yaml 파일을 프로젝트 root 에 아래와 같이 작성한다.\narb-dir: arb파일이 들어있는 경로(project root로부터 상대경로)\ntemplate-arb-file: 사용 언어를 찾지 못했을 때 사용할 언어 파일\noutput-localization-file: arb 파일로 생성할 dart 파일. AppLocalizations class가 정의되어있음\narb-dir: lib/l10n template-arb-file: app_en.arb output-localization-file: app_localizations.dart arb 파일을 lib/l10n 경로에 생성하여 json 형식으로 key-value 세트로 다국어로 번역할 단어를 적는다. 아래는 영어로 번역할 내용의 예시이다. arb 파일의 key는 함수 이름으로 치환되기 때문에 알파벳 소문자로 시작해야 하며, 알파벳이 아닌 다른 문자를 포함하면 안된다. (camel case 사용)\n{ \u0026#34;@@locale\u0026#34;: \u0026#34;en\u0026#34;, \u0026#34;pasteFromClipBoard\u0026#34;: \u0026#34;Paste from clip board\u0026#34;, \u0026#34;textFileReader\u0026#34;: \u0026#34;Text File Reader\u0026#34;, } main.dart에서 다국어를 지원할 text 를 아래와 같이 치환한다. (context 객체가 있어야 함에 주의)\nAppLocalizations.of(context)!.pasteFromClipBoard # 영어 사용권에서 \u0026#34;Paste from clip board\u0026#34; 로 치환됨 flutter pub get 명령을 실행(안드로이드 스튜디오에서는 get dependencies 버튼으로 수행 가능)하여 pubsec.yml 파일을 갱신하면 l10n.yaml 파일에 따라 자동으로 아래와 같은 dart 파일이 생성된다.\nimport \u0026#39;package:intl/intl.dart\u0026#39;; class AppLocalizations { static String of(BuildContext context, String key) { return Intl.message(key, locale: Localizations.localeOf(context).toLanguageTag()); } } → 이 방법은 공식 다국어 지원 방식이지만, 언어 변환에 context 객체가 필요하다는 점이 단점이다.\n2. 문제와 해결 logic에 적용된 delay가 UI에도 적용되어 delay 시간동안 UI가 응답하지 않음\nawait를 사용하여 UI와 병렬로 동작하도록 구현 LinearProgressIndicator 형태는 터치를 지원하지 않음 → GestureDetector 로 캡슐화 하여 터치를 직접 설정할 수 있음\nGestureDetector로 스크롤시, 화면 밖을 벗어나는 영역까지 드래그를 해도 위치가 인식이 된다. 이 때문에 진행률이 음수가 되거나, 100%를 초과하는 경우가 발생하여 logic상으로 border를 처리해 주어야 한다.\nWebBrowser 와 AndroidApp는 파일을 로드하는 방법이 다르다.\n→ web에서 동작하는지, app에서 동작하는지 런타임에 확인할 수 있는 구분자를 사용하여 각각 다른 방법으로 동작하게 분기처리 한다.\nloadTextFile은 _MyHomePageState class의 멤버 함수이다.\ndart:html 은 모바일 기기 빌드 환경에서는 import 할 수 없는 모듈이다. → 조건부 import 구문을 사용하여 특정 조건에서만 해당 라인이 동작하도록 한다. (참조 : https://letyarch.blogspot.com/2021/11/dart-conditional-importexport.html)\nplatform에 따라 web.dart와 app.dart로 파일을 분리한다. ![Untitled](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%208.png)\r2) abstract class를 형성하고, 각 platform dependent 한 로직들은 abstract class 를 상속받아서 web.dart와 app.dart에 작성한다. ![abstract 함수를 선언하고, 조건부 import를 통해 컴파일타임 분기](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%209.png)\rabstract 함수를 선언하고, 조건부 import를 통해 컴파일타임 분기\r![상속받아 만든 함수 (for app)](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2010.png)\r상속받아 만든 함수 (for app)\r3) conditional import 를 활용하여 컴파일 타임에 파일을 분리해서 import하도록 세팅\r→ `import ‘app.dart’ if (dart.library.html) ‘web.dart';`\r- conditional import 관련 문서 : [https://dart.dev/guides/libraries/create-packages#conditionally-importing-and-exporting-library-files](https://dart.dev/guides/libraries/create-packages#conditionally-importing-and-exporting-library-files)\r- 구현 예시 : https://github.com/Zeruel92/cross_picker\r- factory 생성자 관련 설명 : [https://juwon-yun.tistory.com/81](https://juwon-yun.tistory.com/81)\r- conditional import와 factory 패턴 적용 : [https://medium.com/flutter-community/conditional-imports-across-flutter-and-web-4b88885a886e](https://medium.com/flutter-community/conditional-imports-across-flutter-and-web-4b88885a886e)\r- conditional import 사용한 예시 : https://github.com/dart-lang/sdk/issues/48320\r→ 결론, 1. conditional import를 사용해야하는 것은 맞음. 2. factory pattern을 사용하여, getFileLoader() 호출시 특정 객체가 호출되도록 함. (함수는 전역으로 선언해야 함)\r![conditional import/export를 통해 필요한 파일만 플랫폼에 맞게 컴파일타임에 선택 ](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2011.png)\rconditional import/export를 통해 필요한 파일만 플랫폼에 맞게 컴파일타임에 선택 1. 파일을 나누어 각 플랫폼별로 class를 따로 정의, interface를 상속받도록 하고, 각 파일에서 getFileLoader 을 선언한다. (conditional import를 사용하기 때문에 getFileLoader은 중복 선언되지 않고 컴파일타임에 하나만 선택된다. 2. base class를 상속하고, 플랫폼별로 동작이 달라지는 function을 override(재정의) 해서 각 플랫폼마다 다르게 동작하도록 하면 된다. ![Untitled](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2012.png)\r![Untitled](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2013.png)\r3. main에서 getFlieLoader() 로 객체를 호출하면 플랫폼에 맞는 알맞은 객체가 생성된다.\r![Untitled](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2014.png)\r실패1. main에서 호출한 AbstractFileLoader는 loadFile이 미구현된 상태. 미구현 에러 발생\r![cross_platform.dart 파일, base class를 선언](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2015.png)\rcross_platform.dart 파일, base class를 선언\r![app.dart 파일, base class를 상속받고 loadFile 함수 재정의](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2016.png)\rapp.dart 파일, base class를 상속받고 loadFile 함수 재정의\r![main.dart에서 base class 생성](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2017.png)\rmain.dart에서 base class 생성\r![base class에서 구현된 function 호출](%5BBoosted%20Reader%5D%F0%9F%94%A8%20App%20%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF%2011b84e8a72a24cb099094412c4ddd72b/Untitled%2018.png)\rbase class에서 구현된 function 호출\r안드로이드 read external memory 권한 Platform exception: PlatformException(read_external_storage_denied, User did not allow reading external storage, null, null) 와 같은 에러 발생\nandroid/app/src/main/AndroidManifest.xml 파일에 \u0026lt;uses-permission android:name=\u0026quot;android.permission.READ_EXTERNAL_STORAGE\u0026quot; /\u0026gt; 구문이 선언되어있는지 확인. 해당 태그는 manifest 직속, application 선언전에 호출되어야 한다.\nflutter에 권한 관리 모듈을 추가해야 한다. pubsec.yaml 파일에 permission_handler dependency를 추가한다. 이후 permission 이 필요한 동작을 호출하는 함수가 있는 파일에 permission_handler 모듈을 추가한다. import 'package:permission_handler/permission_handler.dart'; 모듈을 이용하여 권한을 체크하는 함수를 생성하고, 저장소 접근 전 권한을 먼저 체크한다. 권한이 없다면 자동으로 팝업을 띄워 권한을 요청하도록 되어있다.\n이후 await 를 통해 결과를 받아서 결과에 따른 처리를 수행하도록 한다.\n다개국어 지원시 AppLocations.of(context) 에서 null을 반환하여 랜더링 실패\nText(AppLocalizations.*of*(context)!.pasteFromClipBoard),) 형태를 widget에 넣을 때, 해당 값이 null로 치환되면 랜더링 오류가 발생한다.\n설정을 제대로 했는지 확인한다. 내 경우에는 아래 라인을 넣지 않아서 오류가 발생했다.\n설정도 제대로 했다면, l10n.yaml에서 언어를 감지하지 못했을 때 동작할 default language를 설정 해 준다.\n이 또한 먹히지 않는다면 MaterialApp 생성시 localeListResolutionCallback 항목을 아래와 같이 파라미터로 추가해 준다. 언어를 감지하지 못했을 시 default language 팩을 en 으로 설정하는 내용이다.\nlocaleListResolutionCallback: (locales, supportedLocales) { print(\u0026#39;device locales=$locales supported locales=$supportedLocales\u0026#39;); for (Locale locale in locales!) { // if device language is supported by the app, // just return it to set it as current app language if (supportedLocales.contains(locale)) { return locale; } } // if language of current location is not supported, use english return Locale(\u0026#39;en\u0026#39;); }, 다개국어 테스트\n구현은 성공적으로 마쳤지만, 한국에서 테스트를 하면 ‘ko’ 밖에 확인할 수 없다. 3. 참조 intl 패키지 intl 패키지는 다국어 설정을 할 때 많이 사용되며, ‘arb’ 확장자의 파일을 dart 파일 형태로, 혹은 그 반대로 변환할 수 있는 패키지이다.\nex) arb 파일을 dart 파일로 변환 flutter pub pub run intl_translation:generate_from_arb \\ --output-dir=lib/localizations \\ lib/localizations/app_localizations.dart \\ lib/localizations/app_localizations_en.arb \\ lib/localizations/app_localizations_es.arb ex) dart 파일을 arb 파일로 변환 flutter pub run intl_translation:extract_to_arb --output-dir=lib/i18n lib/i18n/messages.dart 혹은 i18n.yaml 이름으로 yaml 파일을 생성하여 root 폴더에 넣어두면 pub get package 명령어 실행, 혹은 IDE의 pubsec.yaml 파일 업데이트시 각 yaml 파일의 설정에 따라 arb 파일로 dart 파일을 생성할 수 있다. 파일의 내용은 다음과 같다.\narb-dir: lib/l10n template-arb-file: app_en.arb output-localization-file: app_localizations.dart arb-dir: arb파일이 존재하는 디렉터리 경로 template-arb-file: 사용할 arb 파일 output-localization-file: arb파일을 변환하여 생성할 dart 파일의 이름, 파일은 .darttool/fluttergen/genl10n/ 경로에 생성되며 import 'package:flutter_gen/gen_l10n/app_localizations.dart' 형태로 import 가능하다.\nl10n은 localization이라는 뜻이며, 이외에도 아래와 같은 축약어가 사용된다.\nl10n.yaml (localization) i18n (internationalization) g11n (globalization) m17n (multilingalization)\n다국어 설정 방법 1 (intl, l10n.yaml을 사용한 공식 방식) : https://fronquarry.tistory.com/8\n다국어 설정 방법 2 (intl과 command를 통한 방식) : https://fronquarry.tistory.com/8\n두 방식을 비교한 내용 : https://jay-flow.medium.com/flutter-localizations-완전-정복-하기-8fa5f50a3fd2\n배포 1. 구현 내용 github에 web 페이지 배포 root 경로에 .github/workflows/web.yml 파일을 만든다. name: github-page-work # 작업 이름 on: push: branches: [master] # master 브랜치의 코드 사용해서 동작 # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: token: ${{ secrets.GIT_TOKEN }} - uses: subosito/flutter-action@v1 - uses: bluefireteam/flutter-gh-pages@v7 with: baseHref: /FlickThrough/ https://github.com/settings/tokens 에 접속하여 ‘generate new token’을 선택하여 신규 token을 생성한다.\n배포만이 목적이라면 아래와 같이 권한을 설정 해 주면 충분하다. 토큰이 생성되면 페이지를 닫지 말라. 현재 페이지를 벗어나면 다시 토큰을 볼 수 없다. 그 상태에서 바로 코드가 들어있는 github repository의 setting 으로 진입한다. (https://github.com/AswinBlue/FlickThrough/settings)\nrepository 설정에서 “Secrets and variables” 메뉴에 진입하고, ‘Secrets’ 탭을 선택한 후 ‘New Repository Secret’ 버튼을 눌러서 GIT_TOKEN 을 key로, 이전 단계에서 받은 token을 value로 설정하여 secret variable을 하나 생성한다. (생성한 secret variable도 다시 확인할 수 없으므로 주의한다. 또한 GITHUB_ 로 시작하는 key의 secret varaible은 생성할 수 없다) (https://github.com/AswinBlue/FlickThrough/settings/secrets/actions)\n내용을 작성하고 github에 푸쉬하면 github 의 action 탭에서 action의 실행 결과를 확인할 수 있다. (https://github.com/AswinBlue/FlickThrough/actions/new)\naction이 정상적으로 완료되었다면, setting/page 항목에서 브랜치 ‘gh-pages’로 설정 해 준다. (자동으로 되는 경우도 있음) (https://github.com/AswinBlue/FlickThrough/settings/pages)\n2. 아이콘 변경 https://www.appicon.co/ 에 이미지 파일을 넣으면 android 아이콘 형태로 이미지를 변환하여 추출 해 준다.\n추출된 아이콘을 \\android\\app\\src\\main\\res 경로에 복사 붙여넣으면 된다.\nIOS는 ios/Runner/Assets.xcassets 폴더 안에 AppIcon.appiconset 폴더를 교체 해 준다.\n3. Android 앱 배포 구글 플레이스토어 개발자 계정 생성 개발자 계정이 없다면, https://play.google.com/console 에 접속하여 안내에 따라 계정을 생성한다. 생성에는 $25의 비용이 부과되므로 달러 결제가 가능한 카드를 준비한다. 안드로이드 앱 배포시 자신이 앱의 개발자가 맞다는 것을 증명하고 앱을 업데이트 하기 위해서는 앱에 설정된 key와 동일한 key를 알고 있어야 한다. 이를 key store 시스템이라 하며, 배포전 반드시 설정을 해야 한다. jdk에서 제공하는 keytool 명령어를 사용해야 한다. jdk를 설치하면 C:\\Program Files\\Java\\jdk-21\\bin 경로에 keytool 실행파일이 있다.\nkeytool -genkey -v -keystore C:/Users/USER_NAME/key.jks -keyalg RSA -keysize 2048 -validity 10000 -alias key명령으로 key를 생성한다. key 생성시 비밀번호를 입력 해 주고, 묻는 질문에 필요하다면 대답해 준다.\n생성된 key.jks 파일을 android/app/ 경로로 이동시키고, key.properties 파일을 생성한 후, 아래와 같이 내용을 채워 넣는다.\nstorePassword=\u0026lt;키생성시 입력한 암호\u0026gt; keyPassword=\u0026lt;키생성시 입력한 암호\u0026gt; keyAlias=key storeFile=./key.jks .gitignore 파일로 key.jks와 key.properties 파일이 유출되지 않게 잘 조정한다.\napp/build.gradle 파일에 keystore 을 사용하기 위한 내용을 추가한다.\ndef keystoreProperties = new Properties() def keystorePropertiesFile = rootProject.file(\u0026#39;app/key.properties\u0026#39;) if (keystorePropertiesFile.exists()) { keystoreProperties.load(new FileInputStream(keystorePropertiesFile)) } ... android { ... signingConfigs { release { keyAlias keystoreProperties[\u0026#39;keyAlias\u0026#39;] keyPassword keystoreProperties[\u0026#39;keyPassword\u0026#39;] storeFile file(keystoreProperties[\u0026#39;storeFile\u0026#39;]) storePassword keystoreProperties[\u0026#39;storePassword\u0026#39;] } } buildTypes { release { signingConfig signingConfigs.release } } gradle 파일 수정 후에는 gradle을 프로젝트에 sync 해 주어야 한다. gradle sync라는 항목이 ‘file’ 밑에 있는 경우도, ‘tool → android’ 밑에 있는 경우도 있는데 둘다 보이지 않는다면 build.gradle 파일을 우클릭 한 후 ‘Link gradle project’ 를 눌러준다.\n마지막으로 build를 release 버전으로 수행해야 한다. 좌측 하단에 Build Variants 창을 찾아(혹은 build → Select build variant 선택) 설정을 release로 변경한다.\n이후 콘솔창에 flutter build appbundle 명령어를 입력하여 app bundle을 빌드한다. 빌드한 결과는 /build/app/outputs/bundle/release 경로에 생성된다.\n파일명은 app-release.aab 로 생성되어 있다. playstore console에 배포할때도 aab 파일을 업로드 한다.\n업로드한 파일의 manifest에 적힌 버전과 동일한 버전은 중복 업로드를 할 수 없으므로, 이후 업로드 시에는 높은 버전을 업로드 해야 하며, 기존 버전을 삭제하고 싶다면 playstore console에서 ‘app bundle 탐색기’ 메뉴를 찾아 삭제가 가능하다.\n2. 문제와 해결 fatal: unable to access '[https://github.com/AswinBlue/FlickThrough/](https://github.com/AswinBlue/FlickThrough/)': The requested URL returned error: 403 에러 “erickzanardo/flutter-gh-pages@v3” 과 “bluefireteam/flutter-gh-pages@v7” 을 사용해도 모두 동일한 에러가 발생했다. 해당 url에 접근 권한이 없는 경우 발생한다. gitbash를 이용하여 url을 계정 이름이 포함된 형태로 변경해 준다. git remote set-url origin https://AswinBlue@github.com/AswinBlue/FlickThrough.git checkout job 실행시 token 사용하도록 적용 해 주면 이후 명령들도 권한이 적용 되는듯 하다. ","permalink":"https://aswinblue.github.io/post/projects/flickthrough/flickthrough/","summary":"Flick Through github: https://github.com/AswinBlue/FlickThrough\nLink : aswinblue.github.io/FlickThrough/\n시작날짜: August 21, 2023\n목표 텍스트 파일을 읽어 단어 단위로 슬라이드 쇼를 수행하는 앱 제작\n요구사항 텍스트 파일의 공백과 줄바꿈을 기준으로 단어를 나누고 이를 화면에 출력 출력은 한 단어씩 이루어 지며 분당 300개를 기본으로, 속도는 조절 가능 단어 자르는건 커스텀 가능 특정 문자마다 딜레이 다르게 줄 수 있도록 설정 스크린샷 혹은 클립보드의 내용도 사용할 수 있도록 함 기능 구현 1. 구현 내용 UI 구성 텍스트가 출력될 텍스트박스, 진행률 표시바, 시작/일시정지 버튼, 속도 조절 스크롤바, 파일 읽기 버튼을 구성","title":"FlickThrough"},{"content":"IPC (Inter Process Communicatrion) Signal Signal은 프로세스간 동기화를 위해 프로세스간 전송하는 신호를 의미한다. Software Interrupt 라고도 한다. 커널에서 kill -\u0026lt;SIGNAL_NUMBER\u0026gt; \u0026lt;PROCESS_ID\u0026gt; 명령으로 특정 PROCESS_ID에 ISGNAL_NUMBER에 해당하는 signal을 전달할 수 있다. signal은 총 64까지 정의되어 있고 1~31까지가 일반적으로 사용하는 signal이다. 34~63은 고성능 네트워크 통신을 위한 시그널이다. (32, 33는 미정의) kill -l 명령으로 signal 리스트를 확인할 수 있다. SIGHUP SIGINT : 인터럽트, Ctrl+C 명령으로 전송 가능 SIGQUIT Coredump시 발생 SIGILL : Illegal instruction SIGTRAP : debugger is tracing SIGABRT : Abort process SIGBUS : bus error SIGFPE : Floating point exception SIGKILL : 강제 종료 SIGUSR1\t: User-defined signal 1, 마음대로 사용 가능 SIGSEGV\t: invalid virtual memory reference SIGUSR2 : User-defined signal 2, 마음대로 사용 가능 SIGPIPE\t: 반대편이 연결되지 않은 pip에 신호 전송시 발생하는 에러 SIGALRM : alarm() 함수에 의해 발생한 시그널 1 SIGTERM : 종료 요청, SIGKILL(9)보다 안전한 종료 방법, SIGINT와 유사한 성능 SIGSTKFLT : Stack fault SIGCHLD : 자식 process가 종료될 때 부모에게 전달하는 신호 SIGCONT : SIGSTOP 에 의해 정지된 경우, 다시 시작하라는 신호 SIGSTOP : process 정지 SIGTSTP : process 일시정지, Ctrl+Z 명령으로 전송 가능 SIGTTIN\t: background 에 있을 때 read 요청을 받은 경우 발생 SIGTTOU : background 에 있을 때 write 요청을 받은 경우 발생 SIGURG : 긴급 통신을 받은 경우 (Out Of Band) SIGXCPU : 설정된 CPU 사용량을 초과하여 프로세스가 동작 한 경우 SIGXFSZ : 파일 크기가 허용된 크기를 초과한 경우 SIGVTALRM : 프로세스 실행시간 관리를 위한 시그널1 SIGPROF : 프로세스 실행시간 관리를 위한 시그널2 SIGWINCH : Window change SIGIO, SIGPOLL : Input/output is now possible SIGPWR, SIGLOST : Power failure SIGUNUSED, SIGSYS : Unused signal. Signal Library in C signal.h 에 정의된 signal 함수로 signal을 무시(ignore)하거나, 시그널 발생시 특정 함수를 동작(catch)시키도록 설정할 수 있다. 처리되지 않은 (ignore 또는 catch 처리) signal을 받으면 기본적으로 해당 프로세스는 종료한다. SIGKILL(강제종료 용도)과 SIGSTOP(디버깅시 일시정지 용도)시그널을 제외한 모든 시그널을 무시할 수 있다. signal(SIGNAL, PID) pid \u0026gt; 0 : PID에 SIGNAL 전달 pid \u0026lt; 0 : PID의 절댓값에 해당하는 groupId를 가진 프로세스들에 SIGNAL 전달 pid == 0 : 자신과 같은 groupId를 가진 프로세스들에 SIGNAL 전달 alarm(TIME) : TIME초 이후 SIGALRM 시그널 발생 alarm timer가 만기되기 전 새로운 alarm을 호출하면 값을 덮어쓴다. 대신 alarm 함수는 남은 시간을 반환 한다. alarm(0) 을 호출하면 알림이 취소된다. 시그널 처리 flag는 bit연산으로 관리된다. sigset_t 타입의 bit 하나하나들은 1~64까지의 signal을 의미하고, 아래와 같이 set을 연산하여 process에서 signal을 설정할 수 있다. sigemptyset(siget_t* SET) : SET 모든 비트를 0으로 세팅. sigfillset(int SIGNAL, sigset_t* SET) : | 연산으로 SET 에서 SIGNAL에 해당하는 비트만 1로 세팅 sigdelset(int SIGNAL, sigset_t* SET) : \u0026amp; 연산으로 SIGNAL에 해당하는 비트만 0으로 세팅 sigismember(int SIGNAL, sigset_t* SET) : SET에서 SIGNAL비트가 1로 세팅되었다면 true 반환 sigprocmask(int HOW, siget_t* NEW, sigset_t* OLD) : 특정 SIGNAL을 무시하도록 설정할 수 있다. 필요할 경우 OLD에 siget_t* 타입 변수를 집어넣으면 현재 프로세스에 설정된 set을 담아낸다. SIG_BLOCK : NEW에 set된 signal들을 추가로 무시한다. SIG_UNBLOCK : NEW에 set 된 signal들의 무시처리를 해제한다. SIG_SETMASK : 기존 값에 상관없이 NEW에 set 된 signal들만 무시하도록 set을 덮어쓴다. signal 을 처리하여 signal에 의해 process가 정지되지 않는 구간을 임계영역 이라 한다. Pipe 프로세스간 단방향 통신을 위해 프로세스들의 표준 입출력을 서로 교차하여 연결하는 기법이다. 프로세스간 데이터 전송시 주로 사용된다. flow control이 기본적으로 제공된다. Pipe Library in C pipe(int[2] fd) : 파일 디스크립터 두개를 생성하고, 단방향 통신을 생성함\nfile descriptor를 두 개 열고, fd[0] fd[1]에 그 번호를 넣어준다. write(fd[1], ...), read(fd[0], ...) 으로 사용 fd[0]은 writing을, fd[1]은 reading을 위한 descriptor이다. 파이프 사용을 마치면 fd[0]과 fd[1]에 대해 각각 close를 해 주어야 한다. close(fd[0]), close(fd[1]) 로 사용 pipe를 생성하고 fork를 호출하면 자식 프로세스는 부모 프로세스의 file descriptor를 모두 가져가기 때문에, 부모와 자식간 pipe를 통해 데이터를 전송할 수 있게 된다. (물론 단방향이다. 양방향을 원한다면 pipe를 두번 생성한다)\n쉘에서 명령을 입력할 때 |로 두 명령을 연결시키면, 앞선 명령의 표준 출력 값이 뒷쪽 명령의 input으로 들어간다.\nex) cat file.txt | grep target : file.txt 파일을 출력한 결과에서(cat) target 이라는 문자열을 찾는다(grep). \u0026lsquo;|\u0026rsquo; 명령도 pipe로 fd[0], [1]을 생성하고, dup()를 이용해 fd[0]과 fd[1]을 표준 입력/출력 자리로 복사시키는 기법으로 구현한 것이다. int fd[2], pid;\rpipe(fd);\rpid = fork();\rif (pid == 0)\r{\rclose(fd[1]); // 입력용 파이프 제거\rdup2(fd[0], 0); // 출력 파이프를 표준 입력으로 재배치\r... // 이후 parent process 동작 수행\r}\rclose(fd[0]); // 출력용 파이프 제거\rdup2(fd[1], 1); // 입력 파이프를 표준 출력으로 재배치\r... // 이후 child process 동작 수행 Message Queue IPC namespace 이 외에도 공유메모리, 세마포어, 소켓, FIFO 등으로 프로세스간 통신이 가능하다.\n그중 message queue, shared memory, semaphore은 IPC 통신을 위한 framework이다.\n파이프나 FIFO가 file descriptor을 사용해 통신했던 것과 달리, Key_t 타입의 identifier 라는 IPC를 위한 구분자로 채널(통신을 위한 라인)을 구분한다. 동일한 구조체를 통해 커널이 관리하며, 인터페이스도 유사하다. 권한은 아래와 같은 형태로 관리되며, 실행 권한이 없는 것만 제외하고 파일시스템과 유사하다. struct ipc_perm {\rushort uid;\rushort gid;\rushort cuid;\rushort cgid;\rushort mod;\rushort seq;\rkey_t key;\r} 커널에서 ipcs 명령어로 IPC 구성에 대한 정보를 확인할 수 있다.\nmessage queue는 msqid_ds 구조체에 정보를 담아 관리하고, message들은 struct msgbuf 구조의 linked list 형태로 msqid_ds 구조체에 연결된다. 각 message들은 data, length, type을 가지고 있고, type은 사용자가 원하는 대로 설정 가능한 값이다. struct msgqid_ds {\rstruct ipc_perm msg_perm; // 권한\rstruct msg *msg_first; // msg linked list 시작점\rstruct msg *msg_last; // msg linked list 종료점\rtime_t msg_stime; // 마지막 send가 실행된 시각\rtime_t msg_rtime; // 마지막 receive가 실행된 시각\rtime_t msg_ctime; // 마지막 change가 실행된 시각\rshort msg_lspid; // 마지막 send를 한 pid\rushort msg_lrpid; // 마지막 receive를 한 pid\rushort msg_qbytes; // message queue의 최대 사이즈\rushort_msg_cbytes; // message queue에서 사용중인 바이트\r}\rstruct msgbuf {\rlong mtype; // message의 타입(자료형이 아니라, 어플리케이션 로직상 구분자), 필수\rchar mtext[]; // data, 필수\r// 이외 사용자가 재정의하여 추가적인 데이터를 넣어 헤더를 추가할 수 있다.\r} Message Queue in C Library int msgget(key_t key, int msgflg) : message queue를 생성 혹은 불러오는 함수 key는 int 값을 넣어주면 된다. 함수 성공시 message queue의 qid를 반환하고, 실패시 -1을 반환한다. flag에 IPC_CREAT 가 설정되면 신규로 생성된다. 생성시 권한도 설정 가능하다. ex: IPC_CREAT | 0777 int messagectl(int msqid, int cmd, struct msqid_ds *buf) : message queue의 상태값을 조회 또는 수정한다. cmd 가 IPC_STAT 라면 buf에 현재 상태를 받아오고, IPC_SET 라면 buf의 값으로 message queue 상태를 설정한다. int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg) : message queue에 msgp 데이터를 넣는 함수 msgp는 위에서 언급한 msgbuf 형태를 따라야 한다. msgsz는 msgp안의 mtext 버퍼 크기를 의미한다. (msgp 전체 구조체 크기가 아님) msgflg는 blocking 여부(IPC_NOWAIT), size 에러 여부(MSG_NOERROR) 등을 설정 가능하다. ssize_t msgrcv(int msgqid, void *msgp, size_t msgsz, long msgtyp, int msgflg) : message queue에서 msgtype에 해당하는 데이터를 msgp에 받아옴 반환값은 읽어온 사이즈 type은 지정하지 않을 경우, queue의 head에 있는 message를 가져옴. type \u0026gt; 0 일 경우, 동일한 타입의 첫번째 메시지를 가져옴 type \u0026lt; 0 일 경우, type의 절댓값과 작거나 같은 타입의 첫번째 메시지를 가져옴 flag는 msgsnd 함수와 유사 Semaphore 다중 리소스에 대해 critical section을 처리하는 방법(mutex는 하나의 리소스를 보호에 사용) struct semid_ds 구조체 형태로 관리되며, 보호할 리소스의 정보를 struct sem *sem_base 인자에 담아 관리하며, sem_nsems 인자는 semaphore가 관리하는 리소스의 갯수를 나타낸다. Semaphore in C Library int semop(int sid, struct sembuf* s_buf, size_t num) : semaphore을 조작하는 함수\nsid : semaphore id, 식별자 s_buf : operation. 동작에 대한 상세 정보를 sembuf* 타입에 기록한 후 인자에 적용한다. 배열 형태로 여러개 적용 가능 s_buf.sem_num: 세마포어 번호 s_buf.sem_op : 세마포어 연산 s_buf.sem_flg : 작동 플래그 num : operation의 갯수 int semctl(int sid, int num, int cmd, union semun arg) : semaphore 설정을 가져오거나 수정\nsid : semaphore id, 식별자 num : 세마포어가 관리하는 리소스 중 함수로 접근을 원하는 대상의 index cmd : 명령 GETVAL\t세마포어의 현재 값을 구한다. GETPID\t가장 최근에 접근했던 프로세스의 프로세스 ID를 구한다. GETNCNT\t세마포어 대기중인 프로세스의 개수 GETZCNT\t세마포어 값이 0 이 되기를 기다리는 프로세스의 개수 GETALL\t세마포어 집합의 모든 세마포어 조회 SETVAL\t세마포어 값을 설정 SETALL\t세마퍼어 집합의 모든 세마포어 값을 설정 IPC_STAT\t세마포어의 상세 정보 확인 IPC_SET\t세마포어의 권한 설정 IPC_RMID\t세마포어 집합 삭제 arg : 조회 명령시에는 해당 값에 정보를 받아오고, 설정 명령시에는 해당 값을 적용 p연산 : semaphore에 리소스를 사용하고 있다고 체크하는 연산\nstruct sembuf s_buf = {0,};\rs_buf.sem_num = 0;\rs_buf.sem_op = -1; // 한개 만큼 사용\rsemop(semid, \u0026amp;s_buf, 1); // 한 개 operation 수행 v연산 : semaphore에 리소스를 반환했다고 체크하는 연산\nstruct sembuf s_buf = {0,};\rs_buf.sem_num = 0;\rs_buf.sem_op = 1; // 한개 만큼 사용\rsemop(semid, \u0026amp;s_buf, 1); // 한 개 operation 수행 Shared Memory 프로세스간 공용으로 사용할 수 있는 영역의 메모리를 선언하는 방법 race condition을 해결 할 수는 없으므로, semaphore와 함께 사용해야 한다. Shared Mmory in C Library int shmget(key_t key, size_t size, int shmflg) : shared memory를 생성하거나 key값으로 identifier를 가져오는 함수 size : shared memory의 크기 생성 : shmget(key, sizeof(YOUR_STRUCT), IPC_CREAT) 참조 : shmget(key, sizeof(YOUR_STRUCT), 0) YOUR_STRUCT는 메모리 참조시 사용할 포멧 void *shmat(int shmid, const void *shmaddr, int shmflg) : 가상메모리를 할당하는 작업. attach shmid : shared memory id, 식별자 shmaddr : 공유 메모리 연결 주소 (보통 NULL로 사용) 반환값 : shared memory에 접근할 수 있는 포인터 ex) YOUR_STRUCT *ptr = (YOUR_STRUCT*)shmat(shmid, 0, 0); int shmdt(const void *shmaddr) : 가상메모리를 환원하는 작업. detach ex) shmdt(shmid); int shmctl(int shmid, int cmd, struct shmid_ds *buf) : 공유 메모리에 대한 정보를 가져오거나 설정하는 함수 shmid : shared memory id, 식별자 cmd : 제어 명령 IPC_STAT : shared memory 값 받아와 buf에 작성 IPC_SET : buf의 값으로 해당 shared memory 정보 갱신 IPC_RMID : shared memory를 시스템에서 삭제 buf : 조회 명령시에는 해당 값에 정보를 받아오고, 설정 명령시에는 해당 값을 적용 ","permalink":"https://aswinblue.github.io/post/linux/ipc/","summary":"IPC (Inter Process Communicatrion) Signal Signal은 프로세스간 동기화를 위해 프로세스간 전송하는 신호를 의미한다. Software Interrupt 라고도 한다. 커널에서 kill -\u0026lt;SIGNAL_NUMBER\u0026gt; \u0026lt;PROCESS_ID\u0026gt; 명령으로 특정 PROCESS_ID에 ISGNAL_NUMBER에 해당하는 signal을 전달할 수 있다. signal은 총 64까지 정의되어 있고 1~31까지가 일반적으로 사용하는 signal이다. 34~63은 고성능 네트워크 통신을 위한 시그널이다. (32, 33는 미정의) kill -l 명령으로 signal 리스트를 확인할 수 있다. SIGHUP SIGINT : 인터럽트, Ctrl+C 명령으로 전송 가능 SIGQUIT Coredump시 발생 SIGILL : Illegal instruction SIGTRAP : debugger is tracing SIGABRT : Abort process SIGBUS : bus error SIGFPE : Floating point exception SIGKILL : 강제 종료 SIGUSR1\t: User-defined signal 1, 마음대로 사용 가능 SIGSEGV\t: invalid virtual memory reference SIGUSR2 : User-defined signal 2, 마음대로 사용 가능 SIGPIPE\t: 반대편이 연결되지 않은 pip에 신호 전송시 발생하는 에러 SIGALRM : alarm() 함수에 의해 발생한 시그널 1 SIGTERM : 종료 요청, SIGKILL(9)보다 안전한 종료 방법, SIGINT와 유사한 성능 SIGSTKFLT : Stack fault SIGCHLD : 자식 process가 종료될 때 부모에게 전달하는 신호 SIGCONT : SIGSTOP 에 의해 정지된 경우, 다시 시작하라는 신호 SIGSTOP : process 정지 SIGTSTP : process 일시정지, Ctrl+Z 명령으로 전송 가능 SIGTTIN\t: background 에 있을 때 read 요청을 받은 경우 발생 SIGTTOU : background 에 있을 때 write 요청을 받은 경우 발생 SIGURG : 긴급 통신을 받은 경우 (Out Of Band) SIGXCPU : 설정된 CPU 사용량을 초과하여 프로세스가 동작 한 경우 SIGXFSZ : 파일 크기가 허용된 크기를 초과한 경우 SIGVTALRM : 프로세스 실행시간 관리를 위한 시그널1 SIGPROF : 프로세스 실행시간 관리를 위한 시그널2 SIGWINCH : Window change SIGIO, SIGPOLL : Input/output is now possible SIGPWR, SIGLOST : Power failure SIGUNUSED, SIGSYS : Unused signal.","title":"IPC"},{"content":"Thread thread는 process의 경량화 버전으로 생각할 수 있다. pthread_create() 함수로 fork 명령을 대체하고, pthread_join() 으로 wait 명령을 대체하면 process 대신 thread를 동작시킨다. thread는 함수를 실행시키는 것이 기본이며, 함수를 실행시킬 때 넣을 인자와, 함수의 리턴값을 받을 인자를 pthread_create의 파라미터로 받는다. 리눅스 프로세스 표시 목록에 LWP(light-weight-process) 항목으로 표시되며, proces ID가 같더라도 LWP ID가 다르면 같은 process 안의 thread인 것. pthread_exit() 로 thread만 종료시킬 수 있다. main process가 종료되면 딸려있는 thread들도 함께 종료된다. 다만, main thread만 pthread_exit으로 종료시키면 process가 종료되지 않고 main thread만 종료되고 다른 thread들은 계속 구동되는 형태가 되므로 주의한다. int pthread_join(pthread_t thread, void **retval) : 자식 thread가 종료될 때 까지 대기하고, 종료처리를 해 주는 함수, pthread_exit()에서 반환된 값을 retval로 받아올수 있다. pthread_detach(int tid) : thread id가 tid에 해당하는 thread를 부모 thread에서 분리하는 함수. 이후 종료되고 join 처리를 대기하지 않고 바로 free됨. int pthread_self() : 자신의 thread id 를 확인할때 사용하는 함수 void* func(void* data)\r{\r(struct ARG*) data;\r...\rpthread_detach(pthread_self()); // pthread_join 대신 사용 가능\r}\r...\r// thread 생성\rstruct ARG *arg;\rint tid = pthread_create(\u0026amp;thread, 0, func, arg);\r...\rpthread_join(tid, 0); // pthread_detach 대신 사용 가능\r... process 와 thread 차이 process는 메모리를 수정하는 순간 메모리가 분리되지만, thread는 메모리를 공유하여 수정하고 나서도 같은 영역을 참조할수 있다. (전체 가상메모리를 공유한다.) process는 wait 값의 인자를 확인 에러를 확인할 수 있는 반면, thread의 에러는 pthread_join의 return 값을 확인한다. (값이 0 초과이면 에러가 됨) 일반적인 에러 처리는, errno.h 헤더파일에 errno 라는 변수가 전역변수로 선언되어 있고, 프로세스가 에러에 의해 종료될 경우 이 변수에 값을 채워넣는다. thread는 전역변수를 공유하기 때문에 errno를 사용하지 않는 것 Mutex 전역변수의 상호 참조에 의해 발생하는 race condition 문제를 해결하기 위해 사용할 수 있는 방법 race condition : 둘 이상의 thread가 전역변수를 참조할 때 메모리 접근하려 서로 경쟁하는 상황 pthread.h 헤더를 사용하며, pthread 라이브러리를 사용하기 떄문에 빌드시 옵션에 -lpthread를 추가해준다. pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\r...\rpthread_mutex_lock(\u0026amp;mutex);\r// 전역변수 참조 영역\rpthread_mutex_unlock(\u0026amp;mutex); mutex를 사용해 임계 영역(critical section)에 대해 mutual exclusion 속성을 보장하여 동시 접속에 의한 오동작을 막을 수 있다. Mutex 내부 구조 C언어로는 compare와 set을 atomic하게 수행할 수 없어 mutual exclusion을 구현할 수 없다. cas(compare and set) 라는 코드를 어셈블리어에서 지원하는데, compare와 set을 atomic하게 처리할 수 있다. 아래 함수는 어셈블리어를 사용하여 C에서 cas를 구현한 내용이다. cpu 칩마다 지원하는 형태가 다를 수 있음에 주의한다. (아래는 인텔이 제공하는 형태) typedef int int32_t;\rint mutex = 0; // 초기값 0\r/**\r* @brief old_value와 *ptr을 비교하여 같다면 *ptr에 new_value를 대입한다.\r* mutex lock의 역할을 한다. * @return int old_value와 *ptr의 비교 결과가 같다면 false를, 다르다면 true를 반환\r*/\rint __bionic_cmpxchg(int32_t old_value, int32_t new_value, volatile int32_t* ptr)\r{\rint 32_t prev;\r__asm__ __volatile__ (\u0026#34;lock; cmpxchgl %1, %2\u0026#34;\r: \u0026#34;=a\u0026#34; (prev)\r: \u0026#34;q\u0026#34; (new_value), \u0026#34;m\u0026#34; (*ptr), \u0026#34;0\u0026#34; (old_value)\r: \u0026#34;memory\u0026#34;);\rreturn prev != old_value;\r} Spin Lock while문을 반복하며 mutex를 계속 체크하는 기법 void spin_lock(int* mutex)\r{\rwhile (__bionic_cmpxchg(0, 1, mutex)); // mutex가 0이 될 때 까지 무한 대기 } CPU 활용도가 떨어지므로 임계영역이 짧은 경우만 사용 권장 Sleep Lock mutex를 기다리는 동안 thread를 sleep 시키면 thread에 할당된 리소스를 해제하여 다른 곳에 할당해 줄 수 있게 된다. gcc에서는 slelep lock을 지원하는 라이브러리가 없지만, 시스템 커맨드 라이브러리에는 futex(fast user mutex)라는 함수로 sleep lock을 지원한다. C언어로 사용하려면 시스템 콜로 futex를 호출하면 된다. #include \u0026lt;unisted.h\u0026gt;\rint mutex = 1;\rvoid *foo(void *data)\r{\rsytstemcall 202, \u0026amp;mutex, 0, 1, 0); // __futex_wait();\r... /* critical section */\rsystemcall(202, \u0026amp;mutex, 1, 1); // __futex_wake();\r} __futex_wait 은 mutex_lock, __futex_wake는 mutex_unlock에 대응된다. Self Lock recursive 함수에서 mutex를 사용한다면 하나의 함수에서 동일한 mutex를 두번 호출하게 되는 \u0026ldquo;selfl lock\u0026quot;이 발생할 수 있다. self lock이 발생하면 마찬가지로 deadlock이 발생한다. 재귀 호출을 위한 recursive mutex lock 이 존재한다. mutex 생성시 attribute로 재귀함수를 위한 설정이 존재하며, mutex_lock을 한 thread에서 중복 호출 가능하며, mutex_lock을 호출한 수만큼 mutex_unlock을 호출해 주면 mutex가 해제된다. pthread_mutexattr_t attr;\rpthread_mutex_t mutex;\r...\rpthread_mutexattr_init(\u0026amp;attr);\rpthread_mutexattr_settype(\u0026amp;attr, PTHREAD_MUTEX_RECURSIVE);\rpthread_mutuex_init(\u0026amp;mutex, \u0026amp;attr);\r...\rpthread_mutex_lock(\u0026amp;mutex); // 1\rpthread_mutex_lock(\u0026amp;mutex); // 2\rpthread_mutex_lock(\u0026amp;mutex); // 3\r...\rpthread_mutex_unlock(\u0026amp;mutex); // 1\rpthread_mutex_unlock(\u0026amp;mutex); // 2\rpthread_mutex_unlock(\u0026amp;mutex); // 3 Condition (조건변수) thread에서 전역 변수에 참조할 때, 순서를 제어하기 위해 사용하는 방법 아래 코드는 thread1에서 전역변수를 처리해야 thread2에서 전역변수에 접근이 가능하게 하는 코드이다. pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\r...\rthread1()\r{\rpthread_mutex_lock(\u0026amp;mutex);\r// 전역변수 처리\rpthread_cond_signal(\u0026amp;cond);\rpthread_mutex_unlock(\u0026amp;mutex);\r}\r...\rthread2()\r{\rpthread_mutex_lock(\u0026amp;mutex);\rpthread_cond_wait(\u0026amp;cond);\r// 전역변수 처리\rpthread_mutex_unlock(\u0026amp;mutex);\r} Condition 내부 구조 func1()\r{\rpthread_mutex_lock(); // \u0026lt;- (1)\rdo_something();\rpthread_cond_signal();\rpthread_mutex_unlock();\r}\rfunc2()\r{\rpthread_mutex_lock();\rpthread_cond_wait(); // \u0026lt;- (2)\rdo_something();\rpthread_mutex_unlock();\r} func1이 (1)에서 mutex unlock을 대기하고, func2가 (2)에서 condition signal을 대기하면 deadlock이 걸릴 것 같지만, condition wait와 mutex lock은 서로 교착상태를 만들지 않는다. pthread_cond_wait() 아래와 같이 mutex_unlock, futex_wait, mutex_lock으로 구성되어 있으므로 mutex pthread_cond_wait()\r{\r...\rpthread_mutex_unlock();\rwhile (condition == 0) // condition 조건이 충족될 때 까지 무한 대기\r{\rfutex_wait(); // sleep lock\r}\rcondition = 0; // condition 초기화\rpthread_mutex_lock();\r...\r} 즉, condition wait는 condition signal이 발생한 시점이 아니라, mutex 가 unlock되는 시점에 탈출된다. Deadlock 두 개 이상의 Mutex가 서로 해제되기를 기다리며 대기하여 더 이상 process가 진행되지 못하게 되는 상황을 deadlock이라 한다. lock을 순서대로 잡고, cycle이 생기지 않게 관리하면 deadlock을 피할 수 있다. 재진입 가능 함수 (Reentrant) thread에서 사용할 수 있는 함수를 \u0026lsquo;재진입 가능 함수\u0026rsquo; 라 한다. 즉, Thread-safe 한 함수를 의미한다. 내부적으롱 전역변수, 혹은 static 변수를 사용하는 함수는 \u0026lsquo;재진입 불가능\u0026rsquo; 하다. strtok는 대표적인 재진입 불가능한 함수이다. func1()\r{\rstrtok()\r}\rfunc2()\r{\rstrtok()\r}\rmain()\r{\rpthread_create(func1);\rpthread_create(func2);\r}\r// -\u0026gt; strtok는 재진입 불가능한 함수이기 때문에 결과가 의도한 결과가 나오지 않을 수 있다. C 라이브러리에서는 strtok_r 이라는 재진입 가능한 함수를 제공한다. TLS / TSD thread마다 개별적으로 사용할 수 있는 전역변수 영역을 TLS라 한다. 리눅스에서는 TSD라 부른다. int pthread_setspecific(pthread_key_t key, const void *value) : \u0026lsquo;key\u0026rsquo; 에 해당하는 영역에 \u0026lsquo;value\u0026rsquo;를 연결한다. value로는 동적할당한 메모리가 온다. void* pthread_getspecific(pthread_key_t key) : 기존에 set으로 할당한 key에 해당하는 메모리를 가져온다. void pthread_key_create(pthread_key_t key, void* (*descturctor)(void*)) 할당한 메모리를 해제하는 역할을 수행할 함수 void destructor(void* ptr){free(p);}를 정의하고, destructor의 포인터를 key와 매핑시킨다. void main(void)\r{\rpthread_key_t key;\rpthread_key_create(key, void (*destructor)(void*));\r}\rvoid func1(void)\r{\rint *tsd = pthread_get_specific(key) // key에 해당하는 영역 가져옴\rif (!tsd) // null 받았을 시\r{\rtsd = calloc(1, sizeof int); // int 영역이 필요해서 동적할당. 다른 자료형도 가능\rpthread_set_specific(key, tsd); // TSD 영역에 저장\r}\r}\rvoid destructor(void* ptr)\r{\rfree(p);\r} TLS는 내부적으로 void* tls[] 배열을 bitmap 형태로 지니고, pthread_set_specific을 할 경우 tls[idx]에 메모리 주소를 대입한다. pthread_set_specific을 호출할 때 마다 idx는 자동으로 갱신된다. thread가 종료될 때 모든 key에 대해 소멸자로 정의된 destructor가 호출된다. ","permalink":"https://aswinblue.github.io/post/linux/thread/","summary":"Thread thread는 process의 경량화 버전으로 생각할 수 있다. pthread_create() 함수로 fork 명령을 대체하고, pthread_join() 으로 wait 명령을 대체하면 process 대신 thread를 동작시킨다. thread는 함수를 실행시키는 것이 기본이며, 함수를 실행시킬 때 넣을 인자와, 함수의 리턴값을 받을 인자를 pthread_create의 파라미터로 받는다. 리눅스 프로세스 표시 목록에 LWP(light-weight-process) 항목으로 표시되며, proces ID가 같더라도 LWP ID가 다르면 같은 process 안의 thread인 것. pthread_exit() 로 thread만 종료시킬 수 있다. main process가 종료되면 딸려있는 thread들도 함께 종료된다. 다만, main thread만 pthread_exit으로 종료시키면 process가 종료되지 않고 main thread만 종료되고 다른 thread들은 계속 구동되는 형태가 되므로 주의한다.","title":"Thread"},{"content":"Process Program vs Process Process : 실행중인 프로그램 Program : 실행 가능한 파일 Process는 메모리에 올라가 있는 상태의 프로그램을 의미한다. C언어 Program to Process C언어로 구성된 프로그램은 전처리 - 컴파일 - 링킹 - 로딩의 과정을 거친다. 전처리 : # 으로 시작하는 라인들을 알맞은 형태로 치환한다. 컴파일 : C언어(high-level language)를 어셈블리어(기계어) 로 변환한다. 링킹 : 외부의 ELF(Executable and Linkable Format) 파일들을 호출할 수 있도록 연결한다. 로딩 : 최종 생성된 파일을 실행시켜 메모리에 올려 프로세스로 만든다. 리눅스에서는 execv() 함수에 의해 프로세스화 된다. 프로세스 fork fork() 함수는 프로세스를 복사하는 함수이다. unistd.h 헤더에 선언되어 있다. 복사당한 프로세스를 부모 프로세스, 복사해서 생성된 프로세스를 자식 프로세스라 한다. 복사된 자식 프로세스도 fork 실행 이후부터 코드가 진행된다. fork 함수의 반환값은 pid_t 타입이다. 반환값이 -1이라면 실패를 의미한다. 결과가 0이라면 현재 프로세스는 자식 프로세스임을 의미한다. 0이 아니닌 값이라면 현재 프로세스는 부모 프로세스이다. 반환값은 자식프로세스의 process id를 의미하며, 리눅스 명령어 ps -ef 로 pid를 확인 할 수 있다. Race Condition : 일단 fork가 되어 프로세스가 부모 자식으로 나뉘면, 프로세스의 실행은 병렬적으로 이루어지며, 같은 코드라도 어느 것이 먼저 동작할지 알 수 없다. wait fork() 로 자식 프로세스를 생성한 후 자식 프로세스가 exit()를 호출하여 종료될 때, 부모 process는 자식 process의 종료 결과를 wait() 으로 받을수 있다. wait(statloc *status) : 자식 process에서 호출된 exit() 함수 안에 들어간 인자값을 status(인자는 4byte int지만, 사용하는 부분은 2byte) 에 담아낸다. status 값은 상위 1byte와 하위 1byte를 구분해서 사용한다. 정상적으로 종료가 된경우는 exit() 함수에 의한 종료를 의미하며, status의 상위 1byte에 exit의 인자값을 담아낸다. 비정상 종료는 signal에 의한 종료를 의미하며, signal 번호 값을 status의 하위 1byte에 담아낸다. 0~7번 bit : 자식 process 정상종료시 종료 status 8번 bit : core dump 여부 9~15번 bit : 시그널 번호 status값을 인자로 받아 종료 사유를 회신하는 매크로 함수를 사용하면 쉽게 판단할 수 있다. WIFEXITED, WEXITEDSTATUS, WIFSIGNALED \u0026hellip; 메모리 부모 프로세스를 복사해 자식 프로세스를 생성해도 code 영역은 공유된다. code 영역은 read only memory 이기 때문에 자식 프로세스는 부모 프로세스의 ram 영역 값도그대로 복사 해 온다. 하지만, 자식 프로세스가 새성될 당시 메모리가 바로 복사되는 것이 아니라, 메모리에 값을 작성하는 시점에 복사가 된다. 즉, 부모나 자식 프로세스에서 값을 덮어쓰거나 새로 생성하지 않은 변수에 대해서는 같은 메모리를 바라보고 있다고 볼 수 있다. 메모리는 reference count를 들고 있어 몇개의 프로세스에서 해당 영역을 참조하는지 체크한다. 프로세스 생명 주기 (Life Cycle) 모든 프로세스는 부모 프로세스가 있고, 가장 최초로 실행된 프로세스를 init 프로세스라 하며, init 프로세스의 pid는 1이다.\n생성된 프로세스는 exit() 함수를 호출하면 종료된다. (일반적으로 main 함수의 리턴값이 exit을 호출하도록 되어있다.)\nexit은 라이브러리로 버퍼를 flush하고, open된 모든 파일을 close하고, 프로세스가 사용하고 있는 메모리 풀을 반환한다. 그후 _exit 을 호출하여 프로세스를 종료시킨다.\n하지만, exit만 호출되었다고 해서 프로세스가 완벽하게 종료되는 것이 아니다. exit을 호출하면 부모 프로세스에서 상태코드(exit의 인자값)를 받아가기를 대기한다. 메모리의 반환 작업은 부모 프로세스의 처리가 끝나야 이루어진다.\nexit의 결과값을 처리하는 함수는 wait 이다. 부모 프로세스에서 wait을 실행하면 그제서야 자식 프로세스는 메모리를 정리하고 완벽하게 종료된다. (커널 레벨에서 자식은 부모를, 부모는 자식들의 포인터를 갖고 있어 서로 참조할 수 있도록 연결되어 있다.) 좀비 프로세스 부모 프로세스에서 wait를 호출하지 않아 자식 프로세스를 정리해 주지 않으면 좀비 프로세스가 생성된다. 좀비 프로세스는 사용하지 않는 메모리 및 리소스들을 차지하고 있어서 다른 프로세스들의 성능을 저하시킨다. 고아 프로세스 자식 프로세스보다 부모 프로세스가 먼저 종료되는 경우, 그 자식 프로세스들은 고아 프로세스가 된다. 고아 프로세스들은 종료 처리를 해줄 부모 프로세스가 없기 때문에 좀비 프로세스가 될 수 있는데, 이를 막기 위해 커널은 고아 프로세스를 주기적으로 찾아 \u0026lsquo;init\u0026rsquo; 프로세스의 자식으로 재설정한다. signal wait() 함수를 호출하면 부모 프로세스는 자식 프로세스가 exit를 호출하기를 기다린다.\n이렇게 되면, 부모 프로세스는 다른 동작을 수행하지 못하여 concurrent한 동작 수행이 불가능하다.\n부모가 자기 할 일을 수행하다 자식이 종료될 떄 종료 처리를 해 주도록 하려면 signal 기능을 사용하면 된다.\n자식 프로세스에서 exit를 호출하면 내부적으로 부모 프로세스에 SIGCHLD(sig child) 시그널을 보내도록 되어 있다. 부모 프로세스에서는 signal(SIGCHLD, my_function) 형태로 SIGCHLD 시그널의 처리를 my_function 으로 받아서 처리하도록 하고, myfunction 안에서 wait을 호출하면 된다. signal(SIGCHLD, my_function);\r...\rfork()\r...\rmy_function() { wait(0); } 단, 자식 프로세스가 여러개인 경우, 동시에 종료되는 자식 프로세스들에 대해서는 단순 signal 로 처리가 불가능하다.\nsignal이 호출되어 my_function이 돌고 있는 도중에 다음 signal이 호출되면, my_function 함수가 또 호출되지 않는다. 해당 signal은 무시되는 것이다.\n하지만, signal은 무시되더라도 \u0026lsquo;부모 프로세스가 처리해야할 목록\u0026rsquo; 에는 추가되기 때문에, wait()를 반복한다면 동시에 종료된 자식 프로세스들도 처리할 수있다.\n또한 wait 대신 waitpid 를 사용하여 timeout을 짧게 가져가는 식으로 부모 프로세스의 concurrency도 보장할 수 있다. (WNOHANG 옵션으로 더이상 처리할 내용이 없으면 기다리지 않도록 할 수 있음)\nmy_function() { while ( waitpid(-1, 0, WNOHANG) \u0026gt; 0 ); } 하지만, SIGCHLD 시그널은, 자식 프로세스가 종료 되었을 때 뿐 아니라, 정지되었을 때도 호출된다. signal 설정 옵션으로 자식 프로세스가 종료되었을 때 날아오는 SIGCHLD 는 처리하지 않도록 설정해야 완벽하다.\nsignal의 상위호환인 sigaction 함수를 사용하면 flag를 설정하여 처리 가능하다. Init Process init 프로세스는 고아 프로세스들을 모아서 종료시켜준다. init 프로세스는 socketpair() 을 사용하여 3번4번 entry에 socket을 하나씩 연다. 3번 socket은 4번 socket으로 pipeline이 연결되어 있다. signal handler가 프로세스에서 고아 프로세스를 감지하면 3번 entry의 socket으로 데이터를 write 하면, init 프로세스의 4번 socket에서 데이터가 튀어나온다. 4번 socket에서 데이터를 받은 init 프로세스는 받은 데이터를 기반으로 고아 프로세스를 처리한다. 이런 식으로 구조를 짜면, 커널에서 직접 프로세스를 처리하지 않고, init process가 프로세스 처리를 하도록 할 수 있다. | signal handler | ---write()------↴ ↷ |[0] [1] [2] [3] [4]|\r| init process ↙ |\r| wait() |\r| | | | | | exec 함수 system() 이라는 라이브러리 함수로 커널 명령을 실행할 수 있다. 내부적으로 exec 함수들을 사용한다.\nexec뒤에 붙은 글자에 따라 인자로 받는 데이터의 형태나 종류가 달라지며, 여러 속성들을 합해서 사용 가능하다. exec함수들은 execve 를 제외하고는 모두 라이브러리이며, 최종적으로 execve를 호출한다. l : 리스트 형태의 인자를 받아 명령어 호출시 전달\nex) execl(\u0026quot;ls\u0026quot;, \u0026quot;-l\u0026quot;) v : 벡터 형태의 인자를 받아 명령어 호출시 전달\nex) char* cmd[] = {\u0026#34;/bin/ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, null}; // 파일 위치, 프로세스 이름, argument\rexcecv(cmd); e : 환경변수를 인자를 받아 명령어 호출시 전달\nex) char* env[] = {\u0026#34;name=justin\u0026#34;, \u0026#34;age=20\u0026#34;, null}; excece(cmd); ex) v와e를 혼합해서 사용 가능 char* cmd[] = {\u0026#34;/bin/ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, null}; // 파일 위치, 프로세스 이름, argument\rchar* env[] = {\u0026#34;name=justin\u0026#34;, \u0026#34;age=20\u0026#34;, null}; excecve(cmd, env); c에서 main 함수는 int main(int argc, char** argv, char** envp) 형태이다. argc: 인자의 갯수 argv: 인자의 배열 envp: 환경변수의 배열 p : 환경변수 path를 참조하여 명령어 실행\nexec 파일들은 기본적으로 path를 참조하지 않고 실행되어 명령어 파일의 절대경로를 인자로 넣어야 한다. p옵션이 붙은 함수를 사용하면 환경변수 path를 사용하여 명령어를 실행할 수 있다. ex) execlp(\u0026quot;ls\u0026quot;, \u0026quot;ls\u0026quot;, \u0026quot;-l\u0026quot;, null) 쉘을 이용한 옵션처리 execlp(command, command, null); 형태로 실행하지 않고, execl(\u0026quot;/bin/sh\u0026quot;, \u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, command, null); 형태로 실행하면 \u0026lsquo;command\u0026rsquo; 명령을 쉘이 실행하게 되어 옵션을 알아서 처리해 준다. exec로 생성한 프로세스의 속성 상속되는 속성 파일 디스크립터 사용자 ID, 그룹 ID, 프로세스 그룹 ID, 세션 ID, 제어 터미널 alarm 시그널 남은 설정시간 작업 디렉터리, root 디렉터리 파일 잠금 여부, 파일 생성 마스크 자원 제약, CPU 사용시간 상속되지 않는 속성 signal의 처리는 SIG_IGN 처리되던 시그널 외에는 default로 복구된다. 유효 사용자 ID (파일 속성에서 set_user_ID 비트가 설정된 경우) 유효 그룹 ID (set_group_id 비트가 설정된 경우) reference count exec를 사용하여 프로세스를 호출하면, 그 아래 line들은 실행이 되지 않는다. 프로세스는 코드 영역 메모리를 참조하고, 메모리는 reference count를 두어 몇개의 프로세스가 해당 메모리를 참조하는지 체크한다. 이때, exec를 사용하면 기존 프로세스는 code 영역을 내버려두고 exec에서 사용할 새로운 코드영역을 참조하게 된다. (+program counter 이동) 그렇게 되면 기존에 남아있던 코드 영역 메모리는 reference count가 0이되어 더이상 사용하지 않는 메모리로 취급되어 free된다. -\u0026gt; fork와 exec를 함께 사용하면 exec 아래의 코드도 실행할 수 있게 할 수 있다.\n...\rpid = fork()\rif (pid)\rexec(...);\rwait(0);\rsomething_to_do(); // 부모 process에서 실행 가능\r... 프로세스 그룹 하나 이상의 프로세스들의 집합을 프로세스 그룹이라 한다. 일관된 작업을 하는 프로세스들을 그룹으로 묶어서 관리하며, 이 그룹은 고유한 \u0026lsquo;프로세스 그룹 ID\u0026rsquo; 를 갖는다. 프로세스 그룹에는 \u0026lsquo;프로세스 그룹 리더\u0026rsquo; 가존재한다. 리더는 프로세스 그룹 ID와 동일한 값을 프로세스 ID로 가진 프로세스이다. 리더는 그룹 및 그룹내의 프로세스의 생성/종료 권한을 가진다. 리더가 종료되거나 그룹을 떠나면 해당 프로세스 그룹 내의 다른 프로세스가 리더 권한을 위임받는다. 그룹 내의 마지막 프로세스가 그룹을 떠나면 해당 그룹은 사라진다. pipe 명령으로 묶어서 한번에 실행한 명령들은 같은 프로세스 그룹에 묶인다. 그룹 제어 함수 getpgrp, setpgid getpgrp 호출한 프로세스가 속한 프로세스 그룹 ID를 리턴하는 함수 setpgrid(PROCESS_ID, PROCESS_GROUP_ID) 새로운 프로세스 그룹을 생성하거나, 선택한 프로세스를 특정 그룹에 합류시키는 함수 PROCESS_ID 와 PROCESS_GROUP_ID를 동일한 수를 넣어주면, 해당 프로세스를 리더로 승격시킨다. 자기 자신이나 자식 프로세스의 그룹ID만 변경 가능하며, exec를 수행한 자식 프로세스의 그룹ID는 접근할 수 없다. 세션 일반적으로 같은 터미널에서 수행되고 있는 프로세스 그룹들을 모은 집합을 session이라 한다. 세션, 프로세스 그룹, 프로세스 간 연관관계는 프로세스 ⊂ 프로세스 그룹 ⊂ 세션 형태이다. 세션도 unique한 번호를 가지며 이를 세션ID라 한다. 세션ID와 동일한 프로세스ID를 가진 프로세스를 세션 리더라 한다. 한 세션의 프로세스들은 하나의 foreground 프로세스와 다수의 background 프로세스로 이루어져 있다. foreground 프로세스는 현재 키보드 input을 받을 수 있는 유일한 프로세스이다. 세션 제어 함수 setsid 새로운 세션을 생성하여 특정 프로세스를 해당 세션으로 이동하는 함수이다. 호출한 프로세스가 프로세스 그룹 리더가 아닌 경우에만 실행 가능하다. 프로세스 그룹에 프로세스가 하나밖에 없더라도, fork로 생성된 자식 프로세스는 그룹 리더가 아니기 때문에 setsid를 호출할 수 있다. 새로운 세션이 생성되면, 프로세스 그룹도 신규로 생성하고, 그 안에 프로세스를 이동시킨다. 이동된 프로세스는 세션 리더이자 프로세스 리더가 된다. setsid 명령은 제어 터미널을 갖지 않기 때문에 기존에 연결되어있던 터미널과의 연결이 끊기게 된다. 제어 터미널 하나의 세션은 하나의 제어 터미널을 가질 수 있다.\n프로세스에서 가상 터미널은 \u0026lsquo;pts\u0026rsquo;, 실제 터미널은 \u0026rsquo;tty\u0026rsquo; 라 표시된다. 세션 리더는 제어 터미널과의 연결을 관할한다.\ntcgetpgrp : foreground 프로세스 그룹ID를 반환한다.\ntcsetpgrp : 제어터미널을 갖고 있는 경우, 특정 프로세스 그룹을 전위 프로세스 그룹으로 설정한다.\nstty -a 명령으로 확인시 작업제어를 위한 시그널이 설정되어 있음을 확인할 수 있다.\nDaemon Process 제어 터미널 없이 주기적으로 주어진 일을 처리하거나, 특정 이벤트를 대기하기 위해 background에서 돌고있는 프로세스 보통 시스템이 부팅될 때 시작되며, shutdown 될 때 종료된다. 다른 프로세스가 발생한 시그널에 간섭받지 않아야 한다. 데몬 프로세스는 터미널과 연결이 되어있지 않기 때문에 터미널로 입력/출력을 할 수 없다. 출력은 printf 대신 syslog 를 사용하여 시스템 로그로 출력을 하도록 해야한다. Daemon 구현 방법 fork()로 child process를 생성하고 parent process를 종료한다. child process에서 setsid() 함수로 새로운 세션을 생성한다. background로 실행 가능하며, 터미널에 영향을 받지 않게됨 열려진 모든 file descriptor를 닫는다. 1~64까지 index를 순회하며 close() 로 file descriptor를 모두 닫는다. 작업 디렉터리를 root(\u0026quot;/\u0026quot;)로 바꿔서 다른 파일 시스템의 unmount 동작에 영향을 주지 않도록 한다. chdir(\u0026quot;/\u0026quot;); 로 작업 디렉터리를 옮길 수 있다. 파일 생성 마스크를 0으로 설정한다. umask(0) 명령으로 umask값을 없애준다. umask란, 프로세스에서 생성되는 파일의 파일 접근 권한 설정시 해당 값을 빼도록 설정된 값이다. 즉, 초기 파일 권한 666에서 umask값을 뺀 값이 생성된 파일의 권한이 된다. (디렉터리는 초기값 777) SIGCLD 시그널을 무시한다. signal(SIGCHLD, SIG_IGN) 를 통해 자식이 발생하는 시그널을 무시하도록 설정해야 데몬이 생성한 프로세스들이 좀비 프로세스가 생성되지 않는다. 직접 wait를 해서 처리 해줘도 된다. ","permalink":"https://aswinblue.github.io/post/linux/process/","summary":"Process Program vs Process Process : 실행중인 프로그램 Program : 실행 가능한 파일 Process는 메모리에 올라가 있는 상태의 프로그램을 의미한다. C언어 Program to Process C언어로 구성된 프로그램은 전처리 - 컴파일 - 링킹 - 로딩의 과정을 거친다. 전처리 : # 으로 시작하는 라인들을 알맞은 형태로 치환한다. 컴파일 : C언어(high-level language)를 어셈블리어(기계어) 로 변환한다. 링킹 : 외부의 ELF(Executable and Linkable Format) 파일들을 호출할 수 있도록 연결한다. 로딩 : 최종 생성된 파일을 실행시켜 메모리에 올려 프로세스로 만든다.","title":"Process"},{"content":"System Programming 프로그램이 동작하는 구조는 크게 application, kernel, HW 로 분리할 수 있다. _____________\r| Library |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Application level\r------------------------------\r_____________\r|System call|\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Kernel level\r------------------------------\r_____________\r| Hardware |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ H/W level\r------------------------------ application level에서는 library를 사용하며, 이 코드들은 library buffer를 사용한다. (open(), read(), write(), close() \u0026hellip;) 시스템에서 제공하는 최적의 buffer 단위로 disk에서 값을 읽어오고, library buffer에 담아두면 작은단위로 읽어올 때 효율적이다. 예를들어, 한 줄씩 파일을 읽어야 한다면, 1byte씩 파일에서 \u0026lsquo;\\n\u0026rsquo;을 감지할 때 까지 읽을 수 있지만, BUF_SIZ만큼 파일에서 읽어서 library buffer에 담아두고 library buffer를 1byte씩 읽으며 \u0026lsquo;\\n\u0026rsquo;를 찾는 것이 실행 속도는 더 빠르다. (IO접근은 적을수록 효율적) Kernel level에서는 System call을 사용하며 system buffer를 사용한다. application level 함수를 사용하면, 보통 library buffer를 1차적으로 사용하고, 내부적으로 system call을 수행해 system buffer를 2차적으로 사용하게 된다. printf는 c library 함수이며, \u0026lsquo;\\n\u0026rsquo;을 만나야 화면상에 출력을 한다. \u0026lsquo;\\n\u0026rsquo;이 입력되기 전 까지 문자열들은 library buffer에 기록된다. fprintf는 \u0026lsquo;\\n\u0026rsquo;과 상관없이 문자열을 출력한다. 즉 library buffer를 사용하지 않는다. 파일 입출력 fgetc C에서 파일에 접근하기 위해서는 fopen 함수를 사용한다. fopen은 파일 포인터를 반환하며, 코드 내에서 파일 포인터로 해당 파일에 접근이가능하다. fgetc(FPTR) 함수는 fopen으로 연 파일 포인터를 참조해서 char 하나를 읽고 반환한다. fgetc 함수의 반환 값은 int 형태이다. text file을 읽을 땐, 0xFF값이 내용에 올 수 없지만, binary file을 읽을 땐 중간에 0xFF 값이 올 수 있다. char 형태로 0xFF를 읽으면 -1값에 해당하기 때문에, EOF와 구분이 불가능하여 char 대신 int를 반환하도록 되어있다. 파일 구조체 fopen은 파일 구조체의 주소(포인터)를 반환한다. 파일 구조체는 아래와 같은 내용을 담고 있다. _flags: _IO_read_ptr : 다음 명령시 파일을 읽거나 쓸 위치 _IO_read_end: kernel에서 데이터를 받아서 저장할 버퍼의 끝 위치. _IO_read_base: kernel에서 데이터를 받아서 저장할 버퍼의 시작 위치. 파일에 대한 읽기 명령(fgetc/fgets등) 이 발생했을 때, kernel은 4096byte(BUF_SIZE) 만큼 데이터를 미리 읽어서 이곳에 채워둔다. _fileno: 파일의 offset, kernel에서 해당 파일에 정해준 index(kernel 함수에서 사용할 수 있다.) fopen 시에 파일 구조체가 생성 및 초기화 되지만, IO_read* 인자들은 파일 접근이 이루어짐과 동시에 값이 적용된다. EOF 파일을 끝까지 읽었다고 판단하는 것은, EOF 문자(-1) 으로 판단한다. 하지만 실제파일을 읽어보면 마지막에 -1값이 실제로 들어있지는 않다. EOF 값은 file I/O 함수의 리턴값일 뿐 실제 파일에 기입된 값이 아니다. file I/O 함수는 i-node에 기록된 파일의 크기를 기반으로 파일 끝을 판단한다. ASKII 코드 중 주요 문자의 값 참조 a: 97 A: 68 0: 48 \\n: 10 \\r: 13 (공백): 32 \\t: 9 \\0: 0 fguts(BUFF, SIZE, FPTR) 함수는 fopen으로 연 파일 포인터를 참조해서 line 하나를 읽어온다. fputs(BUFF, FPTR) 함수는 fopen으로 연 파일 포인터를 참조해서 line 하나를 출력한다. 리눅스에서 표준 입력/출력/에러는 기본적으로 파일 포인터를 열어둔다. 각각 아래 문자열 혹은 번호로 참조 가능하다. stdin : 표준 입력 stdout : 표준 출력 stderr: 표준 에러 -\u0026gt; 파일 포인터 대신 stdout 을 입력하면 표준 출력으로 문자열이 출력된다. (ex: fputc(BUF, stdout))\nfile offset fopen 으로 파일을 열게 되면 user는 파일의 읽고 쓸 위치를 설정하지 않는다. 파일을 읽고 쓸 위치를 file offset이라고 하며, kernel 내부의 파일 구조체를 사용하여 kernel에서 자체적으로 관리된다. fseek \u0026amp; ftell fseek(FILE_POINTER, OFFSET, POSITION) : 파일의 POSITION에서 offset 만큼 file offset을 이동. POSITION은 아래 세 가지를 사용 가능하다. SEEK_SET : 파일의 처음 위치 SEEK_CUR : 현재 커서(file offset)의 위치 SEEK_END : 파일의 끝 위치 반환값은 이동 후 file offset의 값이다. ex) fseek (fp, 0, SEEK_SET): 커서를 파일 처음으로 이동 ex) fseek (fp, -10, SEEK_END): 커서를 파일 끝에서 10바이트 앞으로 이동 ex) fseek (fp, 10, SEEK_CUR): 커서를 현재 위치에서 10바이트 뒤로 이동 ftell(FILE_POINTER) : 현재 file offset을 반환 입출력 속도 fgetc / fputc : 바이트 단위로 파일을 읽거나 쓰는 함수 fgets / fputs : 라인 단위로 파일을 읽거나 쓰는 함수 (버퍼가 허용하는 한) fread / fwrite : 특정 크기만큼 파일을 읽고 쓰는 함수\n-\u0026gt; 버퍼 접근 횟수를 적게 할 수록 속도 측면에서 유리하다. (1 \u0026lt; 2 \u0026lt; 3) Application Library vs System Call stdio.h vs fcntl.h : application library는 stdio.h 헤더를, system call은 fcntl.h 헤더에 함수가 정의되어 있다. fopen(FILE_POINTER, TYPE) vs open(FILE_DESCRIPTOR, FLAG, AUTHORITY) : 파일을 여는 함수 fopen은 FILE 타입의 file pointer를 사용하지만, open은 int 타입의 file descriptor를 사용한다. fopen은 \u0026ldquo;r\u0026rdquo;, \u0026ldquo;w\u0026rdquo; 등 파일 용도를 지정하지만, open은 flag로 읽기/쓰기 등 옵션을 적용한다. (flag는 | 연산자로 복합 적용할 수 있음) O_RDONLY: 읽기 전용 O_WRONLY: 쓰기 전용 O_RDWR: 읽기/쓰기 모두 O_CREAT: 파일 없으면 생성 O_EXCL: 파일 존재시 error 반환 O_APPEND: 기존에 있던 파일 맨 뒤부터 이어쓰기 O_TRUNC: 기존에 있던 파일 지우고 처음부터 쓰기 fread vs read : 파일을 읽는 함수 fwrite vs write : 파일에 출력하는 함수 fclose vs close File Descriptor 리눅스에서 파일을 열면, 현재 열어둔 파일마다 index를 매기고, 이를 배열에 저장한다. 이 배열을 file descriptor array라 하고, index를 file descriptor라 한다. file descriptor array의 각 item들은 file structure를 가리킨다. ↱ file descriptor array\r[0] -\u0026gt; [file structure A]\r[1] -\u0026gt; [file structure B]\r[2] -\u0026gt; [file structure C]\r[3] -\u0026gt; [file structure D] file structure는 파일의 metadata를 저장하고 있다(크기, file offset 등). 파일을 열면, 커널 내부적으로 커서를 두고, 어느 위치를 읽을지/쓸지 결정한다. 이를 file offset이라 칭한다. 리눅스는 실행시 stdin, stdout, stderr를 파일 형태로 열고, 이는 각각 0, 1, 2 index에 해당한다. 이후 open() 함수에 의해 열리는 파일들은 3번부터 순서대로 indexing 되며, 이는 커널이 알아서 설정하며 user는 관여할 수 없다. 동일한 이름의 파일들을 여러 번 열더라도, 새로운 file descriptor에 할당된다. Redirection dup(FILE_DESCRIPTOR) 명령은 FILE_DESCRIPTOR 에 해당하는 file structure 주소를 새로운 file descriptor에 담고 반환한다.\n새로운 file structure를 만들지 않고 주소만 복사 해 오기 때문에, 얕은 복사와 같이 file structure 내부의 모든 인자를 두 개의 file descriptor에서 참조할 수 있다. 이 때문에 file structure 에는 몇개의 file descriptor가 file structure를 참조하고 있는지를 나타내는 count 인자가 존재한다. 표준 입출력 에러는 0,1,2 file descriptor를 사용하고 있는데, 이를 close하고 dup를 이용해 원하는 파일 descriptor를 0,1,2 자리에 넣을 수 있다.\n예를 들어 close(1); dup(fd1);을 수행하면 표준 출력을 close하고 1번 descriptor에 fd1 파일을 연결하게 된다.\napplication library에서 표준 입출력을 사용할 때, 내부적으로 read(0, ...), write(1, ...) 을 사용하고 있으므로, printf(\u0026quot;HELLO\u0026quot;); 을 하면 표준 출력으로 \u0026ldquo;HELLO\u0026rdquo; 가 출력되게 된다.\n-\u0026gt; 이렇게 file descriptor 연결 구조를 재구성 하는 작업을 redirection이라 한다.\n파일의 속성 struct stat buf;\rint s = stat(\u0026#34;./file\u0026#34;, \u0026amp;buf); // 성공시 0, 실패시 -1 stat(FILE_NAME, STAT_STRUCT): FILE_NAME 파일에서 stat 데이터(파일 정보)를 추출해 STAT_STRUCT 버퍼에 저장, 데이터는 struct stat 형태이다. sys/stat.h 헤더파일에 정의되어 있다. .st_mode: 2byte로 구성되며, 파일의 종류와 권한을 나타낸다. 파일의 종류는 처음 4bit로 구분이 가능하다. regular, directory, symbolic link 등 종류가 있다. S_ISREG(st.st_mode), S_ISDIR(st.st_mode), S_ISLNK(st.st_mode) 등 매크로로 쉽게 확인 할 수 있다. 다음 3bit는 특수 권한을 타나낸다. 각 bit는 owner, group, other의 특수권한 여부를 나타낸다. 다음 3bit는 owner의 권한을 나타낸다. 각 bit는 read(읽기), write(수정), execute(실행) 권한을 나타낸다. 다음 3bit는 group의 권한을 나타낸다. 각 bit는 read(읽기), write(수정), execute(실행) 권한을 나타낸다. 다음 3bit는 other의 권한(이외 다른 사람)을 나타낸다. 각 bit는 read(읽기), write(수정), execute(실행) 권한을 나타낸다. 디렉터리도 read/write/execute권한을 가지고 있지만, 의미가 달라진다. read : 디렉터리 참조 권한(ls명령) write : 디렉터리 내부에 파일 생성 혹은 삭제 권한 execute : 디렉터리 내부로 이동 권한(cd 명령) 파일 종류\r| 특수권한\r| | owner권한\r| | | group권한\r| | | | ┌ other권한\r[0000][000][000][000][000] .st_nlink 값은 파일에 걸려있는 hard link의 갯수를 나타낸다. (unsigned long int)\n.st_uid 값은 파일을 소유한 user의 uid값을 나타낸다.\n/etc/passwd 경로에 username과 uid 매핑 테이블이 있다. getpwuid 함수로 uid를 넘겨주면 struct passwd 구조체 포인터를 반환해 주는 함수가 있으므로, 사용자 정보가 필요할 경우 이를 사용하면 된다. struct passwd 에는 /etc/passwd 파일에 적히는 데이터들을 그대로 구조체로 담아낸 형태이며, pw_name, pw_passwd, pw_uid, pw_gid 등 데이터를 참조 가능하다. pwd.h 헤더에 정의되어 있다. .st_gid 값은 파일이 속한 group의 gid 값을 나타낸다.\ngetgrgid 함수로 gid를 넘겨주면 struct group 구조체 포인터를 반환해주는 함수가 있다. grp.h 헤더에 정의되어 있다.. 파일 하나에 속한 그룹은 한개 이상일 수 있다. .st_size 값은 파일 크기를 의미한다. (unsigned long int)\n.st_mtime 값은 파일을 마지막으로 수정한 시간이며, 이는 epoch time 값이다.\nctime 함수를 사용하여 ctime(\u0026amp;st.st_mtime)을 활용하면 사용자 친화적으로 변경된 string을 출력할 수 있다. time.h 헤더파일에 정의되어 있다. localtime 함수를 사용하면 epoch time을 받아서 struct tm 구조체에 담아주어 ctime보다 더 유연하게 출력 형태를 정의할 수 있다. ex) printf(\u0026quot;%d월 %d일 %02d:%02d\u0026quot;, _tm-\u0026gt;tm_mon + 1, _tm-\u0026gt; tm_day, _tm-\u0026gt;tm_hour, _tm-\u0026gt;tm_min); .st_rdev 값은 device ID 값으로, 상위 1byte는 major 번호, 하위 1byte는 minor 번호이다. ls 입력시 block device 파일(S_IFBLK)이나 char device 파일(S_IFCHR)들은 파일 크기 대신 major 번호, minor 번호를 출력한다. 심볼릭 링크에 대해 stat을 사용하면, 원본 파일의 정보를 받아오지만, lstat을 사용하면 symbolic link 파일 자체의 정보를 받아온다.\nsymbolic link가 가리키는 원본 파일의 이름은 readlink() 함수에 file path를 넣어 받아올 수 있다. unistd.h 헤더에 선언되어 있다. ls 명령어도 이 정보를 참조하여 파일 정보를 출력 해 준다.\n특수 권한 특수 권한은 3비트로 이루어져 있고, 각각 set_user_id bit, set_group_id bit, sticky bit 를 의미한다. Set User Id\n퍼미션의 일반적인 룰 상 수정할 수 없는 파일도 set_user_id bit를 활성화 하면 수정이 가능하게 된다. ex) 비밀번호는 /etc/shadow 파일에 저장되지만, 이 파일은 일반 user들이 접근할 수 없도록 권한이 설정되어 있다. 하지만, passwd 명령어로 비밀번호를 바꾸면, /etc/shadow에 저장된 비밀번호도 변경할 수 있다. 파일을 실행했을 때 권한은 파일의 소유자가 아닌 실행한 유저의 권한을 따른다. (ps -ef 명령으로 권한 확인 가능) 하지만 set_user_id 비트가 설정된 파일을 실행할 때 파일의 소유자의 권한을 얻게 된다. set_user_id 가 설정되면 ls 명령시 owner의 execute 권한이 \u0026rsquo;s\u0026rsquo; 혹은 \u0026lsquo;S\u0026rsquo;로 표시된다. Sticky Bit\n파일을을 읽고 쓰고 실행하는 것은 \u0026lsquo;파일\u0026rsquo; 자체의 권한을 따른다. 하지만 파일을 생성하고 지우는 것은 파일이 속한 \u0026lsquo;디렉터리\u0026rsquo;의 권한을 따른다. sticky bit를 설정하면 해당 파일은 \u0026lsquo;삭제\u0026rsquo; 동작에 대해 디렉터리의 권한을 따르지 않고, 파일의 소유자만 삭제할 수 있도록 설정된다. sticky bit가 설정되어 있으면 ls 명령시 other의 execute 자리에 \u0026rsquo;t\u0026rsquo; 혹은 \u0026lsquo;T\u0026rsquo;로 표시된다. 연결 계수 \u0026amp; 참조 계수 파일이 지워지는 시점은 연결 계수와 참조 계수가 모두 0이되는 시점이다. 연결 계수\n파일을 생성하면 directory entry와 inode 구조체, data 영역이 생성된다. inode 구조체에는 연결계수(nlink) 값이 1로 설정된다. unlink(D_ENTRY) 함수로 특정 directory entry를 삭제할 수 있다. directory entry가 삭제되면 해당 entry가 참조하던 inode 구조체의 nlink(연결계수) 값도 하나 줄어든다. i-node의 nlink 값이 0 이라면 inode 더이상 해당 파일을 참조하는 entry가 없는 것이다. unlink가 된 시점에 이미 directory entry가 삭제되었기 때문에 해당 파일을 새로 열거나 참조할 방법이 없어진다. 참조 계수\nopen() 함수로 file 구조체를 생성하고, file 구조체는 inode 구조체를 참조한다. inode 구조체는 해당 nlink를 참조하고 있는 \u0026lsquo;file 구조체\u0026rsquo;의 갯수를 count라는 값으로 저장한다. close() 함수로 파일을 닫으면, 파일 구조체가 참조하던 nlink의 참조 계수가 하나 줄어든다. 연결 계수가 0이 된상태라도 참조 계수가 0이 아니면, inode 구조체와 data 영역은 남아있을 수 있다. (file 구조체로 값 참조 가능) 이후 참조 계수마저 0이 된다면 그제서야 inode 구조체와 data 영역을 지운다. 디렉터리 구조 DIR* directory_p = opendir(\u0026#34;.\u0026#34;);\rstruct dirent* directory_entry_p = readdir(directory_p); 디렉터리 정보는 struct dirent 형태의 구조체에 저장된다. struct dirent 구조체는 디렉터리 내부의 파일들의 정보를 담아내는 구조체이다. .d_name: 파일 이름 d_reclen: 파일 이름 길이 d_ino: inode 번호 d_off:: offset opendir() 함수로 directory를 열고 directory pointer를 얻은 다음 readdir() 함수로 directory 정보를 담은 구조체 포인터를 받아온다. directory pointer란, 디렉터리 정보에 접근할 수 있는 포인터이며, file pointer와 유사하게 cursor(offset)를 갖는다. dirent.h 헤더 파일에 정의되어 있다. chdir() 함수로 현재 프로그램이 참조하는 디렉터리 위치를 변경할 수 있다. (쉘에서 cd 명령과 동일) unistd.h 헤더 파일에 정의되어 있다. rewinddir() : 인자로 받은 directory pointer 의 cursor(offset)를 가장 처음으로 되돌리는 명령 커널 명령어 옵션 받기 커널에서 명령어를 사용할 때 - 문자를 사용하여 옵션을 추가할 수 있다. 커널 명령어를 작성할 때 unistd.h 에서 지원하는 getopt 함수를 사용하여 커맨드에 입력된 옵션을 간편하게 파싱할 수 있다. getopt( argc, argv, OPTIONS ): argc와 argv에서 옵션을 파싱한다. OPTIONS 는 옵션으로 처리할 캐릭터들을 char* 형태로 나열한다. (ex: \u0026ldquo;abcd\u0026rdquo;) 한번 호출 할 때 마다 argv를 하나씩 확인하며 OPTIONS에 해당하는 문자열이 들어있을 경우 옵션에 해당하는 캐릭터를 int형으로 반환한다. 옵션이 더이상 없으면 -1 을 반환한다. getopt는 내부적으로 argv의 위치를 변경하여 옵션들을 제일 앞으로 이동시키고, 나머지를 뒤로 옮긴다. -1을 반환하며 옵션 처리가 끝남을 회신한 후에는 전역변수 optind 로 남은 파라미터들을 접근할 수 있다. (ex: argv[optind]) 파일 링크 cp 명령은 directory entry와 i-node, 데이터를 모두 새로 복사하여 생성하는 deep copy 명령이다. 반면 ln 명령은 directory entry만 생성하고, i-node와 데이터를 공유하는 객체를 생성하게 된다. (shallow copy와 유사) ln 명령으로 i-node 데이터를 참조하는 directory entry를 늘리면, i-node안에 n-link 라는 데이터가 증가한다. (해당 i-node 데이터를 참조하는 entry의 개수 표시) 하드 링크 (hard link) mv 명령은 파일을 이동하는 명령으로, \u0026ldquo;복사(cp)\u0026rdquo; 동작과 \u0026ldquo;삭제(rm)\u0026rdquo; 동작을 수행해야 한다. 이때, 데이터가 큰 파일은 복사와 삭제에 자원이 많이 투입된다. 하지만 링크를 사용하여 directory entry만 신규로 생성하고, 기존 directory entry를 unlink 하면 i-node 정보와 data 정보는 복사와 삭제 동작을 수행할 필요가 없기 때문에 연산 속도를 대폭 증가시킬 수 있다. 참조) 디렉터리는 생성과 동시에 n-link 값이 2가 된다. 디렉터리 내부에 \u0026lsquo;.\u0026rsquo; 데이터가 본인을 참조하기 때문. 마찬가지로 \u0026lsquo;..\u0026lsquo;도 부모 디렉터리에 대한 하드링크이다. 심볼릭 링크 (symbolic link) 디렉터리에 대해서는 하드링크를 설정할 수 없도록 커널에서 설정되어 있다. 커널 명령어 중 -R 옵션이 있는 명령들이 있는데, 이는 \u0026lsquo;.\u0026lsquo;과 \u0026lsquo;..\u0026rsquo; 에 대해서는 재귀 호출을 하지 않도록 설정되어 있다. 만약 디렉터리의 하드링크가 가능해지면 이 명령들에 대해 무한 재귀호출이 발생하게 될 수 있어 디렉터리의 하드링크는 금지된다. 파일 시스템이 다르면 하드링크를 설정할 수 없다. 파일 시스템이 다르면 i-node 구조가 다르기 때문에 서로 참조할 수 없다.\n이러한 한계점을 해결할 수 있는 것이 심볼릭 링크이다.\nsymbolic link는 하나의 파일로 취급되며, 디렉터리를 연결시켜도 파일로서 자신의 정보를 가진다.\n(stat 함수와 lstat 함수가 symbolic link에 대해 다르게 동작하는 이유는 stat은 link가 가리키는 대상을 나타내고, lstat은 link 파일 자체를 가리키는 것) symbolic link는 다른 파일 시스템 간에도 연결시킬 수 있다.\n","permalink":"https://aswinblue.github.io/post/linux/system_programming/","summary":"System Programming 프로그램이 동작하는 구조는 크게 application, kernel, HW 로 분리할 수 있다. _____________\r| Library |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Application level\r------------------------------\r_____________\r|System call|\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Kernel level\r------------------------------\r_____________\r| Hardware |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ H/W level\r------------------------------ application level에서는 library를 사용하며, 이 코드들은 library buffer를 사용한다. (open(), read(), write(), close() \u0026hellip;) 시스템에서 제공하는 최적의 buffer 단위로 disk에서 값을 읽어오고, library buffer에 담아두면 작은단위로 읽어올 때 효율적이다. 예를들어, 한 줄씩 파일을 읽어야 한다면, 1byte씩 파일에서 \u0026lsquo;\\n\u0026rsquo;을 감지할 때 까지 읽을 수 있지만, BUF_SIZ만큼 파일에서 읽어서 library buffer에 담아두고 library buffer를 1byte씩 읽으며 \u0026lsquo;\\n\u0026rsquo;를 찾는 것이 실행 속도는 더 빠르다.","title":"System_programming"},{"content":"make 분할 컴파일을 통해 컴파일 작업 효율을 올리고, 이 과정을 자동화 하기 위해 일괄처리를 도와주는 도구이다. batch 파일로 컴파일 하면, 변경점을 감지하지 못해 batch파일을 수정하지 않고서는 분할 컴파일을 수행할 수 없다. make파일은 파일들 간의 의존성을 정의하여, 특정 파일이 수정되면 어떤 파일을 컴파일 해야하는지 알아서 판단해 준다. 리눅스 시스템의 수정 시간을 확인하여, 빌드 결과물이 생성된 시간과 소스가 수정된 시간을 비교해서 컴파일 혹은 링킹이 다시 필요한지 판단하는 원리이다. 기본구조 파일 이름은 Makefile 으로 생성한다. TARGET:DEPENDENCIES\rCOMMANDS COMMANDS 앞에는 공백이 아니라 tab문자이다. COMMAND를 실행하여 TARGET파일 생성한다는 의미이다. TARGET을 생성할 때 DEPENDENCIES 파일들이 필요하다. DEPENDENCIES파일이 수정되면 TARGET파일도 다시 컴파일 해야한다는 의미이다. # 주석 : 주석은 #으로 달 수 있다. @COMMANDS: make파일은 실행시 \u0026lsquo;실행한 명령 원문\u0026rsquo; 과 \u0026lsquo;실행 결과\u0026rsquo; 를 모두 쉘이 출력한다. @를 붙이면 명령 원문은 출력하지 않는다. 기본 형태를 약간 변형하여 명령어를 생성할 수도 있다. DEPENDENCIES 를 없이 TARGET 과 COMMANDS 만 남기면, make TARGET 명령을 입력시 해당 COMMANDS 만 수행되도록 할 수 있다. clean:\rrm -f ${OBJ}${TARGET}\r# make clean 명령시 위 동작 수행\rinstall:\r...\r# 동일한 형태로 다른 명령도 작성 가능 make 파일 정의 COMMANDS 대부분의 명령들은 쉘 명령과 유사하다. echo \u0026lt;VALUE\u0026gt; : VALUE 값을 출력한다. VARIABLE = VALUE : VARIABLE 이라는 이름의 변수를 선언하고, VALUE 값을 대입함 변수 선언시 자기 자신을 참조하는 형태(recursive)는 = 연산자로 사용 불가능하다. (ex: VARIABLE = ${VARIABLE} + DATA) 대신 := 연산과 += 연산을 사용 가능하다. ex) VARIABLE := ${VARIABLE} + DATA, VARIABLE += DATA $(VARIABLE) : VARIABLE 변수에 해당하는 값을 호출 (${VARIABLE} 과 동일) TIP: 컴파일 도구를 변수로 지정해 놓으면 좋다. CC=gcc -\u0026gt; $(CC) -c file.c TIP: 최종 파일 이름을 변수로 지정해 놓으면 좋다. PROJECT_NAME=myProject -\u0026gt; gcc -o $(PROJECT_NAME) file1.o file2.o TIP: .o파일을 만드는 -c 옵션을 CFLAGS 로 변수로 사용하면 좋다. -\u0026gt; CFLAGS = -I./include -c 와 같이 include path 및 기타 설정이 가능하다. TIP: 링킹을 위한 LFLAGS 또한 같은 맥락에서 변수로 활용하면 좋다. ${VARIABLE:ASIS=TOBE} : VALUE 변수에서 ASIS라는 구문을 TOBE라는 구문으로 치환한다. (ex: PROJECT_NAME:my=your-\u0026gt; ${PROJECT_NAME} == yourProject) 내장 매크로 make 파일의 target-dependency-command 라인들에 일일이 파일 이름을 써 넣고 수정하기 번거롭기에, 아래와 같이 매크로를 활용해 좀더 편리하게 작업을 수행할 수 있도록 한다. 내장 매크로를 활용하면 command에 파일 이름을 직접쓰지 않아도 되게 된다. $\u0026lt; : DEPENDENCIES 중 가장 선두 $^ : DEPENDENCIES 전체를 의미 $@ : TARGET을 의미 $* : 확장자가 없는 TARGET을 의미 $? : DEPENDENCIES 중 TARGET보다 수정 시간이 늦은 파일들 .c.o: : Makefile 안에서 언급된 모든 xxx.o 파일을 만들기 위해 동일한 이름을 가진 xxx.c 파일들을 컴파일하여 xxx.o 파일을 생성한다. %.o : %.c : .c.o 와 동일한 효과를 낸다. 좀더 신규 스타일이다. 최종 예시를 보면 다음과 같다. CC = gcc\rCFLAGS = -c\rTARGET = a.out\rOBJ = main.o func1.o\r${TARGET} : ${OBJ}\r${CC} ${OBJ} -o ${TARGET} # gcc main.o func1.o -o a.out 와 동일\r.c.o : # 위에서 언급된 모든 .o 파일(OBJ)을 만들기 위해 .c 파일로 .o 파일 생성\r${CC} ${CFLAGS} $\u0026lt; # $\u0026lt;는 가장 선두의 dependency를 의미함. 즉 gcc -c xxx.c 와 동일 쉘 명령어 make : 현재 경로에 있는 Makefile 을 실행한다. make install : 해당 경로의 소스를 컴파일하여 /usr/local/lib, /usr/local/bin 폴더로 .so파일과 .bin파일 복사 make -f \u0026lt;FILE_NAME\u0026gt; : Makefile 대신 FILE_NAME 을 make파일로 가정하고 실행한다. make -p : 설정된 매크로 옵션들을 확인 가능 ","permalink":"https://aswinblue.github.io/post/c++/make/","summary":"make 분할 컴파일을 통해 컴파일 작업 효율을 올리고, 이 과정을 자동화 하기 위해 일괄처리를 도와주는 도구이다. batch 파일로 컴파일 하면, 변경점을 감지하지 못해 batch파일을 수정하지 않고서는 분할 컴파일을 수행할 수 없다. make파일은 파일들 간의 의존성을 정의하여, 특정 파일이 수정되면 어떤 파일을 컴파일 해야하는지 알아서 판단해 준다. 리눅스 시스템의 수정 시간을 확인하여, 빌드 결과물이 생성된 시간과 소스가 수정된 시간을 비교해서 컴파일 혹은 링킹이 다시 필요한지 판단하는 원리이다. 기본구조 파일 이름은 Makefile 으로 생성한다.","title":"Make"},{"content":"Shell Programming 리눅스 쉘 프로그래밍에 대해 기술한다.\n기본 !/bin/bash : 쉘 파일을 실행할 때 어떤 쉘로 실행될지 설정 하는 것 set -x : 실행되는 내용의 결과를 화면에 출력\n","permalink":"https://aswinblue.github.io/post/linux/shell_programming/","summary":"Shell Programming 리눅스 쉘 프로그래밍에 대해 기술한다.\n기본 !/bin/bash : 쉘 파일을 실행할 때 어떤 쉘로 실행될지 설정 하는 것 set -x : 실행되는 내용의 결과를 화면에 출력","title":"Shell Programming"},{"content":"Aws Aws 로그인 root 로그인과 IAM 로그인이 있다. 필요한 권한만 할당된 IAM 계정을 사용하는 것이 안전하며, root는 외부로 공유되지 않게 하고 보안을 철저히 한다. Window 서버 생성 window 서버 vs Linux 서버\n중소기업쪽에서는 보안 및 관리할 것들이 줄어드는 Window 서버를 많이 선호하는 편이다. t 시리즈는 범용서버이다. t2.large는 꽤 큰 서버이다. 프리티어를 사용하면 일부 서비스를 무료로 사용할 수는 있지만, 성능이 좋지는 않다. 좌측상단 \u0026lsquo;서비스\u0026rsquo;를 선택, EC2를 찾아서 들어간다. (또는 검색창에서 EC2를 검색)\n기본으로 \u0026lsquo;대시보드\u0026rsquo; 에 접근된다. 리소스는 내가 현재 사용하고 있는 제품들을 나타낸다. 리소스에 보안그룹 하나가 떠 있는데, 일종의 방화벽이라 생각하면 된다. 요금과는 상관 없다. 좌측 메뉴에서 인스턴스를 클릭한다.\n내가 만든 인스턴스들을 볼 수 있다. 아직 아무것도 안만들었으면 아무것도 없다. 주황색 버튼 \u0026lsquo;인스턴스시작\u0026rsquo;을 눌러준다. 상단에 보면 7단계가 보여지는데, 이를 모두 수행하면 생성이 완료된다. AMI 선택 Window 이미지를 선택한다. 이미지 ID가 업데이트할 때 마다 달라질 수 있으므로, ID보다 이름을 보고 찾는다. 아이콘에 \u0026lsquo;프리티어사용가능\u0026rsquo; 이라고 적혀있으면 프리티어에서도 사용할 수 있는 이미지다. 이미지는 OS + 기타 설정값을 모두 포함하고 있다. 자동 배포되면 알아서 설치된다. 가상화로 인해 설치가 많이 편해졌다. type 선택 instance 유형을 선택한다. 메뉴에서 직접 체크박스를 선택해 사용할 수도 있고, 드롭박스에 instance 패밀리, 세대를 선택 가능하다. 프리티어 사용 가능한 항목들은 확인 후 선택. 돈은 별로 안나가지만 느리다. CPU 크레딧이라는 용어를 쓴다. T2라지 사이즈의 EC2를 4대정도 갖고 있으면 아무거솓 안해도 하루에 10불정도 나갈 수 있다. 검토 및 시작은 빠르게 시작하기 위해 나머지 설정을 default로 선택하는 것이다. \u0026lsquo;다음\u0026rsquo; 을 클릭하여 인스턴스 세부정보를 선택한다. 인스턴스 세부설정 인스턴스 개수를 원하는 만큼 만들 수 있다. 자동으로 IP, ID, MAC등 각각 할당해준다. 우리가 생성한 네트워크가 있다면 어떤 네트워크에 올릴지 선택 가능. 현재 만들어진 네트워크가 없으면 default 네트워크 하나 선택가능 서브넷 설정하지 않으면 랜덤하게 아무데나 들어간다. default 네트워크는 subnet이 4개가 잡혀있다. 2개 이상의 instance 통신과 관련 public IP는 subnet의 설정을 가져와서 설정하거나(서브넷 사용 설정) 그냥 설정(활성화)하거나 선택 가능 도메인, IAM 선택 가능 절전모드 및 종료 방지 옵션을 선택 가능하다. 검토 및 시작은 다음 옵션을 생략하는 기능이다. 스토리지 추가 OS가 붙는다는 이야기는 스토리지가 붙는다는 이야기이다. 리눅스 서버일 때 VM에 붙는 기본 스토리지는 8GB이다. 윈도우는 기본 30GB이다. 볼륨 유형도 선택 가능. 범용 SSD가 보통이고, 프로비저닝된 IOPS는 속도가 빠름. 마그네틱은 느림 스토리지 암호화도 가능 \u0026lsquo;새 볼륨 추가\u0026rsquo; 버튼으로 추가 스토리지 선택 가능 \u0026lsquo;디바이스\u0026rsquo; 열에서는 이름을 선택하는 것이다. 리눅스에서는 mount할 때 사용할 이름이다. \u0026lsquo;종료시 삭제\u0026rsquo; 옵션으로 EC2종료시 스토리지는 삭제를 안할수도 있다. 태그 추가 VM을 다수로 만들면 태그를 남겨서 검색/관리가 용이하도록 만들어 줄 수 있다. 태그는 key-value값으로 지정이 가능하며 2개 이상도 설정 가능하다. 보안그룹 구성 인스턴스에 대한 트래픽을 제어하는 방화벽 규칙 세트 AWS자체의 방화벽이 따로 있고 종류도 많지만 instance마다 방화벽이 또 따로 존재한다. 새로만들면 이름, 설명에 기본값을 채워준다. 보안그룹은 inbound 규칙을 설정하는 것 기본 규칙으로 RDP(remote desktop protocol)이 있는데, 이를 제거하면 instance로 접속할 방법이 없다. 소스에 0.0.0.0/0은 default라 한다. 누구나 붙을 수 있다는 의미. 누구나 IP만 알면 붙을 수 있지만 key가 없으면 접속이 불가능하도록 되어있음 검토 및 시작 설정한 내용들을 모두 보여준다. 각종 경고들이 뜰 수 있다. 시작하기 선택시 public key, private key 설정팝업 생성됨. 기존 key를 입력하거나 새로 생성할 수 있음 키 페어를 생성하고, 키페어 이름을 설정한 후 다운로드를 하면 .pem파일(private key)가 다운로드 된다. 다운받은것을 확인한 후 시작을 누르면 된다. key가 없으면 instance 접속이 안되니 꼭 확인하도록 한다. 생성이 완료되면 대기중으로 표시되어 있다. 이후 실행중으로 변경됨 완료 후 인스턴스 창으로 가면 생성된 내용이 있다. t2.large는 속도가 빨라 생성이 빠르게 되었다. 성능이 좋지 않으면 pending이 있을 수 있음. private key는 AWS management control에서 다시 받을 수 있는 방법은 없다. 분실한 경우 instance를 새로 생성해야됨. RDP를 이용한 window 서버 접속\n생성한 EC2에 이름을 설정 가능하다. 이름을 설정하면 자동으로 태그에도 Name:{이름} 이 기록된다. window에서 기본으로 제공하는 원격 데스크톱 파일로 접속 가능하다. IP주소, port 입력, key 입력 등 작업이 필요 생성한 EC2를 선택하고 상단 작업중 \u0026lsquo;연결\u0026rsquo;을 선택한다. (원하는 EC2에 우클릭을 해도 된다.) RDP 클라이언트를 선택한다. 세션 매니저는 window와 linux용이 아니라 RDP 클라이언트를 선택한다. 원격데스크톱 파일을 다운로드 받는다. 암호 가져오기로 이전에 다운받아놓은 private key를 불러온다. \u0026lsquo;암호해독\u0026rsquo; 버튼을 눌러 해독을 진행 개인키를 바당으로 생성된 암호가 콘솔에 확인된다. 암호를 복사 후 취소를 눌러 창을 끈다. (4)에서 받은 파일을 실행시켜준다. 일반 \u0026lsquo;원격 데스크톱\u0026rsquo; 앱에서 기본 정보가 세팅된 형태로 제공된다. 아까 복사한 암호를 넣고 인증서 처리를 한 후 확인을 누른다. 정보 확인\n원격 데스크톱 창이 열리면 최초 접속이라 window가 각종 설정들을 수행하는 작업을 한다. 데스크톱 우측 상단에 EC2 정보가 떠있다. cmd창에서 IP를 확인해보면 우측상단 정보와 동일하다. disk management를 열어보면 붙여준 스토리지가 확인된다. 디스크 설정\n추가된 스토리지는 확인은 되는데 기본으로 offline이다. 우클릭을 하여 online으로 바꿔주고, 다시 우클릭을 하여 MBR기반으로 initialize 시켜준다. 다시 우클릭을 하여 new simple volume을 선택해 볼륨을 지정해 준다. 완료해 주면 정상적으로 디스크가 연결되고 동작한다. 인스턴스 종료(terminate)\n윈도우 종료로 instance를 끌 수도 있지만, management console을 통해 종료도 가능하다.\ninstance를 선택 후 상단 작업에서 \u0026lsquo;인스턴스 상태\u0026rsquo; -\u0026gt; \u0026lsquo;종료\u0026rsquo; 작업을 클릭한다.\n종료시키면 경고문이 뜬다. 확인을 누르면 \u0026lsquo;종료중\u0026rsquo; 상태로 돌입하며 잠시 후 삭제된다.\n종류 후에도 \u0026lsquo;종료됨\u0026rsquo; 으로 변경되는데 이 상태도 오랫동안 유지된다.\ninstance 생성시 우리는 기본 볼륨 + 추가볼륨을 선택했는데, 기본 볼륨은 instance삭제시 함께 삭제되도록 했고, 추가볼륨은 유지하도록 했다.\n좌측 메뉴의 Elastic Block Store -\u0026gt; \u0026lsquo;볼륨\u0026rsquo;을 선택하면 instance를 삭제하고도 볼륨이 하나 남아있음을 확인 가능하다.\n볼륨도 선택하여 \u0026lsquo;작업\u0026rsquo; -\u0026gt; \u0026lsquo;삭제\u0026rsquo; 작업으로 삭제 가능하다.\n종류 후 instance 대시보드로 들어가면 보안그룹은 그대로 유지됨을 확인할 수 있다.\n보안그룹, 키페어 등 완전히 삭제되지 않는 요소들이 있다.\n요금확인\nCPU가 돌지 않으면 요금이 발생하지 않는다. 검색창에 billing을 검색하면 대금 서비스로 들어가면 비용을 확인할 수 있다. instance 생성, 삭제에 대해서는 크게 비용이 발생하지 않고 연산을 수행하면 그때 과금이 된다. Linux 서버 생성 instance 생성\nAMI 선택 AmazonLinux2 AMI 는 아마존에 최적화된 debian계열 리눅스. 아마존에 필요한 설정들이 기본적으로 세팅된 이미지이다. 타입 선택 세부설정 스토리지 추가 기본으로 8GB 제공한다. 윈도우 30GB와 차이. 태그 보안그룹 기존에 생성된 보안그룹이 있다면 불러와서 사용도 가능하다. 검토 및 확인 확인을 누르면 키페어 설정이 가능하다. 기존 키페어를 사용할 수도 있다. 생성이 완료되면 대기중으로 표시되어 있다. 이후 실행중으로 변경됨 서버 접속\n리눅스 서버는 ssh 프로토콜로 접속이 가능하다. 로컬 PC가 윈도우라면 putty를 통해 접속하자. 리눅스에서 접속할 시, 아래 명령어로 접속 가능 ssh -i \u0026quot;AWS_EC2_KEY.pem\u0026quot; ec2-user@ec2-3-34-96-253.ap-northeast-2.compute.amazonaws.com ppk(putty private key)생성 putygen을 실행하여 기존의 private key(.pem)를 putty에서 사용가능한 key(.ppk)로 변경한다. \u0026lsquo;conversation\u0026rsquo; -\u0026gt; \u0026lsquo;import key\u0026rsquo; -\u0026gt; \u0026lsquo;save private key\u0026rsquo; 비밀번호를 설정해서 만들 수 있지만 경고가 떠도 그냥 생성도 가능하다. ppk(putty private key) 가 생성된다. putty로 접속 좌측 메뉴의 \u0026lsquo;connection\u0026rsquo; -\u0026gt; \u0026lsquo;Auth\u0026rsquo; 항목에서 Private key file for authentication 항목에서 ppk를 불러와 넣는다. 편의설정 Window-\u0026gt;Appearance: font크기 Terminal-\u0026gt;Bell: 소리없음 Terminal-\u0026gt;Keyboard:backspace key = control-H management consol에서 해당 instance를 클릭해 퍼블릭 ipv4 주소를 확인해 복사해온다. putty에 IP를 넣고 연결한다. putty security alert가 발생하지만 무시하고 accept를 누르면 된다. 기본 ID는 \u0026rsquo;ec2-user\u0026rsquo; 이고, 비밀번호는 없다. 키페어 가져오기 로컬에서 이미 사용하고 있던 key를 가져와서 서버에 적용하는 기능\npublic key를 붙여넣으면 AWS에서 관리하는 key를 생성함\nkey 생성 알고리즘과 key 길이가 이미 규정되어있는 경우 직접 생성해서 사용해야 할때 이렇게 사용하면 된다.\nkey 생성 puttygen을 실행하여 generate 버튼을 누르면 마우스 움직임을 기반으로 랜덤 키를 생성해 준다. instance를 이미지로 제작 AMI를 이용하여 instance를 백업\n백업할 instance에 우클릭 -\u0026gt; 이미지 탬플릿 -\u0026gt; 이미지 생성\n좌측 메뉴의 \u0026lsquo;이미지\u0026rsquo; -\u0026gt; \u0026lsquo;AMI\u0026rsquo; 항목을 선택하면 위에서 선택한 instance가 이미지로 생성되고 있다. 시간이 소모되는 작업\n생성된 이미지에 이름을 붙여준다. AWS에서 객체를 생성하면 이름을 붙여주는게 좋다. 나중에 찾기도 편하고 알아보기도 쉬워진다.\n이미지를 생성하지 않고 instance 자체를 복사할 수는 없다.\n백업한 AMI 다른 리전으로 이동\n이동할 AMI에 우클릭 -\u0026gt; AMI 복사 선택 원하는 리전을 선택하여 복사를 수행한다. 완료 후 management console의 현재 지역을 이동한 위치로 이동하면 이미지가 보인다. 백업한 AMI를 다른 계정으로 전달\nAMI에 우클릭 -\u0026gt; 이미지 권한 수정 선택 계정 번호를 입력하면 다른 계정으로 이미지를 전달할 수도 있다. custom AMI로 EC2 시작 원하는 AMI를 선택하고 우클릭 -\u0026gt; \u0026lsquo;시작하기\u0026rsquo; 선택 기존에 EC2 생성 단계와 동일 볼륨 생성 볼륨 메뉴에서 \u0026lsquo;볼륨생성\u0026rsquo; 버튼을 선택한다. 스냅샷은 현재 생성된 instance의 스냅샷 정보가 보이는 것이다. 세팅을 하여 생성하면 available이 보인다. 볼륨 연결 생성된 볼륨에 우클릭을 하여 \u0026lsquo;볼륨 연결\u0026rsquo;을 선택하면 볼륨을 붙일 수 있다. \u0026lsquo;인스턴스\u0026rsquo;항목에는 볼륨을 붙일 instance의 ID를 찾아서 넣는데, AWS에서 자동으로 적어준다. \u0026lsquo;디바이스\u0026rsquo;항목값은 instance에 붙었을 때 가지는 경로이다. 알맞은 형태로 포멧을 수행한다. : sudo mkfs -t ext4 \u0026lt;파일시스템경로\u0026gt; 마운트 : sudo mount /dev/sdf /mnt 확인 : df -h 언마운트 : sudo umount /mnt 스냅샷 생성 스냅샷은 백업의 목적으로 만들어진 개체 볼륨 항목에서 생성된 볼륨을 우클릭하여 스냅샷 생성을 선택한다. 생성된 스냅샷은 스냅샷 목록에서 확인 가능하다. 스냅샷으로 볼륨 생성 스냅샷 선택하고 우클릭하여 \u0026lsquo;볼륨생성\u0026rsquo; 선택 생성된 볼륨은 available 상태로 대기상태 스냅샷으로 이미지 생성 스냅샷을 우클릭하여 \u0026lsquo;이미지 생성\u0026rsquo; 선택\n확인을 누르면 \u0026lsquo;AMI\u0026rsquo; 항목에 새로운 이미지가 available 상태로 생성된다.\n생성된 이미지가를 실행하면 EC2로 실행된다.\n만약 root 시스템이 담기지 않은 볼륨을 스냅샷으로 만들어 이미지로 만든것이라면, 제대로 실행되지 않는다.\n일반적으로 EBS만 이미지를 만드는 용도의 storage\nEFS나 S3로는 root 파일 시스템을 만드는 용도로는 잘 사용하지 않는다.\n리전간 이동 인스턴스나 볼륨은 리전간 이동이 안된다.\n스냅샷이나 AMI 형태로 전달은 가능하다. 스냅샷은 백업용도, AMI는 인스턴스 생성용도로 약간 용도는 다르다.\n스냅샷 목록에서 원하는 스냅샷 선택, 우클릭, 복사 선택. 대상 리전을 선택\n해당 리전에 스냅샷이 이동된다.\nS3서버 백본 속도 테스트 -http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html 경로에서 확인 가능\nS3 서버 생성 검색창에 S3를 검색하여 진입 \u0026lsquo;버킷\u0026rsquo; 메뉴에서 \u0026lsquo;버킷 만들기\u0026rsquo; 버튼을 클릭하여 버킷 생성 내용 설정 버킷 이름 설정. unique 한 이름을 지정해야 한다. 리전 선택 퍼블릭 엑세스 설정 퍼블릭 엑세스 차단을 해제하면 경고문에 확인 체크를 넣어준다. 생성 버튼을 클릭하면 생성 완료 폴더 생성 버킷 안에도 폴더를 생성하여 경로를 만들 수 있다. 생성된 버킷을 클릭하여 진입한다. \u0026lsquo;폴더 만들기\u0026rsquo; 버튼을 클릭하여 폴더를 생성한다. 파일 업로드 생성된 버킷에 진입. 필요하면 폴더 내부로 진입 원하는 파일 및 폴더를 선택하여 업로드 S3 URI(Uniform Resource Identifier) : S3에서 실제 파일이 있는 위치를 URI로 표현 객체 URL(Uniform Resource Locator): 외부에서 S3로 접근하여 파일을 확인할 수 있는 정확한 위치값(가상hosting 기반 URL) 객체 public으로 설정 표시된 URL 경로로 들어가면 접속 권한이 없어 Access Denied 화면이 뜬다. 버킷이 public이어도 내부 객체들을 public으로 지정해 두어야 외부에서 접속할 수 있다. 버킷에 진입하여 원하는 객체를 선택한 후 \u0026lsquo;작업\u0026rsquo; 버튼을 클릭하여 \u0026lsquo;퍼블릭으로 설정\u0026rsquo; 을 눌러주어야 외부에서 접근이 가능해진다. AWS는 default로 private설정을 가져가는것이 정책이다.(S3뿐 아니라 instance, storage도) 객체 삭제 객체를 선택하고 \u0026lsquo;삭제\u0026rsquo; 버튼을 선택한다. AWS에서는 삭제 후 이상이 생길 수 있는 경우에 대비해 서명하듯이 직접 입력하는 과정이 있다. 버킷 생성시 버전관리를 수행하도록 체크했으면 영구삭제가 불가능하다. \u0026lsquo;삭제\u0026rsquo;=\u0026lsquo;삭제 태그 기입\u0026rsquo; 에 해당한다. 버전관리를 하지 않으면 \u0026lsquo;삭제\u0026rsquo;=\u0026lsquo;영구삭제\u0026rsquo; 에 해당한다. Local 파일 백업 IAM (Identity and Access Management) 사용자 생성, 권한 설정, 비밀번호 설정, 조직 생성 등 작업 수행 가능한 메뉴 IAM 시스템에 진입한다. \u0026lsquo;사용자\u0026rsquo; 메뉴로 진입한다. 설정을 원하는 사용자를 선택하여 진입 MFA : Multi Factor Authentication : OTP같은 추가 인증 수단을 설정 엑세스 키 생성 \u0026lsquo;엑세스 키 만들기\u0026rsquo; 버튼을 클릭하여 키를 생성한 후 다운로드 엑세스 키는 CSV 파일로 제공된다. 다운받은 엑세스 키는 Aws CLI를 사용할 때 필요하다. Aws CLI 실행 aws configure 명령 실행 이전에 받은 csv파일에서 AWS Access Key ID, Secret Access Key 기입 default region : ap-northeast-2 default output format : json 명령어를 통해 백업 폴더 설정 aws s3 sync {로컬위치} {s3버킷 URI} ex) aws s3 sync backup_local s3://fastswimmingapple/backup/ S3 서버 해당 버킷의 위치로 찾아가서 새로고침을 하면 업로드 됨을 확인할 수 있다. 정적 웹사이트 호스팅 버킷을 생성한다. public 연결을 허용하여 만든다. 생성된 버킷을 선택하여 진입한다. \u0026lsquo;속성\u0026rsquo; 항목에서 \u0026lsquo;정적 웹사이트 호스팅\u0026rsquo; 항목을 찾아 \u0026lsquo;편집\u0026rsquo;을 클릭한다. 정적 웹사이트 호스팅을 활성화 시켜주고, default 페이지를 설정해 준다. 웹사이트 hosting 외에 redirect도 수행해 줄 수 있다. 설정을 완료하고 다시 \u0026lsquo;속성\u0026rsquo; 항목에서 웹사이트 호스팅 내용을 보면 URL이 적혀있다. URL로 접속하면 403 Forbidden이 뜬다. index.html이 없고 public이 아니라서 그렇다. index.html을 넣고 public으로 설정해 주면 정상적으로 접속이 된다. Cloud Front 연동 버킷을 생성하고, 데이터를 넣어둔다.\nCloudFront 서비스를 검색, Distribution 메뉴에 진입한다.\n\u0026lsquo;Create Distribution\u0026rsquo; 선택\n(1)에서 생성한 버킷을 설정한다. 원하는 설정을 조정하고, 마지막 \u0026lsquo;settings\u0026rsquo;의 \u0026lsquo;Default root object\u0026rsquo;에 html 이름을 입력한다. 생성을 완료하면 distribution메뉴에서 생성된 내용을 확인 가능하다.\nLast Modified : deploying은 업로드 진행중을 뜻하고, 업로드가 완료되면 완료된 날짜가 뜬다. 생성된 distribution에 들어가 distribution domain name을 복사한다.\n복사된 url을 사용하여 (1)에서 생성한 버킷의 원하는 데이터를 참조할 수 있다.\n그냥 버킷의 url을 사용하면 S3에서 가져오는 것이고, Cloud Front의 URL을 사용하면 CloudFront를 거쳐서 오는 경로이다. ex) https://fastrollingbean.s3.sa-east-1.amazonaws.com/cloudfront/AWS.mp4 ex) https://dx0b54w9entj1.cloudfront.net/cloudfront/AWS.mp4 Cloud Front에서 distribution 선택, \u0026lsquo;create invalidation\u0026rsquo;선택, refresh할 파일의 절대 경로를를 입력하면 즉시 refresh 할 수 있다.\nindex.html을 S3에 적힌 주소를 열어도 Cloud Front가 설정되어 있다면 Cloud Front를 통해서 내용을 받아온다. EFS 생성 및 연동 EFS 생성 EFS이름 설정, 사용할 VPC 선택(없으면 default), 가용성 선택(리전 및 AZ설정) EC2에서 보안그룹 설정 이름 설정, VPC 선택, 인바운드 규칙 설정 EFS 설정 생성된 EFS 선택하여 진입 \u0026lsquo;네트워크\u0026rsquo; 탭 선택 후 \u0026lsquo;관리\u0026rsquo; 버튼 클릭 \u0026lsquo;탑재대상\u0026rsquo; 리스트에 EFS가 생성된 리전의 AZ들이 보인다. AZ들\u0026rsquo;보안그룹\u0026rsquo; 은 모두 삭제 후 (2)에서 생성한 보안그룹을 설정해 준다. 연결 생성된 EFS를 선택한 화면에서 \u0026lsquo;연결\u0026rsquo; 버튼을 클릭 팝업창에서 DNS/IP 에 따른 탑재 방법을 선택가능하다. DNS를 사용하면 명령어 한 줄로 mount를 시킬수 있고(sudo mount -t efs -o tls fs-d81999b8:/ efs) IP를 사용하면 NFS 클라이언트 사용하여 AZ마다 일일이 연결해 줘야한다. EC2 생성 생성시 (3)인스턴스 구성 옵션에서 \u0026lsquo;퍼블릭IP자동할당\u0026rsquo;=활성화, 파일시스템을 추가, 위에서 생성한 EFS 선택 EFS 연결 경로는 /mnt/efs/fs1 으로 설정 보안그룹도 이미 생성했으므로 보안그룹 자동 생성 체크박스를 해제 EC2 접속하여 EFS 접속 확인\ndf -h 명령으로 확인하면 /mnt/efs/fs1 경로에 파일 시스템이 mount된 것을 확인할 수 있다. 해당 파일 시스템 안에 내용을 수정하면 즉각적으로 다른 EC2에서도 수정된 것을 확인 가능하다. 이미 생성된 EC2에 EFS 시스템을 적용\nsudo mkdir -p /mnt/efs/fs1 로 디렉터리를 생성한다. sudo mount -t efs -o tls fs-d81999b8:/ /mnt/efs/fs1 명령어로 생성한 디렉터리에 파일시스템을 mount를 해주면 된다. 단, 기본 AMI에는 EFS 툴이 없기 때문에 sudo yum install -y amazon-efs-utils 명령어를 통해 EFS 툴을 설치하고 위 명령어를 수행해야 한다. mysql instance 실행 RDS 검색하여 진입, 데이터베이스 메뉴에서 생성 클릭 엔진유형 선택, 버전 선택 성능에 따라 템플릿 선택, 클래스 설정 DB 접근을 위한 ID/비밀번호 설정 서브넷 그룹 필요에 따라 설정 외부 접근이 필요한 경우 public access 설정 보안그룹을 새로 만들면 3306 mysql 포트가 새로 설정된다. DB 인증은 암호에 추가로 다른 인증방법을 넣을 수 있다. 생성에 5분정도 시간이 소요된다. workbench 실행 mysql DB에 접속이 가능한 Client 프로그램 workbench 프로그램 홈 화면의 Mysql Connections 의 +버튼을 클릭한다. 혹은 상단 메뉴의 Database -\u0026gt; connection를 선택한다. 생성된 RDS의 정보창에서 엔드포인트, 포트를 확인하고 입력란에 host 정보를 기입한다. RDS 생성시 설정한 DB 계정 이름과 비밀번호를 입력하여 접속한다. workbench에서 쿼리 실행 접속에 성공하면 새로운 탭이 뜬다. 각종 쿼리를 활용하여 DB를 조작한다. ex) show databases;\ruse mysql;\rshow tables;\rselect * from db;\rdesc db; mysql RDS 수정 원하는 RDS 항목을 선택하고 \u0026lsquo;수정\u0026rsquo; 버튼을 클릭한다. 생성시 설정한 대부분의 내용들을 수정할 수 있다. 간혹 설정이 변경되면 에러가 나는 경우가 있는데, 이는 AZ가 해당 설정을 지원하지 않는 경우이다. 프리티어를 선택하였을 때 발생할 수 있는 문제이다. RDS 삭제 삭제시 스냅샷을 남길지, 자동 백업 기능을 남길지 등을 선택한다. 지울시 복구가 불가능한 경고문을 확인하였음을 체크하고 삭제가 가능하다. DynamoDB 생성 dynamoDB 검색 후 진입 \u0026lsquo;테이블 만들기\u0026rsquo; 선택 테이블 이름 설정 파티션키, 정렬키 설정(대소문자 구분) 생성된 테이블 선택 후 \u0026lsquo;항목\u0026rsquo; 탭 선택 \u0026lsquo;항목 만들기\u0026rsquo; 선택 후 내용 기입하면 된다. +를 눌러서 추가 데이터 기입 가능 파티션키와 정렬키는 필수 Append : 뒤에 이어붙이기 Instert : 위에 이어붙이기 항목만들기 한번에 \u0026lsquo;항목\u0026rsquo; 하나가 생성된다. DynamoDB 검색 \u0026lsquo;항목\u0026rsquo; 탭에서 UI를 통해 쿼리를 만들어 항목을 검색할 수 있다. 다른 key를 이용해 \u0026lsquo;인덱스\u0026rsquo; 탭에 들어가 \u0026lsquo;인덱스 생성\u0026rsquo;을 클릭한다. 새로운 파티션키와 정렬키를 추가로 정의하고(GSI), 이를 이용해 검색을 할 수 있다. GSI(global secondary index): 테이블 생성시 정의한 파티션키와 정렬키 외에 다른 속성으로 만든 key key 정의시 \u0026lsquo;타입\u0026rsquo;도 영향을 준다. ex)문자열과 숫자는 \u0026lsquo;항목\u0026rsquo; 탭에서 표기되는 내용은 같아도 실제로는 다른 값이므로 검색시 다르게 필터링될수 있다. VPC 생성(마법사) VPC 메뉴 검색 및 진입 좌측 메뉴에서 \u0026lsquo;탄력적IP\u0026rsquo; 선택, IP를 할당 public IP=공인IP, 탄력적IP=고정IP 할당받은 IP를 직접 연결하거나 instance 생성시 연결 가능 VPC 대시보드 메뉴로 진입, \u0026lsquo;VPC마법사 시작\u0026rsquo; 선택 원하는 구조에 따라 선택 사항을 선택한다. 우측에 그림으로 잘 묘사되어 있다. VPC는 논리적인 것임으로 원한다면 계속 추가할 수 있다. 선택 후 public 및 private instance 이름 및 가용영역을 설정하고, 위에서 할당받은 탄력적IP를 기입해 주면, 해당 IP를 이용한 VPC가 생성된다. 시간이 약간 걸릴 수 있다. 대시보드에서 이전과 비교하면 라우팅테이블, 서브넷, 인터넷 게이트웨이, 네트워크 ACL, 보안그룹 등이 신규로 추가됨을 확인할 수 있다. VPC 생성(수동) 탄력적 IP 생성\n일반적으로는 public IP (공인IP)를 사용하여 외부와 통신을 할 수 있지만, 탄력적IP는 사설IP를 외부 IP로 연동시키기 위해 사용하는 것 VPC메뉴로 이동, VPC 생성\nVPC만 생성하여 시간이 별로 걸리지 않는다. 내부 구성이 아무것도 없는 상태 서브넷으로 이동, 서브넷 생성\n서브넷은 원하는만큼 생성 가능하다. 원하는 VPC를 선택하고, 주소 및 이름 입력하여 생성 인터넷 게이트웨이로 이동, 인터넷 게이트웨이 생성\n게이트웨이는 물리적인 구조이고 가지고 있는 정보가 별로 없다. 연결만 시켜주면 알아서 동작하는 개체 생성하면 게이트웨이는 detached되어있다. VPC에 연결이 필요하다. 생성된 게이트웨이를 클릭하여 VPC에 연결\n우클릭하여 VPC에 연결 선택 원하는 VPC 선택(게이트웨이가 없는 VPC만 보여진다) 연결 후에는 attached로 표기가 변경된다. NAT 게이트웨이 항목으로 이동, NAT게이트웨이 생성\n서브넷을 설정해 준다. NAT는 public 서브넷에 연결되어 private 서브넷이 외부와 통신할 수 있게 하는 용도이다. 위에서 생성한 public 서브넷에 설치해야 한다. 위에서 생성한 탄력적 IP를 선택한다. (사용되지 않은 IP만 보여진다.) NAT 게이트웨이는 사설IP를 공인IP로 변경시켜준다. 생성을 완료하면 pending으로 되어있다. 라우팅테이블을 생성해 연결을 해주어야 available이 된다. 라우팅 테이블 항목으로 이동, 라우팅 테이블 생성\n라우팅 메뉴에 진입하면 생성하지 않았지만 우리가 위에서 생성한 VPC에 대한 라우팅 테이블이 기본적으로 있다. VPC는 자체가 사설망이기 때문에 생성과 동시에 라우팅 테이블을 갖는다. 자동으로 생성된 라우팅 테이블은 private망으로 보면 된다. 우리가 추가로 생성할 라우팅 테이블은 public용 라우팅 테이블이다. 라우팅 테이블을 설정할 VPC 선택하여 생성 생성된 public 라우팅 테이블을 클릭하여 세부정보에서 라우팅 선택, 라우팅 편집 선택 public 라우팅 테이블은 0.0.0.0/0에 대해 \u0026lsquo;인터넷 게이트웨이\u0026rsquo;로 라우팅을 해주어야 한다. 알맞게 설정해 준다. VPC생성시 자동으로 할당된 private 라우팅 테이블을 선택, 라우팅 선택, 라우팅 편집 선택 0.0.0.0/0 에 대해 \u0026lsquo;NAT 게이트웨이\u0026rsquo;로 연결되도록 설정 후 저장 서브넷에 라우팅테이블 적용\n방법1) public 라우팅 테이블의 세부 정보에서 서브넷연결 선택, 서브넷 연결 편집 선택\n이용가능한 서브넷 리스트에서 public용으로 만든 서브넷을 선택하고 연결저장 선택한 서브넷은 이제 public 라우팅 테이블이 적용된다. 방법2) 서브넷 메뉴에서 설정을 원하는 서브넷을 선택하고 세부정보에서 라우팅테이블 선택, 라우팅테이블 편집 선택\n위에서 편집한 라우팅테이블을 찾아 서브넷에 적용한다.\n-\u0026gt; 서브넷 설정이 완료되면 NAT게이트웨이 메뉴로 진입하면 위에서 생성한 NAT게이트웨이가 available 상태로 변경된 것을 확인할 수 있다. peering을 통한 서브넷간 연결 VPC 서비스에서 좌측 메뉴 중 \u0026lsquo;피어링 연결\u0026rsquo; 메뉴 진입, 피어링 생성 현재 리전에서 연결할 VPC 선택 연결할 상대 VPC 선택(리전 및 사용자 설정) 상대방 vpc의 VPC ID 를 복사해서 기입해 준다. peering 생성 peering을 요청한 계정-리전의 VPC 서비스에서 \u0026lsquo;피어링 연결\u0026rsquo; 메뉴로 진입 (1)에서 요청한 내용이 떠있음을 확인하고 우클릭하여 수락을 진행한다. 라우팅 테이블에 peering 주소 추가 peering을 한 각 VPC의 라우팅 테이블 메뉴에 진입하여, 연결한 서브넷에 적용된 라우팅 테이블을 선택, 세부정보의 \u0026lsquo;라우팅\u0026rsquo; 메뉴에 들어가 라우팅 테이블 편집 서로 상대방의 주소를 입력하고, 피어링 타입으로 추가한다. EC2 instance 생성하여 테스트 퍼블릭 IP를 활성화 한다.\n보안그룹 설정시 \u0026lsquo;모든그룹\u0026rsquo; 에 대해 \u0026lsquo;모든프로토콜\u0026rsquo;, \u0026lsquo;모든 포트\u0026rsquo;에 대해 peering 상대방 주소를 입력해 준다.\n리전이 바뀌면 다른 리전에서 사용된 key를 사용할 수 없다. 새로 생성해야 한다. 반대쪽 peering 대상에서도 마찬가지로 동일한 설정으로 생성을 한다.\nputty로 접속하여 각각 ifconfig로 사설IP주소를 확인한 후 서로 사설IP로 ping을 날려본다.\nping이 정상적으로 간다면 성공 subnet을 잘못 설정하거나 보안그룹 설정을 잘못한 경우 정상적으로 ping이 날아가지 않을 수 있다. 보안그룹 설정 ssh 접속 제한 원하는 instance 를 선택하여 해당 instance에 적용된 \u0026lsquo;보안그룹\u0026rsquo;을 찾는다. 해당 보안그룹으로 가서 inboud rule을 편집한다. 기본으로 주어진 ssh 프로토콜 rule을 제거하면 ssh로 접속이 되지 않는다. 원하는 IP로만 ssh 접속을 할 수 있게 ssh프로토콜에 \u0026lsquo;내 IP\u0026rsquo; 로 rule을 추가한다. 현재 접속된 컴퓨터로만 ssh가 접속이 된다. route53으로 도메인 등록 route53 서비스 검색 후 접속\n원하는 도메인 네임 검색하여 가격 확인 후 구매 진행\n구매는 1년단위로 연장할 수 있으며, 구매시 개인정보입력 및 이메일 인증이 필요하다. 같은 이름이라도 prefix에 따라 (.com, .net 등)비용이 다르다. 구매한 name서버를 다른 name서버 서비스에 옮겨서도 1년간 사용할 수 있다. ※구매한 도메인 이름을 \u0026lsquo;mydomain.com\u0026rsquo; 이라고 가정한다. \u0026lsquo;호스팅영역\u0026rsquo; 메뉴로 진입하여 \u0026lsquo;호스팅영역 생성\u0026rsquo;을 진행한다.\n도메인 이름에 mydomain.com을 입력하고 퍼블릭호스팅영역 설정으로 생성하면 된다. 이미 동일한 이름의 호스팅영역이 있다면 따로 만들지 않고 그대로 사용하면 된다. 동일한 이름이 두 개 이상 있을 경우 로직이 꼬일 수 있으므로 추천하지 않는다. 도메인 안에서는 레코드를 추가할 수 있다. 레코드란 주소를 저장하는 방식/내용에 따라 분류된다. NS : 도메인의 네임서버 레코드 SOA : 도메인 관련 정보,권한 관리 레코드 A : IP주소와 도메인 네임을 저장하는 레코드 CNAME : 도메인네임을 도메인네임과 저장하는 레코드 호스팅영역을 생성하면 NS(Name Server), SOA(Start of Authority) 레코드가 기본으로 생성되어 있다. S3와 route 53 연동 S3서버 생성\n웹서버용 S3 생성 버킷 이름을 mydomain.com 으로 설정한다. 버킷 생성 후 속성-\u0026gt;정적웹사이트호스팅 웹사이트 호스팅 활성화, 호스팅 유형=정적웹사이트호스팅 메인페이지를 index.html로 설정 리다이렉션용 S3 생성 버킷 이름을 www.mydomain.com 으로 설정한다. (원한다면 www대신 다른 것으로 넣어도 된다) 버킷 생성 후 속성-\u0026gt;정적웹사이트호스팅 웹사이트 호스팅 활성화, 호스팅 유형=객체에 대한 요청 리다이렉션 호스팅 이름 설정에 \u0026lsquo;mydomain.com\u0026rsquo; 기입\n-\u0026gt; 본 S3서버의 주소로 접속하면 \u0026lsquo;mydomain.com\u0026rsquo;으로 접속된다. A_레코드 생성\n웹 호스팅용 S3서버에 도메인 주소를 연결하는 작업이다. route 53 시스템에서 \u0026lsquo;호스팅 영역\u0026rsquo;메뉴로 진입 \u0026lsquo;호스팅 영역\u0026rsquo; 메뉴에서 위에서 생성된 호스팅 영역을 선택하고 \u0026lsquo;레코드 생성\u0026rsquo; 을 클릭한다. S3서버의 이름이 레코드 이룸과 같아야 한다. 레코드 이름 앞에 suffix를 붙일 수 있는데, 우리는 \u0026lsquo;mydomain.com\u0026rsquo; 앞에 suffix가 없으므로 생략한다. 레코드 유형=A-IPv4 트래픽라우팅 대상 설정에서 \u0026lsquo;별칭\u0026rsquo; 모드로 설정하여 \u0026lsquo;S3웹사이트 엔드포인트에대한 별칭\u0026rsquo; 선택, 리전선택, (1)에서 생성한 웹호스팅용 S3 선택 mydomain.com 으로 접속시 웹호스팅 S3서버의 index.html이 보여진다. CNAME_레코드 생성\n리다이렉션 S3서버에 도메인 주소를 연결하는 작업이다. 리다이렉션 S3서버는 이미 자신의 주소를 가지고 있다. route 53 시스템에서 \u0026lsquo;호스팅 영역\u0026rsquo;메뉴로 진입 \u0026lsquo;호스팅 영역\u0026rsquo; 메뉴에서 위에서 생성된 호스팅 영역을 선택하고 \u0026lsquo;레코드 생성\u0026rsquo; 을 클릭한다. 레코드 이름에 prefix로 \u0026lsquo;www\u0026rsquo;를 넣어준다. S3서버의 이름이 레코드 이룸과 같아야 한다. 레코드 이름 앞에 suffix를 붙일 수 있는데, S3서버의 이름과 동일해지도록 한다. (www대신 다른 이름을 적었다면 알맞게 기입) 레코드 유형=CNAME \u0026lsquo;별칭\u0026rsquo; 토글을 off한다. 값에 리다이렉션용 S3 주소를 입력한다. (\u0026lsquo;http://\u0026lsquo;는 제외하고 www부터 입력한다.) www.mydomain.com으로 접속시 리다이렉션 S3를 통해 웹호스팅 S3서버의 index.html이 보여진다.\n-\u0026gt; 웹호스팅용 S3서버는 CNAME 레코드 생성이 안됨에 주의한다. ELB 생성 VPC 서비스를 검색하여 서브넷 메뉴로 진입, 서브넷 2개 생성(public1, public2)\n이름 및 가용영역 설정, IPv4 CIDR 설정 라우팅 테이블 메뉴로 진입, 라우팅테이블 생성\n생성된 라우팅테이블 선택 후 세부 속성에서 \u0026lsquo;서브넷 설정\u0026rsquo; 선택, 서브넷연결 편집 실행 생성된 서브넷 선택하여 세부 속성에서 라우팅 테이블 탭을 선택하면 안됨, 이는 기본적으로 생성된 내부 연결을 위한 라우팅 테이블이다. EC2 서비스 검색 후 EC2 메뉴로 진입, EC2 instance 2개 생성\n위에서 조작한 VPC, 서브넷을 설정한다. (한개는 public1, 한개는 public2 서브넷을 선택한다) 퍼블릭IP 자동 할당=활성화 각 EC2에 웹서버 구성\nsudo yum install httpd sudo systemctl start httpd.service sudo systemctl enable httpd.service sudo groupadd www sudo usermod -a -G www ec2-user reset cd /var/www sudo chown -R root:www /var/www sudo chmod 2775 /var/www/html cd html vi index.html 후 적당한 내용 작성(EC2-1, EC2-2 서로 내용 다르게) ELB 생성\nEC2 서비스 메뉴에서 로드벨런서 메뉴를 찾아 진입한다. Application 로드밸런를 생성한다. VPC를 선택하고, 가용영역에서 subnet을 선택한다. 보안 설정 구성은 보안 관련 서비스인데, 따로 설정하지 않아도 된다. 보안그룹을 선택해 주고, 라우팅 구성 창으로 넘어간다. 라우팅을 구성하면, 원하는 프로토콜에 대해 LB를 수행할 수 있다. 인스턴스를 대상으로 하고, HTTP 프로토콜에 80번 포트를 대상으로 한다. 고급 상태 검사 설정에서 업데이트 간격 등을 설정할 수 있다. 대상 등록 창에서 LB를 원하는 instance를 선택한다. instance는 앞서 선택한 subnet안에 있는 것들만 보여진다. 원하는 인스턴스 선택 후 추가를 누르면 대상그룹에 인스턴스가 추가된다. 대상그룹에 대상 등록(ELB생성시 5번을 하지 않은 경우)\n생성이 완료되면 \u0026lsquo;대상그룹\u0026rsquo; 메뉴에서 생성한 그룹을 확인할 수 있다. 방금 생성된 그룹을 선택하여 registerTarget를 수행한다. available instances들에서 원하는 인스턴스를 선택하여 \u0026lsquo;Include as pending below\u0026rsquo;, \u0026lsquo;Register pending targets\u0026rsquo; 를 눌러준다. 대상그룹의 상세 속성에서 Health status를 확인했을 때 initialize에서 healthy로 변경되면 정상적으로 수행된 것이다. 결과 확인\n로드밸런서를 들어가면 DNS주소가 생성되어있음을 확인할 수 있다. 해당 DNS 주소를 입력해 http로 접속하면 라운드로빈에 의해 EC2-1, EC2-2의 웹페이지 내용이 번갈아가며 보임을 확인할 수 있다. 인스턴스 하나를 종료시키고 대상그룹 메뉴에서 그룹을 선택하면 \u0026lsquo;health status\u0026rsquo;가 healthy에서 unused로 바뀜을 확인할 수 있다. 이때는 DNS로 접속을 해도 하나의 EC2로만 접속됨을 확인할 수 있다. sticky session\n대상그룹에서 원하는 그룹을 선택 후 \u0026lsquo;Attributes\u0026rsquo; 탭으로 진입해 수정을 누른다. Stickiness라는 메뉴가 확인되면 체크표시를 해 준다. 설정을 완료하면 DNS주소로 접근할 때 새로고침을 해도 최초 접속한 instance에 계속 접속됨을 확인할 수 있다. ALB는 쿠키 기반으로 세션을 잡아준다. stickiness 설정시 duration을 설정할 수 있는데, 접속 후 duration 만큼 시간이 지나면 다른 instance로도 접근이 가능해진다. Auto Scaling EC2 서비스를 검색하면 auto scaling 메뉴를 확인할 수 있다. 시작구성 생성\n시작구성 생성 메뉴를 선택해 진입한 후 시작구성 생성을 클릭한다. AMI 설정 : 내 AMI 혹은 market place에 해당하는 AMI를 검색해서 선택할 수 있다. 하지만 market place 이미지도 내 이미지로 당겨와서 넣는게 더 편함 인스턴스 유형 설정 : t2 micro로 선택한다. t2 micro로 해야 성능이 낮아 부하가 걸릴 수 있고, AZ에 영향을 받지 않고 아무곳에서나 생성이 가능하다. CloudWatch 모니터링을 체크한다. 보안그룹을 선택할 때 새로 생성하는 옵션은 없다. 기존 보안그룹을 선택한다. (보안그룹은 VPC에 의존적이다. 이후 인스턴스를 생성할 VPC에 해당하는 보안그룹을 정의해 줘야한다.) auto scaling 그룹 생성\nauto scaling 그룹 메뉴를 선택해 진입, auto scaling 생성 클릭 시작탬플릿 혹은 구성 선택 시작 탬플릿을 설정해야 한다. 하지만 우리는 탬플릿을 만든적이 없다. 탬플릿 대신 구성으로 변경해 설정할 수 있다. 시작구성으로 전환을 선택하여 (1)에서 생성한 시작구성을 선택한다. 설정 구성 VPC는 디폴트 VPC를 선택한다. 사설 VPC를 선택하면 오류가 날 가능성이 있다(?) 로드밸런서를 연결해서 사용할 수도 있다. 보통은 같이 가지만 지금은 없이 설정한다. 고급 옵션 구성 상태 확인 항목에서 로드 체크 주기를 설정한다. CloudWatch 모니터링 체크를 한다. 4)그룹크기 및 조정 정책 설정 최대,최소,기본 크기(EC2개수)를 설정한다. 조정정책을 사용함으로 설정하고, CPU 사용량에 따른 추적을 설정한다. 알림 설정 부하가 발생할 때 알림이 오도록 설정할 수 있다. 태그설정 결과 확인\nEC2를 만들지 않았다. 대상 설정을 따로 하지 않았다. 하지만 Auto scaling 그룹에 들어가서 생성된 그룹을 클릭, 인스턴스 관리 탭을 들어가면 생성된 인스턴스가 있다. healthy상태의 pending 인 인스턴스가 있다. 시간이 지나 pending이 inService가 되면 정상적으로 세팅된 것이다. 인스턴스 메뉴로 들어가면 인스턴스가 생성됨을 확인할 수 있다. EC2 생성할 때, \u0026lsquo;인스턴스 구성\u0026rsquo; 단계에서 auto scaling을 설정할 수도 있다. 강제 부하 생성, EC2 추가생성 확인\n생성된 instance에 putty로 진입하여 아래 명령어 입력 sudo amazon-linux-extras install -y epel sudo yum install -y stress stress -c 1 생성한 그룹에서 모니터링 탭을 선택하면 현재 상태를 그래프로 확인할 수 있다. 최소 1시간단위밖에 안돼서 즉시 보기는 힘들다. 인스턴스 탭에서 인스턴스가 늘어났는지 확인한다. 지표를 60초 단위로 주었으니 auto scale에서 의사결정을 하여 scale out을 수행할 것이다. 인스턴스가 두개로 늘어났다면, 다시 putty로 돌아가 stress process를 Ctrl+C로 종료시키고, auto scale에 의해 scale in 되는것을 다시 확인한다. 활동 탭에 들어가면 auto scaling 동작에 대한 로그가 남아있다. Cloud Formation 검색창에 Cloud formation 검색 후 서비스 진입 EC2 stack 생성 업로드할 template파일 생성 *.template 이름으로 파일을 생성한다. AMI, instance type 등 세부 설정을 기입한다. 상세 내용은 샘플 파일을 참조한다. 탬플릿에는 stack에 대한 상세 설정이 묘사된다. 스택 메뉴를 선택하여 스택생성(새 리소스 사용)을 선택한다. 이후 준비된 템플릿 옵션을 선택하고 파일을 업로드 한다. 탬플릿을 디자이너로 만들거나 AWS에서 가져올 수 있는데, 우리는 탬플릿을 업로드하여 사용하도록 한다. 파일을 업로드하면 S3 URL이 생긴것을 확인 할 수 있는데, 이는 우리가 올린 stack 탬플릿을 S3에 자동으로 버킷이 만들어져서 업로드 된 것임을 알 수 있다. 스택 세부정보 입력 파라미터에 keyPair 이름을 넣어야 한다. 우리가 생성했던 key 이름과 같아야 한다. 현재 내가 만든 key를 보려면 \u0026lsquo;EC2\u0026rsquo; 서비스에서 \u0026lsquo;네트워크 및 보안\u0026rsquo; -\u0026gt; \u0026lsquo;키페어\u0026rsquo; 를 참조한다. 스택 옵션 구성 IAM에서 우리가 만들 stack이 수행할 수 있는 권한을 지정해 놓은 set을 미리 만들어 놓을 수 있는데, 지금은 그냥 넘어간다. 생성이 완료되면 상세 정보창으로 들어가진다. \u0026lsquo;이벤트\u0026rsquo;에서는 로그를 볼 수 있고, \u0026lsquo;리소스\u0026rsquo;에서는 생성된 객체들을 확인할 수 있다. EC2 서비스의 인스턴스를 확인해도 새로 생성된 인스턴스를 확인할 수 있다. S3 서비스에서 버킷 메뉴를 확인하면 cf-templates\u0026hellip; 형태의 버킷이 확인된다. 우리가 올린 탬플릿이 든 버킷이다. 웹서버 stack 생성 EC2생성 + 아파치 설치까지 적힌 탬플릿을 구성한다. (1-1)에서 수행한 내용을 동일하게 수행 인스턴스가 생성되고 해당 인스턴스의 퍼블릭IP로 진입하면 아파치 메인화면이 보임을 확인할 수 있다. IAM 이전에 보안key pair를 만들었을 때 IAM을 사용하였었다. IAM -\u0026gt; 사용자 -\u0026gt; 보안자격증명 -\u0026gt; 액세스 키 에서 우리가 생성한 키 확인 가능 그룹 생성\nIAM 서비스에서 사용자그룹 메뉴에 진입, 그룹 생성 클릭 이미 생성한 사용자가 있다면 그룹 생성과 동시에 사용자 추가 가능 권한정책에서 원하는 권한을 검색, 체크하여 부여 사용자 생성\n사용자 메뉴에 진입하여 사용자 생성 클릭 이름을 지정하고, 액세스 유형, 비밀번호 설정 후 다음 그룹에 사용자 추가를 클릭하고 다음 마지막 단계에서 생성한 내용에 대한 csv파일을 다운받을 수 있다. 이메일로 내용이 전송되게 할 수도 있다. 생성한 상세 메뉴에서 ARN 주소를 확인할 수 있는데, 이쪽으로 접근하면 자동으로 로그인 화면으로 접근된다. 사용자 권한 추가\n생성 완료된 사용자를 클릭하면 상세 내용중 \u0026lsquo;권한\u0026rsquo; 탭에서 \u0026lsquo;권한추가\u0026rsquo; 버튼을 클릭해 추가 가능 사용자 생성시와 같이 원하는 권한을 검색, 추가할 수 있다. 부여한 권한 삭제는 상세정보의 \u0026lsquo;권한\u0026rsquo; 탭에서 부여된 권한을 확인하고, 해당 row의 오른쪽 끝 X표시를 누르면 권한이 해제된다.\n-\u0026gt; 사용자 변경하여 인스턴스 생성시 권한이 없는 항목에 대해서는 생성이 불가능함을 확인 가능 역할 생성\nAWS 개체들이 수행할 수 있는 작업을 규정한다. IAM서비스에 접속하여 역할 메뉴 진입, 역할 만들기 선택 여러 종류들 중 원하는 개체 유형을 선택한다. (AWS서비스) 원하는 권한을 선택(보기에서는 S3서버 전체 권한) 후 다음 EC2를 생성하여 해당 역할을 할당 인스턴스 생성중 (3)인스턴스 구성 단계에서 IAM역할에 위에서 생성한 role을 설정한다. 인스턴스 생성 인스턴스에서 권한 확인 putty로 인스턴스 접속 후 아래 명령어 수행 aws s3 ls s3://hooon.com -\u0026gt; (OK) aws --region ap-northeast-2 dynamodb scan --table-name UserLeaderboard -\u0026gt; (AccessDeniedException) Cloud watch 인스턴스에 cloud watch 설정 인스턴스를 선택하여 \u0026lsquo;모니터링 및 문제해결\u0026rsquo; -\u0026gt; \u0026lsquo;세부 모니터링 관리\u0026rsquo; 진입, 모니터링 활성화 후 저장 Cloud watch에서 알람 설정 Cloudwatch 서비스에서 \u0026lsquo;경보\u0026rsquo; -\u0026gt; \u0026lsquo;경보상태\u0026rsquo; 메뉴 진입, 경보생성 클릭 지표 선택을 누르면 각 개체별 모니터링 가능한 지표들을 볼 수 있다. EC2를 선택 후 CPU utilization를 검색, 원하는 인스턴스의 CPU utilization 항목을 선택 해당 지표의 값에 대한 감지 조건 및 감지 사이클을 설정해 준 후 다음 클릭. 앞서 설정한 조건에 해당하면 어떤 조치를 취할지 설정 알람을 받을 메일 설정(이메일 인증도 있음) 어떤 알림을 보낼지 \u0026lsquo;주제\u0026rsquo;를 설정. 일반적인 주제를 보낼수도 있고, 새로운 주제 생성도 가능. 완료 후 다음 클릭 EC2에 들어가 부하를 발생하면 지정된 메일로 경보가 날아옴을 확인할 수 있다. ","permalink":"https://aswinblue.github.io/post/cloud/aws/","summary":"Aws Aws 로그인 root 로그인과 IAM 로그인이 있다. 필요한 권한만 할당된 IAM 계정을 사용하는 것이 안전하며, root는 외부로 공유되지 않게 하고 보안을 철저히 한다. Window 서버 생성 window 서버 vs Linux 서버\n중소기업쪽에서는 보안 및 관리할 것들이 줄어드는 Window 서버를 많이 선호하는 편이다. t 시리즈는 범용서버이다. t2.large는 꽤 큰 서버이다. 프리티어를 사용하면 일부 서비스를 무료로 사용할 수는 있지만, 성능이 좋지는 않다. 좌측상단 \u0026lsquo;서비스\u0026rsquo;를 선택, EC2를 찾아서 들어간다. (또는 검색창에서 EC2를 검색)","title":"Aws"},{"content":"GCC C / C++ 언어를 컴파일 해 주는 도구이다. 리눅스에서는 apt 명령으로 설치 가능하며, 윈도우에서는 Mingw을 이용하여 설치 가능하다. gcc는 컴파일러를 포함한 패키지일 뿐, 내부적인 컴파일러는 따로 있다. (cc1 등)\nGCC 컴파일 동작 순서 gcc main.c 파일을 동작시키면 main.c파일을 컴파일하여 실행파일인 a.out 파일을 생성하게 된다.\n하지만 내부적으로는 아래와 같은 과정을 거치게 된다.\n전처리 : c언어로 구현된 .c 파일을 전처리가 완료된 .i 파일로 변환한다.\ngcc -E main.c -o a.i : main.c 파일을 a.i 파일로 전처리 컴파일 : 전처리된 .i 파일을 어셈블리어로 변환\ngcc -S a.i -o a.s : a.i 파일을 a.s 어셈블리어로 어셈블 어셈블: 각 벤더들이 만든 어셈블리어를 목적파일로 변환(어셈블리 언어를 기계어로 변환) gcc -c a.s -o a.o : 어셈블리 파일을 목적 파일 EOL(Executable Linux File)로 변환. 하지만 바로 실행할 수는 없다. file a.o 명령어를 입력 해 보면 \u0026ldquo;LSB relocatable\u0026rdquo; 이라고 표시된다. 즉, 재배치 가능하다는 의미로, 실행 할 수 있는 상태는 아니라는 뜻이다. 링킹: 목적파일에서 참조하는 다른 목적파일들을 linking하여 최종 실행파일을 생성한다.\ngcc a.o -o out : a.o 목적파일로 실행 가능한 파일을 생성한다. file out 명령어를 입력 해 보면 \u0026ldquo;LBS executable\u0026rdquo; 라고 출력된다.\ngcc -v --save-temps -o out : 위 전체 과정을 실행하며 중간 생성물을 남기고, 실행 결과도 출력\n라이브러리 헤더파일에서 include를 하여 사용할 수 있는 목적파일을 라이브러리라고 칭한다.\nC에서 라이브러리 파일은 lib 으로 시작하는 규칙을 지니며 .a 확장자를 가진다\ngcc -c CFILE.c -o OBJ.o 명령으로 OBJ.o 목적파일을 생성했다면, ar rcv libmylib.a OBJ.o 명령으로 libmylib.a라는 사용자 정의 라이브러리/정적 라이브러리를 생성 가능하다.\nar t libmylib.a 로 라이브러리가 가리키는 파일을 검색하면 OBJ.j 파일을 확인할 수 있다.\n라이브러리를 함께 컴파일 할 때 gcc main.c libmylib.a 와 같이 컴파일 할 수도 있지만, 라이브러리를 제대로 활용하는 방법은 gcc main.c -lmylib 와 같이 -l 옵션을 이용한다.\n정적 라이브러리 이름에서 앞쪽의 lib 부분과 뒤쪽의 .a 부분을 제외한 부분이 라이브러리 이름이다. 위 예시에서는 mylib이 라이브러리 이름이다.\n명령어 옵션 -o: 생성될 파일의 이름을 설정. (\u0026lsquo;SRC.c\u0026rsquo; 를 넣으면 결과물은 \u0026lsquo;SRC.o\u0026rsquo;, \u0026lsquo;SRC.s\u0026rsquo; 형태로 나오지만, 실팽파일은 a.out 형태가 된다. 전통적인 unix의 방식) -c: 목적파일 \u0026ldquo;*.o\u0026rdquo; 파일 생성 -E: 전처리된 \u0026ldquo;*.i\u0026rdquo; 파일 생성 -S: 어셈블된 \u0026ldquo;*.s\u0026rdquo; 파일 생성 아무 옵션도 넣지 않으면 실행 파일을 만드는 것이 기본\n-g: gdb(GNU debugger) 로 디버깅 할 때, 소스를 보면서 디버깅 할 수 있게 컴파일 하는 옵션. 디버깅 심벌이 들어가면서 소스 크기가 크게 증가한다. -l: 컴파일시 라이브러리를 추가하는 명령어 gcc -l라이브러리이름 형태로 사용한다. (ex: gcc -lmylib 으로 libmylib.a 라이브러리 첨가 가능) -L: 링크할 라이브러리를 찾을 위치를 추가할 수 있다. gcc -L/usr/local/library 와 같이 경로를 추가할 수 있다. LIBRARY_PATH 환경변수를 참조하도록 되어있으며, LIBRARY_PATH는 일반적으로 /usr/lib 경로를 포함한다.\n-I: include path를 지정해 주는 옵션. gcc -I. (현재위치 추가 명령)와 같이 특정 위치를 include 하도록 할 수 있다. 이렇게 설정한 경로는 .c 파일에서 include\u0026lt;\u0026gt; 명령으로 라이브러리를 참조할 수 있게 한다. -I 옵션으로 경로를 지정하지 않으면 include\u0026quot;\u0026quot; 형태로 같은 경로상의 라이브러리를 참조할 수는 있다.\n-Wall : warning level all, 모든 오류를 출력한다. ","permalink":"https://aswinblue.github.io/post/c++/gcc/","summary":"GCC C / C++ 언어를 컴파일 해 주는 도구이다. 리눅스에서는 apt 명령으로 설치 가능하며, 윈도우에서는 Mingw을 이용하여 설치 가능하다. gcc는 컴파일러를 포함한 패키지일 뿐, 내부적인 컴파일러는 따로 있다. (cc1 등)\nGCC 컴파일 동작 순서 gcc main.c 파일을 동작시키면 main.c파일을 컴파일하여 실행파일인 a.out 파일을 생성하게 된다.\n하지만 내부적으로는 아래와 같은 과정을 거치게 된다.\n전처리 : c언어로 구현된 .c 파일을 전처리가 완료된 .i 파일로 변환한다.\ngcc -E main.c -o a.i : main.c 파일을 a.","title":"Gcc"},{"content":"Linux 생성 배경 Unix unix는 범용 다중 사용자 방식의 시분할 운영체제이다. 즉, multi-user를 목적으로 개발된 운영체제이다. Dennis Ritche, Ken Thompson, Douglas Mcllroy 등이 주축이 되어 개발 이후 다양한 회사들에 의해 개발이 지속되어, 표준화의 필요성이 생겼고, IEEE에서 제안한 POSIX(Portable Operating System Interface) 라는 표준 인터페이스를 따르게 되었다. 리눅스는 unix를 기반으로 개발된 os이다. GNU Richard Stallman이 창시한 FSF(Free Software Foundation) 의 프로젝트 GNU 리눅스도 GNU의 GPL(General Public License) 에 의해 배포된다. 무료로 사용 가능하며 GPL 소스를 적용된 코드를 수정하여 재판매가 가능하지만, 해당 코드를 공개해야 하며, 개발자는 코드로 인해 발생하는 어떤 문제에 대해서도 법적 책임을 지지 않는다. GNU 프로젝트에서 linux를 main os로 채택 Linus Torvalds 리눅스 커널을 최초로 개발하였으며, 현재도 리눅스 커널 최고 설계자로 위치 Git 개발에도 참여하였음 리눅스는 수많은 개발자들이 개발에 동참하기에 개발 속도가 빠르고 분량이 방대하다. 1991년 0.01버전이 공개되고, 1994년 1.0버전이, 1999년 2.4가 발표되었다. 커널은 같지만, Redhat Ubuntu CentOs Fedora 등 다양한 배포 버전이 개발되었다. Linux hierarchy 리눅스는 다음과 같은 구조로 구성되어 하드웨어를 제어한다. Hardware -\u0026gt;\nLinux Kernel -\u0026gt;\nSystem Call Interface -\u0026gt;\nSystem Utilities -\u0026gt;\nLinux Shell\n하드웨어에 가까울 수록 low level, 멀어질 수록 high level 로 동작이 캡슐화 된다. File System 리눅스의 파일 구조는 Tree 형태를 갖고 있다. 가장 최 상단의 경로는 / 이며, root directory라고 칭한다. 모든 주변장치(터미널, 프린터, 디스크) 를 파일로 간주한다. 리눅스는 multi user 를 위한 OS이기 때문에, 각 파일은 접근 권한이 부여된다. file system은 아래와 같이 partition의 연속으로 이루어진다. file system 구조\r---------------------------------\rPartition | Partition | Partition ---------------------------------\rPartition 구조\r------------------------------------------------------------------\rBoot block | Super block | i-node List | Data block ------------------------------------------------------------------\ri-node list 구조\r-------------------------------\ri-node | i-node | i-node | ...\r------------------------------- Boot block Boot block에는 bootstrap loader가 들어있다. Super block Superblock에는 파일 시스템의 정보가 들어있다. 파일 시스템 크기 파일 시스템 내의 자유 블록 수 파일 시스템 내에서 사용 가능한 자유 블록의 리스트 i-node 리스트의 크기 파일 시스템에서 사용 가능한 i-node의 수 파일 시스템에서 사용 가능한 i-node의 리스트 i-node (information node) 각 partition은 i-node list를 가지며, i-node list에는 information node(i-node) 들이 나열되어 있다.\n모든 파일 하나에는 i-node 하나가 할당되며, i-node는 파일의 정보를 나타낸다.\n소유자 ID 파일 유형 파일 접근 권한 파일 접근 시간 링크 수 파일 데이터의 주소 파일의 크기 파일의 이름은 inode 번호와 함께 디렉터리에 기록된다.\ni-node는 부팅시 추가 정보가 포함되어 메모리에 복사된다. 복사된 이 정보를 i-node cache라 한다.\n추가정보에는 참조계수 i-node번호 (ls -li로 확인 가능) 파일 시스템 장치 번호 (ls -l 명령시, 파일 size 대신 major/minor 번호가 표시됨) Data block Data block은 4kB 크기이며, 하나의 파일이 여러 Data block을 가질 수 있다. 디렉터리 구조 /bin : 유저가 사용할 수 있는 명령어나 실행 파일을 보관하는 디렉터리. /boot : 시스템 부팅에 필요한 파일들을 보관하는 디렉터리 /dev : 리눅스에서는 컴퓨터에 연결된 장치들을 디바이스 드라이버라는 파일 형태로 접근하며, 그러한 장치들을 나타내는 파일들은 /dev 경로에 보관된다. /etc : 리눅스에서 동작하는 서비스의 설정 파일들을 보관하는 디렉터리 /home : 각 유저의 홈 디렉토리가 들어가는 디렉터리. /lib : 시스템에 필요한 라이브러리 파일들이 보관되는 디렉터리. /bin 이나 /sbin 에 존재하는 프로그램이 필요로 하는 동적 라이브러리 파일이 /lib 디렉터리에 보관된다. /opt : 최초 설치에 포함되지 않고 유저가 추가로 설치한 프로그램들을 보관하는 디렉터리. (window의 C:\\Program Files 와 유사하다고 보면 된다.) /proc : 리눅스 커널의 상태를 나타내는 파일들을 보관하는 디렉터리 /root : root 유저의 홈 디렉터리 /sbin : /bin 디렉터리와 같이 명령어나 프로그램이 저장되는 디렉터리지만, /sbin은 root 유저가 사용할 수 있는 명령어나 프로그램이 보관된다는 차이가 있다. /tmp : 유저나 프로그램이 파일을 임시로 생성할 떄 사용할 수 있는 디렉터리. 오래된 파일들은 시스템에 의해 자동으로 삭제되므로 주의 /usr : 사용자 바이너리, 문서, 라이브러리, 헤더 파일 등을 담고 있는 디렉터리(윈도우의 C:\\User 폴더와 유사) /var : 프로그램이나 시스템이 실행될 때 저장이 필요한 파일을 저장하는 디렉터리. (ex: /var/log) ","permalink":"https://aswinblue.github.io/post/linux/linux_introduction/","summary":"Linux 생성 배경 Unix unix는 범용 다중 사용자 방식의 시분할 운영체제이다. 즉, multi-user를 목적으로 개발된 운영체제이다. Dennis Ritche, Ken Thompson, Douglas Mcllroy 등이 주축이 되어 개발 이후 다양한 회사들에 의해 개발이 지속되어, 표준화의 필요성이 생겼고, IEEE에서 제안한 POSIX(Portable Operating System Interface) 라는 표준 인터페이스를 따르게 되었다. 리눅스는 unix를 기반으로 개발된 os이다. GNU Richard Stallman이 창시한 FSF(Free Software Foundation) 의 프로젝트 GNU 리눅스도 GNU의 GPL(General Public License) 에 의해 배포된다. 무료로 사용 가능하며 GPL 소스를 적용된 코드를 수정하여 재판매가 가능하지만, 해당 코드를 공개해야 하며, 개발자는 코드로 인해 발생하는 어떤 문제에 대해서도 법적 책임을 지지 않는다.","title":"Linux_introduction"},{"content":"Dev in Linux 리눅스 개발환경 구축을 위한 가이드\n.bashrc 홈 디렉터리에 위치한 user별 설정 파일이다.\nsource ~/.bashrc 명령어로 언제든 새로고침 할 수 있다.\n리눅스 콘솔 프롬프트를 보기 쉽게 색칠하기 위한 설정할 수 있다.\nforce_color_prompt=true\rif [ -n \u0026#34;$force_color_prompt\u0026#34; ]; then\rif [ -x /usr/bin/tput ] \u0026amp;\u0026amp; tput setaf 1 \u0026gt;\u0026amp;/dev/null; then\r# We have color support; assume it\u0026#39;s compliant with Ecma-48\r# (ISO/IEC-6429). (Lack of such support is extremely rare, and such\r# a case would tend to support setf rather than setaf.)\rcolor_prompt=yes\relse\rcolor_prompt=\rfi\rfi\rif [ \u0026#34;$color_prompt\u0026#34; = yes ]; then\rPS1=\u0026#39;${debian_chroot:+($debian_root)}\\[\\033[01;32m\\]\\u\\[\\033[01;36m\\]@\\[\\033[01;35m\\]\\h\\[\\033[00m\\]:\\[\\033[01;033m\\]\\w\\$\\[\\033[00m\\]\u0026#39;\relse\rPS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ \u0026#39;\rfi\runset color_prompt force_color_prompt vi 리눅스에서 활용할 수 있는 기본적인 에디터이다. 진입장벽은 높은 편이지만, 한번 익숙해지면 매우 편리하다.\n~/.vimrc 폴더에 기본 설정을 적용할 수 있다.\n기본적인 설정은 아래와 같이 세팅할 수 있다.\n# 탭을 spacebar 4개로 설정한다. set ts=4 set sw=4 set sts=4\r# 자동으로 indent를 넣어주도록 설정한다. set smartindent\r# 검색시 하이라이트를 넣어준다. set hlsearch\r\u0026#34; \u0026#34; indent for python\u0026#34;\rset smartindent\r\u0026#34; cinwords=if,elif,else,for,while,try,except,finally,def,class\r# 테마를 설정 해 준다. 테마는 \u0026#39;/usr/share/vim/vim[VER]/colors/\u0026#39; 경로에 *.vim 파일이 있어야 한다. 아래는 molokai.vim 파일을 설정하는 방식이다.\r:colorscheme molokai\r:highlight comment term=bold cterm=bold ctermfg=4\r:set hlsearch\r:set expandtab\r:set smartindent\r:set tabstop=4\r:set autoindent\r:set si\r:set shiftwidth=4\r:set cinoptions+=j1 Ctag vi와 함께 쓰이는 툴로, vi 환경에서 파일간 함수/변수 선언위치를 버튼 하나로 이동할 수 있도록 해주는 모듈이다.\ntags라는 파일을 생성하여 기본적인 사용법은 다음과 같다.\n설정 (리눅스 명령어로) ctag를 사용할 가장 root 폴더로 이동한다. ctags -R * 명령어로 하위 폴더의 모든 파일에 대해 태그를 생성한다. (* 대신 *.cpp *.java 등 원하는 파일만 설정할 수도 있다. ) make 모듈이 깔려있다면 make tags 명령으로 커널을 이용하여 더 빠르게 생성할 수도 있다. set tags+=PATH_TO_FILE 형태로 ~/.vimrc 파일에서 tags 경로를 설정해주면, 어떤 위치에서도 ctag 검색이 가능하다. 사용 (vi 창에서) Ctrl + ] : 커서 위치의 함수/변수의 선언부로 이동 (g + ] 로도 가능) Ctrl + T : 이전 위치로 이동 ","permalink":"https://aswinblue.github.io/post/linux/linux_env/","summary":"Dev in Linux 리눅스 개발환경 구축을 위한 가이드\n.bashrc 홈 디렉터리에 위치한 user별 설정 파일이다.\nsource ~/.bashrc 명령어로 언제든 새로고침 할 수 있다.\n리눅스 콘솔 프롬프트를 보기 쉽게 색칠하기 위한 설정할 수 있다.\nforce_color_prompt=true\rif [ -n \u0026#34;$force_color_prompt\u0026#34; ]; then\rif [ -x /usr/bin/tput ] \u0026amp;\u0026amp; tput setaf 1 \u0026gt;\u0026amp;/dev/null; then\r# We have color support; assume it\u0026#39;s compliant with Ecma-48\r# (ISO/IEC-6429). (Lack of such support is extremely rare, and such\r# a case would tend to support setf rather than setaf.","title":"Linux_env"},{"content":"VirtualBox 문제와 해결 root 계정 virtual box를 생성하면 기본 user의 이름은 vboxuser로 세팅되어 있다. 하지만 vboxuser는 sudo 권한이 없어 다른 설정을 수행 할 수가 없다. virtual box에서 root 계정 비밀번호를 변경하는 방법은 다음과 같다. virtualbox에서 원하는 ubuntu machine를 실행시킨다. machine이 실행되는 도중 shift키를 클릭하고 있는다. 부팅 모드 선택 화면이 뜨면 Advanced options for Ubuntu 를 선택하고, (recovery mode)표시가 되어있는 항목으로 부팅을 시도한다. 로딩이 완료되면 root 라는 항목을 선택하여 root 계정의 비밀번호를 재설정 할 수 있다. ","permalink":"https://aswinblue.github.io/post/linux/virtual_box/","summary":"VirtualBox 문제와 해결 root 계정 virtual box를 생성하면 기본 user의 이름은 vboxuser로 세팅되어 있다. 하지만 vboxuser는 sudo 권한이 없어 다른 설정을 수행 할 수가 없다. virtual box에서 root 계정 비밀번호를 변경하는 방법은 다음과 같다. virtualbox에서 원하는 ubuntu machine를 실행시킨다. machine이 실행되는 도중 shift키를 클릭하고 있는다. 부팅 모드 선택 화면이 뜨면 Advanced options for Ubuntu 를 선택하고, (recovery mode)표시가 되어있는 항목으로 부팅을 시도한다. 로딩이 완료되면 root 라는 항목을 선택하여 root 계정의 비밀번호를 재설정 할 수 있다.","title":"Virtual_box"},{"content":"개발환경 및 기본 지식 구성 파일들 analysis_options.yaml : flutter rule을 설정하는 파일 assets : 이미지 등 리소스들을 저장하는 경로 lib/main.dart : 메인 App 소스가 구동되는 dart 파일 pubspec.yaml : 리소스 경로 및 API들을 설정할 수 있는 파일 (assets 폴더 설정 가능)\n# 경로 설정\rflutter:\rassets:\r- assets/\r# dependency 설정\rdependencies:\rflutter:\rsdk: flutter\rcupertino_icons: ^1.0.2\randroid/app/src/main/AndroidManifext.xml : 안드로이드 앱 개발시 권한 부여를 위한 파일\n빌드 및 실행 main.dart 파일을 지정하고 실행시켜야 한다. 이때, dart 빌드가 아닌 flutter 빌드를 해준다.\n문법 길이 단위 (LP) 길이 단위는 LP로 사용된다. 100LP는 약 2.4cm\nWidget xml의 tag와 유사하게 정의된 형태의 class widget은 대문자로 시작한다. 참조 : (flutter widget library)[https://api.flutter.dev/flutter/material/material-library.html]\nMaterialApp() Scaffold() Row() Column() Text() Icon Container() SizedBox() Center() ","permalink":"https://aswinblue.github.io/post/mobileapp/flutter/","summary":"개발환경 및 기본 지식 구성 파일들 analysis_options.yaml : flutter rule을 설정하는 파일 assets : 이미지 등 리소스들을 저장하는 경로 lib/main.dart : 메인 App 소스가 구동되는 dart 파일 pubspec.yaml : 리소스 경로 및 API들을 설정할 수 있는 파일 (assets 폴더 설정 가능)\n# 경로 설정\rflutter:\rassets:\r- assets/\r# dependency 설정\rdependencies:\rflutter:\rsdk: flutter\rcupertino_icons: ^1.0.2\randroid/app/src/main/AndroidManifext.xml : 안드로이드 앱 개발시 권한 부여를 위한 파일\n빌드 및 실행 main.dart 파일을 지정하고 실행시켜야 한다.","title":"Flutter"},{"content":"Computer Science CPU Segment 프로세스가 사용하는 메모리를 Segment라 칭하며, 리눅스에서는 5가지 종류로 이를 분류한다.\n코드 세그먼트 : 실행 가능한 코드가 위치한 영역으로, text segment라고도 부른다. 데이터 세그먼트 : 코드 실행에 필요한 데이터가 있는 영역으로, 전역변수 및 전역 상수들이 위치한다. 읽기/쓰기가 모두 가능한 데이터들은 data segment에 저장된다. 읽기만 가능한 상수 데이터들은 rodata(read-only) segment 에 저장된다. BSS 세그먼트 : Block Started by Symbol 의 약자로, 컴파일시점에 값이 정해지지 않은 전역변수가 저장되는 영역이다. 이 영역은 프로그램 시작시 모두 0으로 초기화 된다. C에서 전역변수가 0 으로 초기화되는 이유가 이 때문이다. 힙 세그먼트 : 동적으로 할당되는 데이터들을 저장하는 영역이다. 스택과 마주보는 방향으로 증가한다. 스택 세그먼트 : 프로세스의 스택이 위치하는 영역으로, 지역변수 및 함수 인자들이 저장된다. 스택 세그먼트는 메모리 마지막 주소(가장 큰 주소)부터 시작해서 힙과 마주보는 방향으로 증가한다. 운영체제가 프로세스 동작 상황에 따라 스택 영역을 관리한다. 세그먼트는 위에서 언급된 순서대로 메모리에 배치되며, 스택 세그먼트만 특이하게 메모리 가장 마지막을 기준으로 할당된다.\nISA Instruction Set Architecture 의 약자로, 명령어 집합 구조라 해석한다.\nx86-64, ARM, MIPS, AVR 등이 대표적인 예시이다.\n컴퓨터 구조는 \u0026lsquo;기능구조\u0026rsquo; \u0026lsquo;ISA\u0026rsquo; \u0026lsquo;마이크로 아키텍처\u0026rsquo; \u0026lsquo;하드웨어 및 컴퓨팅 방법론\u0026rsquo; 과 같이 레벨에 따라 분류가 가능하다.\nx86-64 아키텍처 레지스터 x86-64 아키텍처는 아래와 같이 레지스터를 용도에 따라 구분한다.\n범용 레지스터(General Register) : 8byte를 저장 가능 아래 용도로 주로 사용되지만 그외 용도로도 다양하게 사용 가능한 레지스터. rax (accumulator register) : 함수의 반환 값 rbx (base register) : x64에서는 주된 용도 없음 rcx (counter register) : 반복문의 반복 횟수, 각종 연산의 시행 횟수 - rdx (data register) : x64에서는 주된 용도 없음 rsi (source index) : 데이터를 옮길 때 원본을 가리키는 포인터 rdi (destination index) : 데이터를 옮길 때 목적지를 가리키는 포인터 - rsp (stack pointer) : 사용중인 스택의 위치를 가리키는 포인터 - rbp (stack base pointer) : 스택의 바닥을 가리키는 포인터 세그먼트 레지스터(Segment Register) : 16bit를 저장 가능 - 과거에는 사용 가능한 물리 메모리의 크기를 늘리기 위해 사용했으나, x64 아키텍처에서는 주소영역이 확장되면서 주로 메모리 보호를 위해 사용 cs, ss, ds, es, fs, gs 종류가 존재 - cs, ds, ss 레지스터는 코드 영역과 데이터, 스택 메모리 영역을 가리킬 때 사용 명령어 포인터 레지스터(Instruction Pointer Register, IP) : 8byte 크기 CPU가 실행할 코드 위치를 가리키는 역할 종류로는 rip 가 있다. 플래그 레지스터(Flag Register) : 64bit 프로세서의 현재 상태를 저장하고 있는 레지스터 - 64비트로 CPU의 현재 상태를 표시한다. 주로 우측 20여개를 사용 CF(Carry Flag) : 부호 없는 수의 연산 결과가 비트의 범위를 넘을 경우 설정 됩니다. ZF(Zero Flag) : 연산의 결과가 0일 경우 설정 됩니다. SF(Sign Flag) : 연산의 결과가 음수일 경우 설정 됩니다. OF(Overflow Flag) : 부호 있는 수의 연산 결과가 비트 범위를 넘을 경우 설정 됩니다. CPU의 레지스터들은 32비트 크기를 가지며, eax, ebx, ecx, edx, esi, edi, esp, ebp 가 있다.\n함수 호출 규약 함수 호출시에는 호출자의 상태와 반환주소를 저장하고, 피호출자가 요구하는 인자, 피호출자의 반환값을 처리해야 한다. 이러한 함수 호출 및 반환 매커니즘약을 \u0026ldquo;함수 호출 규약(convention)\u0026rdquo; 이라한다. 함수 호출 규약은 컴파일러에 의해 적용되며, 컴파일러가 target CPU의 종류에 따라 적합한 규약을 적용 해 준다. 예를 들어, 레지스터가 적은 아키텍처에서는 스택을 통해 함수 인자를 전달하고, 반대의 경우는 적은 인자는 레지스터를 통해, 많은 인자는 스택을 통해 전달하는 방식을 취한다. CPU가 같더라도 컴파일러에 따라 함수 호출 규약이 달라질 수 있다. ex) cdecl, stdcall, fastcall, thiscall SYSV SYSV 규약으로 만들어진 대표적인 예로는 리눅스가 있다. SYSV ABI(Application Binary Interface) 함수 호출 규약에는 ELF 포맷, 링킹 방법 등이 정의되어 있다. SYSV 규약의 특징 함수 호출시 인자를 순서대로 RDI, RSI(ESI), RDX(EDX), RCX(ECX), R8(R8D), R9(R9D) 에 저장하며 더 많은 인자를 받을 땐 스택을 사용한다. ","permalink":"https://aswinblue.github.io/post/computerscience/computer_science/","summary":"Computer Science CPU Segment 프로세스가 사용하는 메모리를 Segment라 칭하며, 리눅스에서는 5가지 종류로 이를 분류한다.\n코드 세그먼트 : 실행 가능한 코드가 위치한 영역으로, text segment라고도 부른다. 데이터 세그먼트 : 코드 실행에 필요한 데이터가 있는 영역으로, 전역변수 및 전역 상수들이 위치한다. 읽기/쓰기가 모두 가능한 데이터들은 data segment에 저장된다. 읽기만 가능한 상수 데이터들은 rodata(read-only) segment 에 저장된다. BSS 세그먼트 : Block Started by Symbol 의 약자로, 컴파일시점에 값이 정해지지 않은 전역변수가 저장되는 영역이다. 이 영역은 프로그램 시작시 모두 0으로 초기화 된다.","title":"Computer_science"},{"content":"Git Cache Cache 확인: git ls-files --stage FILE_PATH Cache 삭제: git rm -r --cached FILE_PATH 'PATH' already exists in the index 오류가 발생했을 때, cache를 확인하고 삭제하면 해결 가능하다. config git config 명령으로 git 관련 setting을 확인 및 설정할 수 있다. git config --list : 설정된 내용 확인 git config --add : 설정 추가 --system : 컴퓨터 환경에 적용 --global : 사용자 환경에 적용 --local : repository별로 설정 적용, default값 git config --global user.name \u0026lt;USER_NAME\u0026gt; : 사용자 이름 설정, 구역 인자를 붙이면 \u0026ndash;add 는 생략가능 git config --global user.email \u0026lt;EMAIL\u0026gt; : 사용자 email 설정, 구역 인자를 붙이면 \u0026ndash;add 는 생략가능 git config --unset : 설정 제거 Submodule 생성 git repository 안에 다른 git repository를 관리할 때 사용한다.\ngit submodule add \u0026lt;REPOSITORY\u0026gt; [PATH] 명령어로 추가 가능하다.\nsubmodule 을 사용했던 repository를 clone 했을 때, submodule이 있던 폴더는 비어있다. 이때 git submodule init [PATH] 명령어로 submodule 안의 내용을 추가할 수 있다.\n추가된 내용은 .gitmodules 파일에 저장된다.\nsubmodule의 remote에 변경점이 생기면 git fetch; git submodule update 를 수행해서 변경점을 반영해 준다.\n각 submodule에서 git 명령어 수행: git submodule foreach [git명령어]\n.gitmodules 파일 업데이트 : git submodule sync\nsubmodule의 내용 pull : git submodule update\n관리 submodule에서 commit을 작성하고, 부모 repository에서 commit을 작성하는 순으로 진행해야 모든 변경점이 정상적으로 반영될 수 있다. (child -\u0026gt; parent 순) 부모 repository는 submodule의 변경점을 직접적으로 관리하지는 않지만, 최종 형태(commit)은 관리한다. remote에서 local로 변경점을 받아올 때는, parent를 먼저 pull 하고 submodule을 pull 한다. (parent -\u0026gt; child 순) submodule을 push하지 않고 parent를 push할 경우, submodule의 현재 commit은 local에만 있고, remote에는 없는 상황이다. 이떄 git clone --recursive 명령어를 사용하여 전체 프로젝트를 받으려 하면, submodule을 clone할 때 remote에 없는 commit을 참조하려 하여 오류가 발생한다. CRLF LF 윈도우 형태의 EOL(\\n) 과 리눅스 형태의 EOL(\\r\\n) 차이 떄문에 git은 autocrlf 명령을 통해 자동으로 개행문자를 바꿔주는 기능을 지원한다.\ngit config \u0026lt;--system\u0026gt; core.autocrlf \u0026lt;false\u0026gt; 명령으로 이 기능을 조절할 수 있다.\n--system : per-system solution --global : per-user solution --local : per-project solution true : LF -\u0026gt; CRLF input : LF -\u0026gt; LF false : don\u0026rsquo;t change 개행 문자 차이 때문에 윈도우에서 정상동작 하던 SHA-256이 리눅스 환경에서 비정상 동작을 할 수 있다.\n이때는 아래 명령을 순서대로 입력하여 git에서 발생한 개행문자 오류를 해결할 수 있다.\ngit config --global core.autocrlf input\rgit rm --cached -r .\r# 이후 commit 수행하면 됨 ","permalink":"https://aswinblue.github.io/post/git/git/","summary":"Git Cache Cache 확인: git ls-files --stage FILE_PATH Cache 삭제: git rm -r --cached FILE_PATH 'PATH' already exists in the index 오류가 발생했을 때, cache를 확인하고 삭제하면 해결 가능하다. config git config 명령으로 git 관련 setting을 확인 및 설정할 수 있다. git config --list : 설정된 내용 확인 git config --add : 설정 추가 --system : 컴퓨터 환경에 적용 --global : 사용자 환경에 적용 --local : repository별로 설정 적용, default값 git config --global user.","title":"Git"},{"content":"Thymeleaf 서버에서 view를 구성할 때 사용하는 라이브러리 태그 형식의 문법을 사용하며 vue와 유사하다. 기본 문법 thymeleaf 공식 튜토리얼 에서 기본적인 문법을 확인할 수 있다. 태그 안에 th:속성=\u0026quot;값\u0026quot; 형태의 속성을 추가하는 형태로 사용한다. text \u0026lt;span th:text=\u0026quot;${text}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: 서버에서 \u0026rsquo;text\u0026rsquo;라는 이름으로 정의한 태그가 있으면 text를 표시한다. text변수가 없으면 \u0026lt;span\u0026gt;default text\u0026lt;/span\u0026gt;를 표시한다. utext \u0026lt;span th:utext=\u0026quot;${utext}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: \u0026rsquo;text\u0026rsquo; 이름으로 정의한 텍스트를 \u0026lsquo;span\u0026rsquo; 태그에 넣어 표시한다. \u0026rsquo;text\u0026rsquo;변수가 없으면 \u0026lsquo;default text\u0026rsquo;를 표시한다. fragment \u0026lt;div th:fragment=\u0026quot;name\u0026quot;\u0026gt;: \u0026rsquo;name\u0026rsquo; 이라는 이름으로 fragment를 생성한다. fragment는 th:replace, th:copy 를 사용해서 재활용 가능하다. copy \u0026lt;div th:copy=\u0026quot;this::name\u0026quot;\u0026gt;: 현재 파일의 \u0026rsquo;name\u0026rsquo; fragment를 \u0026lsquo;div\u0026rsquo;태그로 표현한다. \u0026rsquo;this\u0026rsquo; 대신 파일 이름을 사용하면 다른 파일의 fragment를 사용 가능하다. replace \u0026lt;div th:replace=\u0026quot;this::name\u0026quot;\u0026gt;: 현재 파일의 \u0026rsquo;name\u0026rsquo; fragment로 대체한다.(태그도 바뀐다.) \u0026rsquo;this\u0026rsquo; 대신 파일 이름을 사용하면 다른 파일의 fragment를 사용가능하다. ","permalink":"https://aswinblue.github.io/post/webapplication/thymeleaf/","summary":"Thymeleaf 서버에서 view를 구성할 때 사용하는 라이브러리 태그 형식의 문법을 사용하며 vue와 유사하다. 기본 문법 thymeleaf 공식 튜토리얼 에서 기본적인 문법을 확인할 수 있다. 태그 안에 th:속성=\u0026quot;값\u0026quot; 형태의 속성을 추가하는 형태로 사용한다. text \u0026lt;span th:text=\u0026quot;${text}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: 서버에서 \u0026rsquo;text\u0026rsquo;라는 이름으로 정의한 태그가 있으면 text를 표시한다. text변수가 없으면 \u0026lt;span\u0026gt;default text\u0026lt;/span\u0026gt;를 표시한다. utext \u0026lt;span th:utext=\u0026quot;${utext}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: \u0026rsquo;text\u0026rsquo; 이름으로 정의한 텍스트를 \u0026lsquo;span\u0026rsquo; 태그에 넣어 표시한다. \u0026rsquo;text\u0026rsquo;변수가 없으면 \u0026lsquo;default text\u0026rsquo;를 표시한다. fragment \u0026lt;div th:fragment=\u0026quot;name\u0026quot;\u0026gt;: \u0026rsquo;name\u0026rsquo; 이라는 이름으로 fragment를 생성한다.","title":"thymeleaf"},{"content":"Tailwind Css 프레임워크로 빠르고 효율적으로 css를 설정할 수 있는 툴이다. Tailwind Docs Installation tailwind 모듈 설치\nnpm install -D tailwindcss@latest 명령을 사용하여 설치가 가능하다. npx tailwindcss init 명령을 사용하면 현재 경로에 tailwind.config.js 파일이 생성되며, 현재 프로젝트에서 tailwind를 적용할 수 있게 된다. tailwind.config.js 파일은 다음과 같이 구성된다. module.exports = {\r// 포함할 항목\rcontent: [\u0026#39;./src/**/*.{html,js,jsx,ts,tsx, mustache}\u0026#39;],\r// 제외할 항목 (최신 버전에서 사용되지 않는 문법)\r// purge: [\u0026#34;./src/**/*.html\u0026#34;, \u0026#34;./src/**/*.js\u0026#34;],\r// jit mode는 purge와 함께 세트로 사용되었고, 세트로 사라졌다.(?)\r// mode: process.env.NODE_ENV ? \u0026#39;jit\u0026#39; : undefined,\rdarkMode: \u0026#39;class\u0026#39;, // [false, \u0026#39;mdeia\u0026#39;, \u0026#39;class\u0026#39;]\rtheme: {\rfontFamily: {\rdisplay: [\u0026#39;Open Sans\u0026#39;, \u0026#39;sans-serif\u0026#39;],\rbody: [\u0026#39;Open Sans\u0026#39;, \u0026#39;sans-serif\u0026#39;],\r},\rextend: {\rfontSize: {\r14: \u0026#39;14px\u0026#39;,\r},\rbackgroundColor: {\r\u0026#39;main-bg\u0026#39;: \u0026#39;#FAFBFB\u0026#39;,\r\u0026#39;main-dark-bg\u0026#39;: \u0026#39;#20232A\u0026#39;,\r\u0026#39;secondary-dark-bg\u0026#39;: \u0026#39;#33373E\u0026#39;,\r\u0026#39;light-gray\u0026#39;: \u0026#39;#F7F7F7\u0026#39;,\r\u0026#39;half-transparent\u0026#39;: \u0026#39;rgba(0, 0, 0, 0.5)\u0026#39;,\r},\rborderWidth: {\r1: \u0026#39;1px\u0026#39;,\r},\rborderColor: {\rcolor: \u0026#39;rgba(0, 0, 0, 0.1)\u0026#39;,\r},\rwidth: {\r400: \u0026#39;400px\u0026#39;,\r760: \u0026#39;760px\u0026#39;,\r780: \u0026#39;780px\u0026#39;,\r800: \u0026#39;800px\u0026#39;,\r1000: \u0026#39;1000px\u0026#39;,\r1200: \u0026#39;1200px\u0026#39;,\r1400: \u0026#39;1400px\u0026#39;,\r},\rheight: {\r80: \u0026#39;80px\u0026#39;,\r},\rminHeight: {\r590: \u0026#39;590px\u0026#39;,\r},\rbackgroundImage: {\r\u0026#39;hero-pattern\u0026#39;:\r\u0026#34;url(\u0026#39;https://demos.wrappixel.com/premium-admin-templates/react/flexy-react/main/static/media/welcome-bg-2x-svg.25338f53.svg\u0026#39;)\u0026#34;,\r},\r},\r},\rplugins: [],\r}; tailwind는 react와 같은 framework에서는 자동으로 적용이 가능하지만, 그 외의 경우에는 postcss 등과 같은 모듈의 도움이 필요하다. tailwind 모듈 설치와 tailwind.config.js 구성이 끝났다면, tailwind로 작성된 css를 코드에 추가해줘야 한다. index.css에 아래 구문을 추가한다. @tailwind base;\r@tailwind components;\r@tailwind utilities; postcss\nreact 사용시에는 postcss를 설치하지 않아도 되므로 스킵해도 된다.\nnpm install -D postcss postcss-cli : postcss 모듈과, 명령어 입력을 위한 postcss-cli를 설치한다. 이후 cmd창에 postcss 명령어가 동작한다.\npostcss SOURCE_FILE -o OBJECT_FILE : SOURCE_FILE 의 내용을 참조하여 OBJECT_FILE 경로에 파일 생성. SOURCE_FILE의 내용은 아래와 같다.\n@tailwind base;\r@tailwind components;\r@tailwind utilities; --watch 옵션을 붙이면 파일 변경시 다시 빌드하지 않아도 된다.\nscript\npackage.json 파일에 tailwind용 스크립트를 작성한다.\n\u0026#34;scripts\u0026#34;: {\r\u0026#34;build:postcss\u0026#34;:\u0026#34;npx cross-env NODE_ENV=production postcss base.tailwind.css -o target/classes/static/css/tailwind.css\u0026#34;,\r\u0026#34;watch:postcss\u0026#34;:\u0026#34;npx cross-env NODE_ENV=production postcss base.tailwind.css -o src/main/resources/static/css/tailwind.css -w\u0026#34;\r} 이후 npm run build:postcss 명령으로 쉽게 tailwind 빌드를 할 수 있다.\ntailwind.config.js 를 변경하면 빌드를 새로 해줘야 하지만, -w 옵션으로 동작시키면 tailwind.config.js를 변경해도 실시간으로 변경점이 적용된다.\ntailwind를 적용할 파일들을 앞서 tailwind.config.js 파일에서 \u0026lsquo;content\u0026rsquo; 항목에 넣어 지정했었다. 이 파일들에 새로운 class를 사용하였다면 postcss 명령으로 새로 build를 해줘야 한다.\nConfig Project root 경로에 tailwind.config.js 파일에서 tailwind에 사용되는 custom 설정을 할 수 있다. font theme.extend.fontFamily에 사용할 font 이름을 정의하고,\ntheme: {\rextend: {\rfontFamily: {\rbody: [\u0026#39;Nunito\u0026#39;],\r}\r}\r}, 빌드할 tailwind.css 원본 파일에 해당 font가 정의된 url을 import한다.\ngoogle에서 지원하는 font 사이트 에서 font들 import 가능\n@import url(\u0026#39;@import url(\u0026#39;https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,200;1,200\u0026amp;display=swap\u0026#39;);\u0026#39;)\r@tailwind base;\r@tailwind components;\r@tailwind utilities; Classes tailwind에서 사용되는 대표적인 Class들에 대해 사용법을 설명한다. Box flex flex는 특정 tag 안의 내용물들을 가로로 정렬시켜준다. \u0026lt;div class=\u0026#34;flex\u0026#34;\u0026gt;\r\u0026lt;div\u0026gt;1\u0026lt;/div\u0026gt;\r\u0026lt;div\u0026gt;2\u0026lt;/div\u0026gt;\r\u0026lt;div\u0026gt;3\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt; 위치 정렬 위치는 content, item, self 세 가지에 대해 정렬이 가능하다. y축 정렬(위아래)은 align으로 하고, x축 정렬(좌우)은 justify로 한다. justify content: 가로방향 정렬\njustify-start: 좌측 모서리 기준 정렬 justify-end: 우측 모서리 기준 정렬 justify-center: 가운데 정렬 justify-between: 컨테이너 좌우 공간 없이 각 항목들 동등 간격으로 배치 justify-around: 컨테이너 좌우도 공간을 넣으며 항목들 좌우에 일정한 margin을 두고 배치 justify-evenly: 컨테이너 좌우를 포함하여 항목들 사이 간격이 동일하도록 배치 align items: 세로방향 정렬\nitems-start: 위쪽 모서리를 기준으로 정렬 items-end: 아래쪽 모서리를 기준으로 정렬 items-center: 정중앙 가로선을 기준으로 정렬 items-baseline: container의 baseline, 즉 내용물이 표시되는 기준점이 서로 통일되도록 정렬 items-stretch: 가장 긴 항목에 맞게 다른 항목들을 늘려서 정렬 Responsive items 화면 크기에 따라 다르게 Css를 다르게 적용하고 싶다면, sm:, md:, lg:, xl:, 2xl: class를 이용하면 된다.\n기본 설정으로는 각각 640px, 768px, 1024px, 1280px, 1536px 이상일 때 특정 속성을 갖도록 설정할 수 있다.\n아무것도 붙이지 않으면 0~640px의 속성을 정의하며, 더 큰 화면에 대해서는 sm, md 등으로 속성을 덮어쓰는 형식으로 반응형 페이지를 만든다.\n: 0px ~ 640px sm : 640px ~ 768px md : 768px ~ 1024px lg : 768px ~ 1024px xl : 1024px ~ 1280px 2xl : 1280px ~ 1536px \u0026lt;h1 class=\u0026quot;text-sm md:text-lg lg:text-xl\u0026quot;\u0026gt; test \u0026lt;/h1\u0026gt;\n화면 크기에 따라 글자 크기가 바뀌는 예시 Refs ","permalink":"https://aswinblue.github.io/post/webapplication/tailwind/","summary":"Tailwind Css 프레임워크로 빠르고 효율적으로 css를 설정할 수 있는 툴이다. Tailwind Docs Installation tailwind 모듈 설치\nnpm install -D tailwindcss@latest 명령을 사용하여 설치가 가능하다. npx tailwindcss init 명령을 사용하면 현재 경로에 tailwind.config.js 파일이 생성되며, 현재 프로젝트에서 tailwind를 적용할 수 있게 된다. tailwind.config.js 파일은 다음과 같이 구성된다. module.exports = {\r// 포함할 항목\rcontent: [\u0026#39;./src/**/*.{html,js,jsx,ts,tsx, mustache}\u0026#39;],\r// 제외할 항목 (최신 버전에서 사용되지 않는 문법)\r// purge: [\u0026#34;./src/**/*.html\u0026#34;, \u0026#34;./src/**/*.js\u0026#34;],\r// jit mode는 purge와 함께 세트로 사용되었고, 세트로 사라졌다.","title":"Tailwind"},{"content":"Spring Boot Spring boot는 서버 생성을 위한 도구로, spring 프레임워크에 편의성을 향상시킨 프레임워크이다. Java, Kitlin, Groovy 등의 언어로 구현이 가능하다. 개발환경 java 기반으로 동작하기에 jdk 설치가 필요하다. (22년 기준) 11버전 이상을 다운받는것을 추천한다. IDE vs code를 사용한다면 확장패키지로 \u0026lsquo;Java Extension Pack\u0026rsquo; 과 \u0026lsquo;Spring Boot Extension Pack\u0026rsquo; 을 설치한다. java 개발을 위한 eclips나 intelliJ를 사용해도 된다. spring 프로젝트 생성 start.spring.io 페이지에 들어가면 프로젝트를 생성할 수 있는 UI가 구성되어 있다. 원하는대로 설정 후 다운로드를 받아서 사용하면 된다. gradle 설치 https://gradle.org/releases/ 주소에서 gradle 파일을 다운받는다. 이후 path 설정을 마친 후, 프로젝트 root directory에서 gradle wrapper 명령을 수행해 gradlew파일을 생성한다. 기본 설정 포트 설정 application.properties (혹은 yml)파일을 열고, server.port = 8080 와 같이 기입하면 동작 포트를 8080으로 설정할 수 있다. devtools 설정 정적 파일들을 갱신했을 때, 서버 재실행 없이 explorer만 reload 해 주면 변경점이 반영될 수 있도록 한다.\n이 외에 DB, 포트, mvc, thymleaf 등 각종 설정이 포함된 yml 파일 예시는 다음과 같다.\n```\r# web 서버 동작 설정\rserver:\r# 포트 설정\rport: 8080\r# spring boot 설정\rspring:\rconfig:\ractivate:\ron-profile: deploy\r# h2 database 설정\rh2:\rconsole:\renabled: true\r# jpa 설정\rjpa:\rdatabase: h2\rgenerate-ddl: off\rdatasource:\rdriver-class-name: org.h2.Driver\rurl: jdbc:h2:mem:testdb;MODE=MySQL;\rusername: SA\rpassword:\rinitialization-mode: always\rschema: classpath:schema-h2.sql\rdata: classpath:data-h2.sql\r# spring의 MVC 모델 설정\rmvc:\r# view로 사용할 static resources의 위치 및 파일 확장자 설정\r# thymeleaf가 view역할을 하기 때문에 본 프로젝트에서는 mvc 모듈 내용 활용 안됨\rview:\rprefix: /myApp/\rsuffix: .jsp\r# thymeleaf 설정, MVC에서 view를 담당\rthymeleaef:\rcache: false\rmode: HTML\rencoding: UTF-8\rprefix: file:src/main/resources/templates/\r# web 서버 동작시 설정\rweb:\rresources:\r# resource 위치, html파일에서 참조시 연결될 root 디렉터리\rstatic-locations: file:src/main/resources/static/\rcache:\rperiod: 0\r# devtools 설정, apply static resources instantly\rdevtools:\rlivereload:\renabled: true\r# SLF4J 설정, 로그 시스템\rlogging:\rfile:\rname: ${user.dir}/log/test.log # Log file path\rmax-history: 7 # delete period\rmax-size: 10MB # max size of single log file\rlevel: # set log level to each package\rcom.aswinblue.RankServer : debug\rpattern:\rconsole: \u0026quot;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026quot;\rfile: \u0026quot;%d %p %c{1.} [%t] %m%n\u0026quot;\r```\r빌드 설정\ngradle 프로젝트는 ./gradlew build 명령으로 프로젝트를 빌드한다.\n이때 build.gralde 파일 설정으로 하위 프로젝트의 빌드까지 함께 정의할 수 있다.\ngradle 파일이 수정되면 ./gradlew build 명령을 새로 돌려서 업데이트 해 준다.\n아래는 React 프로젝트의 빌드 세팅이다.\n/*********************\r* 기본 설정 및 dependency\r*********************/\rplugins {\rid \u0026#39;org.springframework.boot\u0026#39; version \u0026#39;2.7.1\u0026#39;\rid \u0026#39;io.spring.dependency-management\u0026#39; version \u0026#39;1.0.11.RELEASE\u0026#39;\rid \u0026#39;java\u0026#39;\r}\rgroup = \u0026#39;com.aswinblue\u0026#39;\rversion = \u0026#39;0.0.1-SNAPSHOT\u0026#39;\rsourceCompatibility = \u0026#39;18\u0026#39;\rrepositories {\rmavenCentral()\r}\rdependencies {\rimplementation \u0026#39;org.springframework.boot:spring-boot-starter-data-jpa\u0026#39;\rimplementation \u0026#39;org.springframework.boot:spring-boot-starter-thymeleaf\u0026#39;\rimplementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39;\rimplementation \u0026#39;com.h2database:h2\u0026#39;\rtestImplementation \u0026#39;org.springframework.boot:spring-boot-starter-test\u0026#39;\rimplementation \u0026#39;org.springframework.boot:spring-boot-devtools\u0026#39; //devtools\r}\rtasks.named(\u0026#39;test\u0026#39;) {\ruseJUnitPlatform()\r}\r/*********************\r* React 설정\r*********************/\rdef reactDir = \u0026#34;$projectDir/src/main/webapp\u0026#34;; // react 프로젝트 경로 설정\rsourceSets{\rmain{\rresources{\rsrcDirs = [\u0026#34;$projectDir/src/main/resources\u0026#34;]\r}\r}\r}\r// 최초로 수행할 task 지정\rprocessResources{\rdependsOn \u0026#34;copyReactBuildFiles\u0026#34;\r}\r// $reactDir 위치에서 `npm audit fix` 명령 실행\rtask installReact(type:Exec){\rworkingDir \u0026#34;$reactDir\u0026#34;\rinputs.dir \u0026#34;$reactDir\u0026#34;\rgroup = BasePlugin.BUILD_GROUP\rif(System.getProperty(\u0026#39;os.name\u0026#39;).toLowerCase(Locale.ROOT).contains(\u0026#39;windows\u0026#39;)){\rcommandLine \u0026#34;npm.cmd\u0026#34;, \u0026#34;audit\u0026#34;, \u0026#34;fix\u0026#34;\rcommandLine \u0026#39;npm.cmd\u0026#39;, \u0026#39;install\u0026#39;\r}else{\rcommandLine \u0026#34;npm\u0026#34;, \u0026#34;audit\u0026#34;, \u0026#34;fix\u0026#34;\rcommandLine \u0026#39;npm\u0026#39;, \u0026#39;install\u0026#39;\r}\r}\r// installReact task를 호출\r// $reactDir 위치에서 `npm run-script build` 실행\r// react 프로젝트의 `package.json` 파일에 적힌 build 스크립트가 실행됨.\rtask buildReact(type:Exec){\rdependsOn \u0026#34;installReact\u0026#34;\rworkingDir \u0026#34;$reactDir\u0026#34;\rinputs.dir \u0026#34;$reactDir\u0026#34;\rgroup = BasePlugin.BUILD_GROUP\rif(System.getProperty(\u0026#39;os.name\u0026#39;).toLowerCase(Locale.ROOT).contains(\u0026#39;windows\u0026#39;)){\rcommandLine \u0026#34;npm.cmd\u0026#34;, \u0026#34;run-script\u0026#34;, \u0026#34;build\u0026#34;\r}else{\rcommandLine \u0026#34;npm\u0026#34;, \u0026#34;run-script\u0026#34;, \u0026#34;build\u0026#34;\r}\r}\r// buildReact task를 호출\r// 앞서 지정한 $reactDir 경로의 /build 위치에서 생성된 데이터를 $projectDir/src/main/resources/static 로 복사\rtask copyReactBuildFiles(type:Copy) {\rdependsOn \u0026#34;buildReact\u0026#34;\rfrom \u0026#34;$reactDir/build\u0026#34;\rinto \u0026#34;$projectDir/src/main/resources/static\u0026#34;\r} 각종 설정을 해주는 batch 파일 예시이다.\ngradle wrapper\rgradlew build\r@REM package.json에 script 작성 필요\rnpm run build:postcss 폴더 설정\nresources : html, css 등 화면 구성을 위한 파일들의 root 디렉터리 resources/static : html파일에서 href로 참조하면 아래 디렉터리를 root로 경로 설정 가능 resources/template : mustache 파일에서 root 디렉터리로 사용 웹 서비스 개발 tomcat spring boot에서 web 패키지를 설치하면 tomcat을 사용하여 web server를 동작시킨다. localhost:8080으로 default 주소가 처리되어 있고, application.yml 파일에서 아래와 같이 수정 가능하다. server:\rport : 8081 MVC 모델 model, view, control 을 나누어 개발하는 형태를 MVC 모델이라고 한다. View template view template 은 controller와 model을 합친 개념으로, 화면을 구성하는 역할을 한다. mustache 패키지를 설치하여 view template를 만들 수 있다. jsp 활용\nSpring boot에는 jsp가 잘 어울리지 않는다고 한다. 대신 Thymleaf, mustache 등을 사용하는걸 권장한다?\njsp를 사용하여 model을 구성할 수도 있다.\njsp는 사용하기 전 application.properties(혹은 yml) 파일의 수정이 필요하다. 아래 내용을 추가한다.\nspring.mvc.view.prefix=/myApp/\rspring.mvc.view.suffix=.jsp 위 내용을 적용하면 src/main/webapp/myApp/ 경로 내부에서 jsp파일을 찾게 된다. \u0026lsquo;webapp\u0026rsquo; 폴더는 default로 필요하다.\nmustache 활용\n앞서 말헀듯 mustache는 view template용 패키지로 controller와 model을 관장한다.\ncontroller는 기본 패키지 경로 하위에 배치한다.\ncontroller는 다음과 같이 구성한다.\npackage com.example.firstproject.controller;\rimport org.springframework.stereotype.Controller;\rimport org.springframework.web.bind.annotation.GetMapping;\rimport org.springframework.ui.Model;\r@Controller // controller를 정의하는 annotation\rpublic class FirstController {\r@GetMapping(\u0026#34;/index\u0026#34;) // 연결될 url을 지정하는 annotation, /index 로 연결하면\rpublic String mainPage(Model model) // model 을 통해 가변 인자 control\r{\rmodel.addAttribute(\u0026#34;title\u0026#34;, \u0026#34;hello world\u0026#34;); // title 이름으로 hello world 라는 문자열을 설정\rreturn \u0026#34;mainPage\u0026#34;; // mainPage.mustache 파일과 연동\r}\r} model(.mustache .html 등)은 resources/templates 파일 경로 하위에 배치하고, 확장자를 .mustache로 지정한다.\nhtml 파일은 사실 view에 가깝지만, mustache 파일은 view에 변수를 적용하여 model에 해당한다.\nmodel은 다음과 같이 구성한다.\n\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;{{title}}\u0026lt;/h1\u0026gt; \u0026lt;!-- controller에서 정의한 title이 {{title}}에 치환됨 --\u0026gt;\r\u0026lt;/body\u0026gt; Layout\nmodel을 만들 때는 layout에 따라 화면에 보여지는 형태를 구성할 수 있다. layout을 template화 하여 사용 가능하다. 재사용 되는 부분을 모듈화 하여 파일로 분리하고, 이를 다른 파일에서 불러올 수 있다. {{\u0026gt;FILE_NAME}} 형태로 다른 파일을 호출해 올 수 있다. Controller Controller는 request를 받아 어떤 화면을 보여줄지 결정하는 routing 로직을 담당하게 된다. controller class는 @Controller annotation을 붙여서 선언하며 routing 함수로는 @GetMapping, @RequestMapping annotation을 사용하여 정의한다. 에러 화면 에러 화면도 controller에 의해 유도되며 BasicErrorController가 이를 담당한다. application.yml 파일에서 따로 설정을 하지 않았다면 server.error.path=/error 가 기본이다. JPA spring은 mysql, postgress, M2 등 여러 DB를 적용할 수 있다. controller는 Java로 구현되고, DB는 sql로 동작하기 때문에 java로 sql을 조작하기 위한 JPA라는 라이브러리가 필요하다. Entity : java 객체를 DB가 이해할 수 있게 재구성한 데이터 @Entity : 해당 class를 entity 로 선언 @Table(name=\u0026quot;\u0026quot;) : 특정 table과 객체를 연동. 기본적으로는 calss 이름에 해당하는 DB의 table과 매핑 된다. @Column : 지정한 변수를 DB의 컬럼으로 선언 Repository : entity를 DB에 저장하는 역할을 수행하는 객체 save(ENTITY) : 저장, DB의 insert / update 에 해당\ndelete(ENTITY) : 특정 Entity 삭제, DB의 delete에 해당\n상세 내용은 링크를 참조한다.\nJPA Usage Links\rJPA Repository Query function JPA Repository Query annotation JPA Repository get Top x result JPA update data from DTO DTO 정의\n서버의 Controller에서 이를 처리 가능하며, 사용자 입력을 Java Class로 대응시킨 형태를 DTO라 칭한다. DTO를 다음과 같이 정의하였다고 하자 class DtoSample {\rprivate String name;\rpublic DtoSample(String name) {\rthis.name = name;\r}\r} Entity 정의\nDTO에 해당하는 entity를 정의해야하며, 그 형태는 다음과 같다. entity는 @Entity annotation을 붙여야 한다. Entity는 primary key를 가져야 하며, 이는 @Id annotation으로 지정한다. DB의 column에 해당하는 값들은 @Column annotation을 붙여준다. @GeneratedValue는 자동으로 생성된 값이 들어가도록 한다. \u0026lsquo;실제 DB table\u0026rsquo; ⊃ \u0026lsquo;DTO에 정의된 column들\u0026rsquo; 이 성립해야 한다. @Entity\rpublic class sampleEntity {\r@Id // 대표값\r@GeneratedValue // 자동생성\rprivate Long id;\r@Column\rprivate String name;\rpublic sampleEntity(Long id, String name) {\rthis.id = id;\rthis.name = name;\r}\r} Repository 구현\nEntity를 DB에 저장하기 위한 Repository도 생성한다. repository는 entity로 DB에 접근하는 방법을 정의하기 위한 객체이다. spring에서 기본으로 제공하는 형태를 상속받아 사용도 가능하다. // CrudRepository\u0026lt;관리대상, 대표값의 type\u0026gt;\rpublic interface searchNameRepository extends CrudRepository\u0026lt;sampleEntity, Long\u0026gt; {\r// CrudRepository 의 기본값을 사용\r} 직접 구상한 쿼리를 사용하고 싶다면 camelcase로 구성된 함수 이름으로 쿼리를 추가할 수 있다.\nTips [no property ~ found for type ~ 오류 해결법](https://stackoverflow.com/questions/19733464/order-by-date-asc-with-spring-data)\rpublic interface searchNameRepository extends CrudRepository\u0026lt;SampleEntity, Long\u0026gt; {\r// select * from SampleEntity where name = ?1 @Query(\u0026#34;Select s From SampleEntity\u0026#34;)\rList\u0026lt;sampleEntity\u0026gt; findByName(String name);\r// select * from SampleEntity where name = ?1 and id = 1\r@Query(\u0026#34;Select s From SampleEntity where s.id = 1\u0026#34;)\rList\u0026lt;sampleEntity\u0026gt; findByName(String name);\r} 기타 추가작업\n이전에 만들었던 controller 에 내용을 추가한다. DTO로 받은 내용을 Entity로 변환시켜 repository를 통해 처리한다. @Autowired // String boot가 알아서 new 해서 사용하는 annotation\rsearchNameRepository snr;\r@PostMapping(\u0026#34;/data/part1\u0026#34;)\rpublic String handleForm(DtoSample dto) {\rsampleEntity name = dto.toEntity(); // toEntity 구현 필요\rname = snr.save(name); // \u0026#39;save\u0026#39;는 저장 및 저장된 데이터를 반환함\rreturn \u0026#34;returnView\u0026#34;;\r} contorller에서 받은 DTO 데이터를 entity로 변환시킬 때 사용한 toEntity() 함수를 구현해야 한다. DTO 파일을 추가로 수정한다. class DtoSample {\rprivate String name;\rpublic DtoSample(String name) {\rthis.name = name;\r}\rpublic sampleEntity toEntity() {\rreturn new sampleEntity(null, this.name); // id에 null을 넣는다. @GeneratedValue에 의해 자동으로 생성된다.\r}\r} 데이터 교환 view에서 사용자 입력을 받아 처리하는 과정을 다룬다. 앞서 JPA를 통해 구현한 DB 시스템에 데이터를 넣을 수 있다. view 구현 view쪽에서는 form 태그를 사용하여 controller에 데이터를 전송할 수 있다. form 태그의 인자로 action, method를 적용 가능하다. action : 데이터를 보낼 url을 설정. ex) action=\u0026quot;/data/part1\u0026quot; method : 전송 방법을 설정한다. post 혹은 get 적용 가능 form 태그 안의 input태그를 두고, 인자로 name을 설정한다. \u0026lt;form action=\u0026#34;/data/userRank\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt;\r\u0026lt;label\u0026gt;type your character name\u0026lt;/label\u0026gt;\r\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;userName\u0026#34;\u0026gt;\r\u0026lt;br/\u0026gt;\r\u0026lt;button\u0026gt;see table\u0026lt;/button\u0026gt;\r\u0026lt;br/\u0026gt;\r\u0026lt;/form\u0026gt; controller 구현 DTO로 사용할 class를 선언한다. (ex: DtoSample) controller 를 구현한 java 파일에서 @PostMapping annotation을 달고, 인자로 위에서 선언한 DTO를 받는다. return 값으로 지정한 이름의 view로 redirect 한다. (ex: returnView) @PostMapping(\u0026#34;/data/part1\u0026#34;)\rpublic String handleForm(DtoSample dto) {\rreturn \u0026#34;returnView\u0026#34;;\r} parameter를 꼭 DTO 형태로 받지 않을 수도 있다. @RequestBody, @RequestParam annotation을 이용하여 데이터를 받을 수 있다. public String handleUserNameForm(@RequestBody String userName, Model model) {}\r// userName = \u0026#34;userName=TESTNAME\u0026#34; 과 같이 데이터가 받아진다. public String handleUserNameForm(@RequestParam String userName, Model model) {}\r// userName = \u0026#34;TESTNAME\u0026#34; 과 같이 데이터를 받을 수 있다. Bean Spring boot를 실행하면 container가 동작하는데, 이 container가 관리하는 객체를 bean이라고 한다. 선언\nComponent 사용 @Component annotation을 class에 붙여주면, 해당 class가 bean으로 등록된다. 직접 구현한 객체를 bean으로 적용할 떄 사용할 수 있다. @AutoWired annotation을 이용해 의존성을 정의할 수 있다. @Component\rclass C {\r// C가 bean으로 등록\rpublic C() {\rSystem.out.println(\u0026#34;use C as bean\u0026#34;);\r}\r@AutoWired\rprivate D d; // D 라는 class에 대한 dependency 정의\r} Bean 사용 @Configuration annotation을 class에 붙여주고, 해당 class에 선언된 함수에 @Bean annotation을 붙여준다. @Bean 이 붙은 함수에서 반환되는 값들은 모두 Bean으로 관리된다. 3rd party에서 구현된 객체를 bean으로 적용할 때 사용할 수 있다. bean으로 반환할 객체 생성자에 인자를 넣어 의존성을 정의할 수 있다. class Foo {\rpublic Foo() {\rSystem.out.println(\u0026#34;use Foo as bean\u0026#34;);\r}\r}\rclass Bar {\rpublic Bar() {\rSystem.out.println(\u0026#34;Bar as dependency\u0026#34;);\r}\r}\r@Configuration\rclass configure {\r@Bean\rpublic Bar bar() {\rreturn new Bar(); // Bar을 bean으로 선언\r}\r@Bean\rpublic Foo foo() {\rreturn new Foo(new Bar()); // Foo가 Bar의 의존성을 가짐을 표현\r}\r} spring은 @ComponentScan annotation이 붙은 class에서 component(bean)을 찾아가기 시작한다. spring 프로젝트를 생성하면 main 함수가 있는 class가 있는데, 이 clalss에 붙은 @SpringBootApplication annotation이 @ComponentScan annotation을 포함하고 있다. @Configuration annotation 도 @Component annotation을 포함하고 있어 scan 대상이 된다. @Controller 로 선언된 class들도 bean으로 관리되는데, 이는 @Controller가 @Component annotation을 포함하고 있기 때문이다. Annotation 및 기능 Value @Value annotation을 변수에 선언하면 프로젝트 설정파일(application.yml) 에서 변수를 가져올 수 있다. @Value(${server.port})\rprivate int port; Scheduled spring boot로 특정 주기마다 반복 동작을 수행하는 기능을 구현할 수 있다. main 함수가 선언된 class에 @EnableScheduling 을 선언한다. schedule을 관리할 class(Scheduler)를 선언하고, @Component annotation을 붙인다. 에서 생성한 Scheduler class에 함수를 선언하고, @Scheduled annotation을 붙인다. @Scheduled(cron = \u0026quot;1 2 3 4 5 ?\u0026quot;) : 매 5월4일3시2분1초 에 동작 숫자대신 *을 하면 모든 값에 동작하도록 설정 가능 앞에서부터 초,분,시,일,월,요일이며 요일은 0이 일요일 6이 토요일, 7또한 일요일이다. 상세 내용은 공식 document 참조 fixedDelay=1000 : 매 1초마다 동작(함수 종료 시점부터 1초) fixedRate=1000 : 매 1초마다 동작(함수 시작 시점부터 1초) SLF4J 로그를 쉽게 설정하기 위한 툴 참조한 사이트 https://allonsyit.tistory.com/43 https://galid1.tistory.com/494 https://atoz-develop.tistory.com/entry/Spring-%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B9%88Bean%EC%9D%98-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%83%9D%EC%84%B1-%EC%9B%90%EB%A6%AC https://goateedev.tistory.com/128 https://itworldyo.tistory.com/40 https://docs.spring.io/spring-data/jpa/docs/current/reference/html/ ","permalink":"https://aswinblue.github.io/post/webserver/spring_boot/","summary":"Spring Boot Spring boot는 서버 생성을 위한 도구로, spring 프레임워크에 편의성을 향상시킨 프레임워크이다. Java, Kitlin, Groovy 등의 언어로 구현이 가능하다. 개발환경 java 기반으로 동작하기에 jdk 설치가 필요하다. (22년 기준) 11버전 이상을 다운받는것을 추천한다. IDE vs code를 사용한다면 확장패키지로 \u0026lsquo;Java Extension Pack\u0026rsquo; 과 \u0026lsquo;Spring Boot Extension Pack\u0026rsquo; 을 설치한다. java 개발을 위한 eclips나 intelliJ를 사용해도 된다. spring 프로젝트 생성 start.spring.io 페이지에 들어가면 프로젝트를 생성할 수 있는 UI가 구성되어 있다. 원하는대로 설정 후 다운로드를 받아서 사용하면 된다.","title":"Spring_boot"},{"content":"Algorithm 그래프 탐색 SP(Shortest Path) 단일 출발점에서 단일 목적지까지 최단 경로를 찾는 알고리즘\nDFS 용도 : 경로가 있는지 확인할 때 사용 가능 자로구조 : stack 방법 : 시작 node를 stack에 넣는다. stack이 모두 빌때까지 아래 동작을 반복한다. stack의 top을 현재 node로 설정한다. 현재 node를 \u0026lsquo;visited\u0026rsquo; 처리하고 stack에서 제거한다. 다음으로 이동할 node가 있는지 확인한다. 다음으로 이동할 node \u0026lsquo;A\u0026rsquo;가 있다면, 현재 node에서 그다음에 탐색할 방향을 stack에 push하고, node \u0026lsquo;A\u0026rsquo;도 stack에 push한다. 더이상 갈 곳이 없으면 현재 node의 visited 처리를 복원한다. 최종 목적지에 도달한 경우를 모아 결과값을 비교한다. 예시 : BFS 용도 : 최단경로 탐색에 사용 가능 자로구조 : queue 방법 : 시작 node를 queue에 넣는다. queue가 비거나 목적지에 도달할 때 까지 아래 동작을 반복한다. queue의 front를 pop 하여 현재 node로 설정한다. 현재 node에서 이동 가능한 node가 있는지 확인하고, 이동 가능하다면 모두 queue에 push한다. queue에 push하면서 해당 경로는 \u0026lsquo;visited\u0026rsquo; 처리를 한다. (주의) queue에 넣으면서 visited 처리를 하고, queue에 넣기전에 방문 여부를 판단해야 메모리 부족을 예방할 수 있다. SSSP (Single Source Shortest Path) 단일 출발점에서 모든 node까지 최단 경로를 찾는 알고리즘\nDijkstra 용도: cycle이 없는 graph 음수 node가 없는 graph 자료구조 : list, heap 방법: 출발점 S에서 각 node까지 거리를 list에 표현한다. 현재 S에서 최적의 거리를 가진 node M을 선택한다. (heap 사용) M을 거쳐서 각 node까지 이동하는 경로와 현재 list에 표기된 값을 비교해 최적을 선택한다. for (edge in graph[M]) { // M에서 발생되는 모든 edge들에 대해\rif (list[M] + edge.cost \u0026lt; list[edge.destination]) { // S -\u0026gt; * -\u0026gt; M -\u0026gt; T 까지 거리가 S -\u0026gt; * -\u0026gt; T 거리보다 짧다면\r// S -\u0026gt; * -\u0026gt; T 거리 = list[M], M -\u0026gt; T 거리 = edge.cost\rlist[edge.destination] = list[M] + edge.cost // 값 갱신\r} Bellman-Ford 용도: 자료구조: 방법: APSP (All Pair Shortest Path) 모든 node에서 모든 node로 가는 최적 경로를 찾는 알고리즘\nFloyd-Warshall 용도: 자료구조: 방법: Dynamic Programming 0 1 knapsack 용도 : 나눌수 없는 물건을 최대 무게 한도로 담고 싶을 때 사용 최소 단위로 나눌 수 있다면 greedy를 사용하면 된다. 자료구조: 2d array 방법: 2차원 배열 D를 선언한다. 행은 최대한도 k를 뜻하며, 열은 1부터 n번째 물건을 판단했을 때 최선의 값을 의미한다.\n최대 한도를 0부터 K까지 늘려가고, 모든 물건을 순회하며 가치(v)와 무게(w)를 고려해 아래 식을 체크한다.\n한도가 k일때 n번째 인자에 대해 D[k][n] = max(D[k - w[n]][n-1] + v[n], D[k - 1])[n-1]\n만약 w[n] \u0026gt; k 라면 그냥 D[k][n] = D[k - 1][n-1]\n2차원배열 대신 1차원 배열을 사용하면, 이미 선택한 인자를 중복해서 선택하게 되므로 오답\n2차원 배열에서 첫 열과 첫 행의 값은 0으로 세팅해 주어야 한다. (아무것도 담지 않은/못한 상황)\n예시: # https://www.acmicpc.net/submit/12865\rif __name__ == \u0026#39;__main__\u0026#39;:\rN, K = map(int, input().split())\rW = [0]\rV = [0]\rfor i in range(N):\rw, v = map(int, input().split())\rW.append(w)\rV.append(v)\rresult = [[0 for j in range(N+1)] for i in range(K+1)]\r# 배낭의 한계를 를 1부터 증가시켜가며 dynamic programming을 수행한다.\rfor i in range(1, K+1):\r# 모든 물건에 대해 물건을 넣었을 때와 넣지 않았을 때를 확인한다.\rfor j in range(1, N+1):\rif W[j] \u0026lt;= i:\r# 확인 결과 더 최선의 값을 도출한다.\rresult[i][j] = max(result[i - W[j]][j-1] + V[j], result[i][j-1]) # 넣었을때 vs 넣지 않았을 때\relse:\rresult[i][j] = result[i][j-1]\rprint(result[K][N]) 순서 정렬 minHeap + maxHeap maxHeap + minHeap 을 사용하여 \u0026lsquo;상위 n개의 데이터\u0026rsquo; 혹은 \u0026lsquo;중앙 값\u0026rsquo;을 구할 수 있다. 아래와 같이 top과 top이 마주보는 구조로 minHeap과 maxHeap을 사용한다. https://www.acmicpc.net/problem/1655\r/*\r* by using two heap(minH, maxH), always can get middle value at maxH.top()\r*\r* (maxH) (minH)\r* input -\u0026gt; [ a1, a2, a3, ... an(top)] [ b1(top), b2, b3, .. bm]\r* ^\r* middle value\r*/ 규칙 찾기 정해진 공식을 대입하는것이 아닌, 문제에서 규칙을 찾아 해결하는 방식 키보드 좌표계\n키보드 자판을 보면 행은 똑바르지만, 열은 살짝 어긋나있다. S를 보면 Q,W,E,A,D,Z,X,C 와 접해있다. 한 버튼에서 다른 버튼까지 이동하는데 걸리는 시간을 계산한다 해 보자. Q에서 E까지는 2번, Q에서 D까지는 3번, Q에서 X까지는 3번에 걸쳐 이동할 수 있다. 이러한 좌표에서 특정 문자를 입력하기 위해 각 자판을 이동하는데 걸리는 시간을 계산한다면? 통용되는 규칙을 찾아서 해결한 경우\nPython Code\rdef solve():\r# 키보드 배열을 좌표평면으로 본다. # Q를 (0,2)로, W를 (2,2) E를 (4,2) ...\r# A를 (1,1), S를 (3,1), D를 (5,1) ...\r# Z를 (2,0), X를 (4,0), C를 (6,0) ...\r# 이후 x좌표 거리를 2로 나누고 y좌표 거리를 더한 후, y 좌표의 거리를 2로 나눈 값을 빼주면 실제 이동 거리가 나온다. # 단, x좌표가 동일할 경우에는 예외로 y좌표 거리가 실제 이동 거리이다. # 이는 y좌표가 3 초과여도 적용되는 규칙이다.\r# ex1) Q(0,2) -\u0026gt; C(6,0) = (6/2 + 2) - 2/2 = 4\r# ex2) T(8,2) -\u0026gt; V(8,0) = (0 + 2) = 2\t(예외)\r# ex3) Q(0,2) -\u0026gt; T(8,2) = (8/2 + 0) - 0 = 4\rcoord = {}\rkey3 = ['Q','W','E','R','T','Y','U','I','O','P']\rkey2 = ['A','S','D','F','G','H','J','K','L']\rkey1 = ['Z','X','C','V','B','N','M']\rMOVING_TIME = 2\rTYPING_TIME = 1\rfor i in range(len(key3)):\rcoord[key3[i]] = (i * 2, 2)\rfor i in range(len(key2)):\rcoord[key2[i]] = (i * 2 + 1, 1)\rfor i in range(len(key1)):\rcoord[key1[i]] = (i * 2 + 2, 0)\rword = input()\rtime = len(word) * TYPING_TIME # time elapsed when typing\rprev = None\r# for all words, calculate distance\rfor w in word:\rif prev is None:\rprev = w\rcontinue\rstart = coord[prev]\rend = coord[w]\r# rule exception\rif start[0] == end[0]:\rtime += abs(end[1] - start[1]) * MOVING_TIME\rprev = w\rcontinue\r# time eplased when moving\rtime += (abs(end[0] - start[0]) // 2 + abs(end[1] - start[1]) - abs(end[1] - start[1]) // 2) * MOVING_TIME\r# settings for next cycle\rprev = w\rprint(time)\rif __name__ == '__main__':\rT = int(input())\rfor t in range(T):\rsolve()\r모든 case를 구분하여 해결한 경우\nC++ Code\r#include \u0026lt;map\u0026gt;\r#include \u0026lt;iostream\u0026gt;\r#define DEBUG 0\rusing namespace std;\rint main(void) {\r// initialize keyboard array\rmap\u0026lt;char,pair\u0026lt;int,int\u0026gt;\u0026gt; qwerty;\rchar row1[] = {'Q','W','E','R','T','Y','U','I','O','P'};\rchar row2[] = {'A','S','D','F','G','H','J','K','L'};\rchar row3[] = {'Z','X','C','V','B','N','M'};\rfor (int i = 0; i \u0026lt; (int)sizeof(row1); i++) {\rqwerty.insert(make_pair(row1[i], make_pair(0, i)));\r}\rfor (int i = 0; i \u0026lt; (int)sizeof(row2); i++) {\rqwerty.insert(make_pair(row2[i], make_pair(1, i)));\r}\rfor (int i = 0; i \u0026lt; (int)sizeof(row3); i++) {\rqwerty.insert(make_pair(row3[i], make_pair(2, i)));\r}\r#if DEBUG\rfor (int i = 0; i \u0026lt; (int)sizeof(row1); i++) {\rcout \u0026lt;\u0026lt; qwerty[row1[i]].first \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; qwerty[row1[i]].second \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rcout \u0026lt;\u0026lt; endl;\rfor (int i = 0; i \u0026lt; (int)sizeof(row2); i++) {\rcout \u0026lt;\u0026lt; qwerty[row2[i]].first \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; qwerty[row2[i]].second \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rcout \u0026lt;\u0026lt; endl;\rfor (int i = 0; i \u0026lt; (int)sizeof(row3); i++) {\rcout \u0026lt;\u0026lt; qwerty[row3[i]].first \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; qwerty[row3[i]].second \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rcout \u0026lt;\u0026lt; endl;\r#endif\r// get input\rint T;\rchar txt[110];\rcin \u0026gt;\u0026gt; T;\rfor (int t = 0; t \u0026lt; T; t++) {\rcin \u0026gt;\u0026gt; txt;\r// calculate result\rint total_diff = 0;\rint pre_row = qwerty[txt[0]].first;\rint pre_col = qwerty[txt[0]].second;\rint idx = 1;\rwhile(txt[idx]) {\rint row = qwerty[txt[idx]].first;\rint col = qwerty[txt[idx]].second;\rint diff_row = abs(row - pre_row);\rint diff_col = abs(col - pre_col);\r// ↔ direction\rif (diff_row == 0) {\rtotal_diff += diff_col;\r}\r// ↕ direction\relse if (diff_col == 0) {\rtotal_diff += diff_row;\r}\r// ↙ direction\relse if (col \u0026lt; pre_col \u0026amp;\u0026amp; row \u0026gt; pre_row) {\rtotal_diff += max(diff_row, diff_col);\r}\r// ↗ direction\relse if (col \u0026gt; pre_col \u0026amp;\u0026amp; row \u0026lt; pre_row) {\rtotal_diff += max(diff_row, diff_col);\r}\r// ↘ direction\relse if (col \u0026gt; pre_col \u0026amp;\u0026amp; row \u0026gt; pre_row) {\rtotal_diff += diff_row + diff_col;\r}\r// ↖ direction\relse {\rtotal_diff += diff_row + diff_col;\r}\r# if DEBUG\rcout \u0026lt;\u0026lt; \u0026quot;row: \u0026quot; \u0026lt;\u0026lt; row \u0026lt;\u0026lt; \u0026quot; col: \u0026quot; \u0026lt;\u0026lt; col\r\u0026lt;\u0026lt; \u0026quot; diff_row: \u0026quot; \u0026lt;\u0026lt; diff_row \u0026lt;\u0026lt; \u0026quot; diff_col: \u0026quot; \u0026lt;\u0026lt; diff_col\r\u0026lt;\u0026lt; \u0026quot; idx: \u0026quot; \u0026lt;\u0026lt; idx \u0026lt;\u0026lt; \u0026quot; total_diff: \u0026quot; \u0026lt;\u0026lt; total_diff \u0026lt;\u0026lt; endl;\r# endif\r++idx;\rpre_row = row;\rpre_col = col;\r} // -\u0026gt; while\r// print result\rcout \u0026lt;\u0026lt; idx + total_diff * 2 \u0026lt;\u0026lt; endl;\r} // -\u0026gt; for\r} // -\u0026gt; main\r두 수의 곱이 최대가 나오도록 숫자 배정\n가장 큰 결과값이 나오도록 두 수를 정의하려면,\n높은 자리수가 낮은자리 수보다 값이 커야한다. (21 * 43 \u0026gt; 12 * 34) 두 수의 길이가 같을수록 두 수의 곱은 크다. (12 * 34 \u0026gt; 123 * 4) C++ Code\r#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;cstring\u0026gt;\r#define DEBUG 0\rusing namespace std;\rint main(void) {\rint T = 0;\rcin \u0026gt;\u0026gt; T;\rfor (int t = 0; t \u0026lt; T; ++t) {\r// 1. get inputs\rchar card[20] = {0,};\rcin \u0026gt;\u0026gt; card;\rint card_len = strlen(card);\r# if DEBUG\rcout \u0026lt;\u0026lt; \u0026#34;len : \u0026#34; \u0026lt;\u0026lt; card_len \u0026lt;\u0026lt; endl;\r# endif\rint number[10] = {0,};\rfor (char c : card) {\rnumber[c - \u0026#39;0\u0026#39;] += 1;\r}\r// change all \u0026#39;6\u0026#39; into \u0026#39;9\u0026#39;\rnumber[9] += number[6];\rnumber[6] = 0;\r// 2. divide into two number\rint idx = 9;\rbool flag = false;\r// find max number\rwhile (number[idx] == 0) idx--;\rnumber[idx] -= 1;\runsigned long long num1 = idx;\runsigned long long num2 = 0;\rint l = 1;\rwhile (l \u0026lt; card_len) {\rwhile (number[idx] == 0) idx--;\rnumber[idx] -= 1;\r// 다음 숫자를 어디에 이어붙일지 결정\r// 이전 조합이 최적이라면, 아래 두 번의 비교를 통해 도출된 두 숫자 조합도 최적값임이 보장된다. unsigned long long cmp1 = (num1 * 10 + idx) * num2;\runsigned long long cmp2 = (num2 * 10 + idx) * num1;\rif (cmp1 \u0026gt; cmp2) {\rnum1 = num1 * 10 + idx;\r}\relse {\rnum2 = num2 * 10 + idx;\r}\r++l;\r/*\r// num1 : max, max-3, max-4, max-7, max-8 ...\r// num2 : max-1, max-2, max-5, max-6, ...\rfor (int i = 0; i \u0026lt; 2; ++i) {\rwhile (number[idx] == 0) idx--;\rnumber[idx] -= 1;\rif (flag) {\rnum1 = num1 * 10 + idx;\r}\relse {\rnum2 = num2 * 10 + idx;\r}\r# if DEBUG\rcout \u0026lt;\u0026lt; l \u0026lt;\u0026lt; \u0026#34; / num : \u0026#34; \u0026lt;\u0026lt; num1 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num2 \u0026lt;\u0026lt; endl;\r# endif\r// check condition\rl += 1;\rif (l \u0026gt;= card_len) break;\r} // -\u0026gt; for i\rflag = !flag;\r*/\r} // -\u0026gt; while card_len\rcout \u0026lt;\u0026lt; num1 * num2 \u0026lt;\u0026lt; endl;\r} // -\u0026gt; for T\r} ","permalink":"https://aswinblue.github.io/post/algorithm/algorithm/","summary":"Algorithm 그래프 탐색 SP(Shortest Path) 단일 출발점에서 단일 목적지까지 최단 경로를 찾는 알고리즘\nDFS 용도 : 경로가 있는지 확인할 때 사용 가능 자로구조 : stack 방법 : 시작 node를 stack에 넣는다. stack이 모두 빌때까지 아래 동작을 반복한다. stack의 top을 현재 node로 설정한다. 현재 node를 \u0026lsquo;visited\u0026rsquo; 처리하고 stack에서 제거한다. 다음으로 이동할 node가 있는지 확인한다. 다음으로 이동할 node \u0026lsquo;A\u0026rsquo;가 있다면, 현재 node에서 그다음에 탐색할 방향을 stack에 push하고, node \u0026lsquo;A\u0026rsquo;도 stack에 push한다. 더이상 갈 곳이 없으면 현재 node의 visited 처리를 복원한다.","title":"Algorithm"},{"content":"VS code visual studio code 사용법 개발환경 C / C++ 컴파일러 gcc 혹은 mingw 설치가 필요하다. 인터넷에서 설치하도록 한다. 설정파일 컴파일 및 실행을 위해서는 launch.json, setting.json, tasks.json 파일이 필요하다. vs code에서 알아서 작성해 주지만, 기본 설정으로 부족한 부분은 수정해야 한다. # settings.json\r{\r\u0026#34;C_Cpp_Runner.cStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.cppStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.msvcBatchPath\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.warnings\u0026#34;: [\r\u0026#34;-Wall\u0026#34;,\r\u0026#34;-Wextra\u0026#34;,\r\u0026#34;-Wpedantic\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.enableWarnings\u0026#34;: true,\r\u0026#34;C_Cpp_Runner.warningsAsError\u0026#34;: false,\r\u0026#34;C_Cpp_Runner.compilerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.linkerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includePaths\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includeSearch\u0026#34;: [\r\u0026#34;*\u0026#34;,\r\u0026#34;**/*\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.excludeSearch\u0026#34;: [\r\u0026#34;**/build\u0026#34;,\r\u0026#34;**/build/**\u0026#34;,\r\u0026#34;**/.*\u0026#34;,\r\u0026#34;**/.*/**\u0026#34;,\r\u0026#34;**/.vscode\u0026#34;,\r\u0026#34;**/.vscode/**\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.cCompilerPath\u0026#34;: \u0026#34;gcc\u0026#34;,\r\u0026#34;C_Cpp_Runner.cppCompilerPath\u0026#34;: \u0026#34;C:/Program Files (x86)/mingw-w64/i686-8.1.0-posix-dwarf-rt_v6-rev0/mingw32/bin/g++.exe\u0026#34;,\r\u0026#34;C_Cpp_Runner.debuggerPath\u0026#34;: \u0026#34;C:/Program Files (x86)/mingw-w64/i686-8.1.0-posix-dwarf-rt_v6-rev0/mingw32/bin/gdb.exe\u0026#34;,\r\u0026#34;files.associations\u0026#34;: {\r\u0026#34;hash_map\u0026#34;: \u0026#34;cpp\u0026#34;\r}\r} # launch.json\r{\r\u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;,\r\u0026#34;configurations\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;C/C++ Runner: Debug Session\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;,\r\u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;,\r\u0026#34;args\u0026#34;: [],\r\u0026#34;stopAtEntry\u0026#34;: false,\r\u0026#34;cwd\u0026#34;: \u0026#34;f:/Documents/GitHub/acmicpc/15997\u0026#34;,\r\u0026#34;environment\u0026#34;: [],\r\u0026#34;program\u0026#34;: \u0026#34;동작시킬 프로그램 경로\u0026#34;,\r\u0026#34;internalConsoleOptions\u0026#34;: \u0026#34;openOnSessionStart\u0026#34;,\r\u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;,\r\u0026#34;miDebuggerPath\u0026#34;: \u0026#34;C:/Program Files (x86)/mingw-w64/i686-8.1.0-posix-dwarf-rt_v6-rev0/mingw32/bin/gdb.exe\u0026#34;,\r\u0026#34;externalConsole\u0026#34;: false,\r\u0026#34;setupCommands\u0026#34;: [\r{\r\u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;,\r\u0026#34;ignoreFailures\u0026#34;: true\r}\r]\r}\r]\r} # tasks.json\r{\r// See https://go.microsoft.com/fwlink/?LinkId=733558\r// for the documentation about the tasks.json format\r\u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;,\r\u0026#34;tasks\u0026#34;: [\r{\r\u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;,\r\u0026#34;label\u0026#34;: \u0026#34;execute\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;${fileDirname}/${fileBasenameNoExtension}.exe\u0026#34;,\r\u0026#34;group\u0026#34;: {\r\u0026#34;kind\u0026#34;: \u0026#34;test\u0026#34;,\r\u0026#34;isDefault\u0026#34;: true\r},\r\u0026#34;problemMatcher\u0026#34;: []\r},\r{\r\u0026#34;type\u0026#34;: \u0026#34;cppbuild\u0026#34;,\r\u0026#34;label\u0026#34;: \u0026#34;C/C++: g++.exe 활성 파일 빌드\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;C:\\\\Program Files (x86)\\\\mingw-w64\\\\i686-8.1.0-posix-dwarf-rt_v6-rev0\\\\mingw32\\\\bin\\\\g++.exe\u0026#34;,\r\u0026#34;args\u0026#34;: [\r\u0026#34;-fdiagnostics-color=always\u0026#34;,\r\u0026#34;-g\u0026#34;,\r\u0026#34;${file}\u0026#34;,\r\u0026#34;-o\u0026#34;,\r\u0026#34;${fileDirname}\\\\${fileBasenameNoExtension}.exe\u0026#34;\r],\r\u0026#34;options\u0026#34;: {\r\u0026#34;cwd\u0026#34;: \u0026#34;${fileDirname}\u0026#34;\r},\r\u0026#34;problemMatcher\u0026#34;: [\r\u0026#34;$gcc\u0026#34;\r],\r\u0026#34;group\u0026#34;: \u0026#34;build\u0026#34;,\r\u0026#34;detail\u0026#34;: \u0026#34;컴파일러: \\\u0026#34;C:\\\\Program Files (x86)\\\\mingw-w64\\\\i686-8.1.0-posix-dwarf-rt_v6-rev0\\\\mingw32\\\\bin\\\\g++.exe\\\u0026#34;\u0026#34;\r}\r]\r} 단축키 Ctrl + Shift + P 단축키로 명령을 일일이 수행해도 되지만, 단축키를 설정해 바로 실행하는게 빠르다. 파일 -\u0026gt; 기본설정 -\u0026gt; 바로가기키 (Ctrl + K \u0026amp; Ctrl + S) 를 누르고, 우측 상단 \u0026lsquo;바로가기 키 열기\u0026rsquo; 를 클릭하여 단축키를 직접 입력한다. // 키 바인딩을 이 파일에 넣어서 기본값 재정의\r[\r{\r\u0026#34;key\u0026#34;: \u0026#34;ctrl+alt+c\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;workbench.action.tasks.build\u0026#34;,\r},\r{\r\u0026#34;key\u0026#34;: \u0026#34;ctrl+alt+e\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;workbench.action.tasks.test\u0026#34;,\r}\r] ","permalink":"https://aswinblue.github.io/post/developtips/vscode/","summary":"VS code visual studio code 사용법 개발환경 C / C++ 컴파일러 gcc 혹은 mingw 설치가 필요하다. 인터넷에서 설치하도록 한다. 설정파일 컴파일 및 실행을 위해서는 launch.json, setting.json, tasks.json 파일이 필요하다. vs code에서 알아서 작성해 주지만, 기본 설정으로 부족한 부분은 수정해야 한다. # settings.json\r{\r\u0026#34;C_Cpp_Runner.cStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.cppStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.msvcBatchPath\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.warnings\u0026#34;: [\r\u0026#34;-Wall\u0026#34;,\r\u0026#34;-Wextra\u0026#34;,\r\u0026#34;-Wpedantic\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.enableWarnings\u0026#34;: true,\r\u0026#34;C_Cpp_Runner.warningsAsError\u0026#34;: false,\r\u0026#34;C_Cpp_Runner.compilerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.linkerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includePaths\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includeSearch\u0026#34;: [\r\u0026#34;*\u0026#34;,\r\u0026#34;**/*\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.","title":"VsCode"},{"content":"C++ STL 자료구조 map key-value 쌍으로 이루어진 tree형태의 자료구조 중복을 허용하지 않음 C++에서는 red black tree로 구현되어 삽입,삭제가 O(log n) 안에 이루어진다. 내부적으로 key를 기준으로 오름차순으로 자료를 정렬한다. 헤더 : #include \u0026lt;map\u0026gt;\n선언 : map\u0026lt;int, int\u0026gt; map1;\n내림차순으로 선언 : map \u0026lt;int, int, greater\u0026gt; map2 삽입 : insert : map1.insert({\u0026quot;key\u0026quot;,VALUE}) [] : map1[\u0026quot;key\u0026quot;] = VALUE 삭제 : 특정 index : map1.erase(map1.begin()+2) 특정 key : map1.erase(KEY) 구간 : map1.erase(map1.begin(), map1.end()) 전체 : map1.clear() 검색 : map\u0026lt;int, int\u0026gt;::Iterator res;\rif ((res = map1.find(KEY)) != m.end()) {\rres -\u0026gt; first; // key\rres -\u0026gt; second; // value\r} 반복문 : for (auto itr = map1.begin(); itr != map1.end(); itr++) {\ritr-\u0026gt;first // key\ritr-\u0026gt;second // value\r} hash map hash table을 이용한 자료구조 정렬이 필요없는 비순차적 구조 헤더 : #include\u0026lt;hash_map\u0026gt;\n선언 : hash_map\u0026lt;int, float\u0026gt; h1\n삽입 :\ninsert 구문 : h1.insert(hash_map\u0026lt;int, float\u0026gt;::value_type(1,2.0f)) [] 구문 : h1[1] = 2.0f 검색 : hash_map\u0026lt;int, float\u0026gt;::Iterator res;\rif ((res = h1.find(10)) != h1.end()) {\rres-\u0026gt;first; // key\rres-\u0026gt;second; // value\r} 반복문 for (auto itr = h1.begin(); itr != h1.end(); itr++) {\ritr-\u0026gt;first; // key\ritr-\u0026gt;second; // value\r} 삭제 : 특정 index : h1.erase(h1.begin()) 특정 key : h1.erase(1) 구간 : h1.erase(h1.begin(), h1.end()) 전체 : h1.clear() Heap 헤더: #include\u0026lt;queue\u0026gt; 선언: min queue : priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; Heap max queue : priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, less\u0026lt;int\u0026gt;\u0026gt; Heap greater, less가 반대로 되어있음에 주의한다. 활용: Heap.push() : 삽입 Heap.top() : 가장 작은/큰 값 Heap.pop() : top 값을 삭제 Heap.size() : 인자 개수 Heap.empty() : size가 1 이상이면 false, 아니면 true 정렬 stable_sort 오름차순 혹은 내림차순으로 정렬하되, 같은 값의 경우 기존의 순서를 유지하는 정렬방식 int v[10];\rint idx[10];\r// 오름차순 정렬\rstable_sort(idx, idx + 10, [](int a, int b){return a \u0026gt; b;});\r// index를 이용한 정렬\rstable_sort(idx, idx + 10, [\u0026amp;v](int a, int b){return v[a] \u0026gt; v[b];}); ","permalink":"https://aswinblue.github.io/post/c++/c++_stl/","summary":"C++ STL 자료구조 map key-value 쌍으로 이루어진 tree형태의 자료구조 중복을 허용하지 않음 C++에서는 red black tree로 구현되어 삽입,삭제가 O(log n) 안에 이루어진다. 내부적으로 key를 기준으로 오름차순으로 자료를 정렬한다. 헤더 : #include \u0026lt;map\u0026gt;\n선언 : map\u0026lt;int, int\u0026gt; map1;\n내림차순으로 선언 : map \u0026lt;int, int, greater\u0026gt; map2 삽입 : insert : map1.insert({\u0026quot;key\u0026quot;,VALUE}) [] : map1[\u0026quot;key\u0026quot;] = VALUE 삭제 : 특정 index : map1.erase(map1.begin()+2) 특정 key : map1.erase(KEY) 구간 : map1.erase(map1.begin(), map1.end()) 전체 : map1.","title":"C++_stl"},{"content":"#MS Window\nMS window 사용시 필요한 편이 기능들을 나열 WSL2 윈도우에서 리눅스를 실행하는 방법이다. windows 10 이상부터 지원 가능하며, microsoft store에서 ubuntu를 설치하는 방식이다. PowerShell을 관리자 권한으로 실행하여 아래 명령어 입력 $ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n$ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n$ wsl \u0026ndash;set-default-version 2\n환경변수 환경변수 설정시 컴퓨터를 재부팅하지 않고 적용하는 방법 콘솔에 taskkill /f /im explorer.exe, explorer.exe 명령을 순서대로 입력한다. 작업표시줄이 없어졌다 생겨나면 적용이 된 것이다. 켜져있던 탐색기는 복원되지 않으니 주의 batch call 기본 command가 아닌 package command를 수행할 경우, batch파일에 명령어를 그대로 넣어서 수행하면 첫번째 줄만 수행될 수 있다. 이때 call 명령어를 사용해주면 여러 라인을 실행 가능하다. ex) call npm run build\rcd server\rcall gradle wrapper 리눅스에서 파일 가져오기 scp 명령을 사용해서 리눅스에서 파일을 가져올 수 있다. scp \u0026lt;계정\u0026gt;@\u0026lt;리눅스_IP주소\u0026gt;:리눅스에서_가져올_파일_경로 윈도우에_저장할_경로 형태로 사용 가능하다. ex) scp kim@10.162.32.11:target_file C:\\ : C 경로에 target_file을 받아온다. target_file에 절대경로를 사용하는게 좋다. 상대경로를 사용할 시 절대 경로는 /home/kim/target_file 가 된다. ","permalink":"https://aswinblue.github.io/post/developtips/window/","summary":"#MS Window\nMS window 사용시 필요한 편이 기능들을 나열 WSL2 윈도우에서 리눅스를 실행하는 방법이다. windows 10 이상부터 지원 가능하며, microsoft store에서 ubuntu를 설치하는 방식이다. PowerShell을 관리자 권한으로 실행하여 아래 명령어 입력 $ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n$ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n$ wsl \u0026ndash;set-default-version 2\n환경변수 환경변수 설정시 컴퓨터를 재부팅하지 않고 적용하는 방법 콘솔에 taskkill /f /im explorer.exe, explorer.exe 명령을 순서대로 입력한다. 작업표시줄이 없어졌다 생겨나면 적용이 된 것이다.","title":"Window"},{"content":"Firebase with React react에서 firebase를 활용하는 방법 firebase SDK를 설치하거나 웹상에서 설치없이 사용하는 방법은 firebase 기본을 참조 인증 (Auth) firebase 로 계정 생성 및 로그인 firebase API를 import하여 사용 \u0026lt;AppFirebase.js\u0026gt; import firebase from \u0026#34;firebase/compat/app\u0026#34;;\rimport \u0026#34;firebase/compat/auth\u0026#34;;\rconst firebaseConfig = {\rapiKey: process.env.REACT_APP_API_KEY,\rauthDomain: process.env.REACT_APP_AUTHDOMAIN,\rprojectId: process.env.REACT_APP_PROJECTID,\rstorageBucket: process.env.REACT_APP_STORAGEBUCKET,\rmessagingSenderId: process.env.REACT_APP_MESSAGINGSENDERID,\rappId: process.env.REACT_APP_APPID\r};\rexport default firebase.initializeApp(firebaseConfig);\rexport const authService = firebase.auth(); AppFirebase.js 를 활용하여 business logic에 필요한 로그인 / 회원가입 기능을 구현 \u0026lt;Auth.js\u0026gt; import { authService } from \u0026#34;../components/AppFirebase\u0026#34;;\rconst data = await authService.createUserWithEmailAndPassword(email, password) // email, passwd로 계정 생성\rconst data = await authService.signInWithEmailAndPassword(email, password) // email, passwd로 로그인 createUserWithEmailAndPassword / signInWithEmailAndPassword 실행 이후 authService.currentUser를 참조하면 user 정보를 받아올 수 있다. 하지만, authService.currentUser 정보를 갱신하는데는 시간이 걸린다. firebase API에서는 observer를 등록하여 currentUser의 변경 시점을 확인할 수 있다. currentUser 변경시점에 특정함수 동작 user 정보가 갱신된 시점에 특정 동작을 원한다면, 아래와 같이 onAuthStateChanged 함수를 사용하면 된다. authService.onAuthStateChanged((user) =\u0026gt; { /* something to do */ }}); 로그아웃 authService.signOut() 함수를 호출하여 로그아웃이 가능하다. 참고로 크롬 웹 디버깅 화면에서 \u0026lsquo;Application\u0026rsquo;탭에 들어가서 IndexedDB -\u0026gt; firebaseLocalDb 안의 내용을 🚫버튼으로 삭제해 주면 로그인 정보가 사라진다. 에러 authService의 함수(createUserWithEmailAndPassword, signInWithEmailAndPassword, \u0026hellip;) 사용시 에러가 발생할 수 있으므로, try, catch문으로 묶어서 사용한다. try {\rlet data\rdata = await authService.createUserWithEmailAndPassword(email, password)\r} catch(error) {\rconsole.log(error.code) // 에러의 원인이 코드 형태로 출력된다.\rconsole.log(error.message) // 에러의 원인이 메시지 형태로 출력된다.\r} ref) 오류발생 원인\n6자리 이하로 비밀번호 생성시 동일한 e-mail로 계정 생성시 Google 계정으로 로그인 firebase에서는 google, facebook 등 계정으로 로그인 할 수 있도록 기능을 제공한다. 팝업으로 로그인을 유도하는 방식과, redirect로 로그인하는 방식이 있다. import { authService, firebaseModule } from \u0026#34;../components/AppFirebase\u0026#34;;\rconst onSocialClick = async (event) =\u0026gt; {\rtry {\rlet provider;\rprovider = new firebaseModule.auth.GoogleAuthProvider(); //\r} catch (error) {\rconsole.log(error);\r}\rawait authService.signInWithPopup(provider); // 팝업으로 로그인\r} ","permalink":"https://aswinblue.github.io/post/database/firebase_react/","summary":"Firebase with React react에서 firebase를 활용하는 방법 firebase SDK를 설치하거나 웹상에서 설치없이 사용하는 방법은 firebase 기본을 참조 인증 (Auth) firebase 로 계정 생성 및 로그인 firebase API를 import하여 사용 \u0026lt;AppFirebase.js\u0026gt; import firebase from \u0026#34;firebase/compat/app\u0026#34;;\rimport \u0026#34;firebase/compat/auth\u0026#34;;\rconst firebaseConfig = {\rapiKey: process.env.REACT_APP_API_KEY,\rauthDomain: process.env.REACT_APP_AUTHDOMAIN,\rprojectId: process.env.REACT_APP_PROJECTID,\rstorageBucket: process.env.REACT_APP_STORAGEBUCKET,\rmessagingSenderId: process.env.REACT_APP_MESSAGINGSENDERID,\rappId: process.env.REACT_APP_APPID\r};\rexport default firebase.initializeApp(firebaseConfig);\rexport const authService = firebase.auth(); AppFirebase.js 를 활용하여 business logic에 필요한 로그인 / 회원가입 기능을 구현 \u0026lt;Auth.","title":"Firebase_react"},{"content":"Cryptocurrency Cryptographic Hash function hash function은 아래와 같은 속성을 갖는다. 모든 크기의 String을 input 으로 받는다. 정해진 크기의 output을 생성한다. (bitcoin에서는 256bit) 적당한 시간 안에 계산이 가능하다. (계산 시간이 너무 길지 않다) cryptographic hash function은 아래와 같은 security 속성을 추가로 갖는다.\ncollision-free hiding puzzle-friendly 속성1. collision-free x != y 라면, H(x) = H(y) 인 경우를 찾을 수 없어야 한다. 이 말은 collision 이 존재하지 않는다는 뜻은 아니다. num(possible_input) \u0026gt; num(possible_outputs) 이다. \u0026lsquo;찾을 수 없다\u0026rsquo; 라는 말은, collision이 존재하지만, hahs function의 결과를 예측할 수 없다는 뜻이다. 실제로, 2^130 개의 무작위 수를 선택하여 hash function을 돌렸을 때, 99.8%의 확률로 충돌이 발생한다. 하지만 이 수치는 천문학적으로 크기 때문에 걱정할 필요가 없다. (collision을 발견할 확률은 인류가 만든 최고의 컴퓨터로 우주 생성시부터 계산을 해도, 2초뒤 지구에 운석이 떨어질 확률만큼 낮다.) collision을 쉽게 구하는 방법이 있는가? -\u0026gt; 특정 hash function에 대해서는(SHA256에 대해서도 최단기간 collision을 찾아내는 방법이 알려져 있다.) 가능하지만, 대부분은 그렇지 않다. hash as message digest collision을 구하는 것이 매우 어렵기 때문에, H(x) = H(y)라면, x = y라고 확신해도 된다. 즉, hash를 이용해 데이터 전송/비교에 드는 비용을 절감 가능하다. (전체 message 대신 hash만 비교) 속성2. hiding H(x)를 갖고 x를 유추할 수 없다. hiding 속성을 가지려면 아래와 같은 방법을 사용한다. high min-entropy 를 가진 무작위 상수 \u0026lsquo;r\u0026rsquo;을 x와 조합(concatenate)하여 hash function의 input에 넣으면 hiding 속성을 갖게 된다. (H(r|x)) high min-entropy 란 넓고 고르게 퍼져있음을 뜻한다. 즉, 넓은 선택범위 안에서 특정 값이 특출나게 여려번 중복해서 뽑히지 않는다는 뜻이다. (no particular value is chosen with more than negligible probability) commitment 편지를 동봉하듯 데이터가 가지고 있는 내용을 공개하지 않고 데이터를 공개하는 것\ncommitment를 위해 제공하는 commitment API 는 다음과 같이 동작한다.\n(commitment, key) = commit(msg) msg를 동봉하고, 그 결과로 commitment와 key를 생성한다. commitment는 봉투에 해당하고, key는 열쇠에 해당한다. commit은 hash function으로 다음과 같이 구성된다. commit(msg) = (H(key | msg), key) 즉, (commitment, key) = H(key|msg), key 이다. match = verify(commitment, key, msg) commitment, key, msg 세가지를 이용해 msg가 올바른지 검증한다. commitment는 두 가지 security property를 갖는다.\nhiding : commitment만으로 msg를 파악할 수 없다.\nbinding : msg1 != msg2 라면, verify(commit(msg1),msg2) != false 이다.\n속성3. puzzle-friendly 임의의 \u0026lsquo;k\u0026rsquo;가 high min-entropy 속성을 갖고 있다면, H(k|x) = y 를 만족시키는 x를 찾을 수 없다. 즉, 특정 값 y가 나오도록 x를 임의로 조작할 수 없다는 뜻이다. 앞서 말한 hash function으로는 여러가지 종류들이 있다. 그중 SHA-256에 대해 살펴보자.\nSHA-256 동작 방법은 아래와 같다. message를 512bit씩 잘라서, 256bit의 데이터\u0026rsquo;IV\u0026rsquo;와 함께 hashing 연산 \u0026lsquo;C\u0026rsquo;을 수행한다. 위 결과와 다음 256bit 메시지를 다시 \u0026lsquo;C\u0026rsquo;연산시킨다. 이를 메시지 끝까지 반복한다. 마지막 메시지가 256bit가 되지 않는다면 (10*|length) 로 이루어진 padding을 집어넣어 연산한다. collision-free를 만족하기 때문에 \u0026lsquo;C\u0026rsquo; 연산 각각도 collision-free이다. Hash Pointer data structure의 hash와 동일하게, hash pointer는 특정 데이터를 가리키는 pointer이다. 다만, 데이터는 info와 cryptographic hash를 포함한다. hash pointer를 이용하면 데이터와, 데이터의 변경여부를 확인할 수 있다. hash pointer를 이용하여 다양한 data structure를 구성할 수 있다. hash pointer를 이용해 linked list를 구성하면 흔히 block chain이라 불리는 구조가 형성된다. linked-list의 block 하나가 \u0026lsquo;주소 + 데이터\u0026rsquo; 로 이루어져 있는데, block chain 에서는 \u0026lsquo;주소\u0026rsquo; 부분이 이전 block의 hash값(hash + data 의 hash값)으로 구성되어 있다. ex) H(root) - B1[data1, H(B2)] - B2[data2, H(B3)] - B3[data3, H(B4)] ... hash값을 이용하여 다음 데이터가 수정이 이루어졌는지 확인 가능하다. (tamper-evident) data3을 수정하면 H(B3)값과 B2의 H()값이 일치하지 않게 된다. B2의 H()값을 수정하면 이번에는 H(B2)와 B1의 H()값이 일치하지 않는다. 연쇄적으로 B2, B1, root까지 수정하면 다시 모든 hash값이 맞아 떨어지게 된다. 가장 최초의 block을 \u0026lsquo;genesis block\u0026rsquo;이라 부른다. hash pointer로 binary tree를 구성할 수도 있다. (Merkle tree) tree의 leaf node에는 data가 들어가고, 이후 root node 포함 모든 node들은 left\u0026amp;right 자식 node들의 hash값을 갖게 된다. 데이터가 변경되면, 부모 node의 hash값이 연쇄적으로 어긋나게 되고, 최종적으로 root node의 hash값 R과 달라지게 된다. (H(root) 값을 기억하면 데이터 변경을 감지할 수 있게 된다.) 데이터 검증을 위해 모든 block들을 사용해야 했던 기존 block chain과 다르게, Merkle tree는 O(log n) 개의 node만으로도 데이터 무결성을 증명할 수 있다. 검증 시간 및 검색, 정렬 시간이 직렬 데이터 구조보다 절감된다. hash pointer는 cycle이 없는 모든 pointer-based data structure에 사용 가능하다. Digital Signature Digital Signature 은 아래와 같은 속성을 지녀야 한다. only you can sign, but anyone can verify : 본인만 사용 가능하며 본인임을 인증할 수 있어야 한다. tied to a particular document : 서명과 인증할 대상이 분리 불가능해야 한다. digital signature의 API는 아래와 같을 것이다. (secret_key, public_key) := generateKeys(size_of_key) : Key를 생성하는 함수. randomize 되어있어야 한다. sig := sign(secret_key, message) : 특정 message에 서명을 하는 함수 마찬가지로 randomize가 잘 되어있어야 한다. message의 길이가 너무 길면 처리하기 힘드므로, Hash function의 collision-free 특성을 이용해 message의 hash 값을 쓰도록 한다. isValid := verify(public_key, message, sig) : public key와 message, sig의 조합으로 알맞은 서명인지 검증하는 함수 Requirements for signature 위 API로 만든 signature의 조건으로는 아래 두가지가 있다. public_key, sig, message로 message가 당신의 것임을 인증 가능 다른 이가 당신의 public_key, sig를 이용해 다른 message′ 에 서명을 할 수 없어야 한다. secret_key 를 공개하지 않고, public key를 타인에게 공개한 후, 수 많은 message [m0, m1, m2, \u0026hellip;] 에 대해 서명을 한 결과 [sign(m0), sign(m1), sign(m2), \u0026hellip;]를 타인에게 주었을 때, 그 사람이 새로운 메시지 m′에 대한 서명 sign(m′)을 만들어 낼 확률은 극히 낮아야 한다. + Hash pointer를 sign하면, hash pointer 뿐만 아니라, pointer가 가리키는 전체 구조를 sign하는 효과를 얻을 수 있다. + bitcin은 ECDSA(Elliptic Curve Digital Signature Algorithm) 표준을 사용한다.\nPublic Keys \u0026amp; Secret Keys public key는 개인을 식별할 수 있는 \u0026lsquo;식별자\u0026rsquo;이다. public key는 모두에게 공개되며, public key로 개개인을 구분할 수 있다. secret key는 public key로 특정 발언을 할 수 있는 \u0026lsquo;권한\u0026rsquo; 이다. public key 와 secret key는 pair로 존재하며, \u0026lsquo;identity\u0026rsquo; (고유함)를 구성한다. identity는 아무 때나, 몇개든 만들 수 있으며, 모든 identity를 관리하기위한 중앙 체제가 필요없다. (decentralized) 다만, 랜덤 요소가 약하다면 다수의 public key와 message를 통해 secret key가 유출될 가능성이 있음에 주의한다. 이러한 속성 덕분에 bitcoin에서도 identity를 \u0026lsquo;address\u0026rsquo; 라는 용어로 사용한다. address 는 탈 중앙화로 동작하지만, 개인이 만든 address는 즉시 identity 속성을 갖지는 못한다. address가 identity 속성을 갖게 하기 위해서는 다른 address들과 엮어야 하는데, observer가 주기적으로 이 동작을 수행하도록 해야한다. address를 추적하면 address 명의로 수행한 행위들을 추출할 수 있는데, 이 내용으로 특정 개인을 추정할 수 있는 취약점이 있다. Cryptocurrency CryptoCurrency(이하 coin)에는 다음과 같은 조건이 필요하다. public key, unique coin id 를 이용해 coin을 만들 수 있어야 한다. A 가 unique coin id 를 인자로 coin을 만들고, 이를 public key로 sign하는 방식으로 coin을 생성한다.([pk_A, createCoin(unique_coin_id)]) coin은 다른 사람에게 전달 가능해야 한다. A 가 B 에게 coin을 전달한다고 할 때, 만들어진 coin을 가리키는 거래내역 block을 생성한다. [pk_A, pay_to(pk_B)] -\u0026gt; [pk_A, createCoin(unique_coin_id)]\npay_to 블럭의 hash pointer가 createCoin 블럭을 가리킨다. 이러면 coin의 소유자가 A에서 B로 넘어간 것이다. 이후 B가 C로 coin을 전달하면 [pk_B, pay_to(pk_C)] -\u0026gt; [pk_A, pay_to(pk_B)] -\u0026gt; [pk_A, createCoin(unique_coin_id)] 형태가 될 것이다.\n모든 chain을 따라가면 coin이 누구의 소유인지 확인 가능하다.\ndouble spending attack coin의 chain은 직렬로 이루어져야 한다. 만약 branch가 생겨나면 소유권이 꼬이게 된다. 아래와 같이 B가 특정 coin을 두번 이상 spend 하는 형태가 발생할 수 있다. [pk_B, pay_to(pk_C)] [pk_B, pay_to(pk_D)]\r↓ ↓\r[pk_A, pay_to(pk_B)]\r↓\r[pk_A, createCoin(unique_coin_id)] 이러한 경우, 이 코인은 secure하지 않기 때문에 cryptoCurrency로서는 좋지 않다.\ndouble spending attack을 해소하려면 history를 관리하면 된다.\nhistory는 위에서 살펴본 block chain(hash pointer를 이용한 linked list) 형태로 구성한다.\n거래내역(transactions) 들을 content로 갖는 block들 생성하고, 이를 hash pointer로 연결한다. (보통 한 block 안에는 다수의 transaction들을 포함한다.) 관리자가 root hash 및 block들을 public key로 인증하여 publish하면, history가 관리되어 안정성이 확보된다. H() -\u0026gt; ... -\u0026gt; [H(), transaction3] -\u0026gt; [H(), transaction2] -\u0026gt; [H(), transaction1] transaction들은 관리자에 의해 publish되어야 한다. (pk로 sign)\ntransaction들은 다음과 같이 구성된다.\ncreate coin value와 recipient를 설정한다. 생성한 coin에 고유 id를 붙인다. (trainsaction Id + index로 조합) pay consume -\u0026gt; create 작업을 수행한다. consume은 coin id를 이용해 coin을 폐기하는 작업이다. create 작업은 create coin과 동일하다. 작업을 수행하기 전 다음 사항들을 validate 하고 수행한다. 1) consume하는 coin이 valid한지 체크 2) consume 하는 coin이 이미 consume되지 않았는지 체크(not double spend) 3) consume 되는 양과 create 되는 양이 같은지 체크 4) consume 되는 coin들은 각 owner에 의해 sign 되어있는지 체크 - 모든 사항이 확인되면 관리자에 의해 publish된다. -\u0026gt; double spending 문제는 해결했지만 centralization 문제가 발생한다. (\u0026lsquo;관리자\u0026rsquo; 가 중앙 체제에 해당)\nDecentralization Crypto currency를 구성하기 위해서는 탈 중앙화가 이루어져야 한다. 앞서 보았듯이 거래 장부(transaction)를 관리하기 위해서는 이를 인증해 줄 주체가 필요했다. 이 주체를 분산시키는 것이 필요하다. (Distributed Consensus) Dsitributed Consensus 분산의 개념은 암호화 회폐 이전에 서버 동작에서도 논제가 되었다. 여러개의 서버가 병렬로 동작할 때, consistency를 유지하기 위해 distributed consensus protocol이 필요했다. 방법중 하나로 distributed key-value store 방식이 있는데, DNS, public key directory, stock trade 등 여러 방면에서 사용되고 있고, altcoin에도 사용되고 있다. public consensus in crypto currency 암호화 화폐에서는 transaction가 모여 block을 이루고, 이를 모아 block chain을 만든다.\nblock chain에 들어간 모든 block들은 consensus된 내용들이어야 한다.\ntransaction 하나를 consensus 해도 괜찮지만, block 단위로 consensus하여 효율을 높인다.\npeer to peer 통신은 완벽하지 않기 때문에 여러개의 각기 다른 block들을 비교해야 한다.\n비교한 block들 중 특정 block을 block chain 에 추가하면, 어떤 transaction은 빠질 수도 있는데, 이는 다음번 consensus때 까지 대기해야 한다.\nNode간 충돌은 consensus protocol이 쉽지 않은 이유중 하나이다. 모든 Node들이 연결되어 있지 않기 때문에 Node간 충돌은 불가피하다. network latency 혹은 fault도 Node간 차이를 발생하는 원인이 된다. Byzantine general problems 는 consensus problem 중 하나이다. Fischer-Lynch-Paterson impossibility result 라는 이름의 증명은 하나의 fault만 존재해도 consensus는 불가능하다는 것을 증명한 내용이다.\n그럼에도 불구하고 대표적인 consensus protocol들이 있다. 그중 하나는 Paxos 프로토콜이다.\nPaxo 프로토콜은 inconsistent 한 상황은 절대 발생시키지 않지만, 특정한 상황이 되면 dead-lock 처럼 로직이 멈춰 더이상 동작하지 않는 상태가 발생할 수 있다. 현실 bitcoin에서는 이론에 비해 consensus가 더 잘 이루어지고 있다. 이론은 아직 실제 현상을 따라잡아 가는 형태이지만, 여전히 이론은 예상치 못한 공격에 대한 대응과 bitcoin 생태계에서의 확신을 주기 위한 존재로서 중요하다.\n현실의 bitcoin에서는 어떤점이 다른가?\nbitcoin에서는 insentive의 개념이 있다. 정직하게 활동한 참여자에게는 insentive를 줌으로써 시스템에 우호적으로 활동할 계기를 준다.\n이는 bitcoin이 currency의 개념이기 때문에 가능하며, 이번의 모든 distributed consensus system 에서는 없었던 개념이다.\ninsentive를 통해 bitcoin은 distributed consensus system를 근본적으로 해결하지 않았지만, 해결책을 찾은 셈이다.\nconsensus system은 즉각적이지 않고, consensus를 수행하는데도 약 1시간 정도가 소요된다. 하지만 시간이 지날수록 transaction이 반영되지 않거나 잘못될 확률은 exponential하게 줄어들게 된다.\nconsensus without identity bitcoin에서는 persistent long term identities 없이 consensus가 이루어진다. 즉, node를 칭할 수 있는 identity가 없다.\nidentity가 있다면 다음과 같은 이점이 있다.\n실용성(pragmatic) : 프로토콜에서 id를 이용한 로직을 사용할 수 있다. 보안(security) : 특정 인물의 malicious한 행동을 tracking 가능하다. 그럼에도 불구하고 bitcoin에서 identity를 사용하지 않는 이유는 p2p system의 한계 때문이다.\np2p는 중앙 체제가 없기 때문에 인정받은 identity를 갖기 어렵다. bitcoin 자체가 현실의 identity를 사용하는 것을 원하지 않는다. (특정 node에서 이루어지는 transaction들은 구분할 수 있지만, 그 node가 현실의 누구 것인지는 알 수 없다.) 이러한 identity가 없는 특징 때문에 p2p network는 Sybil attack에 취약하다. Sybil attack : 한 명이 가상의 node들을 다수로 만들어 마치 여러 사람인 것 처럼 보이게 하는 것. weaker assumption node마다 identity를 부여하고, 이 부여받은 identity를 검증하는 작업은 매우 복잡하다.\nauthenticated 된 identity를 부여하는 것 대신 랜덤한 token을 node에 부여한다.\ntoken으로 특정 node를 구분할 수 있으며, 특정 사용자가 여러 node들을 만드려 할 경우 해당 node들에 동일한 token을 부여하는 방식으로 Sybil attack을 방지할 수도 있다.\nimplicit consensus : 매 round마다 random node가 선택되고, 이 node는 block chain에 들어갈 다음 block을 추천하는 방식.\n이 추천은 일방적이며, consensus 알고리즘이나 투표같은게 없다. 다른 node들은 implicitly 하게 이 block을 수락하거나 거절함으로써 malicious한 node의 행위를 막을 수 있다. implicitly 하다는 뜻은, 직접적으로 투표를 행하지는 않지만, 해당 block을 포함한 block chain을 사용하면 찬성하는 것이고, 그렇지 않다면 반대하는 것이다. block chain에서 특정 block은 마지막 block의 hash를 가지고 있기에 가능하다. bitcoin에서 사용되는 consensus algorithm을 간단하게 살펴보면 아래와 같다.\n신규 transaction은 모든 node들에 broadcast된다. 각 node들은 transaction들을 모아 block을 구성한다. 매 round마다 random node가 선출되고, 그 node에서 생성한 block을 broadcast한다. 다른 node들은 (3)에서 전송된 block을 보고, valid(unspent, valid signature) 하다면 이를 수락한다. Node들은 다음번 만드는 block에다 (3)에서 전송된 block의 hash를 집어넣음으로써 implicit하게 수락을 표현할 수 있다. (그렇지 않으면 거절을 표현한 것) 그렇다면 위 방식에 문제는 없을까?\nsignature 설정 방식이 견고하다면, transaction을 위조할 수 없기 때문에 타인의 coin을 강제로 탈취할 수 없다. 특정 node가 valid 한 데이터를 계속 deny 하더라도, 해당 node가 다음 round에서 선택되지 않으면 transaction들은 정상적으로 올라가게 된다. 약간의 번거로움만 있을 뿐 전체 시스템에 치명적인 문제가 발생하지는 않는다. node가 수행할 수 있는 악의적인 행위로는 \u0026lsquo;double spending attack\u0026rsquo; 이 있다. double spending attack\nblock chain의 block1을 base로 A가 B에게 coin을 넘겨준 transaction [b1 : A -\u0026gt; B] 이 있다고 하자 이때, A가 악의적으로 A가 자신의 또다른 계정 A\u0026rsquo;에게 coin을 넘겨주었다는 거짓 transaction [b1 : A -\u0026gt; A\u0026rsquo;] 를 추가한다면, 정상적으로 수행된 [b1 : A -\u0026gt; B] transaction과 충돌이 발생한다. 즉, merge conflict가 발생하는 2개의 branch가 생성되는 것이다. 이는 moral distinction을 요하기 때문에 기술적으로 어렵다. node들은 대체로 먼저 들어온 block을 수락하고, 더 긴 branch를 정당한 branch로 취급한다. 조작된 transaction [b1: A -\u0026gt; A\u0026rsquo;]이 든 block이 network 지연 등의 이슈로 인해 먼저 broadcast되고, 정당성을 확립하면 실제 transaction[b1 : A -\u0026gt; B] 는 orphan block이 되고, 네트워크에서 사라지게 된다. 0 confirmation transaction\ndouble spending attack을 막기 위해, block chain에 내가 coin을 지불받는 transaction이 정상적으로 들어있는 것을 확인한 후 현실 세게에서 물건을 전달하는 방식 다른 node가 올린 block에서 내 transaction이 정상적으로 적용되었는지 확인할 수 있다. 해당 block 뒤에 더 많은 block이 붙을 수록 \u0026rsquo;long term consensus chain\u0026rsquo; 이 될 확률이 높아진다. double spending attack의 성공 확률은 confirmation의 횟수만큼 exponential 하게 줄어든다. block chain의 형태가 아래와 같을 때,\r[block1] - [block2] - [block3] - [block4] - [block5]\rblock3는 3 confirmation을 받은 상태이다.\rblock4는 2 confirmation을 받은 상태이다. 일반적인 bitcoin에서는 transaction이 정상적으로 이루어진 것을 판단하기 위해서 6 confirmation을 확인한다. 이는 시간과 확률의 trade-off 관계에서 성립된 수치이다. honesty problematic 우리는 탈 중앙화를 위해 랜덤한 node에서 block을 받아 block chain에 적용하기로 했다. 하지만 모든 node가 honest 한지에 대해서는 보장할 수 없다. 각 node들은 현실 정보의 개인정보를 갖고있지 않기 때문에 block chain에 위해를 가하는(double spent 같은 공격) node를 처벌할 수 없다. 대신 올바른 block들을 만들어주는 node들에 대해 보상을 주는 방법은 가능하다. 이는 block chain으로 구성된 내용이 가치를 가지는 crypto currency 이기 때문에 가능하다. Incentive Algorithm bitcoin은 decentralize를 위해 기술적인 부분(distributed consensus)과 incentive aoglrithm 을 사용한다. block reward block chain의 규칙에 따라, block을 생성하는 node는 특수한 coin-creation transaction을 추가할 수 있다. 이를 통해 coin을 생성하고, 그것을 자신의 계좌로 연결하여 수익을 얻을 수 있다. bitcoin에서 현재(14.08) coin 생성 양은 25 코인으로 고정되어 있는데, 이는 매 4년마다 절반으로 줄어든다. 최초에는 50코인이었다. coin-creation transaction은 다른 transaction과 마찬가지로 취급된다. transaction이 consensus chain에 들어가야 효력이 발생한다. 즉, 자신의 coin-creation transaction이 든 block이 consensus chain에 포함되려면, 다른 node들이 agree 할 만한 block을 base로 하여 block을 연결하는게 유리하다. 악의적인 node가 double-spending attack을 위해 길이가 긴 block-chain을 무시하고 임의의 block을 base로 하여 자신의 block을 연결한다면, 다른 node들은 그가 만든 block-chain을 reject 할 것이고, 그가 받는 보상은 무효화 될 것이다. 이러한 방식으로 node들이 honest하게 동작하도록 유도한다. 새로운 bitcoin은 transaction시 발생하는 coin-creation transaction에 의해서만 생성되고, 현재 규칙이 계속 유지될 경우 2140에는 새로운 coin이 생성되지 않고 21 million 에서 수렴할 것이다. transaction fee transaction을 생성하는 자는(거래를 하는 자) output value를 임의로 설정할 수 있다. (단, output value \u0026lt; input value)\n해당 transactio을 최초로 block에 넣는 node는 input-output 의 차액을 가져갈 수 있다.\ntransaction fee는 자발적이고, tip과 같은 느낌이지만, block reward가 점차 감소하는 시점에서 시스템을 유지하기 위해서는 필수적인 요소가 된다.\n이러한 시스템에서도 아직 해결안된 문제는 남아있다.\n어떻게 random 한 node를 선택할 것인가 보상을 위해 과도한 경쟁(free-for-all)을 하는 현상을 어떻게 막을 것인가 Sybil attack 의 방지(2번의 심화 형태) 위 세가지 문제점은 모두 연관되어 있고, 하나의 방법으로 해결 가능하다. Proof of work 직접 random 한 node를 선택하는 대신, resource(computing power) 의 비율로 다음 node가 선택되게 하는 방법이다.\n즉, 각 node들이 각각의 computing power을 이용해 서로 경쟁하도록 하는 것이다.\n이러한 경쟁 방법을 Hash puzzle이라 부른다.\nblock을 [nonce, previous hash, {Tx1, Tx2, \u0026hellip;}] 형태로 구성하도록 한다. nonce를 포함한 전체 block을 hash 로 취했을 때, 결과값 중 target space(일반적으로 1% 이하의 매우 작은 영역)가 특정한 값이 나오도록 해야한다. (target 값보다 작은 값이 되도록) hash function이 충분히 secure 하다면, nonce를 찾으려면 random한 nonce 값을 넣으며 계산을 시도해야 하며, 일반적으로 많은 computing power가 필요할 것이다. 이를 통해 단순히 node의 숫자를 늘려서 다음 block을 선택할 기회를 얻을 확률을 높일 수 없게 되었다.\n또한 누군가가 랜덤한 block을 선출하는 것이 아닌, 경쟁과 확률을 통해 자연적으로 선출될 수 있도록 하였다.\nProof of work의 속성 Difficult to compute hash puzzle을 푸는데는 현재(14.8) 기준 block당 약 10^20 hash를 계산해야 한다. (target space의 크기가 1/10^20 이란 의미) 일반적인 PC로는 감당할 수 없고, 많은 양의 computing power을 사용하여야 하는 작업이다. 이렇게 nonce 값을 찾는 것을 흔히 bitcoin mining이라 하는 과정이다. parameterizable cost target space의 범위를 고정된 %로 취하는 것이 아닌, 가변적인 값으로 설정한다.\np2p 에 연결된 모든 node들은 자동적으로 매 2주마다 target space를 재 설정하도록 동작한다.\ntarget space의 값은 hash puzzle을 푸는데 걸리는 시간이 약 10분이 되도록 하는 것을 목표로 한다.\nblock 간의 간격이 10분이 되는 이유는, 너무 빨리 block이 갱신되면 한 block에 여러 transaction(현재기준 약 수백개)을 담아 효율적으로 운영할 수 없게 된다. latency는 기술적으로는 더 낮게 설정할 수도 있지만, 모두의 동의 하에 하한값을 설정하여 작동한다. 특정 node가 다음 block을 설정하게 될 확률은, 전체 node들의 computing power에서 그 node가 갖고 있는 computing power 의 비율에 비례한다.\n결과적으로, 다량의 computing power을 가지고 mining을 하고 있는 사람들은 대부분이 honest하고, 다음 block 선택을 경쟁적으로 수행하기 때문에 적어도 50% 이상의 확률로 block이 honest node에서 선택되었음을 보장할 수 있다.\nnonce는 확률적으로 밖에 도출될 수 없다. 이는 discrete probability process로, Bernoulii trial 이다.\nnonce를 찾는 과정은 Bernoulii trial을 연속적으로 수행하는 poisson process에 속한다. 전 network에서 누군가가 nonce를 찾는데 걸리는 시간을 확률 밀도함수(probability density)로 표현하면 exponential distribution을 이룬다. (0에 수렴하도록 감소하는 지수 함수) Trivial to verify 특정 node가 hash puzzle을 해결하여 올린 block을 다른 node에서 쉽게 검증할 수 있어야 한다. H(block) \u0026lt; target, block의 모든 값을 hash 계산한 결과가 target 보다 작은지 확인 ","permalink":"https://aswinblue.github.io/post/crypto/cryptocurrency/","summary":"Cryptocurrency Cryptographic Hash function hash function은 아래와 같은 속성을 갖는다. 모든 크기의 String을 input 으로 받는다. 정해진 크기의 output을 생성한다. (bitcoin에서는 256bit) 적당한 시간 안에 계산이 가능하다. (계산 시간이 너무 길지 않다) cryptographic hash function은 아래와 같은 security 속성을 추가로 갖는다.\ncollision-free hiding puzzle-friendly 속성1. collision-free x != y 라면, H(x) = H(y) 인 경우를 찾을 수 없어야 한다. 이 말은 collision 이 존재하지 않는다는 뜻은 아니다. num(possible_input) \u0026gt; num(possible_outputs) 이다.","title":"Cryptocurrency"},{"content":"firebase firebase는 실시간 db로 유명하며, google에 인수되고 폭이 넓어졌다. Amazon의 Amplify가 firebase와 유사하다. 일정 사용량 까지는 무료로 사용 가능하며, 이후에는 요금이 부가된다. 설치 및 사용 온라인으로 콘솔에 접속하여 프로젝트를 생성 및 설정하고, firebase sdk를 로컬에 다운받아 코드에 적용한다. firebase는 다양한 운영체제에 설치 가능하며, 각각의 설치 방법을 따르면 된다. (웹에서는 설치하지 않고 url로 참조해 사용할 수도 있다.) 버전이 올라감에 따라 참조방법, 인터페이스 등 사용법이 바뀌는 경우가 많으니 항상 docs를 잘 살펴보자\nfirebase link: https://firebase.google.com\nfirebase docs : https://firebase.google.com/docs\nfirebase를 코드에 적용하려면 config 데이터를 작성해야 한다.\nfirebase 콘솔에서 앱을 생성하고, 내 소스를 firebase의 내 프로젝트와 연동에 필요한 config 정보들을 복사하여 소스에 적용한다. ex) AppFirebase.js import firebase from \u0026#34;firebase/compat/app\u0026#34;;\rimport \u0026#34;firebase/compat/auth\u0026#34;;\rconst firebaseConfig = {\rapiKey: process.env.REACT_APP_API_KEY,\rauthDomain: process.env.REACT_APP_AUTHDOMAIN,\rprojectId: process.env.REACT_APP_PROJECTID,\rstorageBucket: process.env.REACT_APP_STORAGEBUCKET,\rmessagingSenderId: process.env.REACT_APP_MESSAGINGSENDERID,\rappId: process.env.REACT_APP_APPID\r};\rexport default firebase.initializeApp(firebaseConfig);\rexport const authService = firebase.auth(); 기능 firebase 콘솔에 로그인 하고, 프로젝트를 생성한다. 생성된 프로젝트에 진입하여 원하는 기능을 사용할 수 있다. 인증 (Auth) \u0026lsquo;Authentication\u0026rsquo; 탭을 선택하여 사용 가능하다. email, phone, google account, facebook account 등 다양한 인증 방법을 제공한다. 다만, 주의할 점은 firebase API를 이용해 인증 서비스를 이용하면, 이후 확보된 사용자층을 다른 플랫폼으로 옮길 수 없다는 점이다. 로그인에 사용된 계정들은 콘솔창에서 관리할 수 있으며, 비밀번호 재설정 등을 위한 메일도 커스텀할 수 있도록 환경이 제공된다. React code import { authService } from \u0026#34;../components/AppFirebase\u0026#34;;\rconst data = await authService.createUserWithEmailAndPassword(email, password) // email, passwd로 계정 생성\rconst data = await authService.signInWithEmailAndPassword(email, password) // email, passwd로 로그인 email 인증 Authentication 탭에서 signed-in method를 선택한다. 원하는 \u0026lsquo;로그인 제공업체\u0026rsquo; 를 선택하여 추가한다. ","permalink":"https://aswinblue.github.io/post/database/firebase/","summary":"firebase firebase는 실시간 db로 유명하며, google에 인수되고 폭이 넓어졌다. Amazon의 Amplify가 firebase와 유사하다. 일정 사용량 까지는 무료로 사용 가능하며, 이후에는 요금이 부가된다. 설치 및 사용 온라인으로 콘솔에 접속하여 프로젝트를 생성 및 설정하고, firebase sdk를 로컬에 다운받아 코드에 적용한다. firebase는 다양한 운영체제에 설치 가능하며, 각각의 설치 방법을 따르면 된다. (웹에서는 설치하지 않고 url로 참조해 사용할 수도 있다.) 버전이 올라감에 따라 참조방법, 인터페이스 등 사용법이 바뀌는 경우가 많으니 항상 docs를 잘 살펴보자","title":"Firebase"},{"content":"Go 설치 및 프로젝트 생성 구글 검색을 통해 설치파일을 다운받는다. root 디렉터리 설정이 필요하다.(\u0026lsquo;C:\\Go, \u0026lsquo;/usr/local/go/bin/\u0026rsquo;) 이후 생성할 프로젝트는 이 root 디렉터리 하위 경로에 생성된다. 외부 경로에는 프로젝트를 생성할 수 없다. root 디렉터리 안 src 디렉터리에 프로젝트를 생성한다. Go는 npm, pip 와 같이 패키지 매니저가 없다. git 등에서 코드를 받아오면 src 디렉터리 안에 도메인별로 정리해서 관리하는게 정석이다. 문법 printf format specifier %v: used as a placeholder for the default format representation of a value %+v: a detailed representation of the value, including all the fields and their corresponding values for structs and maps. ","permalink":"https://aswinblue.github.io/post/golang/golang/","summary":"Go 설치 및 프로젝트 생성 구글 검색을 통해 설치파일을 다운받는다. root 디렉터리 설정이 필요하다.(\u0026lsquo;C:\\Go, \u0026lsquo;/usr/local/go/bin/\u0026rsquo;) 이후 생성할 프로젝트는 이 root 디렉터리 하위 경로에 생성된다. 외부 경로에는 프로젝트를 생성할 수 없다. root 디렉터리 안 src 디렉터리에 프로젝트를 생성한다. Go는 npm, pip 와 같이 패키지 매니저가 없다. git 등에서 코드를 받아오면 src 디렉터리 안에 도메인별로 정리해서 관리하는게 정석이다. 문법 printf format specifier %v: used as a placeholder for the default format representation of a value %+v: a detailed representation of the value, including all the fields and their corresponding values for structs and maps.","title":"Golang"},{"content":"#Tensorflow\nTensorFlow는 구글에서 수치연산을 위해 만든 라이브러리이다. 기본 개념 node와 edge로 구성된 graph를 이용해 수치 연산을 수행한다. node들은 특정한 데이터가 들어오면 연산을 수행하거나, 형태를 변경하거나, 결과를 출력하는 역할을 한다.\nedge는 학습데이터가 저장되는 다차원 배열이다.\nedge는 node에서 계산된 데이터를 다음 node로 이동시킨다.\nedge는 방향성이 있으며(directed), tensor라 불린다.\narchive.ics.uci.edu/ml 에서 학습용 데이터를 받아 사용할 수 있다.\n설치 python과 pip를 설치한다. pip install tensorflow 명령을 수행한다. window에서 \u0026lsquo;client_load_reporting_filter.h\u0026rsquo; 파일을 찾지 못해 설치를 못했다면, path 경로가 너무 길어서 발생하는 오류이다. 실행에서 regedit을 실행하고, \u0026lsquo;HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\u0026rsquo; 레지스트리를 찾아 값을 1로 세팅해준다. 연관 모듈 함께 쓰면 효율이 좋은 모듈들 matplotlib numpy data = np.loadtxt(FILE_NAME, delimiter=',') : ,를 기준으로 데이터를 나누는 csv 파일을 읽어들임. 숫자 데이터를 읽을 때 사용 keras (tensorflow 설치시 자동성치된다) y_encoded = to_categorical(y_data) : y_data 를 one-hot-encoding 하는 함수 (tensorflow.keras.utils.to_categorical) pandas df = pd.read_csv(FILE_NAME) : csv 파일을 읽어서 dataframe을 구성한다. 숫자 및 문자열 데이터를 읽을 때 사용 가능 sklearn 데이터 전처리 e = sklearn.preprocessing.LabelEncoder()\re.fit(data) # data 에 들어있는 값 중 unique한 값을 뽑아(중복 제거) 특정 string에 번호를 매기는(indexing) 함수\rdata = e.transform(data) # indexing 된 정보를 바탕으로 실제 data값을 index로 치환 기본 문법 상수 선언\nval = tf.constant(value, dtype=None, shape=None, name='Conts', verify_shape=False) value = 값 dtype : 데이터 타입, ex) \u0026rsquo;tf.float32\u0026rsquo;, \u0026rsquo;tf.float64\u0026rsquo;, \u0026rsquo;tf.int8\u0026rsquo; float(32, 64), int(8, 16, 64),uint(8, 16), string, bool, complex(64, 128 : 복소수) shape : 차원, value 형태에 따라 자동으로 설정 됨, ex) \u0026lsquo;[3,3]\u0026rsquo; name : 상수의 이름 verify_shape : tensor의 shape를 바꿀수 있는지 여부 배열 생성 arr = tf.range(5) output : tf.Tensor : shape(5,), dtype=int32, numpy=([0, 1, 2, 3, 4], dtype=int32)\n\u0026rsquo;tf.zeros([2,3])\u0026rsquo; output : [[0, 0, 0], [0, 0, 0]]\n\u0026rsquo;tf.ones([2,3])' output : [[1, 1, 1], [1, 1, 1]]\n\u0026rsquo;tf.fill([2,3], 5)' output : [[5, 5, 5], [5, 5, 5]]\n연산자 tf.add(x,y) : x + y\ntf.subtract(x,y) : x - y\ntf.multiply(x,y) : x * y\ntf.div(x,y) : x / y\ntf.floordiv(x,y) : x // y\ntf.mod(x,y) : x % y\ntf.pow(x,y) : x ** y\ntf.less(x,y) : x \u0026lt; y\ntf.less_equal(x,y) : x \u0026lt;= y\ntf.greater(x,y) : x \u0026gt; y\ntf.greater_equal(x,y) : x \u0026gt;= y\ntf.logical_and(x,y) : x \u0026amp; y\ntf.logical_or(x,y) : x | y\ntf.logical_xor(x,y) : x ^ y\ntf.maximum(x,y) : max(x,y)\ntf.reduce_sum(a) : 배열 a에서 같은 index 위치의 값을 모두 더한 스칼라 값을 반환\ntf.reduce_mean(a) : 배열 a에서 같은 index 위치의 값을 평균낸 스칼라 값을 반환 x,y가 배열인 경우, 연산자는 같은 index에 위치한 값끼리 연산한다.\nex) tf.add(x,y) = [(x[0] + y[0]), (x[1] + y[1]), (x[2] + y[2]), ...] \u0026lsquo;reduce\u0026rsquo; 가 들어간 연산은 axis 파라미터를 설정하여 어느 축을 기준으로 연산을 수행할지 설정 가능\nex) a = [[1,2,3],[4,5,6]]\rtf.reduce_sum(a, axis=0) = [5, 7, 9]\rtf.reduce_sum(a, axis=1) = [6, 15] 변수 tensorflow에서 변수는 node를 만들고, 그 안의 값을 참조하는 방식이다.\nvar = tf.Variable(value, dtype=type)\nvalue : 변수에 담을 값 dtype : 변수 타입 2.x 버전에서는 위와같이 선언과 동시에 초기화가 가능하다. node를 생성하고 var은 그 node의 주소를 가리킨다.\nvar.assign(value)\nvar이 가리키는 node에 value 값을 적용\nvar.assign_add(value)\nvar이 가리키는 node에 value 값을 더함\nvar.assign_add(value)\nvar이 가리키는 node에 value 값을 뺌\ntf.cast()\n변수를 특정 값, 특정 형태로 치환해주는 함수\n출력\nval.numpy() : \u0026lsquo;val\u0026rsquo; tensor를 numpy 배열 형태로 출력\n비교 tf.equal() : tensorflow 변수를 비교하는 함수\n랜덤 tf.random.set_seed() : 정수를 이용해 랜덤값 시드 설정 tf.random.normal([2, 1], mean=0.0)) : 정규분포에 기반한 랜덤값, 인자로 행렬 shape와 평균이 들어간다.\n심화 내용 tensorflow와 행렬 TensorFlow에서 배열은 행렬로 표현되며, 행렬은 shape라 불린다. 행렬 계산을 위한 함수를 제공한다. tf.matmul(a, b) : 행렬의 내적(곱) tf.linalg.inv(a) : 역행렬 Broadcasting 행렬을 곱셈 혹은 덧셈을 하기 위해서는 shape에 대한 제약조건이 있고, tensorflow에서도 마찬가지다. tensorflow에서는 행렬 연산에서 차원(shape)이 맞지 않을 때 행렬을 자동으로 늘려서(Stretch) 차원을 맞춰주는 Broadcasting기능이 있다. 연산시 shape는 첫번째 피연산자를 기준으로 한다. stretch 시 새로 생성된 공간에는 기존 내용을 복사하여 채워넣는다. 단, 늘릴 수는 있지만, 줄일수는 없다. ex) a[4,3] + b[1,3] : 가능 a[4,3] + b[1,5] : 불가능 (3 \u0026lt; 5 이므로, 5를 3으로 바꾸려면 축소해야함) a[4,1] + b[1,3] : 가능 tensorflow 함수 tensorflow 1.x 버전은 placeholder를 통해 입력을 받는 객체를 생성하고, 실행시 session을 통해 feed 값을 전달한다. 즉 명시적으로 입력 형태를 구성해야 했다. tensorflow는 2.x 버전부터 python 프로그램처럼 라이브러리를 사용할 수 있도록 연산에 함수를 제공하고 있다. 함수를 사용하면 placeholder를 생략하고 사용할 수 있다. tensorflow 함수는 파이썬 함수처럼 정의하여 사용 가능하며, 컴파일시 속도 향상을 원한다면 @tf.function 데코레이터를 적용하면 된다.\nex) @tf.function\rdef t_func(a,b):\rreturn tf.matmul(a,b)\rx = [[4,5,6],[6,7,8]] # tensorflow 변수가 아님\rw = tf.Variable([2,5],[6,5],[17,10])\rprint(t_func(x,w))\r# tensorflow 2.x 이후부터는 변수 x같은 값들도\r# placeholder를 만들고 feed 값을 주는 복잡한 과정 없이\r# tensorflow 함수를 이용해 연산 가능해졌다. tensorflow 미분 gradient 계산에 미분이 많이 사용고, tensorflow는 미분 함수를 제공한다. tape.gradient(y,x) : 텐서 x에 대한 y의 미분값 tape.watch() : 상수형 텐서를 변수형 텐서로 변환 ex)\nx1 = tf.Variable(tf.constant(1.0)) # 변수 선언\rx2 = tf.Variable(tf.constant(2.0)) # 변수 선언\rwith tf.GradientTape() as tape: # 미분을 위해 GradientTape 객체 생성\ry = tf.multiply(x1, x2) # 미분할 함수값을 GradientTape 객체 안에서 정의\rgradients = tape.gradient(y, [x1, x2]) # x1 미분값과 x2 미분값을 각각 반환\r# y = x1 * x2\r# x1 에 대한 미분값 : 2.0\r# x2 에 대한 미분값 : 1.0\r# gradients = [2.0, 1.0]\ra = tf.constant(2.0)\rgradients2 = tape.gradient(y,a)\r# 상수로 미분하면 None 값이 된다.\r# gradients2 = None\r# 상수를 변수로 변환시켜 미분시킬 수 있다.\rwith tf.GradientTape() as tape:\rtape.watch(a)\ry = tf.multiply(x1, a)\rgradients3 = tape.gradient(y,a)\r# gradients3 = 1.0 선형 회귀 \u0026lsquo;딥러닝\u0026rsquo;은 데이터를 통해 관계를 학습하고, 학습된 모델을 통해 데이터가 주어지면 예측값을 도출해 내는 기술이다. \u0026lsquo;딥러닝\u0026rsquo;의 가장 기본적인 계산 원리는 \u0026lsquo;션형 회귀\u0026rsquo;와 \u0026lsquo;로지스틱 회귀\u0026rsquo; 이다. 선형회귀 : 데이터 분포를 통해 데이터들과 가장 근접한 선을 도출해내는 계산법 로지스틱 회귀 : 0과 1 둘 중 하나를 선택하는 계산법 판단의 근거를 마련할 때 사용 sigmoid 함수를 사용하여 확률값으로 사용 선형 회귀 정의 종속변수 y와 한개 이상의 독립변수 x와의 선형 상관관계를 모델링하는 회귀분석 기법\n단순 선형회귀 : 하나의 변수에 기반하여 동작 다중 선형 회귀 : 둘 이상의 변수에 기반하여 동작 선형 예측함수를 통해 회귀식을 모델링하고, 알려지지 않은 파라미터를 데이터로 추정\n회귀식을 선형 모델이라고 한다.\n값을 예측하기 위해 학습 데이터로 적합한 예측 모형을 개발한다.\n종속변수 y와 이에 연관된 독립변수들 x1, x2\u0026hellip; 에 대해 x와 y간의 관계를 정량화 할 수 있다.\n일반적으로 최소제곱을 사용해 선형 회귀 모델을 구할 수 있다. (y = ax + b 형태)\n독립변수(x)가 증가하면 최소 제곱법으로 처리가 불가능하다. 딥러닝에서는 y = wx + b 형태로 표현하는데, w 는 weight, b는 bias 를 뜻한다.\nweight : 가중치, 입력값 x의 영향도를 표현하는 상수 bias : 기준점, 판단의 근거가 되는 식의 기준점을 표현하는 상수 오차방정식 선형 회귀에서 입력값이 여러개일 경우, 첫번째 입력으로 임의의 선을 그린다.\n정답과 임의의 선이 맞는지 확인하고 평가한다 (오차 확인)\n확인된 오차 값을 이용해 임의의 선을 수정한다.\n즉, y = ax + b 에서 (x,y)를 입력으로 받고 a,b를 추론한다. 이러한 계산 식을 오차방정식이라 한다.\n오차의 합 = ∑ (예측값 - 정답)²\nMSE : Mean Squared Error, 평균제곱오차 = (오차의 합) / n\nRMSE : Root Mean Squared Error, 평균 제곱근 오차 = root(편균제곱오차)\n경사 하강법 대표적인 \u0026lsquo;최적화 알고리즘\u0026rsquo;으로, 비용 함수를 최소화하기 위해 반복해서 파라미터를 조정해나가는 방식이다.\ny = a*x 방정식에서 x = [1,2,3] y = [1,2,3] 이라고 한다면 a값은 1이다. 이때 MSE 오차식과 x에 대해 그래프를 그리면 2차원 그래프가 나오게 된다. 이때 기울기가 0인 부분, 즉 꼭짓점의 x 값이 정답이 된다.\n이러한 특성을 이용하여 다음과 같이 정답을 찾는 recursive한 전략을 취할 수 있다.\n임의의 값 x1에서 미분을 구한다. 구해진 기울기의 반대 방향으로 이동하여 그래프와 겹쳐지는 부분의 x좌표를 x2라 한다. 1~2 과정을 반복하면 점차 기울기가 줄어들고, 이를 충분히 수행하면 정답값에 수렴한다. 하지만 오차 그래프의 폭이 좁은 경우, 위 방식을 수행하면 특정 값으로 수렴하지 않고 결과값이 발산한다.\n이를 막기 위해 기울기를 100% 취하지 않고, \u0026lsquo;학습률\u0026rsquo; 이라는 상수를 곱해 일정 양만큼만 전략에 반영될 수 있게 한다.\n학습률은 정해진 값이 아니고, 데이터에 따라 적합한 값이 달라지는 상수이다.\n위 전략을 수정하여 다시 적용하면\n임의의 값 x1에서 미분을 구하고, 학습률을 적용하여 값을 조정한다. 구해진 값을 기울기로하여 이동할 때 그래프와 겹쳐지는 부분의 x좌표를 x2라 한다. 1~2 과정을 반복하면 점차 기울기가 줄어들고, 이를 충분히 수행하면 정답값에 수렴한다. learning_rate = 0.1\rwith tf.GradleTape() as tape:\rhypothesis = W * x_data\rcost = tf.reduce_mean(tf.square) 로지스틱 회귀 선형회귀와 함께 대표적인 딥러닝 알고리즘이다.\n독립변수의 선형 결합을 이용하여 사건 발생의 가능성을 예측하는데 사용되는 \u0026lsquo;통계 기법\u0026rsquo; 이다. (확률 계산)\n로지스틱 회귀는 종속변수와 독립변수 간의 관계를 함수로 나타내어 향후 예측모델에서 사용하므로, 독립변수의 선형 결합으 종속변수를 설명한다는 관점에서 선형 회귀분석과 유사하다.\n하지만, 로지스틱 회귀는 데이터의 결과가 특정 분류로 나뉘어 지기 때문에 classification 기법으로 볼 수 있다.\n이진 분류 문제, 즉 0과 1 중 하나를 판별하는 문제는 로지스틱 회귀를 이용하여 풀 수 있다.\nstep function 혹은 sigmoid를 사용하는데, 보통 0과 1 사이의 확률값을 표현할 수 있는 sigmoid를 사용한다.\n시그모이드 시그모이드 방정식은 아래와 같다.\ny = 1 / (1 + e \u0026lt;sup\u0026gt;-x\u0026lt;/sup\u0026gt;)\ne는 자연상수이며, 자연상수를 사용하였기 때문에 확률값으로 사용 가능하다.\nsigmoid 함수에 선형 회귀 함수를 대입하면 아래와 같이 된다.\ny = 1 / (1 + e \u0026lt;sup\u0026gt;(-wx+b)\u0026lt;/sup\u0026gt;)\n이 함수에 경사하강법을 이용하여 w와 b를 찾아낼 수 있다.\nw값이 증가하면 sigmoid 함수는 step function에 유사하게 경사가 가팔라 진다.\nb값이 증가하면 그래프가 우측 방향으로 이동한다.\n오차함수 로지스틱 회귀는 target이 0 또는 1 두가지라는 점에서 선형 회귀와 다르다.\n때문에 로지스틱 회귀는 오차함수도 두가지가 있다.\n정답이 0일 경우 -log(l-h) 그래프 형태이다. 정답이 1일 경우 -log(h) 그래프 형태이다. 정답값 0 혹은 1을 대입하면 원하는 오차함수가 나오는 식을 binary cross entropy 라 하고, 그 식은 다음과 같다.\nY = -(Y * LOG(H) + (1-Y)*LOG(1-H))\n로지스틱 회귀법을 tensorflow 함수로 구현하면 아래와 같다.\n# 6 by 2 형태의 x 데이터 학습값\rx_train = np.array([[1., 1.],\r[1., 2.],\r[2., 1.],\r[3., 2.],\r[3., 3.],\r[2., 3.]],\rdtype=np.float32)\r# 6 by 1 형태의 y 데이터 학습값\ry_train = np.array([[0.],\r[0.],\r[0.],\r[1.],\r[1.],\r[1.]],\rdtype=np.float32)\r# 이 학습값을 이용해 W와 b를 찾아본다.\r# 랜덤값을 위한 설정\rtf.random.set_seed(12345)\r# W와 b의 초기값을 랜덤하게 설정, x값이 [6, 2] 이므로 W 형태를 [2, 1] 로 해야 y 값인 [6, 1] 에 맞게 matmul이 가능하다.\rW = tf.Variable(tf.random.normal([2, 1], mean=0.0))\rb = tf.Variable(tf.random.normal([1], mean=0.0))\rprint(\u0026#39;weights: \\n\u0026#39;, W.numpy(), \u0026#39;\\n\\nbias: \\n\u0026#39;, b.numpy())\r# x값을 sigmoid 함수에 대입하여 y값을 반환하는 함수\r# x값의 shape가 [,2] 형태이므로 z = -(w1*x1 + w2*x2 + b) 가 된다.\rdef predict(X):\rz = tf.matmul(X, W) + b\rhypothesis = 1 / (1 + tf.exp(-z))\rreturn hypothesis\r# 반복 학습\rfor i in range(2001):\rwith tf.GradientTape() as tape:\rhypothesis = predict(x_train)\r# cost : binary cross entropy 식으로 loss 값을 계산\rcost = tf.reduce_mean(-tf.reduce_sum(y_train*tf.math.log(hypothesis) + (1-y_train)*tf.math.log(1-hypothesis)))\r# w와 b로 편미분하여 오차값 계산\rW_grad, b_grad = tape.gradient(cost, [W, b])\r# 오차값에 learning rate를 적용한 결과값으로 w와 b를 재설정\rW.assign_sub(learning_rate * W_grad)\rb.assign_sub(learning_rate * b_grad)\r# 계산된 w,b를 사용하여 x, y에 대해 정상적으로 예측값이 나오는지 확인\rdef acc(hypo, label):\r# 0.5 이상이면 0, 이하이면 1의 확률이 더 높으므로, 0.5를 기준으로 0 또는 1로 치환해 준다.\rpredicted = tf.cast(hypo \u0026gt; 0.5, dtype=tf.float32)\r# 정확도 = 계산값과 정답을 비교하여 맞으면 1점, 틀리면 0점으로 판단한 후 전체 점수를 평균 낸 값\raccuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, label), dtype=tf.float32))\rreturn accuracy\r# 결과 계산\raccuracy = acc(predict(x_train), y_train).numpy() 퍼셉트론 퍼셉트론은 뉴럴 네트워크의 기본이 되는 개념으로, 인간의 신경망을 본따 프랑크 로젠블라트가 1957년에 고안한 알고리즘이다. 인간의 신경망은 외부 자극을 입력으로 받아 뉴런을 타고 신호가 전달된다. 뉴런과 뉴런 사이의 시냅스에서 신호를 전달하려면 역치값을 넘겨야 신호가 전달된다. 퍼셉트론은 입력을 받아 가중합(w1x1 + w2+x2 + \u0026hellip; + wixi+ b)을 취하고, 활성화 함수(sigmoid)를 거쳐 출력값을 생성한다. 다층 퍼셉트론 한 개의 퍼셉트론은 여러 문제를 해결할수 있다.\n좌표 평면에서 선 하나로 그룹을 구분지을 수 있는 경우에 해당한다. 대표적인 모델로는 AND모델, OR 모델이 있다. 하지만 단일 퍼셉트론으로 풀지 못하는 문제도 존재한다.\nXOR 모델이 대표적이다. 선 하나를 그어서 그룹을 분류할 수 없다. XOR 모델은 OR 퍼셉트론과 NAND 퍼셉트론을 1차적으로 수행하고, 두 수행에 대한 결과를 AND 연산하면 구할 수 있다. 이를 그래프로 표현하면 아래와 같다.\n0층 1층 2층\rx1 → s1 ↘ ↘ ↗ y\r↗ ↘ x2 → s2 ↗ 다중 퍼셉트론은 여러 layer를 두고 연산을 한다는 의미이며, layer가 증가하면 더 많이 분석된다는 뜻. 0층(가장 처음)은 input layer, 2층(가장 마지막)은 output layer, 그 사이의 layer는 hidden layer라 칭한다. hidden layer를 많이 만들면 대체로 데이터를 많이 분석하여 더 좋은 결과를 낼 수 있다고 할 수 있다. 오차 역전파 은닉층에 있는 각각의 w와 b를 구하는 방법이다.\n다층 퍼셉트론을 구성하면 각 layer마다 w와 b값이 구성되는데, 이때 오차를 구하기 위해 미분값을 구하는 것이 쉽지 않다.\n미분 안에 연결된 식이 많기 때문 layer의 개수는 변동될 수 있기 때문에 계산이 복잡하다 이 문제를 해결하기 위해 1980년도 오차 역전파 알고리즘이 발명된다. 이전에도 w와 b를 구할수는 있었지만, 구하는 방법에 대해 규칙성을 찾지는 못했다.\n오차 역전파 개요 최적화의 계산 방향이 output layer 에서 input layer 방향으로 진행된다. 이 떄문에 이 알고리즘을 back propagation 이라 부른다. 퍼셉트론에서 w와 b값을 찾기 위해 오차가 작아지는 방향으로(기울기가 0이 되는 방향으로) 업데이트 해 나갔는데, 다층 퍼셉트론에서는 다음 식으로 가중치를 변화시켜 나간다. W(t+1) = W * t - (∂오차) / (∂w): 새 가중치는 현 가중치에서 가중치에 대한 기울기를 뺀 값 출력층 오차 다층 퍼셉트론의 각 노드는 (1)입력값을 이용해 가중합을 만들고, (2) 가중합을 활성화 함수를 적용해 출력하는 두 단계를 수행한다. 3개 layer를 가지는 형태를 표현하면 아래와 같다. yh1, yh2 : hidden layer의 출력값 y_out1, y_out2 : output layer의 출력값, 예측값 0층 1층 2층\rx1 (w11)→ [가중합1 -\u0026gt; 활성화함수1] → yh1 (w31)→ [가중합3 -\u0026gt; 활성화함수3] → y_out1\r(w21)↘ ↗ (w41)↘ ↗\r(w12)↗ ↘ (w32)↗ ↘\rx2 (w22)→ [가중합2 -\u0026gt; 활성화함수2] → yh2 (w42) → [가중합4 -\u0026gt; 활성화함수4] → y_out2 오차 역전파는 y_out 값에서 반대로 진행하여 가중치 w를 업데이트 한다.\nw31(t+1) = w31 * t - (∂오차 y_out)/(∂w31) : 현재 weight에 미분값을 빼주면 다음 weight가 된다.\n오차 y_out 안에는 여러개의 출력값이 존재할 수 있다. (output layer의 node 개수만큼)\ny_out 안의 각각의 예측값에 대한 오차는 MSE를 이용해 구한다.\noutput layer의 node가 n개라고 하면, k번째 오차는 다음과 같다. 오차_y_out_k = (y_target_k - y_out_k)² / n 오차 역전파로, y_out1 값의 오차로 w31을 업데이트 해 보자.\n오차의 값은 ∂오차y_out / ∂w31 이다.\nchain rule에 의해 ∂오차y_out / ∂w31 = (∂오차y_out / ∂y_out1) * (∂y_out1 / ∂가중합3) * (∂가중합3 / ∂w31) 가 성립한다. 이 식의 우항을 각각 나누어 계산하여 보자. 2-1) (∂오차y_out / ∂y_out1)을 y_out1에 의해 편미분을 하면 y_out1과 관계없는 y_out2는 상수가 되어 사라진다. y_out = y_out1 + y_out2 = (y_target1 - y_out1)² / 2 + (y_target2 - y_out2)² / 2 이기때문에 최종 식은 (∂오차y_out / ∂y_out1) = 1/2 * ∂(y_target1 - y_out1)² / ∂y_out1 = y_out1 - y_target1 가 된다. 2-2) (∂y_out1 / ∂가중합3) 은 \u0026lsquo;활성화함수3\u0026rsquo;을 미분 해 주는것과 같다.\n우리는 활성함수로 시그모이드를 사용했고, 시그모이드의 미분은 ∂σ(x) / ∂x = σ(x) * (1 - σ(x)) 이다.\n따라서 ∂y_out1 / ∂가중합3 = y_out1 * (1 - y_out1) 이 된다. 2-3) 가중합3 = w31 * yh1 + w41 * yh2 + 1(bias) 형태인데, (∂가중합3 / ∂w31) 식에 첫 식을 대입하면 (∂가중합3 / ∂w31 = yh1 이 된다.\n(2)에서 구한 세 식을 합하면 (y_out1 - y_target1) * (y_out1 * (1 - y_out1)) * (yh1) 형태이다. 이때,\ny_out1 - y_target1 은 출력값, y_out1 * (1 - y_out1) 은 활성화함수의 미분 값이다. 이를 활용하여 델타 식으로 표현하면\nw31(t + 1) = w31 * t - δ * y * yh1 이 된다. (δ * y = (y_out1 - y_target1) * (y_out1 * (1 - y_out1)))\n은닉층 오차 위에서 w31을 구했고, 이제 w11을 구해보자\nw31은 y_out1에만 영향을 주고, y_out2에는 영향을 주지 않았다. 하지만 w11은 y_out1과 y_out2에 모두 영향을 주어서 식의 복잡도가 높다.\n점화식을 표현하면 w11(t+1) = w11 * t - (∂오차 y_out) / ∂w11 가 된다.\n(∂오차 y_out) / ∂w11 = (∂오차 y_out) / ∂yh1 * (∂yh1/∂가중합1) * (∂가중합1/∂w11) 형태로 chain rule을 사용할 수 있다. (∂yh1/∂가중합1) 은 activation 함수의 미분값이므로, (∂yh1/∂가중합1) = yh1(1 - yh1) 이 된다. 가중합을 w에 의해 미분하면 입력값이 된다. 따라서 (∂가중합1/∂w11) = x1 (∂오차 y_out) / ∂yh1 = ∂(오차y_out1 + 오차y_out2)/∂yh1 = ∂오차y_out1/∂yh1 + ∂오차y_out2/∂yh1\n5-1) 4 식을 나눠서 계산해보자. 먼저 ∂오차y_out1/∂yh1 = ∂오차y_out1 / ∂가중합3 * ∂가중합3 / ∂yh1' 5-1-1) 이때 ∂가중합3 / ∂yh1 = ∂(w31 * yh1 + w32 * yh2)/∂yh1 = w31 5-1-2)∂오차y_out1 / ∂가중합 = (∂오차y_out1 / ∂y_out1) * (∂y_out1 / ∂가중합3) = ( y_out1 - y_target1) * w31 * (1-y_out1) * y_out1 (∂오차y_out1 / ∂y_out1는 오차를 의미하고,∂y_out1 / ∂가중합3는 활성함수의 미분값을 의미하기 때문) 5-1-3) 최종적으로∂오차y_out1 / ∂yh1 = (y_out1 - y_target1) * w31 * (1 - y_out1) * y_out1 = δy_out1 * w31형태로 델타식을 만들 수 있다. 5-2) 다음∂오차y_out2/∂yh1도 5-1 에서 사용한 방식으로 계산하면 ∂오차y_out2/∂yh1 = δy_out2 * w41형태가 된다. 5-3) 위 값들로 4 에서 봤던 식을 구성하면 (∂오차 y_out) / ∂yh1 = δy_out1 * w31 + δy_out2 * w41` 이 된다. 2, 3, 5-3 에서 나온 값으로 1식을 재구성해보면 (∂오차 y_out) / ∂w11 = (δy_out1 * w31 + δy_out2 * w41) * yh1(1 - yh1) * x1 이다. 출력층의 오차 업데이트 : (y_out1 - y_target1) * y_out1 * (1 - y_out1) * yh1\n(y_out1 - y_target1) : 오차 은닉층의 오차 업데이트 : (y_out1 * w31 + y_out2 * w41) * yh1 * (1-yh1) * x1\n(y_out1 * w31 + y_out2 * w41) : hidden layer를 통해 출력값을 미분한 값 \u0026lsquo;출력층의 오차 업데이트\u0026rsquo;와 \u0026lsquo;은닉층의 오차 업데이트\u0026rsquo;는 공통적으로 y_out(1 - y_out) * x 의 형태(sigmoid function 미분 * 입력값)를 지니고 있다.\n은닉층의 가중치 업데이트를 델타식으로 표현하면 w11(t+1) = w11 * t - δh * x1 이다.\n델타식으로 표현하면 generic 한 형태로 식을 가져갈 수 있어 꼭 필요하다.\n그래디언트 소실(gradient vanishing) 다층 퍼셉트론을 사용할 때, 층이 많을 수록 데이터 분석 능력이 높아지지만, 실제로는 분석 증가량이 미미하다. 이는 활성화 함수 때문이다. 가중치를 수정할 때, 오차 값을 미분한 값을 사용하였다. 각 층의 activation function 으로 sigmoid를 사용했는데, sigmoid 함수는 미분시 최대치가 0.3 밖에 되지 않는다. 층을 지날수록 activation function을 여러번 거치는데, sigmoid의 미분값을 여러번 거치게 되면 미분값이 중간에 0이 되어버리는 현상(vanishing gradient) 문제가 발생한다. 층을 거쳐 갈수록 기울기가 사라져 가중치를 수정할 값이 소실되어 뒤쪽 layer는 더이상 학습이 되어지지 않는다. 그래디언트 소실 문제를 해결하기 위해 sigmoid를 대체할 다른 활성화함수들이 만들어 졌다. 하이퍼볼릭 탄젠트 : 미분 최대값 1, 소실문제를 약화시킬 순 있지만 해결되진 않는다. 렐루 : 0미만은 미분값 0, 0이상은 미분값 1. 많은 층을 사용할 때는 relu를 많이 사용한다. 소프트플러스 xavier와 he 초기화 초기 w와 b 할당시 표준편차가 1이고, 평균이 0인 정규분포를 사용하였다. 이렇게 되면 node를 통과한 결과값이 0과 1에 치중되어 있는 형태를 볼 수 있다. 표준편차를 0.01을 주면 결과값이 0.5로 치중되게 된다. 이렇게 되면 layer를 몇개를 쓰던 layer가 하나인 경우와 동일한 효과가 나온다. 이를 표현력의 제한이라 한다. 이러한 문제점을 xavier 방법을 사용하면 해결할수 있다. 가중치 초기화를 설정하는 방법으로, 결과값의 분포를 더 광범위하게 설정할 수 있게 하는 방법이다. √(2/n_in + n_out) 형태로 최초 사용하는 분포를 만들게 되면 더 광범위한 형태로 만들 수 있다. (n_in : layer의 입력node 개수, n_out : layer의 출력node 개수) 우리는 입력,출력 값이 같은 hidden layer를 사용하므로 √(1/n) 형태를 가진다. 단, xavier 방식은 좌우 대칭인 activation function 에서는 효과적이지만, relu와 같은 좌우 비대칭 형태의 activation function에서는 한쪽으로 치우친 결과값이 얻어진다. 이때는 \u0026lsquo;카밍 히\u0026rsquo;의 이름을 따서 he 초기값을 사용한다. √2/n 의 정규분포 값을 사용한다. (분포 범위를 더 넓게 잡는다) 고속 옵티마이저 옵티마이저란 경사하강법을 뜻한다. 고속 옵티마이저란 경사 하강법을 더 효율적으로 하는 방법이다. 경사 하강법은 대체로 학습 속도와 정확도 문제를 갖고 있다. (learning rate 혹은 data에 의해 발생) 경사 하강법은 업데이트 시마다 전체 데이터에 대해 미분을 계산하여야 하여 속도가 매우 느리다. 학습률이 너무 크면 더이상 최적값으로 수렴하지 못하는 경우가 있다. 경사 하강법은 구현하기 쉽고 단순하다는 장점이 이 있지만, 비등방성 함수에서는 탐색 경로가 비효율적이다. (ex: f(x,y) = 1/20x^2 + y^2 와 같은 타원형 형태) y축은 가파르지만, x축 변동은 거의 없다. 최적값은 (0,0) 이지만 미분으로 기울기 값을 구하면 (0,0) 이 아닌 다른 방향을 가리킬 확률이 매우 높다. 정상적으로 도달하더라도 지그재그 형태로 비효율적인 방식으로 이동하게 된다. 경사 하강법은 무작정 기울어진 방향으로 진행하기 때문에 간단하지만 위와같은 문제점을 야기한다. 경사 하강법의 문제점을 개선해 주는 모델들로는 \u0026lsquo;모멘텀\u0026rsquo;, \u0026lsquo;adagrad\u0026rsquo;, \u0026lsquo;adam\u0026rsquo; 등이 있다. 모멘텀 모멘텀 알고리즘은 물리 현상의 운동량에 착안하여 만들어 졌다. 이전 회차의 미분값 중 일정 비율을 반영하여 현재 weight 값 설정에 영향을 주도록 하여 더 빠르게 최적점을 찾을 수 있도록 하는 방식이다. 기존에는 현재 미분값 * 학습률을 현재 w에 빼주었지만, 모멘텀에서는 (일정 비율) * (이전 미분값) - (학습률) * (현재 미분값) 을 현재 w에 더해준다. 이 값은 V(t) = γ*v(t-1) - η*∂오차/∂w(t) 로 표현한다. 즉, W(t+1) = W(t) + V(t) 와 같은 식이 된다. 이전의 미분값을 일부 적용함으로써 현재 미분값을 상충하는 효과를 얻을 수 있다. 이를 통해 학습 속도를 높일 수 있다. 네스테로프 모멘텀 네스테로프 모멘텀에서는 w를 업데이트 할 때 γ*v(t-1) - η*∂오차/∂w(t) 값 대신 γ*v(t-1) - η*∂오차/∂(w(t) + γ*v(t-1)) 를 사용한다. 모멘텀 방법으로 이동될 방향을 미리 예측하여 해당 방향으로 한단계 미리 이동한 그래디언트 값을 사용함으로써 불필요한 이동을 줄일 수 있다. 속도는 그대로이지만 단계를 절약할 수 있다. 아다그리드 학습률을 조절하여 효율을 높인 모멘텀이다. 아다그라드는 weight값이 업데이트 될 때 마다 점점 최적점을 찾아간다고 가정하고, 학습을 시킬때 마다 일정량의 learning rate를 떨어뜨린다. 학습률을 변화시키기 위해 G(t)값을 G(t) = G(t-1) + [∂오차/∂w(t)]^2 형태로 가져가며, 최종적으로 W(t+1) = W(t) + η * (1/√G(t) + ε) * ∂오차/∂w(t) 형태가 된다. (ε 는 0이 되는것을 방지하기 위해 더해주는 아주 작은 상수값) RMSprop 아다그라드에서 G(t)는 무한히 커지게 되는 문제점이 있다. 이를 해결하기 위해 G(t) = γ * G(t-1) + (1-γ) * [∂오차/∂w(t)]^2 형태를 취한다. \u0026lsquo;γ\u0026rsquo; 값을 이용해 G(t) 값을 조절할 수 있도록 하였다. Adam RMSprop의 정확도, 모멘텀 방식의 속도 장점을 모두 취하는 방식이다.\nRMSprop의 G(t) 값과 모멘텀의 V(t) 값을 유사하게 구하여 사용한다.\nV(t) = γ_1 * G(t) + (1 - γ_1) * ∂오차/∂w(t) G(t) = γ_2 * G(t) + (1 - γ_2) * [∂오차/∂w(t)]^2 V(t)와 G(t) 값을 조절하여 V\u0026rsquo;(t), G\u0026rsquo;(t) 를 만들어 W(t+1) 을 구한다.\nV'(t) = V(t) / (1-r_1^t) G'(t) = G(t) / (1-r_2^t) W(t+1) = W(t) - η * (G'(t) / √(V'(t) + ε)) 이때까지 내용을 모두 분석해 보면 전반적으로 adam 옵티마이저가 좋은 성능을 내기는 한다.\n하지만 항상 adam이 최적의 효율을 내지는 않는다. 이는 데이터 형태가 다르기 때문이다.\n데이터 형태에 따라 취해지는 패턴과 오차 그래프의 모양이 다르기 때문이다.\ngradient descent, momentum, adagrid, adam, RMSprop 중 어느것이 효과가 좋은지 확인이 필요하다.\n다중 분류 입력값을 기준으로 단순 0 또는 1을 판단하는게 아니라, 여러 class 중 하나로 분류하는 모델을 알아보자 출력 node 개수를 분류되는 항목 개수로 설정한다. 활성화 함수를 적용하려면 Y값이 0과 1로 이루어져 있어야 한다. (100% 혹은 0%) 출력 node가 하나라면 Y값은 0 또는 1이면 되지만, 2개 이상이라면 배열이 되어야 한다. 1 =\u0026gt; [1,0,0], 2 =\u0026gt; [0,1,0], 3 =\u0026gt; [0,0,1] 형태로 변형해서 사용해야 한다. 이렇게 Y값을 0 또는 1로만 이루어진 형태로 바꾸어주는 기법을 one-hot-encoding 이라 한다. 텐서플로에서 one_hot() 함수를 지원한다. softMax classification 문제를 풀 때 점수 벡터를 클래스 별 확률로 변환하기 위해 사용하는 함수이다. 각 점수 벡터에 지수를 취한 후 정규화 상수로 나누어 총합이 1이 되도록 계산한다. exponential을 취하는 이유는 값이 클 수록 훨씬 더 높은 점수를 갖게 하기 위함이다. y_k = exp(a_k) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i) softMax는 exponential을 사용하기 때문에 큰 값의 나눗셈을 수행해야 하여 overflow가 발생하기 쉽다. 수식을 개선하여 다음과 같이 사용한다. (keras에서도 개선된 수식을 사용함) y_k = exp(a_k) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i)\r= C * exp(a_k) / C * ∑\u0026lt;i=1,n\u0026gt; exp(a_i)\r= exp(a_k + log C) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i + log C)\r= exp(a_k + C\u0026#39;) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i + C\u0026#39;) Cross Entropy softmax 에서 사용하는 오차방정식 cross entrpoy는 서로 다른 두 값의 확률 차이를 나타낼 수 있다. E = - ∑\u0026lt;k\u0026gt; t_k * log y_k 형태를 가진다. ex) 정답이 [0, 1] 이고, 결과가 [1, 0] 인 경우, E = 0 * log1 + 1 * log0 = ∞ ex) 정답이 [0, 1] 이고, 결과가 [0, 1] 인 경우, E = 1 * log1 + 0 * log0 = 0 오버피팅 훈련 데이터에 지나치게 적응하여 훈련 그 외의 데이터에 대해서는 제대로 평가를 하지 못하는 경우를 일컫는다. 학습 데이터를 통해 경향성만 추출해 내는 것이 가장 바람직한 학습 목표이다. 오버피팅은 모든 데이터를 모으지 못하면 발생할 수 있다. (훈련 데이터가 적을 때) 한쪽으로 편향된 데이터를 학습에 사용하거나, 노이즈를 일으키는 데이터를 사용한 경우에 발생할 수 있다. 은닉층이 너무 많거나 각 층의 노드 수가 많아 변수가 복잡해지면 발생할 수 있다. 테스트 셋과 학습 셋이 중복될 때 생기기도 한다. 데이터 처리 방법 오버피팅을 줄이기 위해서 데이터를 조작하는 방법을 사용할 수 있다. 학습 데이터셋과 테스트 데이터셋을 구분해서 사용한다. 학습 : 테스트 를 7:3 또는 8:2 정도로 사용하는 것이 일반적이다. 학습 데이터를 \u0026lsquo;학습\u0026rsquo; 데이터와 \u0026lsquo;검증\u0026rsquo; 데이터로 나눈다. 학습 데이터를 이용하여 모델을 학습시킨다. 학습을 시키면서 중간중간 검증 데이터를 이용하여 학습된 모델을 검증한다. 데이터를 학습시킬수록 \u0026lsquo;학습\u0026rsquo; 데이터에 대한 오차는 점점 줄어들지만, \u0026lsquo;검증\u0026rsquo; 데이터에 대한 오차는 일정 구간이 되면 증가하게 된다. \u0026lsquo;검증\u0026rsquo; 데이터 오차가 증가하는 시점이 over-fitting이 시작되는 구간이므로 학습을 중단한다. \u0026lsquo;검증\u0026rsquo; 데이터는 학습에 사용되지 않고, 검증에만 사용됨에 주의한다. Dropout 규제 방법 제프리 힌튼이 2012년에 제안한 방법 매 훈련 step에서 일정 node를 훈련에서 무시하는 방법이다. ex) node = {n1, n2, n3, n4} 가 있다면, step 1에서는 n1, n2만 있는 것 처럼 동작하고, step 2에서는 n3, n4만 있는 것 처럼 동작하고 \u0026hellip; 데이터를 증식한다. 관련 데이터를 모두 수집하는것이 최선이지만, 현실적으로 불가능하다. 대신 데이터를 증식하는 방법을 사용한다. 데이터 증식이란, 실제와 같은 훈련 데이터를 생성한다. 데이터 증식은 인공적으로 만든 샘플과 실제 데이터를 구분할 수 없어야 한다. 백색소음(white noise)를 추가하는 것은 도움이 되지 않는다. 의미있는 학습 데이터가 필요하다. 데이터 증식은 이미지 데이터를 처리할 때 매우 유용하다. 이미지는 확대, 축소, 이동, 회전, 반전 등을 통해 하나의 이미지로 여러 데이터를 만들 수 있다. K겹 교차 검증의 이해 데이터 셋을 학습용과 테스트용으로 나누었을 경우, 테스트에 사용되는 데이터는 극히 일부밖에 되지 않는다 데이터 셋을 k등분 하여, 테스트 셋과 학습 셋을 돌려가며 사용하는 방법을 k겹 교차검증이라 한다. 전체 데이터를 5개로 나누었다 가정하고, 나눈 데이터의 덩어리를 각각 d1, d2, d3, d4, d5라 하자 이때 d1을 테스트 데이터로 사용, 나머지를 훈련 데이터로 사용한 경우 결과를 R1이라 하자 d2를 테스트 데이터로 사용, 나머지를 훈련 데이터를 사용한 경우 결과를 R2라 하자 d3, d4, d5도 마찬가지로 하여 R3, R4, R5를 도출해 낸다. R1~R5를 모두 합치면 최종 결과가 나온다. 데이터를 5등분 했으므로, 위 방법은 5겹 교차검증이 된다. from tensorflow.keras.models import Sequential\rfrom tensorflow.keras.layers import Dense\rfrom sklearn.preprocessing import LabelEncoder\rfrom sklearn.model_selection import StratifiedKFold\rimport numpy\rimport pandas as pd\rimport tensorflow as tf\rnumpy.random.seed(777)\rtf.random.set_seed(777)\rdf = pd.read_csv(\u0026#39;sonar.csv\u0026#39;, header=None)\rdataset = df.values\rx_data = dataset[:,0:60].astype(float)\ry_data = dataset[:,60]\r# y_data를 one-hot 으로 처리해 준다.\re = LabelEncoder()\re.fit(y_data)\ry_data = e.transform(y_data)\r# k-fold 알고리즘을 사용할 객체를 형성한다.\r# n_splits : 10등분하여 사용할 것이다.\r# shuffle : 섞어서 사용할 수 있도록 허용\r# random_state : shuffle 사용시 사용할 랜덤한 seed 값\rn_fold = 10\rskf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=48)\raccuracy = []\r# skf.split() 함수를 통해 x_data와 y_data를 k-fold 알고리즘에 맞게 분해하여 반환한다.\r# for문을 통해 데이터를 반복하여 학습을 수행한다.\rfor train, test in skf.split(x_data, y_data):\r# 모델을 구성한다.\r# 활성함수로 sigmoid, 오차함수로 binary-crossentropy를 사용할 것이다.\rmodel = Sequential()\rmodel.add(Dense(30, input_dim=60, activation=\u0026#39;relu\u0026#39;))\rmodel.add(Dense(10, activation=\u0026#39;relu\u0026#39;))\rmodel.add(Dense(1, activation=\u0026#39;sigmoid\u0026#39;))\rmodel.compile(loss=\u0026#39;binary_crossentropy\u0026#39;,\roptimizer=\u0026#39;adam\u0026#39;,\rmetrics=[\u0026#39;accuracy\u0026#39;])\rmodel.fit(x_data[train], y_data[train], epochs=100, batch_size=5)\rk_accuracy = \u0026#34;%.3f\u0026#34; % (model.evaluate(x_data[test], y_data[test])[1])\raccuracy.append(k_accuracy)\rprint(\u0026#34;\\n %.f fold accuracy:\u0026#34; % n_fold, accuracy)\r# 결과값은 데이터에 따라 달라질 수 있다. 학습에 사용된 데이터가 편향되어 있는 경우 평가 결과가 떨어지는 모습을 볼 수 있다.\r# k-fold 알고리즘을 사용하면 이러한 경우를 예방할 수 있다. 이미지 데이터 모델링 MNIST 는 대표적인 이미지 모델링 데이터로, 70,000개의 글자 이미지에 각각 0부터 9까지 정답이 포함되어있는 데이터 셋이다.\ntrain data 6만개, test data 1만개로 나누어져 있다. 이미지 크기는 28 by 28 크기로 구성되어 있고, 각 픽셀은 0~255 사이의 밝기 값을 가진다. 이미지 데이터를 학습할 때는 전처리가 필요하다. MNIST를 예로 들어 알아보자.\n이미지 데이터는 2차원 데이터이다. 이를 1차원 데이터로 직렬화 하여야 학습이 가능하다. reshape() 함수를 이용하여 784개의 속성을 가진 1차원 배열로 바꿔준다. 0~255 값은 데이터 폭이 큰 편이다. 데이터 폭이 크면 분산이 커지므로 이를 줄여주는것이 좋다. normalization 을 하거나, scaling을 해 준다. max 값이 정해져 있으면 단순히 값을 max로 나눠주면 0~1 구간으로 scaling이 된다. max 값이 미정인 경우는 min-max scaler를 사용할 수 있다. (요소값 - 최소값) / (최대값 - 최소값) 결과 값이 0~9의 class로 나뉘기 때문에 one-hot encoding을 통해 y 값을 전처리 해준다. CNN 연속하는 layer 상의 모든 node들이 서로 연결되어있는 형태를 \u0026lsquo;fully connected layer\u0026rsquo;(FC layer) 라고 한다. 한 장의 컬러 사진은 3차원 데이터이다. 이를 FC 신경망을 이용하여 학습할 시 제약이 많다. 이러한 다차원 데이터 학습을 손실 없이 사용할 수 있도록 만든 모델이 Neural Network이다. 그 중 Convolution Neural Network를 사용하면 이미지의 공간 정보를 유지한 채로 학습이 가능하다. CNN 과 FCNN 비교 Fully Connected Neural Network는 2차원 그림을 1차원으로 재구성하여 학습시켰다. CNN은 2차원 배열을 특정 그룹(Kernal, filter)으로 나누어 특징을 추출하는 형태로 학습시키기 때문에 입출력 데이터에 대한 형상 유지가 가능하다. 이미지 공간 정보를 유지하기 때문에 인접 이미지에 대한 특징을 효과적으로 인식할 수 있다. 여러개의 filter(kernal)을 사용함으로써 다양한 특징을 추출하여 학습할 수 있다. filter를 공유 파라미터로 사용하기 때문에 FCNN 보다 학습 파라미터가 적다. CNN 이론 CNN 은 이미지의 특징을 추춣해 내는 부분과, 클래스를 분류하는 부분으로 구성된다. CNN을 통해 특성별로 분류를 하면, fully connected neural network로 값을 전달하여 원하는 class 를 판단하도록 한다. 필터, 커널, 윈도우 라고 부르는 m by n lalyer를 정의한다. 필터는 원본 데이터보다 크기가 작아야 한다. 필터도 각 픽셀마다 값을 갖고 있다. 전체 이미지 위에 필터를 겹쳐놓았을 때, 필터와 원본 이미지가 맞닿는 부분을 서로 곱한 다음, 모든 결과물을 합한다. 필터를 한 픽셀씩 움직여 가며, 위 계산을 반복하고, 그 결과물을 m by n 형태로 정렬하면, convolved layer 결과물을 얻을 수 있다. 채널 한 이미지에 대해 여러 겹으로 쌓여져 있는 형태를 채널이라 한다. 컬러를 표현하기 위해서는 R,G,B 세 색깔의 채널을 합하면 된다. 색상이 많을수록 채널은 많아진다. 필터 일반적으로 (3,3), (4,4) 와 같은 정사각형 행렬로 정의된다. CNN에서 학습의 대상은 필터 파라미터이다. (필터 안의 픽셀 값) 필터를 사용해 원본 데이터를 순회하며 채널별로 합성곱을 구하고, 모든 채널의 합성곱을 다시 합해 Feature Map으로 만든다. 입력 데이터가 여러 채널을 가지는 경우, 필터도 채널의 갯수에 맞게 가져야 한다. 각 채널별로 필터를 적용하여 feature map을 구하고, 최종적으로 모든 채널의 feature map을 합산하여 최종 feature map을 도출한다. 스트라이드 (stride) 필터를 순회하는 간격을 stride라 한다. stride는 (1,1) 과 같은 형태로 표현한다. (가로로 1칸씩 이동, 세로로 1칸씩 이동) stride와 필터의 크기로 feature map 크기가 결정된다. padding 원본 데이터의 테두리에 0으로 채운 dummy pixel을 넣어줌으로써 feature map의 크기와 원본의 크기가 같아지도록 하는 것 pooling 필터를 사용해 얻어낸 convolution layer의 모든 값을 더하는게 아닌, 특정 데이터만 뽑아서 feature map을 구성하는 방법이다. 출력 데이터의 크기를 줄이거나 데이터를 강조하는 용도로 사용한다. 방법에 따라 max pooling, average pooling, min pooling 등이 있다. from tensorflow.keras.datasets import mnist\rfrom tensorflow.keras.utils import to_categorical\rfrom tensorflow.keras.models import Sequential\rfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\rimport matplotlib.pyplot as plt\rimport numpy as np\rimport tensorflow as tf\rnp.random.seed(3)\rtf.random.set_seed(3)\r(x_train, y_train), (x_test, y_test) = mnist.load_data()\r# 4차원형태 데이터 구성\r# [batch, x size, y size, channel]\rx_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\u0026#39;float32\u0026#39;)/255\rx_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(\u0026#39;float32\u0026#39;)/255\ry_train = to_categorical(y_train)\ry_test = to_categorical(y_test)\rmodel = Sequential()\r# CNN 모델 구성\r# 커널을 32개, 크기는 3 by 3\r# 입력층, 28 by 28 크기에 1채널 사용, relu 사용\r# stride 는 설정 하지 않으면 (1,1) 이 기본\r# padding은 설정하지 않으면 없음.\r# padding이 없고 stride가 (1,1) 이기 때문에 결과값은 (26,26) 크기가 될 것\rmodel.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation=\u0026#39;relu\u0026#39;))\r# 커널 62개, 3 by 3\r# relu 사용\rmodel.add(Conv2D(64, (3,3), activation=\u0026#39;relu\u0026#39;))\r# pooling 사용\r# max pooling 방법, pool_size = 2 이므로, stride는 자동으로 (2,2) 가 된다. (pooling은 중복되게 필터를 설정하지 않음)\r# 결과값은 절반의 크기(12,12) 가 될 것\rmodel.add(MaxPooling2D(pool_size=2))\r# dropout layer\rmodel.add(Dropout(0.25))\r# FCNN 모델 구성, 결과값으로 classification\r# 입력값이 (12,12,64) 이다. 이를 직렬화(1차원 배열화) 시켜 준다.\rmodel.add(Flatten())\r# 128 node를 가진 hidden layer\rmodel.add(Dense(128, activation=\u0026#39;relu\u0026#39;))\r# FC에서 over-fitting이 두드러지기 때문에 더 높은 값으로 dropout을 설정하였다.\rmodel.add(Dropout(0.5))\r# MNIST는 10개중 하나를 선택하므로, 출력 layer의 node는 10개로 설정, softmax 사용\rmodel.add(Dense(10, activation=\u0026#39;softmax\u0026#39;))\r# 모델 구조 확인\rmodel.summary()\r# 모델 학습 및 평가\rmodel.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;,\roptimizer=\u0026#39;adam\u0026#39;,\rmetrics=[\u0026#39;accuracy\u0026#39;])\rresult = model.fit(x_train, y_train,\rvalidation_data=(x_test, y_test), # split 대신 직접 평가용 데이터를 지정하는 방법\repochs=30,\rbatch_size=200)\rprint(\u0026#39;loss \u0026amp; accuracy:\u0026#39;,model.evaluate(x_test, y_test))\ry_vloss = result.history[\u0026#39;val_loss\u0026#39;]\ry_loss = result.history[\u0026#39;loss\u0026#39;]\rx_len = np.arange((len(y_loss)))\rplt.plot(x_len, y_vloss, \u0026#39;.\u0026#39;, c=\u0026#39;red\u0026#39;, label=\u0026#39;validation loss\u0026#39;)\rplt.plot(x_len, y_loss, \u0026#39;.\u0026#39;, c=\u0026#39;blue\u0026#39;, label=\u0026#39;train loss\u0026#39;)\rplt.legend(loc=\u0026#39;best\u0026#39;)\rplt.show() FC layer를 사용하여 이미지 학습을 한 것 보다 CNN을 활용하여 학습을 한 것이 over-fitting 및 오차가 더 적음을 확인할 수 있다. CNN으로 이미지를 학습시키는게 더 효율적이다. RNN Recurrent Neural Network 로, 시계열 데이터를 처리하기 위한 모델이다.\n이전 데이터가 아후 데이터에 영향을 주는 데이터를 시계열 데이터라 한다. 데이터가 순서대로 입력되었을 때, 앞서 받은 데이터 처리 결과값을 잠시 기억해 놓는 방법을 사용한다.\n하나의 layer의 node간 연결되는 edge가 생긴다. 한 layer안 node들을 cell이라 칭한다. cell간 연결된 edge에는 \u0026lsquo;hidden_state\u0026rsquo; 데이터가 전달된다. x1 → [A1] → h1\rWhh ↓ h1\rx2 -Wxh→ [A2] → h2\r↓ h2\rx3 → [A3] → h3 RNN 에서 한 layer 내부의 node간 edge에 있는 weight는 hyperbolic tangent를 이용한다. h_t = f(h_t-1, x_t) = tanh(x) = tanh(W_hh * h_t-1 + W_xh * x_t)\nRNN 모델링 RNN 모델은 \u0026lsquo;3 tensor\u0026rsquo;를 사용한다. 3 tensor의 각 요소는 아래와 같다. batch : 데이터 set의 개수 time step : 데이터 한 set에서 데이터의 개수 input dimension : 입력 데이터를 one-hot encoding 했을 때 크기 output, hidden_state = SimpleRnn(3, return_state=True, return_sequences=True)(input) : 결과값으로 크기 3인 데이터를 반환 input으로는 3차원 배열이 필요, batch, time step, input dimension 을 고려한 형태 return_sate가 true이면 output을 반환, 아니면 hidden_state(마지막시점 state)만 반환 return_sequences가 true면 output으로 3차원 값 (각 batch별 학습결과)를 전달, false면 2차원(최종 결과)를 반환 hidden_state 에는 LSTM RNN은 gradient에 의한 vanishing 문제가 크다. 이를 개선하기 위한 모델이 LSTM 이다. Long Short Term Memory, 중요한 데이터는 길게 기억하고 중요하지 않은 데이터는 짧게 기억한다. 데이터를 다음 cell에 넘길지 말지 판단하는 절차를 거친다. LSTM에서는 \u0026lsquo;hidden_state\u0026rsquo;에 더해 \u0026lsquo;cell_state\u0026rsquo; 값을 추가로 전달한다. cell_state 는 과거로부터 전달되는 값들을 유지할 수 있도록 한다. LSTM 에서는 Gate 가 추가된다. 데이터를 얼마나 통과할지 필터링 해주는 역할이다. 총 3개(forget, input, output)의 gate가 있다. 각각 데이터를 얼마나 잊을지, 입출력으로 들어온 데이터 양 조절을 관장한다. Gate Input Gate 최종 cell_state에 현재 cell의 cell_state 값을 얼마나 적용할지 설정 i_t = σ(W_i * [h_t-1, x_t] + b_i) : hidden_state와 입력값에 input gate의 weight, bias를 적용한 후 sigmoid를 취함. Forget Gate sigmoid 함수로 cell_state 값을 얼마나 통과시킬지 설정 forget gate도 weight와 bias가 존재한다. (W_f, b_f) f_t = σ(W_f * [h_t-1, x_t] + b_f) : hidden_state와 입력값에 forget gate의 weight, bias를 적용한 후 sigmoid를 취함. Output Gate 최종 cell_state 값으로 최종 hidden_state 값이 얼마나 출력될지 결정\no_t = σ(W_o * [h_t-1, x_t] + b_o) : hidden_state와 입력값에 output gate의 weight, bias를 적용한 후 sigmoid를 취함.\nC_t = f_t * C_t-1 + i_t * C'_t : 최종 cell_state는 (forget gate를 통과한 이전 cell_state) + (hidden_state와 입력값으로 hidden_state를 계산하고, input gate를 통과시킨 값)이다.\nC'_t = tanh(W_c * [h_t-1, x_t] + b_c) : C\u0026rsquo;_t 값은 입력값과 hidden_state로 현재 cell의 cell_state를 구하는 식이다. 이를 input gate에 통과시키면 i_t * C'_t 값이 된다. C_t-1 은 이전 cell에서 받은 cell_state 이다. 이를 forget gate에 통과시키면 f_t * c_t-1 값이 된다. h_t = o_t * tanh(C_t) : 최종 cell_state 를 hyperbolic tangent 취한 값에 output gate를 적용하면 최종 hidden_state 값이 결정된다.\nLSTM은 기본 RNN보다 복잡하지만 훨씬 더 좋은 성능을 낼 수 있다.\n모델 딥 러닝을 위한 신경망 구조를 모델이라 한다 모델 정의 방법과 최적화 x 데이터는 attribute, y 데이터는 class라 칭한다. 입력층, 은닉층, 출력층 구성 아래 내용들은 일반적인 경우에 해당하는 경우이므로, 실제 모델 정의시에는 직접 확인해볼 필요가 있다. 데이터에 맞게 입력층의 node 개수를 결정한다. 얕은 신경망보다 심층 신경망이 효율적인 파라미터를 구성한다. (하나씩 layer를 늘려가 본다.) 은닉층의 노드 개수를 입력 노드 개수보다 많이 편성한다. (무조건은 아니므로 확인 필요) 결정할 수 있는 데이터를 조금씩 줄여 깔때기 모양으로 은닉층을 설정하는게 좋다. (갈수록 node 개수를 줄여감) 첫 은닉층의 노드 개수는 과대적합(over fitting)이 시작되기 전까지 뉴런 수를 점진적으로 늘리는 것이 좋다. 은닉층이 많아질수록 ReLU 함수를 사용하는것이 좋다.(vanishing 현상 방지) 출력층의 활성화 함수를 결정하고, 출력층의 활성화 함수에 따라 오차함수도 결정한다. 둘중 하나를 선택한다면 sigmoid 함수와 binary_crossentropy 를 사용한다. 다중분류 모델링 데이터의 속성에 맞게 입력 node의 수 구성 문자열로 된 class 값을 indexing 하고, one-hot-encoding으로 값을 변형해준다. class의 개수에 맞게 출력층 node 개수를 설정한다. 활성화 함수 및 오차방정식으로 softMax와 categorical cross-entropy를 적용한다. 생성 방법 tensorflow.keras.Sequential : Sequential 함수를 이용하는 방법 functional approach : 직접 함수를 구성하는 방법 tensorflow.keras.Model : Model 클래스를 상속하고 재정의하여 사용하는 방법 Keras.Sequential keras를 이용해서 sequential 모델을 생성하는 방법 model = Sequential() : sequential 한 layer 형태를 가진 모델을 생성 model.add(Dense(units =2, activation='sigmoid', input_dim = 2)) : layer 추가 node 수가 2개 activation function이 sigmoid 입력값이 2차원 형태 input_dim 인자는 첫번 째 layer에만 사용해 주면 된다. model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy']) : model 객체를 어떤 형태로 학습시킬지 정의 binary_crossentropy 를 loss function으로 설정 optimizer로 sgd 설정 실행될 때 마다 loss 값과 accuracy 값을 출력으로 보여줌 result = model.fit(x_train, y_train, epochs=50000, batch_size = 10, validation_split=0.3) : model에 training 실행 x_train, y_train : 학습용 x, y 데이터 epochs : 학습 데이터를 통해 반복 학습시킬 횟수 batch_size : 입력 데이터를 몇 묶음 단위로 전달할지 설정, 하나씩 학습하는 것 보다 학습률 출렁임이 더 안정적이다. validation_split : 데이터중 0.3%는 검증용으로 사용, \u0026lsquo;validation_data\u0026rsquo; 로 직접 데이터를 전달할 수도 있음 result : result.history 에서 \u0026rsquo;loss\u0026rsquo;, \u0026lsquo;val_loss\u0026rsquo;, \u0026lsquo;accuracy\u0026rsquo;, \u0026lsquo;val_accuracy\u0026rsquo; 키워드로 loss, accuracy 값 확인 가능 model.layers[0].get_weights()[0] : model.layers 는 입력 layer을 0번째 index로 하여 특정 layer를 반환 get_weights() 는 해당 layer의 [weight, bias] 를 담고 있는 배열을 반환 model.predict(x_predict) : 학습된 모델에 x_predict 값을 넣을 시 특정 y 값을 추정하여 반환하는 함수 model.evaluate(x_data, y_data) : 학습된 모델에 입력값(x_data)과 정답(y_data) 를 전달받아 [loss, accuracy] 를 반환하는 함수 ","permalink":"https://aswinblue.github.io/post/machinelearning/tensorflow/","summary":"#Tensorflow\nTensorFlow는 구글에서 수치연산을 위해 만든 라이브러리이다. 기본 개념 node와 edge로 구성된 graph를 이용해 수치 연산을 수행한다. node들은 특정한 데이터가 들어오면 연산을 수행하거나, 형태를 변경하거나, 결과를 출력하는 역할을 한다.\nedge는 학습데이터가 저장되는 다차원 배열이다.\nedge는 node에서 계산된 데이터를 다음 node로 이동시킨다.\nedge는 방향성이 있으며(directed), tensor라 불린다.\narchive.ics.uci.edu/ml 에서 학습용 데이터를 받아 사용할 수 있다.\n설치 python과 pip를 설치한다. pip install tensorflow 명령을 수행한다. window에서 \u0026lsquo;client_load_reporting_filter.h\u0026rsquo; 파일을 찾지 못해 설치를 못했다면, path 경로가 너무 길어서 발생하는 오류이다.","title":"Tensorflow"},{"content":"#kivy\nBasic concepts Widget 어플리케이션을 구성하는 객체 widget은 다른 widget을 tree형태로 포함 가능하며 버튼, 라벨 등상호작용 가능한 객체 또는 Widget의 집합 위치는 좌표로 표현되는데 좌표는 좌측하단이 (0,0)이다. Layout 화면 구성을 설정한 요소 widget 혹은 layout을 포함 가능하다. structure main.py에 python으로 내용을 작성한다. class TheLabApp(App):\rpass\rTheLabApp().run() main.py에서 선언한 class \u0026lsquo;TheLabApp\u0026rsquo; 에서 App을 뺀 TheLab을 따서 main.py와 같은 경로에 \u0026lsquo;TheLab.kv\u0026rsquo;파일을 생성한다. /\r|-main.py\r|-TheLab.kv .py파일에서 원하는 layout class를 상속받아 객체를 구성할 수도 있고, .kv파일에서 바로 작성할 수도 있다. 단, .kv파일에서 객체를 생성하려면 .py파일에 정의된 class를 사용해야 한다. \u0026lt;EXAMPLE@BoxLayout\u0026gt; 와 같이 .py파일의 class 선언을 생략하고 default 객체를 사용하는 방법도 있다. ///////// .py /////////\rclass Box(BoxLayout):\rpass\r///////// .kv /////////\r\u0026lt;Box\u0026gt;: # .py에서 정의된 Box객체를 사용 가능\rGridLayout: # 이후부터는 kivy에서 제공하는 객체들 사용 가능\rlabel:\rtext:\u0026#34;lb\u0026#34;\r\u0026lt;Box2@BoxLayout\u0026gt;: # .py파일에서 아무것도 하지 않는 객체를 선언하기 싫을 때 사용\r/////////////////////// ex) class 안에서 속성 설정 :self.orientation = \u0026quot;vertical\u0026quot; ex) kv파일에서 속성 설정 : orientation: \u0026quot;vertical\u0026quot; \u0026lt;NAME\u0026gt;형태로 선언한 객체는 다른 객체에서 사용할수 있게 된다. \u0026lt;Box\u0026gt;:\r...\r\u0026lt;Box2\u0026gt;:\rButton:\r...\rBox: # 사용자 정의 객체\r... .kv파일은 아래와 같이 구성된다. 화면을 구성하는 내용들의 속성을 정의하고 배치할 수 있다. MainWidget: # 화면에 표기할 객체(widget, layout, \u0026hellip;) : # widget 정의 Button: # widget 내부 항목 선언, kivy에서 지원하는 객체의 종류 text:\u0026ldquo;A\u0026rdquo; Button: text:\u0026ldquo;B\u0026rdquo;\n- .py파일에서도 화면을 구성할 수 있다. class LayoutExample(BoxLayout): # BoxLayout은 기본적으로 가로로 구성된다. def init(self, **kargs):\nsuper().init(**kargs) b1 = Button(text=\u0026ldquo;A\u0026rdquo;) # 객체를 생성 b2 = Button(text=\u0026ldquo;B\u0026rdquo;) self.add_widget(b1) # 객체를 layout에 추가 self.add_widget(b2)\nUsage layout BoxLayout 가로 혹은 세로로 차곡차곡 쌓아가는 레이아웃 AnchorLayout 화면의 각 모서리, 꼭지점, 정중앙 총 9개의 위치를 지정할 수 있는 레이아웃 GridLayout n행m열의 그리드를 나누고, 내용을 채우는 레이아웃 StackLayout n행m열의 표에 좌측상단부터 차곡차곡 쌓아가는 레이아웃. BoxLayout의 2차원형태 ScrollView 상하 또는 좌우로 스크롤이 가능한 화면 PageLayout 디스플레이간 slide를 통해 이동이 가능한 레이아웃 FloatLayout RelativeLayout ScatterLayout Commons size_hint : 레이아웃 내 객체의 비율 설정 layout 안의 객체는 size 조절이 불가능하다. (size: 설정 해도 적용 안됨) size_hint 값이 default로 설정되어있기 때문이다. size_hint값이 적용된 객체는 화면 크기에 따라 객체 크기도 함께 변경된다. size_hint값은 default 1,1로 설정되어있다. size_hint: None, None으로 설정한다면 size: 값을 설정할 수 있다. (화면 크기에 상관없이 고정된 크기를 가질 수 있게 된다.) ex) spacing:\u0026quot;10dp\u0026quot; : layout내부 요소간 간격 설정 BoxLayout orientation: \u0026quot;vertical\u0026quot;: 세로정렬(가로 : \u0026ldquo;horizontal\u0026rdquo;) \u0026lt;BoxLayoutSample\u0026gt;:\rorientation: \u0026#34;vertical\u0026#34;\rButton:\r# 배정받은 크기에 대해 가로비율 50%, 세로비율 60%로 설정.\rtext: \u0026#34;b1\u0026#34;\rsize_hint: .5, .6 AnchorLayout ahcnor_x:\u0026quot;center\u0026quot;: x축 정렬 위치, left, right, center 가능, default center ahcnor_y:\u0026quot;center\u0026quot;: y축 정렬 위치, top, bottom, center 가능, default center 객체를 순서대로 쌓는것이 아니라 지정한 자리에 그대로 넣는것이므로, 이전 객체는 이후에 나오는 객체에 덮어씌워질 수 있음 \u0026lt;AnchorExample\u0026gt;:\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .2, .2\rpos_hint:{\u0026#34;X\u0026#34;:.1, \u0026#34;Y\u0026#34;: .1}\rButton:\rtext:\u0026#34;btn2\u0026#34;\rsize_hint: .1, .1\rpos_hint:{\u0026#34;X\u0026#34;:.5, \u0026#34;Y\u0026#34;: .5} GridLayout rows: Grid의 행 개수를 선언한다. default 1 cols: Grid의 열 개수를 선언한다. default 1 size_hint로 내부 요소의 비율을 조절하고 싶을 때, 같은 행/열에 속한 값들도 모두 같은 값으로 설정해야 적용이 된다. 설정한 Grid를 초과하는 객체를 선언하면 Widget에서 객체를 생성한것으로 취급된다. \u0026lt;GridExample@GridLayout\u0026gt;:\rrows: 2\rcols: 3\rButton: # 0,0\rtext: \u0026#34;btn\u0026#34;\rsize_hint: .5, 1 # 비율 조정\rButton: # 0,1\rtext: \u0026#34;btn\u0026#34;\rsize_hint: None, 1\rwidth:\u0026#34;100dp\u0026#34; # 고정된 크기\rButton: # 0,2\rtext: \u0026#34;btn\u0026#34;\rButton: # 1,0\rtext: \u0026#34;btn\u0026#34;\rsize_hint: .5, 1\rButton: # 1,1\rtext: \u0026#34;btn\u0026#34;\rsize_hint: None, 1\rwidth:\u0026#34;100dp\u0026#34; # 고정된 크기\rButton: # 1,2\rtext: \u0026#34;btn\u0026#34;\rButton: # out of bound\rtext: \u0026#34;btn\u0026#34;\rpos:100, 200 StackLayout 내부 객체들을 가로 한줄로 나열한다. 한 줄에 있는 객체들의 비율이 100%를 넘어가면 다음줄부터 객체를 채워넣는다. 가로 혹은 세로는 가장 큰 크기의 객체에 맞춰져 grid형식으로 정렬된다. \u0026lt;StackExample\u0026gt;:\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .3\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .4\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5\rButton: # 가로비율이 1을 넘어가기때문에 줄바뀜됨\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .4, .5\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5\rButton: # 세로 비율상으로 1을 넘어가기 때문에 화면 밖으로 나가서 보이지 않음\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5 고정된 크기로 wiwdget을 추가하면 화면 크기가 변함에 따라 widget의 행,열이 변경된다. class로 설정을 할 수도 있다. 이때 class의 __init__에 설정한 내용이 .kv파일에서 설정한 내용보다 우선하여 적용된다. class StackExample(StackLayout):\rdef __init__(self, **kwargs):\rsuper().__init__(**kwargs)\rfor i in range(0, 10):\rsize = dp(100) # dp로 크기 선언법\rb = Button(text=str(i + 1), size_hint=(None, None), size=(size, size)) # 버튼 세팅\rself.add_widget(b) # layout에 widget 추가 Widgets 기본크기 100 X 100, 기본위치 (0,0) 이다. Commons pos_hint: 정렬 위치 size_hint등으로 비율을 조절하면 기본적으로 좌측 상단으로 정렬이 된다. 이때, 다른 방향으로 정렬을 하려면 pos_hint:{\u0026quot;x\u0026quot;:.5, \u0026quot;y\u0026quot;:.5}와 같이 설정 가능하다. pos_hint: 다음에는 dictionary가 와야하며, 두 개의 항목이 들어간다. 첫번째 인자는 \u0026ldquo;x\u0026rdquo;, \u0026ldquo;center_x\u0026rdquo;, \u0026ldquo;right\u0026rdquo; 중 하나를 사용하며, 두번째 인자는 \u0026ldquo;y\u0026rdquo;, \u0026ldquo;center_y\u0026rdquo;, \u0026ldquo;top\u0026rdquo; 중 하나를 사용한다. pos_hint:{\u0026#34;x\u0026#34;:.5} # 좌측부분을 50%위치로 설정\rpos_hint:{\u0026#34;center_x\u0026#34;:.5} # 중앙을 50%위치로 설정\rpos_hint:{\u0026#34;right\u0026#34;:.5} # 우측부분을 50%위치로 설정 Button 텍스트, 크기, 위치를 지정한 버튼 아래쪽에 있는 내용이 나중에 그려져 이전 내용을 덮어씌운다. MainWidget:\r\u0026lt;MainWidget\u0026gt;:\r# 고정 크기를 가진 버튼\rButton:\rtext: \u0026#34;Hello\u0026#34;\rsize: 400, 200\rpos: 100, 200\r# 기기 화면 크기에 따른 크기와 위치를 가진 버튼\rButton:\rtext: \u0026#34;hello2\u0026#34;\rsize: \u0026#34;400dp\u0026#34;, \u0026#34;200dp\u0026#34;\rpos: \u0026#34;100dp\u0026#34;, \u0026#34;200dp\u0026#34; lalbel 텍스트, 크기, 위치, 글자색을 지정한 레이블 MainWidget:\r\u0026lt;MainWidget\u0026gt;:\rLabel:\rtext: \u0026#34;Hello\u0026#34;\rsize: \u0026#34;100dp\u0026#34;, \u0026#34;80dp\u0026#34;\rpos: \u0026#34;100dp\u0026#34;\rcolor: 1, 2, 3, 1 # r, g, b, a 기타 .kv파일에서 동일한 이름의 객체를 여러개 정의하면, 하나의 정의로 보고 내용을 이어붙인다. \u0026lt;BoxLayoutSample\u0026gt; # layout 정의\rButton:\rtext:\u0026#34;A\u0026#34;\rsize_hint: \u0026#34;.1\u0026#34;\r...\r\u0026lt;BoxLayoutSample\u0026gt; # 동일한 이름의 layout 정의\rButton:\rtext:\u0026#34;B\u0026#34; #버튼 B는 버튼 A 다음에 생성됨\rsize_hint: \u0026#34;.1\u0026#34; .py 에서 class를 선언하고, .kv파일에서 해당 class를 사용한다면, .py의 init() 함수가 먼저 호출된 후 .kv파일에서 세팅한 내용이 적용된다. 참조 유튜브 강의 import:\nfrom kivy.app import App\rfrom kivy.uix.button import Button\rfrom kivy.uix.boxlayout import BoxLayout\rfrom kivy.uix.widget import Widget ","permalink":"https://aswinblue.github.io/post/windowapp/kivy/","summary":"#kivy\nBasic concepts Widget 어플리케이션을 구성하는 객체 widget은 다른 widget을 tree형태로 포함 가능하며 버튼, 라벨 등상호작용 가능한 객체 또는 Widget의 집합 위치는 좌표로 표현되는데 좌표는 좌측하단이 (0,0)이다. Layout 화면 구성을 설정한 요소 widget 혹은 layout을 포함 가능하다. structure main.py에 python으로 내용을 작성한다. class TheLabApp(App):\rpass\rTheLabApp().run() main.py에서 선언한 class \u0026lsquo;TheLabApp\u0026rsquo; 에서 App을 뺀 TheLab을 따서 main.py와 같은 경로에 \u0026lsquo;TheLab.kv\u0026rsquo;파일을 생성한다. /\r|-main.py\r|-TheLab.kv .py파일에서 원하는 layout class를 상속받아 객체를 구성할 수도 있고, .","title":"Kivy"},{"content":"Python 기본 내장 함수 입력 한줄 받기 : a = input()\n받은 값은 string 형태이다.\n받은 단어 끊어서 해석 : a, b = input().split() split() 함수 안의 인자에 따라 구분자 설정 가능. 빈칸이면 공백을 기준으로 끊어줌\n받은 단어 끊고 숫자로 변환 : a, b = map(int, input().split()) int 외 다른 형태도 사용 가능 출력 print() 와 sys.stdout.write() 로 화면에 출력할 수 있다. Flush print() 함수는 효율을 위해 버퍼에 내용을 채워놓고 있다가 버퍼가 일정량 채워지면 화면에 버퍼의 내용을 출력한다. print() 함수에는 bool 형태의 인자 flush 를 받을 수 있는데, flush를 True로 설정하면 버퍼가 찰 때 까지 대기하지 않고 바로 출력할 수 있다. ex) print(\u0026quot;print this immediately\u0026quot;, flush=True) sys 모듈의 sys.stdout.flush() 함수를 사용하여 동일한 효과를 낼 수 있다. python을 실행할 때, -u 옵션을 넣어서 실행하면 내부적으로 표준 출력이 모두 버퍼링 없이 즉시 flushing 된다. 함수 함수 인자로 배열 형태를 표현할 때 *를 붙인다.\ndef func1(*arg)\rprint(*arg)\rfunc1(1, 2, 3) # 출력: [1, 2, 3] 숫자 읽기쉬운 숫자 표기: x = 10000 vs x = 10_000\n숫자 정의할 때 _를 중간에 넣어도 python은 숫자만 골라서 해석한다. 배열 오름차순 정렬: list.sort()\n튜플 두번째 인자 기준 오름차순 정렬: list.sort(key=lambda x:x[1])\n내림차순 정렬 : list.sort(reverse=True)\n문자열 문자열 뒤에 format() 함수를 호출해서 문자열 안에 {} 를 변수로 치환할 수 있다. ex) \u0026quot;sample text {} {}\u0026quot;.format(\u0026quot;var1\u0026quot;, \u0026quot;var2\u0026quot;) 은 sample text var1 var2 으로 출력된다. 라이브러리 numpy 기본 구문\nwhere(조건, 값1, 값2): 조건문이 참이면 값1, 거짓이면 값2를 반환. 3항연산자와 동일 bisect 오름차순으로 정렬된 배열에서 lower-bound, upper-bound 를 찾는 함수 bisect_left(list, x, key) : lower bound (x보다 같거나 큰 수들 중 최좌측 값의 위치)\nbisect_right(list, x, key) : upper bound (x보다 같거나 작은 수들 중 최우측 값의 위치)\n또는 lower bound (lower bound 를 찾았는데 동일 값이 존재할 경우 최우측 값의 위치)\nbisect(list, x, key) : bisect_right와 동일 tueple 적용 방법 : bisect(list_of_tuples, (3, None)) 형태로 사용하면 된다. 두 번째 인자에 튜플 형태를 넣어주면 됨. https://stackoverflow.com/questions/20908047/using-bisect-in-a-list-of-tuples\n","permalink":"https://aswinblue.github.io/post/python/python/","summary":"Python 기본 내장 함수 입력 한줄 받기 : a = input()\n받은 값은 string 형태이다.\n받은 단어 끊어서 해석 : a, b = input().split() split() 함수 안의 인자에 따라 구분자 설정 가능. 빈칸이면 공백을 기준으로 끊어줌\n받은 단어 끊고 숫자로 변환 : a, b = map(int, input().split()) int 외 다른 형태도 사용 가능 출력 print() 와 sys.stdout.write() 로 화면에 출력할 수 있다. Flush print() 함수는 효율을 위해 버퍼에 내용을 채워놓고 있다가 버퍼가 일정량 채워지면 화면에 버퍼의 내용을 출력한다.","title":"Python"},{"content":"Angular Angular JS와 Angular는 다르다. Angular JS는 초창기 Angular를 의미하고, 그냥 Angular는 Angular2 이상의 버전을 의미한다. javascript기반의 textscript를 사용한다. 확장자가 ts로 끝난다. 개발환경 세팅 nodejs 설치 $ sudo apt install npm :nodejs와 npm 동시에 설치 angular client 설치 $ npm install -g @angular/cli 명령어를 이용하여 설치 workspace 생성 client 설치가 완료되었으면 workspace를 생성하고 application을 생성한다.\n$ ng new \u0026lt;application_name\u0026gt; 명령어를 이용하여 설치한다.\nnodejs 버전이 낮다고 한다. github에서 받아서 빌드하여 써 보자.\n공식 사이트는 https://github.com/nodejs 이다.\n소스코드를 받아 빌드하는 내용은 없고, 바로 바이너리를 다운받기를 권장하는 듯 하다.\nhttps://nodejs.org/en/download/ 로 가서 리눅스용 바이너리를 받아보자.\n.xz 형태의 파일이다. $ tar -xvf \u0026lt;file_name\u0026gt; 로 압축을 푼다.\n압축을 푸니 안의 내용들이 /usr/lib/ 경로에 어울릴 것 같다. mv 명령으로 옮겨준다.\nbin 폴더 안의 내용은 링크로 /usr/local/lib/ 에 넣어준다.\nln -s /usr/lib/\u0026lt;file\u0026gt;/bin/\u0026lt;binary\u0026gt; /usr/local/lib/bin/\u0026lt;binary\u0026gt;\n다시 돌아와서 명령어를 수행하여 application을 생성한다. stylesheet format을 선택하라고 하는데, 가장 위에있는 CSS로 선택해 본다.\napplication 실행 application을 생성하면 현재 경로에 \u0026lt;application_name\u0026gt;에 해당하는 폴더가 생성된다. 테스트용으로 application을 실행해 보자. $ng serve --open 4200 포트로 서버 접속이 가능함을 알 수 있다. 방화벽 설정 방화벽이 아직 열려있지 않은 것 같다. 방화벽을 열어보자. iptables -I INPUT 1 -p tcp \u0026ndash;dport 12345 -j ACCEPT $sudo ufw allow 4200/tcp 프로젝트 구조 WORKSPACE src app : 화면을 구성하는 요소들의 root component, WORKSPACE와 같은 이름 \u0026lt;COMPONENT\u0026gt; : root component의 일부를 구성하는 component, 원하는만큼 추가 가능, [css, html, ts] 항목들이 기본 세트로 생성됨 COMPONENT.component.css : 기본적으로 비어있다. COMPONENT.component.html COMPONENT.component.ts : type script로 짜여진 코드, class들이 정의되어 있다. app.component.css app.component.html app.component.ts app.module.ts component view라는 단위의 화면을 구성하는 모듈 ng generate component COMPONENT_NAME 명령으로 workspace에 component 생성 가능 component를 생성하면 css, html, ts파일을 기본적으로 갖는다. component는 다른 component를 가질 수 있다. 최상위 component를 root component라고 한다. ts 파일 angular에서 제공하는 모듈을 import할 수 있다. class를 선언하고, component에서 사용할 기능(함수)을 구현한 후 export한다. component가 생성될 때 상위 component로 부터 input을 받을 수 있다. ts파일 문법 Component : Component를 사용하기 위한 기본 모듈 OnInit : Component 시작시 동작 정의, constructor 와 유사한 동작을 하지만 OnInit은 angular가 관할하고, constructor은 js가 관할하여 초기화하는 차이가 있다. Input : Component 생성시 상위 Component로 부터 받을 변수를 선언, 상위 Component에서는 해당 변수로 값을 집어넣어 줄 수 있다. Output : 상위 Component에서 사용할 수 있는 변수를 정의, Component에서 변수를 선언하면 상위 Component에서 해당 변수를 사용할 수 있다. @component 로 다음 class가 컴퍼넌트임을 표시한다. selector : 해당 component가 view에서 어떤 이름으로 표시될지 명명한다. (Tag 이름이 된다.) templateUrl : html 파일의 이름을 지정한다 styleUrls : css파일의 리스트를 나열한다. @Input() product; // product라는 변수로 input을 받겠다는 선언\r@Output() notify = new EventEmitter(); // notify 라는 변수를 상위 Component에서 사용 가능하게 하겠다고 선언\r// 한 component에서 다른 component를 호출할 때에는 ts 파일에서 정의한 이름을 태그로 생성한다.\r\u0026lt;app-product-alerts // 태그 이름이 곧 component 이름(selector에 정의한)이다.\r[product]=\u0026#34;product\u0026#34; // product라는 변수에 \u0026#34;product\u0026#34;라는 내용을 을 넣을 때 사용한다.\r(notify)=\u0026#34;onNotify()\u0026#34;\u0026gt; // notify라는 변수에서 이벤트가 들어오면 onNotify() 함수를 실행, (onNotify() 함수는 class 안에 정의되어 있어야 함)\r\u0026lt;/app-product-alerts\u0026gt; Routing app.modules.ts(main component의 ts파일) 파일에서 routing 설정이 가능하다. import { RouterModule } from \u0026#39;@angular/router\u0026#39;; // Routing을 위해 필요한 모듈\rimport { ProductListComponent } from \u0026#39;./product-list/product-list.component\u0026#39;;` // ProductListComponent라는 변수에 \u0026#39;./product-list/product-list.component파일을 대응\rimport { ProudctDetailsComponent } from \u0026#39;./product-detail/product-detail.component\u0026#39;;\r@NgModule({\rimports: [\rBrowserModule,\rReactiveFormsModule,\rRouterModule.forRoot([ // Router 모듈로 Routing 세팅\r{ path: \u0026#39;\u0026#39;, component: ProductListComponent }, // root 경로 \u0026#39;/\u0026#39; 에 위에서 ProductListComponent 변수에 대응시킨 파일을 매칭\r{ path: \u0026#39;products/:productId\u0026#39;, component: ProductDetailsComponent }, // 마찬가지로 \u0026#39;/products/{productId}\u0026#39; 에 ProudctDetailsComponent를 매칭\r])\r], ./product-detail/product-detail.component.ts 에서 아래와 같은 설정을 추가로 해주어야 한다. import { ActivatedRoute } from \u0026#39;@angular/router\u0026#39;; // routing을 당하는 곳에서 필요한 모듈\rexport class ProductDetailsComponent implements OnInit { // component 를 정의할 class 선언\rproduct; -\u0026gt; product 변수 선언\rconstructor(private route: ActivatedRoute,) // 라우팅 관련 정보를 route라는 변수에 받았다.\r{ } -\u0026gt; constructor 뒤에 붙여주는 형식, 비어있는 채로 둔다.\r}\rngOnInit() { // view 생성시 동작을 정의\rthis.route.paramMap.subscribe(params =\u0026gt; { // constructor에서 정의한 route를 참조하여\rthis.product = products[+params.get(\u0026#39;productId\u0026#39;)]; // this.product는 products[index] 값을 가진다. 이때 index는 app.modules.ts에서 설정한 값이다. (url 경로에서 \u0026#39;products/\u0026#39; 다음에 들어간 숫자값)\r});\r} ./product-detail/product-detail.component.html 에서 아래와 같이 설정한다. \u0026lt;h2\u0026gt;Product Details\u0026lt;/h2\u0026gt;\r\u0026lt;div *ngIf=\u0026#34;product\u0026#34;\u0026gt; // product에 값이 들어가 있다면 아래 수행. 즉, ts파일에서 대입시킨 products[idx] 값이 존재하면 아래 동작 수행\r\u0026lt;h3\u0026gt;{{ product.name }}\u0026lt;/h3\u0026gt; // json 형태의 값을 참조해 대입한다.\r\u0026lt;h4\u0026gt;{{ product.price | currency }}\u0026lt;/h4\u0026gt;\r\u0026lt;p\u0026gt;{{ product.description }}\u0026lt;/p\u0026gt;\r\u0026lt;/div\u0026gt; 문법 반복, 출력, 링크 \u0026lt;div *ngFor=\u0026#34;let product of products; index as productId\u0026#34;\u0026gt;\r/*\r*ngFor 은 반복을 뜻하는 예약어다. products 안의 원소를 하나씩 꺼내서 product 라 칭한다. 마치 java나 python의 ``for item in array`` 와 같다.\r\u0026#39;;\u0026#39; 로 구문을 구분할 수 있다.\rproductId 변수에 index를 대입한다.\r*/\r\u0026lt;a [title]=\u0026#34;product.name + \u0026#39; details\u0026#39;\u0026#34; [routerLink]=\u0026#34;[\u0026#39;/products\u0026#39;, productId]\u0026#34;\u0026gt;\r/*\r[title] 은 마우스를 올릴 때 나오는 텍스트를 뜻한다.\rrouterLink는 클릭시 넘어갈 링크이다. 링크를 []로 설정하면 []안의 내용을 appepnd 한 값을 의미한다. 즉 \u0026#34;/product/:productId\u0026#34; 의 주소를 나타낸다.\r\u0026#34;\u0026#34;안의 내용은 ts문법이고, 단순 텍스트는 \u0026#39;\u0026#39; 사이에 집어넣으면 된다.\r*/\r\u0026lt;h3\u0026gt;\r{{ product.name }} // product 객체의 name 필드를 출력한다.\r\u0026lt;/h3\u0026gt;\r\u0026lt;/a\u0026gt;\r\u0026lt;/div\u0026gt; 조건 \u0026lt;p *ngIf=\u0026#34;product.description\u0026#34;\u0026gt; // *ngIf는 조건문을 뜻하는 예약어다. product 객체에 description 필드가 존재하면 아래를 실행한다.\rDescription: {{ product.description }}\r\u0026lt;/p\u0026gt; 버튼 \u0026lt;button (click)=\u0026quot;share()\u0026quot;\u0026gt; (click)은 클릭 event 발생시 실행할 내용을 적는다. share()라는 함수를 실행하도록 연결한다.\n-\u0026gt; 요점 *ngFor *ngIf Interpolation {{ }} Property binding [ ] Event binding ( )\n","permalink":"https://aswinblue.github.io/post/webapplication/angular/","summary":"Angular Angular JS와 Angular는 다르다. Angular JS는 초창기 Angular를 의미하고, 그냥 Angular는 Angular2 이상의 버전을 의미한다. javascript기반의 textscript를 사용한다. 확장자가 ts로 끝난다. 개발환경 세팅 nodejs 설치 $ sudo apt install npm :nodejs와 npm 동시에 설치 angular client 설치 $ npm install -g @angular/cli 명령어를 이용하여 설치 workspace 생성 client 설치가 완료되었으면 workspace를 생성하고 application을 생성한다.\n$ ng new \u0026lt;application_name\u0026gt; 명령어를 이용하여 설치한다.\nnodejs 버전이 낮다고 한다. github에서 받아서 빌드하여 써 보자.","title":"Angular"},{"content":"Spring basic 설치 spring CLI를 설치한다. 직접 다운받아서 원하는 곳에 압축을 푼 후 PATH설정을 해 주는게 빠르다.\n참조 프로젝트 생성 CLI로 프로젝트를 생성해 보자. spring init --build=gradle -d=web -a=myApp -g=com.aswin.blue [location] --build=gradle 기본으로 maven을 사용하지만 gradle로 설정 가능하다. -d=web dependency를 web으로 설정 -a=myApp artifactId, 즉 project명을 설정한다. -g=com.aswin.blue 그룹 명을 설정한다. [location] 생성할 폴더를 지정한다. 없으면 새로 생성한다. 지정하지 않으면 zip 형태로 압축해서 생성한다. 설정 maven으로 프로젝트를 생성하면 pom.xml을 설정해야 한다. 각종 라이브러리를 플러그인 형태로 사용하려면 dependency와 repository 설정을해 줘야 한다. \u0026ldquo;https://mvnrepository.com/\u0026quot; 주소처럼 maven repository를 정리해 놓은 사이트에서 원하는 repository를 찾아서 dependency를 작성한다. repository 추가시 compile dependency를 확인하고 추가로 pom.xml을 작성한다. maven 사이트보다는 github의 readme를 더 신용하자, maven 사이트 업데이트가 안돼서 잘 동작하지 않는 것도 있다. 실행 maven 프로젝트의 실행에도 maven이 사용된다. mvn -X clean install exec:java -Dexec.args=\u0026quot;\u0026quot; 로 실행이 가능하다. -X 는 디버깅 로그 출력을 의미한다. -Dexec.args= 는 main 함수의 argv를 설정한다.\nspring 프로젝트는 mvn spring-boot:run 으로 실행시킬 수 있다. ","permalink":"https://aswinblue.github.io/post/webserver/spring/","summary":"Spring basic 설치 spring CLI를 설치한다. 직접 다운받아서 원하는 곳에 압축을 푼 후 PATH설정을 해 주는게 빠르다.\n참조 프로젝트 생성 CLI로 프로젝트를 생성해 보자. spring init --build=gradle -d=web -a=myApp -g=com.aswin.blue [location] --build=gradle 기본으로 maven을 사용하지만 gradle로 설정 가능하다. -d=web dependency를 web으로 설정 -a=myApp artifactId, 즉 project명을 설정한다. -g=com.aswin.blue 그룹 명을 설정한다. [location] 생성할 폴더를 지정한다. 없으면 새로 생성한다. 지정하지 않으면 zip 형태로 압축해서 생성한다. 설정 maven으로 프로젝트를 생성하면 pom.xml을 설정해야 한다.","title":"Spring basic"},{"content":"Jython Java 환경에서 python을 실행하게 하는 방법 중 하나 역으로 Jython 환경에서 java를 실행 가능하기도 하다. spring에서 jython을 사용하는 방법에 대해 묘사하겠다. 설치 pom.xml에 의존성을 작성한다. pom을 사용하면 jython을 설치하지 않고 일부 동작이 실행되게 할 수 있지만, 외부 모듈 사용에는 제한적인 부분이 있기에 설치가 필요하면 설치를 해야한다. \u0026lt;!-- https://mvnrepository.com/artifact/org.python/jython --\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.python\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jython\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt; 실행 PythonInterpreter 을 선언한다. 이후 execfile, exec 함수를 이용하여 python 문법을 사용 가능하다. PythonInterpreter jython;\rjython.execfile(PYTHON);\rjython.exec(\u0026#34;print(1+1)\u0026#34;); execfile로 특정 함수를 정의하였다면 그 아래에 있는 exec함수에서 함수를 호출할 수도 있다. ","permalink":"https://aswinblue.github.io/post/java/jython/","summary":"Jython Java 환경에서 python을 실행하게 하는 방법 중 하나 역으로 Jython 환경에서 java를 실행 가능하기도 하다. spring에서 jython을 사용하는 방법에 대해 묘사하겠다. 설치 pom.xml에 의존성을 작성한다. pom을 사용하면 jython을 설치하지 않고 일부 동작이 실행되게 할 수 있지만, 외부 모듈 사용에는 제한적인 부분이 있기에 설치가 필요하면 설치를 해야한다. \u0026lt;!-- https://mvnrepository.com/artifact/org.python/jython --\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.python\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jython\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt; 실행 PythonInterpreter 을 선언한다. 이후 execfile, exec 함수를 이용하여 python 문법을 사용 가능하다. PythonInterpreter jython;\rjython.","title":"Jython"},{"content":"Web Scrapping x-path /a/b/c/d/e/f/g/... 와 같이 특정 경로를 가진 개체를 가리키는 방법이다. //*[@id=\u0026quot;abcd\u0026quot;] // 는 모든 경로에서 찾겠다는 의미 는 모든 태그에 대해 찾겠다는 의미. *대신 TAG를 넣으면 \u0026lsquo;TAG\u0026rsquo; 라는 이름의 태그를 가진 항목에서만 검색함 @id=\u0026ldquo;abcd\u0026rdquo; 는 id라는 속성이 abcd 인 항목을 찾겠다는 의미 브라우저에서 자동으로 해줒기 때문에 보통은 걱정할 필요가 없다. 정규식 . : 하나의 문자 ^ : 문자열의 시작 $ : 문자열의 끝 * : 모든 문자 # : 하나의 숫자 정규식 참조 link\nUseragent 특정 페이지에서는 request 헤더를 확인하여 매크로 접속을 막는 경우가 있다. 서버에서는 useragent 정보를 확인하여 접속하는 웹 브라우저, 기기 등의 정보를 확인할 수 있다. 참조 https://www.youtube.com/watch?v=yQ20jZwDjTE https://www.w3schools.com/python/python_regex.asp\n","permalink":"https://aswinblue.github.io/post/developtips/web_scrapping/","summary":"Web Scrapping x-path /a/b/c/d/e/f/g/... 와 같이 특정 경로를 가진 개체를 가리키는 방법이다. //*[@id=\u0026quot;abcd\u0026quot;] // 는 모든 경로에서 찾겠다는 의미 는 모든 태그에 대해 찾겠다는 의미. *대신 TAG를 넣으면 \u0026lsquo;TAG\u0026rsquo; 라는 이름의 태그를 가진 항목에서만 검색함 @id=\u0026ldquo;abcd\u0026rdquo; 는 id라는 속성이 abcd 인 항목을 찾겠다는 의미 브라우저에서 자동으로 해줒기 때문에 보통은 걱정할 필요가 없다. 정규식 . : 하나의 문자 ^ : 문자열의 시작 $ : 문자열의 끝 * : 모든 문자 # : 하나의 숫자 정규식 참조 link","title":"Web_scrapping"},{"content":"GDB GNU Debugger의 약자 유닉스의 디버거는 오픈소스가 아니라 GNU에서 새로 개발한 디버거 디버깅을 위해서는 register(레지스터 값), disassem(rip 부근 주소를 디스어셈 한 값), stack(스택의 값), backtrace(현재 rip에 도달 할 때 까지 거쳐간 함수들) 을 파악해야 하며, 이를 context(맥락) 이라 한다. 컴파일 gcc로 컴파일시 옵션에 -g 를 붙여야 소스를 보면서 디버깅이 가능 리눅스에서 컴파일한 파일은 ELF (Executable and Linkable Format) 의 실행 파일이 된다. ELF 파일은 파일 실행에 필요한 정보가 든 헤더와 여러 섹션들로 구성된다. 섹션에는 기계어 코드 등의 정보들이 들어있다. readelf -h [ELF파일] 명령으로 ELF 파일의 헤더 정보를 확인 할 수 있다. gdb 옵션 gdb [파일이름] : 해당 파일이름 디버깅 실행 --args [arg1] [arg2] [...] : 파일 실행에 필요한 argument를 전달 기타 명령어 coredumb 파일 생성 프로그램이 비정상적으로 종료될 때 메모리의 현재 상황을 블랙박스처럼 남기는 coredump 파일이 생성된다.다만, coredump 파일 생성에는 사전에 설정이 필요하다. 리눅스 프롬프트에서 ulimit -a 명령을 입력 해 보면 각종 파일들의 크기 설정을 볼 수 있다. 이때 core file size 가 보통 0으로 설정되어 있다. ulimit -c unlimited 로 설정하면 coredump 파일의 크기가 최대로 설정된다. 이후에는 프로그램 실행 중 비정상적으로 종료가 되면 core 라는 이름의 파일이 생성된다. gdb에서 core파일을 사용하여 디버깅을 할 수 있다. 디버깅 심벌이 있는 실행파일과, core파일이 있다면, gdb 실행파일 core 라고 입력 해 주면 gdb는 프로그램이 죽기 직후 까지 동작을 수행하고 break 한다. 이때 bt 명령으로 stack을 확인할 수도 있다. 디버깅 중 명령어 breakpoint b \u0026lt;라인\u0026gt; : 해당 라인에 breakpoint 설정 (break와 동일) b \u0026lt;함수명\u0026gt; : 해당 함수 시작점에 breakpoint 설정 b \u0026lt;파일명\u0026gt;:\u0026lt;라인\u0026gt; : 특정 파일 해당 라인에 breakpoint (ex : b test.cpp:10) b \u0026lt;라인\u0026gt; \u0026lt;조건문\u0026gt; : 특정 조건일 때 해당 라인에 breakpoint 작동 (ex: break 25 if x==0 x가 0일때만 25번 라인에서 break) tb : 임시 중단점 설정, 일회성 w \u0026lt;변수\u0026gt; : 조사식에 해당 변수 추가하고, 실행 중 조사식에 담긴 변수들의 값이 변할 때 마다 자동으로 break (watch와 동일) 로컬 변수는 해당 변수를 확인할 수 있는 scope에 들어가서 지정할 수 있다. i b : breakpoint 모두 확인 (info breakpoint 와 동일) d : 모든 brekapoint 삭제 (delete와 동일) d [index] : 특정 breakpoint 삭제 cl [라인] : 해당 라인의 brekapoint 삭제 cl [함수] : 해당 함수의 breakpoint 삭제 cl : 모든 breakpoint 삭제 enable [index] : 해당 brekapoint 활성화 disable [index] : 해당 breakpoint 비활성화 condition [index] [조건] : 해당 breakpoint는 조건을 만족할 때에만 동작 (ex : condition 2 var_a == 0) 실행 file [파일이름] : 해당 파일 이름 디버깅 실행 r [arg1] [arg2] [...]: 지정된 파일을 argument와 함께 실행 (run과 동일) run 명령은 breakpoint를 설정해 놓지 않으면 프로그램을 끝까지 실행하고 종료한다. start 명령은 아무런 breakpoint가 없어도 자동으로 시작지점에서 한번 정지한다. r $() : 쉘 프롬프트를 실행, 표준출력 결과를 인자로 프로그램 실행 r \u0026lt;\u0026lt;\u0026lt; $() : 프로그램 실행시 표준 입력으로 필요한 데이터를 $() 안의 쉘 프롬프트 표준 출력 결과로 대체한다. ex: r \u0026lt;\u0026lt;\u0026lt; $(python3 -c \u0026quot;print('hello world')\u0026quot;) : 프로그램 실행 후 표준 입력으로 \u0026ldquo;hello world\u0026rdquo; 전달 c : 다음 breakpoint로 진행 (continue 와 동일) n [숫자] : 해당 숫자만큼 다음 라인으로 진행. 숫자 생략가능 (next와 동일) s [숫자] : 다음 라인이 함수라면 함수 내부로 이동. 해당 숫자만큼 진행. 숫자 생략 가능 (step 과 동일) k : 실행중인 프로그램 종료 set \u0026lt;변수\u0026gt;=\u0026lt;값\u0026gt; : 특정 변수에 강제로 값을 집어넣음 set {타입}\u0026lt;주소\u0026gt;=\u0026lt;값\u0026gt; : 특정 타입의 값을 해당 주소에 집어넣음 (ex: set {int} 0x123456 = 10 : 0x123456 주소에 10이라는 int값 주입) entry : 프로그램의 첫 실행지점을 break point 로 잡고 디버깅을 실행시킨다. start 명령과 동일한 효과 finish : 현재 실행중인 함수를 종료시키고 함수 호출지점 다음으로 이동 (fin 으로 사용 가능) 확인 l : main을 기점으로 소스 출력 (list와 동일) l [라인] : 해당 라인을 기점으로 소스 출력 l [함수] : 해당 함수를 기점으로 소스 출력 info locals : 지역변수들 확인 info variables : 전역변수 확인 p [변수] : 변수 값 확인 p *[배열]@[숫자] : 해당 숫자만큼 배열의 값 출력 p [구조체] : 구조체 주소 확인 p *[구조체] : 구조체 전체 값 확인 p *[구조체].인자 : 구조체 인자 값 확인 (ex: p *s1.name : s1 구조체의 name필드 값 확인) linked list 는 포인터를 계속 참조할 수 있음 (ex: p s1.next-\u0026gt;next-\u0026gt;next-\u0026gt;name) p \u0026lt;함수\u0026gt; : 함수 실행 결과를 확인 p/t var : var 변수를 2진수로 출력 p/o var : var 변수를 8진수로 출력 p/d var : var 변수를 부호가 있는 10진수로 출력 (int) p/u var : var 변수를 부호가 없는 10진수로 출력 (unsigned int) p/x var : var 변수를 16진수로 출력 p/c var : var 변수를 최초 1바이트 값을 문자형으로 출력 p/f var : var 변수를 부동 소수점 값 형식으로 출력 p/a addr : addr주소와 가장 가까운 심볼의 오프셋을 출력 x \u0026lt;메모리주소\u0026gt; : 메모리값 확인 x $pc : program counter (다음 실행할 명령어 번지) 확인 x 뒤에 \u0026lsquo;/\u0026rsquo; 를 입력하여 옵션을 추가 할 수 있다. x/o : 8진법으로 표시 x/x : 16진법으로 표시 x/u : 10진법으로 표시 x/t : 2진법으로 표시 x/b : 1 byte 단위로 표시(byte) x/h : 2 byte 단위로 표시(half word) x/w: 4 byte 단위로 표시(word) x/g : 8 byte 단위로 표시(giant) x/i : 역어셈블된 기계여 표시 x/c : ASCII 표의 바이트 표시 x/s : 문자 데이터의 전체 문자열을 표시. ex1) x/4wx : 주소값부터 다음 네 개의 주소를 4byte씩 16진수로 표시 ex2) x/10gx : 주소값부터 다음 80byte를 8byte씩 16진수로 표시 i r : 레지스트 값 모두 확인 (info registers 와 동일) bt : 프로그램 중단시 최종 스택 프레임을 출력 (backtrace와 동일) display [변수명] : 변수 값을 매번 화면에 디스플레이 display/[출력형식] [변수명] : 변수 값을 출력 형식으로 디스플레이 undisplay [디스플레이번호] : 디스플레이 설정을 없앤다 disable display [디스플레이번호] : 디스플레이를 일시 중단한다. enable display [디스플레이번호] : 디스플레이를 다시 활성화한다. f [인덱스] : stack frame에서 인덱스에 해당하는 함수로 포커스를 변경한다. 0번이 가장 최근에 호출된 함수이며, 인덱스를 생략하면 0번 함수가 선택된다. (frame 과 동일)` 포커스를 변경한다는 말은, 해당 함수 stack 내부에 선언된 로컬 변수 등을 참조할 수 있다는 뜻이다. pd : rip 주변의 기계어를 어셈블리로 번역하여 출력한다. pdisas 의 축약으로, debugger에 따라 disiassemble 로 동작하는 경우도 있다. tele : telescope의 축약으로 rsp 주변의 메모리를 덤프함과 동시에 메모리에 담긴 주소를 참조하여 그 안에 담긴 값도 함께 보여준다. vmmap : 가상 메모리 레이아웃을 보여줌 기타 q : 종료 ","permalink":"https://aswinblue.github.io/post/c++/gdb/","summary":"GDB GNU Debugger의 약자 유닉스의 디버거는 오픈소스가 아니라 GNU에서 새로 개발한 디버거 디버깅을 위해서는 register(레지스터 값), disassem(rip 부근 주소를 디스어셈 한 값), stack(스택의 값), backtrace(현재 rip에 도달 할 때 까지 거쳐간 함수들) 을 파악해야 하며, 이를 context(맥락) 이라 한다. 컴파일 gcc로 컴파일시 옵션에 -g 를 붙여야 소스를 보면서 디버깅이 가능 리눅스에서 컴파일한 파일은 ELF (Executable and Linkable Format) 의 실행 파일이 된다. ELF 파일은 파일 실행에 필요한 정보가 든 헤더와 여러 섹션들로 구성된다.","title":"GDB"},{"content":"React basic 개발환경 설치 및 실행 node.js 로 만들어진 create-react-app 툴을 이용하면 손쉽게 react 앱을 생성할 수 있다. npm을 설치하고 아래 명령어를 수행하여 create-react-app을 설치한다. npm install -g create-react-app 원하는 경로에 들어가 프로젝트를 생성한다. create-react-app \u0026lt;NAME\u0026gt; : NAME 경로에 프로젝트 생성 주의 : 프로젝트가 생성되는 폴더명은 대문자를 사용할 수 없다. 실행 npm run start 를 수행하면 localhost:3000에서 웹페이지를 퍼블리싱한다. 기본 설정 실행 포트 package.json 파일에서 \u0026quot;proxy\u0026quot;: \u0026quot;http://localhost:3000/\u0026quot; 과 같이 입력하면 실행시 포트를 3000으로 설정할 수 있다. 기본 구조 /public/index.html 에서 기본 화면 구성 \u0026lsquo;root\u0026rsquo; 이름으로 된 division이 있는데, 이 division에 대한 설정은 javascript로 정의되어있다. src 경로에 javascript파일들 구성 \u0026lsquo;index.js\u0026rsquo; 에 메인 화면에 사용된 객체가 정의되어 있다. 아래 내용은 id가 \u0026lsquo;root\u0026rsquo; 인 division에 \u0026lsquo;App\u0026rsquo;을 적용하겠다는 의미이다.\nReactDOM.render(\r\u0026lt;React.StrictMode\u0026gt;\r\u0026lt;App /\u0026gt;\r\u0026lt;/React.StrictMode\u0026gt;,\rdocument.getElementById(\u0026#39;root\u0026#39;)\r); \u0026lsquo;index.js\u0026rsquo;에서 \u0026lt;App/\u0026gt; 라 되어있는 사용자 정의 태그를 생성했는데, App은 \u0026lsquo;App.js\u0026rsquo;에 정의되어 있고, \u0026lsquo;index.js\u0026rsquo;에서 \u0026lsquo;App.js\u0026rsquo;를 참조한다.\n\u0026lsquo;App.js\u0026rsquo;에서 선언된 \u0026lsquo;App\u0026rsquo; 이라는 이름의 함수가 반환하는 값이 \u0026lsquo;App\u0026rsquo;태그에 치환된다고 보면 된다.\n\u0026lsquo;App\u0026rsquo;이 함수가 아니라 class로 정의되어 있다면 \u0026lsquo;App\u0026rsquo; class의 \u0026lsquo;render()\u0026rsquo; 함수의 리턴값이 \u0026lsquo;App\u0026rsquo;태그로 치환된다.\n리턴값은 무조건 특정 태그 안에 들어가 있어야 한다. 태그로 감싸주도록 한다.\nsrc경로에 css파일 구성 index.css에서 css설정 구성 디렉터리 src 하위에 디렉터리를 만들 수 있고, 각 디렉터리에는 index.jsx 파일을 넣을 수 있다.\nindex.js 파일은 아래와 같이 디렉터리 안의 파일들에서 export 된 내용들을 export한다.\n// src/component/index.js\rexport { default as Navbar } from \u0026#39;./Navbar\u0026#39;; // src/component/Navbar.jsx에서 Navbar을 default로 export한 경우\rexport { Footer } from \u0026#39;./Footer\u0026#39;; // src/component/Footer.jsx에서 Footer을 export한 경우 이렇게 export 된 내용들을 다른 폴더에서는 디렉터리만 import 하고 해당 모듈을 사용할 수 있다.\n// src/App.js\rimport { Navbar Footer } from component ❗ 단, index.js에 의해 세팅이 되는 시점이 App.js가 랜더 되는 시점보다 느리다는점에 주의한다. 아래는 이 문제로 발생할 수 있는 오류.\n// component/index.js\rexport { default as Button } from \u0026#39;./Button\u0026#39;\r// App.js\rimport Navbar from \u0026#39;./component/Navbar\u0026#39; // navbar을 import하는 라인이 먼저 호출됨\r// component/Navbar.js\rimport { Button } from \u0026#39;.\u0026#39; // button을 import하기 전에 App.js에서 Navbar을 호출했기 때문에 오류 발생, App.js를 구성하지 못해 빈 화면이 보여짐 모듈 import / export 특정 모듈을 export하고, 이를 다른 파일에서 import하여 사용할 수 있다. export 방법으로는 default 방법과, 일반 방법이 있습니다. default 방법\n// A.jsx\rexport default A; // import A from \u0026#39;./A\u0026#39;\r// 혹은 import B from \u0026#39;./A\u0026#39;도 가능\rexport {default as A}; // import {A} from \u0026#39;./A\u0026#39; 일반 방법\n// A.jsx\rexport { A }; // inport { A } from \u0026#39;./A\u0026#39; 위 두가지 예시를 보면 알겠지만, default로 export를 하면 다른 파일에서 import를 할 때 중괄호 없이 import가 가능하며, 그 이름도 아무렇게나 정할 수 있다.\ndefault 없이 export를 하면 중괄호 안에서 받아야 하며, 변수 명도 동일해야 한다.\nimport나 export에는 wildcard * 을 사용할 수 있다. export * from \u0026#39;./A\u0026#39; // 보통 index.jsx에서 사용\rimport * as A from \u0026#39;./A\u0026#39; // A.jsx에서 export한 것들을 모두 받아와 A로 사용.\r// 받아온 컴포넌트는 A.name, A.number 와 같이 사용하게 됨 배포 npm run start로 \u0026lsquo;create-react-app\u0026rsquo;으로 만든 앱을 실행시킬 수는 있지만, 이는 개발자용 실행 방식이다. 웹 브라우저에서 페이지에 접속하고 다운로드받은 용량을 확인해보면 아무 기능이 없어도 MB단위가 다운받아짐을 확인할 수 있다. 이러한 상태로 배포를 하면 효율 및 보안 관점에서 적합하지 않다. npm run build 명령어를 수행하면 \u0026lsquo;build\u0026rsquo;라는 새로운 디렉터리와 데이터들이 생성된다. \u0026lsquo;build\u0026rsquo; 안에 있는 파일들은 공백 등을 제거하여 용량 및 보안에 최적화된 상태로 제공된다. 배포시에는 \u0026lsquo;build\u0026rsquo;디렉터리 안의 내용을 사용하면 된다. 웹서버의 최상위 디렉터리를 \u0026lsquo;build\u0026rsquo;로 설정하면 된다. npm install serve 명령어로 serve 툴을 설치한다. serve는 웹서버를 실행시키는 도구이다. serve -s build 명령어로 \u0026lsquo;build\u0026rsquo; 디렉터리를 root 디렉터리로 웹서버를 실행한다. 만약 vsCode 사용 중 \u0026ldquo;이 시스템에서 스크립트를 실행할 수 없으므로 \u0026hellip;\u0026rdquo; 문구가 발생한다면, 콘솔에서 설정을 변경해야 한다. 관리자코드로 vsCode를 실행시킨 후, 콘솔 창에 Set-ExecutionPolicy RemoteSigned 를 입력한다. 이후 get-ExecutionPolicy 를 입력하여 결과값이 RemoteSigned 가 나오는지 확인한다. 이후에는 정상적으로 serve 명령이 동작함을 확인 할 수 있다. 보통은 이렇게 일일이 작업을 수행하지 않고, npm run deploy 명령으로 package.json 파일에 기록된 설정대로 배포 작업을 자동화시킨다. github에 배포 create-react-app으로 프로젝트 생성 : create-react-app \u0026lt;NAME\u0026gt; gh-pages 설치(이미 설치시 생략가능) : npm install -g gh-pages git hub에서 원하는 이름으로 repository 생성( 이후 {repo-name} 로 지칭) 생성된 git repository와 react 폴더 연동한다. git init git remote add origin {your-repository-url} package.json파일 수정 ({username}은 github 계정 이름) \u0026ldquo;homepage\u0026rdquo; : \u0026ldquo;http://{username}.github.io/{repo-name}\u0026rdquo; \u0026ldquo;scripts\u0026rdquo;: {\u0026ldquo;predeploy\u0026rdquo;: \u0026ldquo;npm run build\u0026rdquo;, \u0026ldquo;deploy\u0026rdquo;: \u0026ldquo;gh-pages -d build\u0026rdquo;} 배포를 실행한다. npm run deploy gh-pages 라는 branch를 자동으로 생성하고, package.json에 설정한 \u0026lsquo;homepage\u0026rsquo; 주소에 react 페이지가 업로드된 것을 볼 수 있다. 문법 주석 React 는 react code(typescript)와 JSX(xml) 코드가 있다. typescript에서는 \u0026lsquo;//\u0026rsquo; 혹은 \u0026lsquo;/* */\u0026rsquo; 로 주석을 사용한다. JSX에서는 \u0026lsquo;{/* */}\u0026rsquo; 로 주석을 사용한다. 함수 일반 함수 javascript와 동일하게 선언 가능하다.\nfunction Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;a href=\u0026#34;/\u0026#34; onClick={ function(e) {\re.preventDefault();\rthis.props.onChangePage(); // 상위 컴퍼넌트로 부터 받은 함수 실행\r}\r\u0026lt;/div\u0026gt;\r); arrow 함수 FUNCTION_NAME = (VARIABLES) =\u0026gt; { BODY } 형태로 이루어져 있다.\nVARIABLES는 \u0026lsquo;,\u0026lsquo;로 나누어져 두개 이상의 인자를 선언할 수 있고, BODY에서 사용될 수 있다.\n위 함수를 호출하려면 FUNCTION_NAME(VARIABLES) 형태로 호출 가능하다.\nhighlightSquares = i =\u0026gt; {\rif (this.props.winningSquares.length \u0026gt; 0) {\rif (this.props.winningSquares.indexOf(i) \u0026gt; -1) {\rreturn \u0026#34;square winningSquares\u0026#34;;\r} else {\rreturn \u0026#34;square\u0026#34;;\r}\r} else {\rreturn \u0026#34;square\u0026#34;;\r}\r}; arrow 함수는 javascript를 반환할 수도 있고, html을 반환할 수도 있다. 방법은 아래와 같이 구분된다.\nconst js = () =\u0026gt; { // 함수 내용 }\rconst html = () =\u0026gt; ( // html ) 변수 hoisting : javascript에서는 변수를 scope(함수 혹은 블록)의 가장 위로 끌어올려서, 먼저 선언된것처럼 인식하는 기능이 있다. var var는 function-scoped 변수이다. 함수가 끝나기까지 해당 변수는 유지된다. (hoisting)\nvar를 block-scoped로 낮추기 위해서는 IIFE, \u0026lsquo;use strict\u0026rsquo; 등의 방법을 사용할 수도 있지만 let으로 선언하는게 빠르다.\nfunction TEST() {\rfor (var i = 0; i \u0026lt; 10; i++) {\rconsole.log(\u0026#39;i: \u0026#39;, i); // 정상출력\r}\rconsole.log(\u0026#39;i: \u0026#39;, i); // 정상출력\r}\rconsole.log(\u0026#39;i: \u0026#39;, i); // 오류 동일한 이름의 변수를 재선언할 수 있고, hoisting에 의해 나중에 선언한 변수를 먼저 사용할수도 있다. (오류를 일으키기 좋은 허용이다)\nvar A = 1\rvar A = 2 // 가능\rstr=\u0026#39;abcd\u0026#39; // 가능\rvar str let es2015에서 추가된 문법\n재선언 불가능\nhoisting 동작 안함\nlet A = 1\rlet A = 2 // 불가능\rA = 3 // 가능\rstr=\u0026#39;abcd\u0026#39; // 불가능\rlet str const es2015에서 추가\n선언과 동시에 값 할당 필요, 재정의 불가능\nhoisting 동작 안함\nconst A = 1\rconst A = 2 // 불가능\rA = 3 // 불가능\rstr=\u0026#39;abcd\u0026#39; // 불가능\rconst str // 불가능 선언없이 정의 아무 타입을 붙이지 않고 선언하면 전역변수로 선언된다.\nstr=\u0026#39;12345\u0026#39;\rA=5 string 문자열을 담는 변수로, 아래와 같은 함수들을 지원한다. contains(str) : 문자열 내에 주어진 문자열(str)이 포함되었는지 확인, 결과를 반환 배열 배열은 arr=[1, 2, 3] 과 같은 형태로 선언한다. arr=[,,,]과 같이 크기3(쉼표개수)의 배열 선언도 가능하지만, 배열의 요소는 undefined로 정의된다. arr = new Array(1,2,3)로 선언도 가능하다. 배열의 길이는 arr.length 로 추출 가능하다. 좌항에 배열 형태를 두어 배열의 요소를 각각 정의할 수 있다. [a, b, c] = [1, 2, 3] 이때, 일부 값을 무시할 수 있다. [a, , c] = [1, 2, 3] 전개 연산자(\u0026rsquo;\u0026hellip;\u0026rsquo;)을 이용하여 나머지 개체들을 통틀어 지정할 수 있다. [a, b, ...c] = [1, 2, 3, 4, 5] // a = 1, b = 2, c = [3, 4, 5] 전개 연산자 이후 다른 변수가 오면 오류가 난다. [a, b, ...c, d] = [1,2,3,4,5] // 오류 선언된 변수를 전개연산자로 다른 변수에 넣을수도 있다. ARRAY.indexOf(ITEM) : ARRAY 배열안의 ITEM의 index를 반환한다. var A = [1, 2, 3, 4, 5]\rvar B = [...A] // B = [1, 2, 3, 4, 5] 반복(순회) 배열 내용을 순회하는 방법은 다음과 같다. map 함수 var A = [1,2,3]\rA.map((a) =\u0026gt; {\r// 원하는 동작을 입력하면 된다.\r})\rA.map(Math.sqrt) // lambda함수 외 일반함수를 넣어도 된다. for-of var A = [1,2,3]\rfor (var a of A) {\r// java의 for( : ) 와 같다\r} 객체의 배열도 동일한 방법으로 순회가 가능하다. 다만 비구조화(destructing)가 포함된다. var B = [{a:1, b:2, c:3}, {a:4, b:5, c:6}]\rB.map({a,b,c} =\u0026gt; {\r// 원하는 동작 수행\r})\rfor (var {a:aa, b:bb, c:cc} of B) {\r// key가 마음에들지 않으면 재정의도 가능하다.\r} foreach map과 유사하게 동작한다. 하지만 map은 callback함수에서 조작한 내용으로 새로운 배열을 구성하고, foreach는 단순 반복만 수행한다. const lists = [\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;]\rreturn(\r// map\r{lists.map(element =\u0026gt; {\rconsole.log(\u0026#39;name\u0026#39;, element);\rreturn \u0026lt;div\u0026gt; {element} \u0026lt;/div\u0026gt;\r})} // -\u0026gt; \u0026lt;div\u0026gt;1\u0026lt;/div\u0026gt;, \u0026lt;div\u0026gt;2\u0026lt;/div\u0026gt;, \u0026lt;div\u0026gt;3\u0026lt;/div\u0026gt; 이 화면에 출력되고, 로그가 출력된다. // foreach\r{lists.foreach(element =\u0026gt; {\rconsole.log(\u0026#39;name\u0026#39;, element);\rreturn \u0026lt;div\u0026gt; {element} \u0026lt;/div\u0026gt;\r})} // -\u0026gt; 화면에는 아무것도 나오지 않고 로그만 출력된다.\r) 비교 filter 함수를 이용하여 조건에 맞는 요소만 선택 가능하다. var a = [1,2,3,4,5,6,7]\rvar b = a.filter(i =\u0026gt; i \u0026lt; 4); // b = [1,2,3] 객체 Json형태로 이루어져 있다. var obj = {'a':10, b:20} key값은 \u0026lsquo;\u0026lsquo;를 붙여도 되고 안붙여도 된다. value를 변수로 추출할때는 다음과 같이 수행한다. 이를 비구조화라 한다. var {a,b,c} = {a:1, b:2, c:3} // a==1, b==2, c==3 비구조화시 기본값을 설정할 수도 있다. var {a=1,b=2} = {a:10} // a==10, b==2. b=2를 설정하지 않으면 b==undefined 다른 key를 사용하고싶다면 다음과 같이 수행한다. var {a:one, b:two} = {a:10, b:20, c:30} // one==10, two==20, c==30 key값으로 사용불가능한 값이 올 경우 다음과 같이 비구조화 한다. var {'a-b-c':a_b_c, [key]:A_B_C} = {'a-b-c':10, 'A B C':20} // a_b_c = 10, A_B_C = 20 재구조화시 전개 연산자를 사용할 수 있지만, 전개연산자를 재정의 할 수는 없다. {a:A, ...rest} = {a:10, b:20, c:30} // rest:B 는 불가능 unpack 전개 연산자 ... 을 사용하여 객체 내용을 나열할 있다. ex)\nconst obj = () =\u0026gt; {\rvar value = \u0026#34;value\u0026#34;;\rvar onChange = () =\u0026gt; {console.log(\u0026#34;onchange\u0026#34;)}\rreturn {value, onChange};\r}\r...\r// 아래 두 줄은 같은 효과를 가진다.\r\u0026lt;input placeholder=\u0026#34;\u0026#34; {...obj}\u0026gt;\u0026lt;input/\u0026gt;\r\u0026lt;input placeholder=\u0026#34;\u0026#34; value = {obj.value} onchange={obj.onChange}\u0026gt;\u0026lt;input/\u0026gt; 복사 배열 var a = [1,2,3]\rvar b = [...a] // 깊은복사\rvar [...c] = a // 깊은복사\rvar d = a // 얕은복사 객체 var A = {one:1, two:2, three:3}\rvar B = {...A} // 깊은복사 : one==1, two==2, three==3\rvar C = {...A, three:30} // 깊은복사+값 할당 : one==1, two==2, three==30 조건 특정 조건을 만족할 때에만 내용이 출력되도록 한다.\n{CONDITION \u0026amp;\u0026amp; \u0026lt;div\u0026gt; ! \u0026lt;/div\u0026gt;} // CONDITION 이 true일 때만 '!'를 표시한다. 3항 연산자 : C, java의 3항 연산자와 동일\n\u0026lt;span\u0026gt;{A ? \u0026quot;True\u0026quot; : \u0026quot;False\u0026quot;}\u0026lt;/span\u0026gt; \u0026amp;\u0026amp; : 앞의 내용이 참이면 뒤의 내용 수행\n\u0026lt;span\u0026gt;{A \u0026amp;\u0026amp; \u0026quot;True\u0026quot;}\u0026lt;/span\u0026gt; promise 비동기 처리시 사용하는 객체 promise 객체는 async와 wait를 이용한다. async function f1() {} : async 함수 선언, f1 함수는 비동기로 동작하고, 내부에 await 구문을 사용할 수 있다. const var = await f1() : async 함수가 완료될 때 까지 대기하도록 await로 명시 Component React는 js파일에서 정의한 컴포넌트를 html로 컴파일 한다. ex) \u0026lsquo;Subject\u0026rsquo;라는 이름의 component를 생성해 본다. 생성된 \u0026lsquo;Subject\u0026rsquo;는 custom tag가 된다. HTML에서 tag를 호출하듯 사용 가능하다. class형태로 만들기 class Subject extends Component {\rrender() {\rreturn (\r\u0026lt;header\u0026gt;\r\u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt;\r\u0026lt;/header\u0026gt;\r);\r}\r} 함수 형태로 만들기 function Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r} -\u0026gt; 함수형은 자원을 덜 사용하고, 선언하기 쉬운 장점이 있다.\n\u0026lsquo;index.js\u0026rsquo;가 default라 가정하고, \u0026lsquo;App.js\u0026rsquo;에서 App 객체 안에 \u0026lt;Subject\u0026gt;\u0026lt;/Subject\u0026gt; 와 같이 태그를 생성한다. (다른 파일에 선언했다면 해당 파일을 \u0026lsquo;App.js\u0026rsquo;에서 참조 필요)\n※ \u0026lsquo;App.js\u0026rsquo; 파일은 확장자가 js이지만 코드 문법은 javascript가 아니다. props props를 활용하여 js파일에서 컴포넌트 태그 생성시 속성을 설정 가능하다.\n\u0026lt;Subject title=\u0026quot;TITLE\u0026quot;, content=\u0026quot;CONTENT\u0026quot;\u0026gt; : title 값으로 \u0026ldquo;TITLE\u0026rdquo;, content 값으로 \u0026ldquo;CONTENT\u0026rdquo; 설정\nSubject 객체 생성시 {this.prop.title}, {this.prop.content}와 같이 참조하여 사용한다.\nfunction Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;h1\u0026gt;{this.prop.title}\u0026lt;/h1\u0026gt;\r\u0026lt;h2\u0026gt;{this.prop.content}\u0026lt;/h2\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r} 응용하여 아래와 같은 활용도 가능하다.\nfunction Subject() {\r{title, content} = {this.prop}\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;h1\u0026gt;{title}\u0026lt;/h1\u0026gt;\r\u0026lt;h2\u0026gt;{content}\u0026lt;/h2\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r} state props는 부모 컴퍼넌트가 자식에게 설정해 주는 값이라면, state는 컴퍼넌트가 자기 자신을 위해 사용하는 값이다. state는 함수형에서는 사용 불가능하고 클래스형에서 사용 가능하다. 대신 함수형에서는 \u0026lsquo;훅\u0026rsquo; 이라는 기능을 이용해 state와 유사한 효과를 낼 수 있다. state 세팅 constructor : 컴퍼넌트가 생성되었을 때 최초로 실행되는 함수. 초기화를 담당한다.\nclass App extends Component {\rconstructor(props) {\rsuper(props); // constructor 함수 기본\rthis.state : { // state 초기화\rsubject:{title:\u0026#34;TITLE\u0026#34;, content: \u0026#34;CONTENT\u0026#34;}\r}\r}\rrender() {\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;Subject title={this.state.subject.title} content={this.state.subject.content}\u0026gt;\u0026lt;/Subject\u0026gt; // html형태의 return값 안에서 javascript문법을 사용하려면 \u0026#39;{}\u0026#39;로 묶어준다.\r\u0026lt;/div\u0026gt;\r);\r}\r} -\u0026gt; App 컴퍼넌트가 생성되면 초기 설정된 state 값으로 Subject 컴퍼넌트를 생성한다.\nindex.js -\u0026gt; App.js -\u0026gt; Subject.js 순으로 호출이 이루어지는데, index.js에서는 App.js의 상태값을 알지 못한다. 즉, 부모에게 자신의 정보를 노출하지 않고 은닉한다. state로 배열 사용\nclass App extends Component {\rconstructor(props) {\rsuper(props); // constructor 함수 기본\rthis.state = { // state 초기화\rsubject:{title:\u0026#34;TITLE\u0026#34;, content: \u0026#34;CONTENT\u0026#34;},\rcontents:[\r{id:1, title:\u0026#39;title1\u0026#39;, desc:\u0026#39;desc1\u0026#39;},\r{id:2, title:\u0026#39;title2\u0026#39;, desc:\u0026#39;desc2\u0026#39;},\r{id:3, title:\u0026#39;title3\u0026#39;, desc:\u0026#39;desc3\u0026#39;},\r]\r}\r}\rrender() {\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;TOC data={this.state.contents}\u0026gt;\u0026lt;/TOC\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r}\r}\rclass TOC extends Component {\rrender() {\rvar lists = [];\rvar data = this.props.data;\rvar i = 0;\rwhile (i \u0026lt; data.length) {\rlists.push(\u0026lt;li key={i}\u0026gt;\u0026lt;a href={\u0026#34;/content/\u0026#34; + data[i].id}\u0026gt;{data[i].title}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;)\r/*\r* 반복문을 통해 여러 객체를 만들 때, react에서는 \u0026#39;key\u0026#39;라는 유니크한 속성을 요구한다.\r*\r*/\ri = i + 1;\r}\rreturn (\r\u0026lt;nav\u0026gt;\r\u0026lt;ul\u0026gt;\r{lists} // lists에 \u0026lt;li\u0026gt;태그들을 넣어놓은 것들이 그대로 출력된다.\r\u0026lt;/ul\u0026gt;\r\u0026lt;/nav\u0026gt;\r);\r}\r} ※ react에서는 props나 state가 바뀌면, 이를 사용하는 하위 컴퍼넌트들의 render() 함수가 모두 다시 호출된다. 즉, 화면이 재구성된다.\nrender component 안의 render() 함수는 실제로 랜더링할 때 사용할 로직 및 html 형태를 반환한다. render() 함수 안에서 javascript로 로직 구현이 가능하다.\nex) 조건문 class App extends Component {\rconstructor(props) {\rsuper(props); // constructor 함수 기본\rthis.state = { // state 초기화\rmode: \u0026#39;read\u0026#39;\r}\rrender() {\rvar _mode = state.mode;\rif (_mode == \u0026#39;read\u0026#39;) { // 조건문\r} else if (_mode == \u0026#39;write\u0026#39;) {\r}\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;TOC data={this.state.contents}\u0026gt;\u0026lt;/TOC\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r}\r} return render() 함수의 return 값은 html 형태가 되어야 한다. 하지만 return 안에서도 {} 구문 안에서 간단한 문법은 사용 가능하다. 조건문 3항 연산자 : C, java의 3항 연산자와 동일\n\u0026lt;span\u0026gt;{A ? \u0026quot;True\u0026quot; : \u0026quot;False\u0026quot;}\u0026lt;/span\u0026gt; \u0026amp;\u0026amp; : 앞의 내용이 참이면 뒤의 내용 수행\n\u0026lt;span\u0026gt;{A \u0026amp;\u0026amp; \u0026quot;True\u0026quot;}\u0026lt;/span\u0026gt; {``} : 문자열 편집, 문자열 안에 연산을 추가할 수 있다.\n\u0026lt;div className={`bg-white' ${flag ? 'flex' : 'flex-2'}\\`}\u0026gt; 이벤트 버튼 클릭, 내용 변경 등 사건이 발생했을 때, 이벤트 함수가 호출된다.\nonClick html에서 onclick은 \u0026lsquo;C\u0026rsquo;가 소문자이지만, react에서는 대문자이다.\nonClick은 인자로 함수를 받는다.\n인자로 들어가는 함수는 \u0026rsquo;event\u0026rsquo; 객체를 인자로 받는다. 이 함수를 이벤트 함수라 한다. class App extends Component {\rconstructor(props) {\rsuper(props); this.state = {}\r}\rrender() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;a href=\u0026#34;/\u0026#34; onClick={function(e) {\rconsole.log(e); // 로그 찍는 방법\re.preventDefault(); // 해당 태그의 기본 클릭동작을 수행하지 않도록 한다.\r// \u0026#39;a\u0026#39; 태그의 경우 링크로 접속하는 동작을 막는다.\r}\r}\u0026gt;Click_here\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt;\r);\r}\r} 이벤트 함수 안에서 this.state.mode='write'와 같이 state를 변경하면 react가 변경 여부를 확인하지 못해 render()함수를 다시 호출하지 않아 화면이 갱신되지 않는다.\nthis.setState({mode:'write'});와 같이 state를 수정하도록 하자.\nonChange \u0026lsquo;input\u0026rsquo; 등 항목에서 내용이 변경되었을 경우\n아래와 같이 사용 가능\nconst onChange = (event) =\u0026gt; {\r// console.log(event.target.name);\rconst {target: {name, value}} = event; // get some values from \u0026#39;event\u0026#39;\r... +) bind\n이벤트 함수는 기본적으로 \u0026rsquo;this\u0026rsquo;를 가지지 않는다. 이때 강제로 this를 주입시키는 함수가 bind이다.\n이벤트 함수 안에서는 기본적으로 \u0026rsquo;this\u0026rsquo;를 호출해도 아무것도 bind되어있지 않다.\nonClick={function(e) { ... }.bind(this)} 와 같이 this를 bind해주면 this를 사용할 수 있게된다.\nvar obj = {name:\u0026#39;obj\u0026#39;};\rfunctiotn bindTest() {\rconsole.log(this.name);\r}\rbindTest(); // 아무 반응이 없다.\rbindTest.bind(obj); // obj가 bindTest의 this가 된다. +) custom event\n함수를 하위 컴퍼넌트에 전달해 준다.\nclass App extends Component {\rrender() {\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;Subject\rtitle={this.state.subject.title}\rcontent={this.state.subject.content}\ronChangePage={\rfunction(){\ralert(\u0026#34;page chaged\u0026#34;); // 경고창 출력\r}.bind(this);\r}\r\u0026gt;\r\u0026lt;/Subject\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r}\r}\rfunction Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;a href=\u0026#34;/\u0026#34; onClick={ function(e) {\re.preventDefault();\rthis.props.onChangePage(); // 상위 컴퍼넌트로 부터 받은 함수 실행\r}\r\u0026lt;/div\u0026gt;\r);\r} 하위 컴퍼넌트를 수정하지 않고 하위 컴퍼넌트의 태그 클릭시 수행할 작업을 변경할 수 있다.\n하위 컴퍼넌트에서 상위 컴퍼넌트의 state를 변경할 수 있게 된다.\n라이프사이클 컴퍼넌트는 \u0026lsquo;마운트 -\u0026gt; 업데이트 -\u0026gt; 언마운트\u0026rsquo; 생명주기를 갖는다. 마운트 마운트 단계 메서드로는 다음이 존재한다. constructor : 생성시 호출되는 메서드 (생성자) getDerivedStateFromProps : props 값을 state에 넣는 메서드 render : UI를 렌더링 하는 메서드(화면 재구성) componentDidMount : 컴퍼넌트 랜더링 완료 후 호출되는 메서드 업데이트 컴퍼넌트가 업데이트 되는 경우는 아래의 경우들이 속한다.\nsetProps를 이용한 props변경시 setState를 이용한 state변경시 부모 컴퍼넌트가 리렌더링 될 시 this.forceUpdate로 강제 렌더링시 업데이트 단계의 메서드로는 다음이 존재한다.\ngetDerivedStateFromProps : props의 값을 state에 입력 shouldComponentUpdate : 컴퍼넌트의 변화를 인지하고, 랜더링 필요 여부를 판단. true: 랜더링 필요, false: 랜더링 불필요. render : 컴퍼넌트 리렌더링 getSnapshotBeforeUpdate : 컴퍼넌트 변화를 DOM에 반영하기 바로 직전에 호출되 메서드 componentDidUpdate : 컴퍼넌트 업데이트 작업이 끝난 후 호출되 메서드 언마운트 언마운트 단계의 메서드로는 다음이 존재한다. componentWillUnmount : 컴퍼넌트가 브라우저상에서 사라지기 직전 호출되는 메서드 this javascript 문법의 this와 동일하게 동작한다.\nclass 안에서는 this를 호출하면 class(컴퍼넌트)에 소속된 요소들에 접근할 수 있다.\n일반 function 안에서 this를 호출하면 자신이 종속된 객체에 접근한다.\narrow function 안에서 this를 호출하면 자신이 종속된 인스턴스(컴퍼넌트)에 접근한다.\nfunction func1() {\rthis.name = \u0026#34;func1\u0026#34;\rreturn {\rname : \u0026#34;return\u0026#34;\rarrow : () =\u0026gt; {\rconsole.log(this.name) // \u0026#39;func1\u0026#39; 출력\r}\rnormal : function() {\rconsole.log(this.name) // \u0026#39;return\u0026#39; 출력\r}\r}\r} hook class component에는 this.state가 있지만 function component 에서는 this.state가 없다. 대신 hook을 사용하여 동일한 기능을 수행한다. React에서는 built-in hook을 지원하고, 사용자가 직접 정의해서 사용할 수도 있다. hook의 조건 hook은 React 함수에서만 호출해야 한다. 일반 javascript 함수에서 호출하면 안된다. hook은 반복문, 조건문, nested function에서 호출되면 안된다. 위 두 조건을 이해하려면 hook의 동작 원리를 이해해야한다.\nReact는 컴퍼넌트를 처리할때 hook 함수들을 호출된 순서대로 관리한다.\n만약 컴퍼넌트를 업데이트할 때 hook 함수들의 순서가 변경된다면 React는 이를 정상적으로 처리하지 못한다.\n이때문에 hook은 항상 컴퍼넌트의 최상단에서 호출되어야 한다.\nhook의 종류 State Hooks import { useState } from 'react' 로 참조한다. [state, updateState] = useState( VALUE ): 컴퍼넌트에 VALUE값을 저장하고, 배열을 반환한다. \u0026lsquo;state\u0026rsquo; 는 VALUE 와 동일한 값이며, \u0026lsquo;updateState\u0026rsquo; 는 state값을 업데이트할 수 있는 함수 페어를 반환한다. \u0026lsquo;updateState\u0026rsquo; 는 this.setState와 유사한 효과를 가진다. VALUE값으로는 숫자, 문자열, 객체 모두 수용 가능하다. Effect Hooks import React, { useEffect } from 'react';로 참조한다.\ncomponentDidMount, componentWillUnmount 혹은 componentDidUpdate 와 유사한 효과를 발생시키며, 한 함수에서 여러번 선언 가능하다.\nuseEffect의 첫번째 인자로 함수가 들어가는데, 이 함수는 componentDidMount와 같은 시점에 동작된다.\nuseEffect의 첫번째 인자로 들어간 함수는 return값으로 함수를 반환하는데, 이 반환된 함수는 componentWillUnmount와 같은 시점에 동작된다.\nuseEffect의 두번째 인자로는 배열이 들어가고, 빈 배열을 넣을수도 있고, 값을 넣을수도 있다.\n이 배열 요소의 값이 바뀔경우 useEffect의 첫번째 인자로 들어간 함수를 실행시킨다. (componentDidUpdate와 유사하게 특정 변수가 변할때 rerendering을 할 수 있다.)\n또한, 이 배열 요소의 값이 바뀌기 직전, 첫번째 인자로 들어간 함수의 return 값이 실행된다.\n// return 없는 함수만 오는 경우\ruseEffect( () =\u0026gt; {\rconsole.log(\u0026#34;componentDidUpdate\u0026#34;);\r}\r// return 이 포함된 함수가 오는 경우\ruseEffect( () =\u0026gt; {\rconsole.log(\u0026#34;componentDidMount\u0026#34;);\rreturn (\r() =\u0026gt; { console.log(\u0026#34;componentWillUnmount\u0026#34;) }\r)\r})\r// 두번쨰 인자가 들어간 경우\ruseEffect( () =\u0026gt; {\rconsole.log(\u0026#34;\u0026#39;value\u0026#39; changed\u0026#34;);\rreturn (\r() =\u0026gt; { console.log(\u0026#34;value will be change\u0026#34;)}\r)\r}, [value]) class 의 componentdidMount와 같은 함수에 비해 간단하고 직관적으로 사용할 수 있다.\nContext Hooks useContext Reducer Hooks useReducer Custom Hooks hook을 담고 있는 사용자 정의 함수를 custom hook이라 칭한다. 반복되는 hook 호출 + 일련의 처리 과정을 하나의 함수로 묶어서 사용할 수 있다. 통념적으로 \u0026lsquo;use\u0026rsquo;로 시작하는 이름을 붙여준다. 호출된 custom hook도 일반 hook과 마찬가지로 중복해서 사용이 가능하며 각 hook들 끼리는 독립적이다. 6.Reference hook\nuseRef() 함수가 속한다. import { useRef } from 'react' 구문으로 참조 가능 랜더링과 독립적으로 변하지 않는 데이터를 저장한다. useRef는 변경될 시 페이지를 재 랜더링 하지 않는다. ref = useRef(null) 형태로 선언하며, reference object를 생성한다. null대신 저장하고싶은 데이터를 넣어도 된다. ref.current 로 저장한 데이터를 참조한다. ex) if (ref.current == null) useContext와 함께 사용하여 다른 component들에서 이 값을 참조하도록 할 수 있다. 객체 생성 후 값을 대입하려면 ref.current = data 형태로도 가능하다. \u0026lt;textarea ref={textareaRef}/\u0026gt; 형태로도 대입이 가능하다. textarea 객체 자체를 reference 하는 형태가 된다. \u0026lsquo;ref\u0026rsquo; 는 변수 명이 아니고 고정 속성값임에 주의 각종 모듈 package.json에 dependency를 기록해놓은 경우, npm install --legacy-peer-deps 명령으로 모든 dependency를 한번에 다운받을 수 있다. package.json에 기록되지 않는 모듈은 지워버리니 주의. Router SPA (Single Page Application) 에서 사용하지 않는 리소스를 로딩하느라 시간이 오래걸리는 것을 방지하기 위해, 소스를 분할처리하여 사용시에만 받을수 있게 하는 모듈\n설치 : npm install react-router-dom\n사용 :\nimport { HashRouter, Route, Routes, BrowserRouter} from \u0026#34;react-router-dom\u0026#34;;\rconst sample = () =\u0026gt; {\rreturn (\r\u0026lt;HashRouter\u0026gt;\r/* can add any components you want */\r\u0026lt;Routes\u0026gt;\r/* can only put \u0026#39;Route\u0026#39; components in \u0026#39;Routes\u0026#39; */\r\u0026lt;Route path=\u0026#34;/\u0026#34; element={\u0026lt;Home/\u0026gt;} /\u0026gt; // \u0026#39;/\u0026#39; 주소 호출시 Home component를 호출\r\u0026lt;Route path=\u0026#34;/about/*\u0026#34; element={\u0026lt;About/\u0026gt;} /\u0026gt; // \u0026#39;about\u0026#39; 및 \u0026#39;about/...\u0026#39; 형태의 주소 호출시 About component 호출\r/* add as you wish */\r\u0026lt;/Routes\u0026gt;\r\u0026lt;/HashRouter\u0026gt;\r);\r}; Route는 위에서부터 순차적으로 적용된다. if-else if 구문으로 생각하면 편하다.\n정규식 wild card *을 사용할 수 있다. (v5에서 exact 옵션 삭제되고 \u0026lsquo;*\u0026lsquo;로대체)\nroute 하는 대상에 props을 전달하고 싶다면,\nLink 특정 페이지로 경로를 전환해 주는 기능을 한다.\nreact-router-dom 모듈 안에 포함되어있다.\n\u0026lt;a\u0026gt; 태그와 동일한 역할을 하지만, React에서는 \u0026lt;a\u0026gt;를 사용하면 페이지를 새로 호출하여 React가 지니고 있던 상태들이 모두 초기화되기 때문에 \u0026lt;a\u0026gt; 태그 대신 link를 사용하는것이 맞다.\nlink는 페이지의 개념이고, button은 operation의 개념이다. 모두 event를 발생시킬 수 있지만 구분을 하는게 좋다.\n설치 : npm install react-router-dom\n사용 :\nimport { Link } from \u0026#34;react-router-dom\u0026#34;;\r...\r\u0026lt;Link to=\u0026#34;/\u0026#34;\u0026gt;Root\u0026lt;/Link\u0026gt; // 클릭하면 \u0026#39;/\u0026#39; 경로로 redirect 되는 Link 생성 Redirect react-router-dom에서 redirect를 지원하는 방법은 여러가지가 있다. Navigate 모듈 사용 :\nimport { HashRouter, Routes, Route, Navigate } from \u0026#34;react-router-dom\u0026#34;;\r...\r\u0026lt;HashRouter\u0026gt;\r\u0026lt;Routes\u0026gt;\r\u0026lt;Route path=\u0026#34;/\u0026#34; element={\u0026lt;Home/\u0026gt;}\r\u0026lt;Route path=\u0026#34;/about\u0026#34; element={\u0026lt;About/\u0026gt;}\r/* add as you wish */\r\u0026lt;Route path=\u0026#34;/index\u0026#34; element={\u0026lt;Navigate replace to=\u0026#34;/\u0026#34; /\u0026gt;} /\u0026gt; // \u0026#39;index\u0026#39; 페이지를 \u0026#39;/\u0026#39; 경로로 redirect\r\u0026lt;Route path=\u0026#34;*\u0026#34; element={\u0026lt;Navigate to=\u0026#34;/\u0026#34; /\u0026gt;} /\u0026gt; // 위에서 설정되지 않은 경로에 대해서는 모두 \u0026#39;/\u0026#39;로 redirect\r\u0026lt;/Routes\u0026gt;\r\u0026lt;/HashRouter\u0026gt; useHistory 사용 :\nconst history = useHistory();\rhistory.push(\u0026#34;/\u0026#34;); // \u0026#39;/\u0026#39; 경로로 redirect useNavigation 사용 :\nconst navigation = useNavigation()\rnavigation(\u0026#34;/\u0026#34;); // \u0026#39;/\u0026#39; 경로로 redirect cross-env 운영체제마다 환경변수 제공 방식이 달라 절대경로 표시가 어려웠던 점을 해결해주는 모듈 설치 : npm install cross-env --dev typeof react에서 기본적으로 제공하는 함수이다. ex)\nvar x = 1;\rif (typeof(x) === \u0026#39;number\u0026#39;) {\r...\r} 반환하는 결과값은 다음과 같다.\nundefined, object, number, boolean, bigint, string, symbol, function\n정의되는 값 참조\nDOM JSX에서 DOM을 조작하는 내용을 살펴보자 script 참조 javascript에서 아래와 같이 script를 추가할 수 있다.\n\u0026lt;script async defer src=\u0026quot;https://apis.google.com/js/api.js\u0026quot; onload=\u0026quot;gapiLoaded()\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\nreact에서는 위 방식 대신, hook과 document 인자를 사용하여 아래와 같이 작성한다.\nconst [calendarApiLoaded, setCalendarApiLoaded] = useState(false);\ruseEffect( ()=\u0026gt; {\r// check api is loaded\rconst existingCheck = document.getElementById(\u0026#39;gapi\u0026#39;);\r// if not loaded, load\rif (!existingCheck) {\rconst gapiScript = document.createElement(\u0026#39;script\u0026#39;);\rgapiScript.src = \u0026#34;https://apis.google.com/js/api.js\u0026#34;\rconst gisScrpit = document.createElement(\u0026#39;script\u0026#39;);\rgisScrpit.src = \u0026#34;https://accounts.google.com/gsi/client\u0026#34;\r// merge two scripts\rgapiScript.append(gisScrpit);\rgapiScript.id = \u0026#39;gapi\u0026#39;;\r// append to body\rdocument.body.appendChild(gapiScript);\r// change state\rsetCalendarApiLoaded(true);\r}\r}); window 변수 window는 전역번수를 attach된 모든 script에서 접근할 수 있는 변수이며, react에서도 마찬가지로 window.value 혹은 window['value'] 형태로 접근이 가능하다. 기타 함수형, 클래스형 react는 함수형 방식과 클래스형 방식으로 작성할 수 있다. 최근에는 함수형 방식을 선호하는 추세이다. 함수형이 클래스형보다 메모리를 덜 사용한다. 다른 파일 참조 react에서 다른 파일을 참조할 때에는 \u0026lsquo;import\u0026rsquo;를 사용하며, 확장자가 없으면 \u0026lsquo;.js\u0026rsquo;가 생략된 것으로 본다.\nimport React, { Component } from \u0026quot;react\u0026quot;는 기본으로 필요하다. html에서 예약어로 사용하는 태그들은 \u0026lsquo;synamtic tag\u0026rsquo;라 한다. \u0026lsquo;h1\u0026rsquo;, \u0026lsquo;header\u0026rsquo;, \u0026rsquo;nav\u0026rsquo;, \u0026lsquo;article\u0026rsquo; 등이 있다. export : 특정 객체를 다른 파일에서 import할 수 있도록 한다.\nex) export App debugger라는 예약어는, chrome에서 실행할 때 break point역할을 한다. 개발시 코드로 break point를 설정할 수 있다. 추가 활용 이미지 첨부 이미지는 /resources 파일에 첨부하고, import로 가져와 사용할 수 있다.\n확장자가 없으면 js파일로 취급하니 확장자도 꼭 적어주도록 한다.\nimport screen_img from \u0026#39;../resources/screen_img.webp\u0026#39;\r...\r// INFO: React JSX에서 style 설정\rvar _style = {\r\u0026#39;top\u0026#39;: 0 //- scrollPos\r}\rvar _style_img = {\r\u0026#39;background-image\u0026#39;: \u0026#34;url(\u0026#34; + screen_img + \u0026#34;)\u0026#34;,\r\u0026#39;top\u0026#39;: -694 - scrollPos * 4/5\r}; key 숨기기 API key 등 사용자에게 드러내지 않고싶은 정보들을 react가 아닌 다른 곳에 저장해야 한다. react app에 저장하게 되면 개발 도구를 사용해 Client에서 어떻게든 내용을 확인할 수 있다. 다만, .env 파일에 따로 저장하게 되면 git에서는 나타나지 않게 설정할 수 있다. .env 파일 사용법 root 경로에 .env파일을 생성한다. .gitignore에 .env파일을 예외처리 한다. 정의하고 싶은 내용을 REACT_APP_ 뒤에 이어붙여 정의한다. (ex: REACT_APP_API_KEY) 정의한 내용은 react JSX에서 process.env.REACT_APP_API_KEY 형태로 사용 가능하다. Custom Tag Custom tag \u0026lsquo;CAT\u0026rsquo; 를 새로 만든다고 할때, \u0026lt;CAT name={name}/\u0026gt; 과 같이 생성하였다. Custom tag 안에 다른 내용을 집어넣고 싶으면, \u0026lt;CAT name={name}\u0026gt; {props.children} \u0026lt;/CAT\u0026gt; 형태로 사용하면 된다. Custom tag를 정의할 때, tag 사이에 든 child를 포함하여 아래와 같이 구조를 정의할 수 있다. const CAT ({child}) =\u0026gt; {\r\u0026lt;div\u0026gt;start\u0026lt;/div\u0026gt;\r{child}\r\u0026lt;div\u0026gt;end\u0026lt;/div\u0026gt;\r}; 참조 자바스크립트 문법 문법 Document React LifeCycle What \u0026amp; Why Hook\n","permalink":"https://aswinblue.github.io/post/webapplication/react_basic/","summary":"React basic 개발환경 설치 및 실행 node.js 로 만들어진 create-react-app 툴을 이용하면 손쉽게 react 앱을 생성할 수 있다. npm을 설치하고 아래 명령어를 수행하여 create-react-app을 설치한다. npm install -g create-react-app 원하는 경로에 들어가 프로젝트를 생성한다. create-react-app \u0026lt;NAME\u0026gt; : NAME 경로에 프로젝트 생성 주의 : 프로젝트가 생성되는 폴더명은 대문자를 사용할 수 없다. 실행 npm run start 를 수행하면 localhost:3000에서 웹페이지를 퍼블리싱한다. 기본 설정 실행 포트 package.json 파일에서 \u0026quot;proxy\u0026quot;: \u0026quot;http://localhost:3000/\u0026quot; 과 같이 입력하면 실행시 포트를 3000으로 설정할 수 있다.","title":"React basic"},{"content":"C++ basics 매크로 #define MACRO 1 : MACRO 값으로 1을 지정 #undef MACRO : MACRO값에 지정된 내용 해제 여러줄의 매크로 값 지정 : #define PRINT(X) printf(\u0026#34;%d\u0026#34;, X);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 1);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 2); 매크로 합성 : #define A 1\r#define B 1\r#define C A##B // A##B = 12 함수형태 매크로 작성 : // 일반함수에는 \u0026#39;;\u0026#39; 를 붙이지만 매크로 함수에는 \u0026#39;;\u0026#39;를 붙일 필요가 없다.\r// 일관성을 갖기 위해 do-while문 안에 작성하면 매크로 함수에도 \u0026#39;;\u0026#39;를 붙이도록 할 수 있다.\r#define FUNC(a, b) do { \\\ra = b * 2;\\\r} while (0) 연산자 우선순 : // 매크로 함수는 계산 전 치환을 먼저 수행한다. 연산자 우선순위에 주의한다.\r#define ADD1(a,b) a+b\r#define ADD2(a,b) (a+b)\r#define MULT(a,b) a*b\r#define MULT2(a,b) (a)*(b)\r...\rprintf(\u0026#34;%d\u0026#34;,ADD1(3,4) * 2) // 예상값 (3 + 4) * 2 = 14\r// 3 + 4 * 2 로 치환하여 계산되어 실제 결과는 11\r// ADD2 처럼 계산 결과를 괄호로 묶어야 안전하다.\rprintf(\u0026#34;%d\u0026#34;,MULT(2+2,3+3)) // 예상값 (4 * 6) * 2 = 26\r// (2 + 2 * 3 + 3) 로 치환하여 계산되어 실제 결과는 11\r// MULT2 처럼 각 변수를 괄호로 묶어야 안전하다.\r// ADD1, MULT2 경우를 종합하여 아래와 같이 사용하자\r#define ADD3(a,b) ((a) + (b))\r#define MULT3(a,b) ((a) * (b)) 조건부 컴파일 if-elif-else 사용 가능 조건에 !, \u0026amp;\u0026amp; || 논리연산 가능 #define MACRO\r#define DEBUG 1\r#ifdef MACRO // 정의가 되어있으면 수행\r#endif\r#if DEBUG // DEBUG가 나타내는 값 또는 식이 참이면 수행\r#endif 파일 포함 #include \u0026lt;FILE_NAME\u0026gt; // 표준라이브러리에서 파일 참조\r#include \u0026#34;FILE_NAME\u0026#34; // 현재 경로 기준 파일 참조 → [활용]: 헤더파일 중복 참조 방지법\n#ifndef 사용 #ifndef __FILE_NAME_H__\r#define __FILE_NAME_H__\r// 헤더파일 내용\r#endif pragma once 사용 #pragma once // 일부 컴파일러에서만 지원 입출력 redirection 입력 재설정 freopen(\u0026quot;in.txt\u0026quot;, \u0026quot;r\u0026quot;, stdin); : \u0026lsquo;in.txt\u0026rsquo; 파일을 표준입력 대신 사용 cin cout 속도 향상 cin, cout을 사용하면 printf, scanf보다 속도가 느리다. 아래 코드로 세팅을 해 주면 출력 속도가 빨라진다. 하지만 printf, scanf와 함께 사용하면 순서가 섞이게 되니 설정 후에는 cin, cout만 사용하여야 한다. ios_base :: sync_with_stdio(false);\rcin.tie(NULL);\rcout.tie(NULL); std library printf printf(\u0026quot;%*d\u0026quot;, width, value) : value를 width글자 수만큼 앞에 공백을 두고 출력 printf(\u0026quot;%0*d\u0026quot;, width, value) : value를 width글자 수만큼 앞에 0을 두고 출력 printf의 버퍼가 출력되는 조건 프로그램이 종료될 때 버퍼가 가득찬 경우 강제로 버퍼를 비우도록 명령받은 경우(ex: fflush) 버퍼에 개행문자가 들어온 경우 sscanf sscanf(base_buffer, \u0026quot;%64[^\\n]\u0026quot;, target_buffer) : base_buffer에서 \u0026lsquo;\\n\u0026rsquo;이 아닌 문자열 64개를 읽어와 target_buffer에 담는다. (정규식 사용) ","permalink":"https://aswinblue.github.io/post/c++/c++/","summary":"C++ basics 매크로 #define MACRO 1 : MACRO 값으로 1을 지정 #undef MACRO : MACRO값에 지정된 내용 해제 여러줄의 매크로 값 지정 : #define PRINT(X) printf(\u0026#34;%d\u0026#34;, X);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 1);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 2); 매크로 합성 : #define A 1\r#define B 1\r#define C A##B // A##B = 12 함수형태 매크로 작성 : // 일반함수에는 \u0026#39;;\u0026#39; 를 붙이지만 매크로 함수에는 \u0026#39;;\u0026#39;를 붙일 필요가 없다.\r// 일관성을 갖기 위해 do-while문 안에 작성하면 매크로 함수에도 \u0026#39;;\u0026#39;를 붙이도록 할 수 있다.","title":"C++ basic"},{"content":"CMake Cmake란 : C,C++ 언어 컴파일시 make 툴을 이용할 때, 규모가 큰 프로젝트에서 컴파일 의존성 관리를 쉽게 하기 위한 도구 명령어 cmake CMakeList.txt : CMakeList.txt파일 안의 내용을 수행한다.\ncmake . : 파일 경로를 입력하면 해당 경로에서 CMakeList.txt파일을 찾아서 수행.\nmake : cmake를 이용해 생성한 파일들을 이용해 make로 컴파일\ncmake 명령 후 make를 이용해 컴파일을 수행하면 부산물들이 많이 생성된다. 이를 방지하기 위해 보통 새로운 폴더를 만들어 넣어서 사용한다. 1. mkdir build\r2. vi CMakeList.txt 후 내용 작성\r3. cd build\r4. cmake ..\r5. make CmakeLists.txt 작성은 쉘 프로그래밍과 유사하다. cmake 문법을 사용하여 작성해 주면 된다. 미리 지정된 변수들도 있는데, 해당 변수들에 주의하며 작성한다. 문법 ADD_EXECUTABLE : 실행파일 생성 ex) ADD_EXECUTABLE(main.exe main.cpp function.cpp) : main.cpp와 function.cpp를 사용해 main.exe를 생성한다. 헤더 파일은 자동으로 적용된다.\nTARGET : 목표 생성물, 생성할 실행 파일을 의미한다. add_executable(), add_library(), add_custom_target() 등의 함수로 수정 가능하다.\nadd_subdirectory : 하위 디렉터리를 빌드 환경에 추가한다.\nadd_subdirectory를 사용한 경우 find_package를 사용하지 않는다.\nadd_dependencies : subdirectory 이름을 사용하지 않고, add_library 혹은 add_executable로 생성한 이름을 첫번째 인자로 사용해야 한다.\nex) add_dependencies(\u0026lt;생성한 객체이름\u0026gt; \u0026lt;모듈1\u0026gt; \u0026lt;모듈2\u0026gt; ...)\n참조 https://nowonbun.tistory.com/712\n","permalink":"https://aswinblue.github.io/post/c++/cmake/","summary":"CMake Cmake란 : C,C++ 언어 컴파일시 make 툴을 이용할 때, 규모가 큰 프로젝트에서 컴파일 의존성 관리를 쉽게 하기 위한 도구 명령어 cmake CMakeList.txt : CMakeList.txt파일 안의 내용을 수행한다.\ncmake . : 파일 경로를 입력하면 해당 경로에서 CMakeList.txt파일을 찾아서 수행.\nmake : cmake를 이용해 생성한 파일들을 이용해 make로 컴파일\ncmake 명령 후 make를 이용해 컴파일을 수행하면 부산물들이 많이 생성된다. 이를 방지하기 위해 보통 새로운 폴더를 만들어 넣어서 사용한다. 1. mkdir build\r2.","title":"CMake"},{"content":"Docker 리눅스 커널의 cgroups와 namespace에 의해 제공되는 기술 가상화 기능의 일종으로, 별도의 OS를 갖지 않아 VM(Virtual Machine) 보다 가볍다. 게스트는 호스트 OS와 자원을 공유한다. immutable infrastructure : 서비스 운영 환경을 통째로 이미지화 하여 배포하는 형태 설치 링크 참조\n실행 DockerFile 이름의 파일을 생성하고 내용을 채워넣는다. https://docs.docker.com/engine/reference/builder/ DockerFile 명령어\nFROM: base image를 지정하는 명령어 DockerFile의 시작은 무조건 FORM 이 필요하다. FROM \u0026lt;IMAGE\u0026gt;:\u0026lt;VERSION\u0026gt; 형태로 사용한다. FROM base:${CODE_VERSION} ARG: 변수를 선언 ARG CODE_VERSION=latest 선언한 변수는 ${CODE_VERSION} 형태로 참조 가능하며, build시 자동으로 argument로 사용된다. ARG port 와 같이 값을 정의하지 않고 선언만 한 경우에는, \u0026ndash;build-arg 옵션으로 값 설정이 가능하다. docker build --build-arg port=80 CMD: 컨테이너 실행 시 디폴트로 실행할 커맨드를 설정 CMD [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] 형태로 사용 ENTRYPOINT와 조합하여 사용 가능하며, ENTRYPOINT에서 \u0026ldquo;executable\u0026rdquo;(명령어) 를 선언한 상태라면 CMD에서 executable 없이 param만 선언 가능하다. CMD [\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] 여러개의 CMD를 선언하면 가장 마지막의 것만 동작 CMD /code/run-app 와 같이 사용 COPY: 호스트 컴퓨터의 디렉터리나 파일을 Docker 이미지의 파일 시스템으로 복사 COPY: \u0026lt;SRC\u0026gt; \u0026lt;DEST\u0026gt; COPY: [\u0026quot;\u0026lt;SRC1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;SRC2\u0026gt;\u0026quot;, ... \u0026lt;DEST\u0026gt;] ADD: COPY의 상위호환 명령어로, 압축 파일이나 링크상의 파일도 추가 가능하다. ENV: 환경변수를 설정하기 위한 명령어 EXPOSE: 컨테이너로 유입되는 트래픽에 대한 처리 EXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;/\u0026lt;protocol\u0026gt;...] 프로토콜은 tcp,udp 중 선택 가능 ENTRYPOINT: 컨테이너 시작시 수행할 명령어 ENTRYPOINT [\u0026quot;\u0026lt;CMD\u0026gt;\u0026quot;, \u0026quot;\u0026lt;PARAM1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;PARAM2\u0026gt;\u0026quot;] 형태로 사용 ENTRYPOINT [\u0026quot;npm\u0026quot;, \u0026quot;start\u0026quot;] LABEL: 이미지에 metadata를 정의하는 명령어 LABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... STOPSIGNAL: 시스템이 종료하기 위한 SIGNAL을 설정한다. SIGINT, SIGKILL 등을 설정할 수 있으며, 이를 전달받으면 컨테이너가 종료하게 된다. 설정하지 않으면 SIGTERM 이 자동으로 세팅된다. USER: RUN: 쉘 프롬프트에 명령어를 입력하는 효과 VOLUME: 볼륨을 mount 하기 위한 자리를 세팅하는 명령어 WORKDIR: 컨테이너에서 작업 디렉터리 이동 리눅스의 cd 명령과 유사 ONBUILD: 빌드 후에 동작해야 할 명령들을 설정하는 명령어 DockerFile 명령어는 이미지 빌드를 위한 명령어이며, 빌드 할 때 마다 동일한 결과물을 산출한다. 하지만 빌드된 이미지의 결과물을 다음 빌드 때 사용하고 싶다면 이 명령을 사용한다. ONBUILD\rLearn more about the \u0026#34;ONBUILD\u0026#34; Dockerfile command.\rADD . /app/src\rONBUILD RUN /usr/local/bin/python-build --dir /app/src 다음 빌드 때 ONBUILD가 호출된 순서대로 명령이 동작한다. docker inspect 명령어로 확인 가능 예시\n# python:3.10의 이미지로 부터\rFROM python:3.9\r# 제작자 및 author 기입\rLABEL maintainer=\u0026#34;huisam@naver.com\u0026#34;\r# 해당 디렉토리에 있는 모든 하위항목들을 \u0026#39;/app/server`로 복사한다\rCOPY . /app/server\r# image의 directory로 이동하고\rWORKDIR /app/server\r# 필요한 의존성 file들 설치\rRUN pip3 install -r requirements.txt\r# 환경 설정 세팅\rRUN python setup.py install\r# container가 구동되면 실행\rENTRYPOINT [\u0026#34;python\u0026#34;, \u0026#34;Server.py\u0026#34;] 오류 와 해결방법 is docker daemon running? 에러 service docker status 입력시 docker daemon이 꺼져있는지 확인 service docker start 명령으로 daemon 실행 만약 명령은 수행되나 켜지지 않는다면 systemctl명령 수행 systemctl start docker : docker를 daemon으로 실행 systemctl enable docker : OS실행시 docker daemon을 기본 실행 systemctl 명령도 안된다면 /lib/systemd/system/docker.service , /lib/systemd/system/docker.socket 이 제대로 있는지 확인하여 설치 여부를 재확인한다. 참조 init 프로세스(PID 1)이 /bin/bash로 실행되지 않을 때, docker 실행 방법\ndocker run -t -i ubuntu:16.04 /bin/bash docker 명령어 이미지 : 특정 환경을 만들기 위해 세팅된 정보. 컨테이너 : 실행가능한 상태의 프로세스. 이미지를 컨테이너에 담아 실행시킬 수 있다. 생성 및 설정 버전 확인 docker -v 이미지 다운 docker pull \u0026lt;이미지명\u0026gt;[:태그] 이미지 생성 : 현재 경로에서 Dockerfile을 찾아 그 안의 docker build -t \u0026lt;이미지명\u0026gt; 설치된 도커 이미지 확인 docker images 실행 컨테이너 생성, 실행하지 않고 정지 docker create [옵션] \u0026lt;이미지명\u0026gt;[:태그] 컨테이너 실행 후 CLI 접속 docker attach \u0026lt;컨테이너 id 또는 이름\u0026gt; 컨테이너 실행. 지정된 작업이 수행된다. docker start \u0026lt;이미지명\u0026gt; 이미지 다운받아 실행 docker run \u0026lt;이미지명\u0026gt; 환경변수 설정 docker run -e \u0026lt;환경변수=설정값\u0026gt; 옵션 이미지 다운받아 실행 후 CLI 접속 docker run -it \u0026lt;이미지명\u0026gt; 컨테이너 실행시 이름 지정 docker run --name \u0026lt;컨테이너명\u0026gt; \u0026lt;이미지명\u0026gt; 디렉터리 연결 docker run -v \u0026lt;로컬경로\u0026gt;:\u0026lt;컨테이너 내부 경로\u0026gt; \u0026lt;이미지명\u0026gt; 포트 연결 docker run -p \u0026lt;로컬포트\u0026gt;:\u0026lt;컨테이너 포트\u0026gt; \u0026lt;이미지명\u0026gt; 백그라운드 실행 docker run -d \u0026lt;이미지명\u0026gt; 프로세스 종료시 컨테이너 자동 삭제 docker run -rm \u0026lt;이미지명\u0026gt; 관리 실행중인 컨테이너 확인 docker ps 일시중지 docker container pause \u0026lt;컨테이너명\u0026gt; 일시중지 해제 docker container unpause \u0026lt;컨테이너명\u0026gt; 컨테이너 삭제 docker rm \u0026lt;컨테이너 id 또는 이름\u0026gt; 모든 컨테이너 삭제 docker rmdocker ps -a -q 볼륨까지 같이 삭제 docker rm -v \u0026lt;컨테이너 id 또는 이름\u0026gt; 이미지 삭제 docker rmi [옵션] \u0026lt;이미지 id\u0026gt; 컨테이너 내부에서 커맨드라인을 수행하도록 외부에서 입력 ` docker exec [옵션] \u0026lt;컨테이너 id 또는 이름\u0026gt; \u0026lt;커맨드\u0026gt; 컨테이너 실행 후 지정된 명령어 수행 docker exec -it \u0026lt;컨테이너 id 또는 이름\u0026gt; [명령어] 백그라운드 실행중인 도커 로그 확인 docker logs -f \u0026lt;컨테이너 id 또는 이름\u0026gt; Dockerfile FROM \u0026lt;이미지명\u0026gt; : 이미 생성된 이미지에 덧붙여서 아래 내용을 수행, import와 비슷한 느낌 MAINTAINER : 메인테이너 정보 WORKDIR : 명령어를 실행할 위치 설멍, 리눅스 cd에 해당 VOLUME [\u0026ldquo;경로1\u0026rdquo;, \u0026ldquo;경로2\u0026rdquo;, \u0026hellip;]: run의 -v 옵션과 유사하지만, docker가 임의로 생성한 디렉터리에 volume을 연결한다. 이는 docker volume 명령어로 관리 가능하지만, 컨테이너가 삭제되고 나면 직접 접근하기 힘들다. ADD \u0026lt;DIR_SOURCE\u0026gt; \u0026lt;DIR_DEST\u0026gt;: 현재 이미지의 파일들을 내부 이미지의 특정 디렉터리에 복사. 이미지 안에 해당 경로가 없으면 생성하여 추가 RUN \u0026lt;명령어\u0026gt; : 컨테이너가 이미지를 실행하기 전 수행할 쉘 명령어 CMD \u0026lt;명령\u0026gt; : 실행하고 나서 수행할 명령어, 쉘을 불러 실행한다. CMD [\u0026ldquo;인자 1\u0026rdquo;, \u0026ldquo;인자 2\u0026rdquo;, \u0026hellip;] : 쉘 없이 명령 실행. \u0026lsquo;[]\u0026rsquo; 안에 문자열 배열로 치환해 넘겨주는 형태 EXPOSE : 외부와 연결할 포트, 컨테이너 실행시 -p 옵션을 사용하기 위해 설정해 두어야 함. ARG \u0026lt;옵션\u0026gt; : 설정 옵션들을 정의 ENV \u0026lt;환경변수\u0026gt; : 환경변수 설정 .dockerignore Docker 이미지 생성시 들어가지 않을 파일들을 지정 가능 docker-compose 각각의 Dockerfile들을 묶어 하나의 시스템을 구성하는 도구 docker 실행시 명령어를 미리 작성해 놓은 스크립트라고 보면 된다. docker-compose up 명령으로 docker-compose 파일 빌드 가능. 하위 경로에 Dockerfile들이 각각의 서비스에 해당됨 version: \u0026#39;3\u0026#39; // 도커 컴퍼즈 버전 3이상 요구\rservices: // 서비스 내용들이 아래에 옴\rservice1: // 서비스 이름으로, 마음대로 정의 가능\rbuild: ./S1 // docker-compose 파일로부터 경로를 지정\rvolumes:\r- ./S1:/home/root //\tdocker run -v 옵션 적용과 동일\rports:\r- \u0026#34;1234:1234\u0026#34;\t// docker run -p 옵션 적용과 동일\renvironment:\r- DEBUG_LEVEL=debug\t//\t환경변수 설정 가능\rlinks: // docker-compose 3부터는 필요없어진 기능, 네트워크 연결을 위해 사용\r- service2\rservice2: // 또다른 서비스, 위와 같이 작성 가능\r... ","permalink":"https://aswinblue.github.io/post/ci_cd/docker/","summary":"Docker 리눅스 커널의 cgroups와 namespace에 의해 제공되는 기술 가상화 기능의 일종으로, 별도의 OS를 갖지 않아 VM(Virtual Machine) 보다 가볍다. 게스트는 호스트 OS와 자원을 공유한다. immutable infrastructure : 서비스 운영 환경을 통째로 이미지화 하여 배포하는 형태 설치 링크 참조\n실행 DockerFile 이름의 파일을 생성하고 내용을 채워넣는다. https://docs.docker.com/engine/reference/builder/ DockerFile 명령어\nFROM: base image를 지정하는 명령어 DockerFile의 시작은 무조건 FORM 이 필요하다. FROM \u0026lt;IMAGE\u0026gt;:\u0026lt;VERSION\u0026gt; 형태로 사용한다. FROM base:${CODE_VERSION} ARG: 변수를 선언 ARG CODE_VERSION=latest 선언한 변수는 ${CODE_VERSION} 형태로 참조 가능하며, build시 자동으로 argument로 사용된다.","title":"Docker"},{"content":"Json library in C++ Rapid Json 커뮤니티 오픈소스로 다양한 예제코드를 찾을 수 있다. parsing 속도 다른 Json 파싱 라이브러리와 비교시 상위권에 위치 라이브러리 헤더 온리 사용이 가능 참조 https://joycecoder.tistory.com/9 https://github.com/Tencent/rapidjson/ ","permalink":"https://aswinblue.github.io/post/c++/json_c++/","summary":"Json library in C++ Rapid Json 커뮤니티 오픈소스로 다양한 예제코드를 찾을 수 있다. parsing 속도 다른 Json 파싱 라이브러리와 비교시 상위권에 위치 라이브러리 헤더 온리 사용이 가능 참조 https://joycecoder.tistory.com/9 https://github.com/Tencent/rapidjson/ ","title":"Json in C++"},{"content":"리눅스 기본 stty -a: 시그널 단축키들의 값 확인 strace FILE_NAME: 실행파일이 실행되는 상세 과정을 라인별로 보여준다. sed 기본적인 기능은 ed에서 따 왔으며, 이 기능들은 모두 sed에 적용이 된다. ed는 대화형 편집기이며, sed는 스트리밍 편집기 \\n 을 개행문자로 사용하는 스트리밍 에디터 sed [-e script][-f script-file][file...]\n찾기/출력 sed -n '/abd/p' list.txt : list.txt : 파일을 한줄씩 읽으면서(-n : 읽은 것을 출력하지 않음) abd 문자를 찾으면 그 줄을 출력(p)한다. 치환 sed 's/addrass/address/' list.txt : list.txt파일에서 addrass를 address로 바꾼다. 단, 원본파일을 바꾸지 않고 출력을 바꿔서 한다. sed 's/□□*/□/' list.txt : ( *표시: □ 는 공백 문자를 표시한다. ) 위의 구문은 한개이상의 공백문자열을 하나의 공백으로 바꾼다. 삭제 sed '/TD/d' list.txt : TD 문자가 포함된 줄을 삭제하여 출력한다. sed '/Src/!d' list.txt : Src 문자가 있는 줄만 지우지 않는다. sed '1,2d' list.txt : 처음 1줄, 2줄을 지운다. sed '/^$/d list.txt : 공백라인을 삭제하는 명령이다 압축 압축과 해제는 tar 명령어로 수행 가능하다.\ntar -xvf \u0026lt;FILE_NAME\u0026gt; : 압축 해제 tar -cvf \u0026lt;FILE_NAME\u0026gt; : 압축 에러와 해결 tar (child): xz: Cannot exec: No such file or directory sudo apt-get install xz-utils 명령으로 모듈을 설치 해 주어야 한다. tar (child): xz: Cannot exec: No such file or directory\rtar (child): Error is not recoverable: exiting now\rtar: Child returned status 2\rtar: Error is not recoverable: exiting now 이때 확장자가 gz로 되어있는 경우에는 옵션에 \u0026lsquo;z\u0026rsquo;를 추가해준다. (tar -zxvf, tar-zcvf)\n파일 관리 / 접근 wc FILE_NAME : 파일의 라인, 단어, 글자 수를 출력 (단어는 공백문자(줄바꿈, 공백, 탭) 으로 구분된 글자 집합) wc -c FILE_NAME: 파일 크기를 byte단위로 출력 xxd FILE_NAME: binary파일의 hexdump 출력 file FILE_NAME: 파일이 어떤 종류의 내용을 담고 있는지(C language, text \u0026hellip;)를 확인할 수 있다. readelf FILE_NAME: ELF 파일의 meta data를 확인한다. ELF란 Executable and Linkable Format을 의미한다. (*.o 형태의 파일이다) objdump -S FILE_NAME: object file을 어셈블리 형태로 주소별로 출력 해주는 명령이다. 리다이렉션 CMD1 \u0026gt; FILE_NAME: 표준 출력을 리다이렉션, CMD1의 결과를 FILE_NAME에 저장한다. CMD1 1\u0026gt; FILE_NAME 명령과 동일하다. 즉, 1\u0026gt; 은 \u0026gt;로 대체 가능하다. CMD1 2\u0026gt; FILE_NAME: 표준 에러를 리다이렉션, CMD1에서 발생한 에러를 FILE_NAME에 저장한다. CMD1 \u0026gt;\u0026gt; FILE_NAME: 표준 출력을 리다이렉션, CMD1의 결과를 FILE_NAME에 저장하되, 기존 파일 뒤부터 이어서 쓴다. CMD1 2\u0026gt; FILE_NAME_1 1\u0026gt; FILE_NAME_2: CMD1의 표준에러와 표준출력을 FILE_NAME_1 과 FILE_NAME_2에 나누어 기록한다. CMD1 \u0026gt; /dev/null: 출력할 내용을 버린다. dev/null 로 리다이렉트 된 내용은 모두 버려진다. 참조 http://m.egloos.zum.com/slog2/v/3689816\n","permalink":"https://aswinblue.github.io/post/linux/linux_command/","summary":"리눅스 기본 stty -a: 시그널 단축키들의 값 확인 strace FILE_NAME: 실행파일이 실행되는 상세 과정을 라인별로 보여준다. sed 기본적인 기능은 ed에서 따 왔으며, 이 기능들은 모두 sed에 적용이 된다. ed는 대화형 편집기이며, sed는 스트리밍 편집기 \\n 을 개행문자로 사용하는 스트리밍 에디터 sed [-e script][-f script-file][file...]\n찾기/출력 sed -n '/abd/p' list.txt : list.txt : 파일을 한줄씩 읽으면서(-n : 읽은 것을 출력하지 않음) abd 문자를 찾으면 그 줄을 출력(p)한다. 치환 sed 's/addrass/address/' list.txt : list.","title":"Linux commands"},{"content":"spdlog C++ 프로젝트에서 로그를 세팅할 수 있는 라이브러리 fast, header only, no dependency, .. 등 장점 참조 https://isocpp.org/blog/2014/11/spdlog https://github.com/gabime/spdlog\n","permalink":"https://aswinblue.github.io/post/c++/log_c++/","summary":"spdlog C++ 프로젝트에서 로그를 세팅할 수 있는 라이브러리 fast, header only, no dependency, .. 등 장점 참조 https://isocpp.org/blog/2014/11/spdlog https://github.com/gabime/spdlog","title":"spdlog C++"},{"content":"Node.js 기본 명령 npm init : 패키지 생성 npm install : 라이브러리 설치 -P : package.json에 저장, 기본옵션 -O : optionalDependencies에 저장 -D, --no-save : 기록없이 다운로드 -g : 글로벌 설치, 모든 프로젝트에 적용 MODULE_NAME@VERSION : 버전 설정, latest는 가장 최근 버전을 의미 node main.js : 실행(main.js) npx \u0026lt;package_name\u0026gt; : 설치하지 않고 일회만 실행 node main.js : 패키지 실행 (main.js파일) npm audit : 의존성 문제가 발생했을 때, npm audit fix : 의존성 문제를 자동으로 해결하는 명령어, 일부 해결을 할 수는 있지만 package.json 파일을 수정할 수 있으므로 주의. \u0026ndash;fix 옵션을 넣어서 강제로 수정할 수도 있지만, 오히려 되던 기능이 안 될 수도 있으므로 추천하지 않는다. npm cache clean : 캐싱된 데이터를 정리할 수 있다. \u0026ndash;force 옵션을 넣어 강제로 처리 가능 구조 main.js : nodejs 실행시 실행할 메인 파일 package.json : root 경로에 존재하며, npm 프로젝트를 관리하는 파일 /node_modules : 프로젝트에서 사용되는 모듈들이 저장되는 파일이다. npm install 명령 사용시 모듈들이 다운받아지는 경로이다. package.json nodejs 설정을 담고있는 파일로, 참조할 내용이 많아 아래에 따로 정리한다.\n\u0026quot;//\u0026quot; : \u0026quot;comment\u0026quot; : 주석을 넣는 방법, json key를 //로 하고, value에 comment를 작성한다.\nscripts : npm run SCRIPT(SCRIPT는 원하는 명령) 명령으로 특정 command를 수행하게 할 수 있음\nscript 명령은 os별로 명령이 상이할 수 있다. 이때는 다음과 같이 설정하여 각 os별로 다르게 동작할 수 있도록 한다. (npm run test 명령시 자동으로 수행해주는것 같지는 않음) os에 따라 명령어가 다를 수 있으므로, cross-env 모듈을 설치해서 사용하면 문제를 간단히 해결할 수 있다. ex) cross-env NODE_ENV=production \u0026#34;scripts\u0026#34;: {\r\u0026#34;test\u0026#34;: \u0026#34;run-script-os\u0026#34;,\r\u0026#34;test:darwin:linux\u0026#34;: \u0026#34;export NODE_ENV=test \u0026amp;\u0026amp; mocha\u0026#34;,\r\u0026#34;test:win32\u0026#34;: \u0026#34;SET NODE_ENV=test\u0026amp;\u0026amp; mocha\u0026#34;\r} devDependencies : 내부에 필요한 모듈들. npm install -D 명령어로 dependency를 추가 가능하다.\n{\r\u0026#34;name\u0026#34;: \u0026#34;rankingserver\u0026#34;,\r\u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;,\r\u0026#34;description\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;,\r\u0026#34;scripts\u0026#34;: {\r\u0026#34;//\u0026#34; : \u0026#34;this line is a comment\u0026#34;,\r\u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;,\r\u0026#34;build:postcss\u0026#34;: \u0026#34;NODE_ENV=production postcss src/main/resources/static/css/tailwind.css -o target/classes/static/css/tailwind.css\u0026#34;,\r\u0026#34;watch:postcss\u0026#34;: \u0026#34;NODE_ENV=development postcss src/main/resources/static/css/tailwind.css -o src/main/resources/static/css/tailwind.css -w\u0026#34;\r},\r\u0026#34;repository\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;,\r\u0026#34;url\u0026#34;: \u0026#34;git+https://github.com/AswinBlue/RankServer.git\u0026#34;\r},\r\u0026#34;keywords\u0026#34;: [],\r\u0026#34;author\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;,\r\u0026#34;bugs\u0026#34;: {\r\u0026#34;url\u0026#34;: \u0026#34;https://github.com/AswinBlue/RankServer/issues\u0026#34;\r},\r\u0026#34;homepage\u0026#34;: \u0026#34;https://github.com/AswinBlue/RankServer#readme\u0026#34;,\r\u0026#34;devDependencies\u0026#34;: {\r\u0026#34;autoprefixer\u0026#34;: \u0026#34;^10.4.7\u0026#34;,\r\u0026#34;postcss\u0026#34;: \u0026#34;^8.4.14\u0026#34;,\r\u0026#34;postcss-cli\u0026#34;: \u0026#34;^9.1.0\u0026#34;,\r\u0026#34;tailwindcss\u0026#34;: \u0026#34;^3.0.24\u0026#34;\r}\r} 모듈 사용 var express = require('express');\nvar session = require('express-session');\nvar bodyParser = require('body-parser');\nvar app = express();\nstatic 설정 app.use('/static', express.static(__dirname + '/static'));\n\u0026lsquo;/static\u0026rsquo; 이라는 경로로 \u0026lsquo;현재경로/static\u0026rsquo; 폴더를 연결시킴, 즉 \u0026lsquo;/static/file\u0026rsquo; 을 호출하면 \u0026lsquo;현재경로/static/file\u0026rsquo; 이 호출됨 session 설정 app.use(session({ -\u0026gt; session 사용 설정\nsecret:\u0026quot;SECRET_CODE\u0026quot;, -\u0026gt; 세션을 암호화 할 시드 설정\nresave:false,\nsaveUninitialized:true\n}));\nbody parser app.use(bodyParser.urlencoded({extended: false}));\nhtml의 body의 내용을 express의 js파일에서 불러와 사용할 수 있도록 하는 모듈 routing r_edit = require('./route/edit.js'); -\u0026gt; \u0026lsquo;/edit\u0026rsquo; 경로로 요청이 오면 \u0026lsquo;./route/edit.js\u0026rsquo; 파일로 연결, 라우팅 처리함\napp.use('/edit', r_edit);\nr_login = require('./route/login.js');\napp.use('/login', r_login);\nr_default = require('./route/default.js');\napp.use('/', r_default);\nejs app.set('views', './views'); -\u0026gt; \u0026lsquo;./view\u0026rsquo; 경로를 view로 사용, view 폴더 안에는 html파일들을 넣으면 됨\napp.set('view engine', 'html'); -\u0026gt; view 를 html로 구성함\napp.engine('.html', require('ejs').renderFile);\nServer var server = app.listen(80, function() { -\u0026gt; 80번 포트로 서버 오픈\nvar host = server.address().address -\u0026gt; 호스팅한 서버의 주소\nvar port = server.address().port -\u0026gt; 호스팅한 서버의 포트\nconsole.log(\u0026quot;App listening at http://%s:%s\u0026quot;, host, port) -\u0026gt; 로그\n});\nedit.js main 파일에서 라우팅을 위해 r_edit 변수에 연결시켜 사용하는 파일, ./route 폴더에 정리되어 있다. var express = require('express'); -\u0026gt; express 모듈 사용\nvar router = express.Router(); -\u0026gt; express의 routing 모듈 사용\n함수 사용 function stringToInt(x, base) { -\u0026gt; js 파일 안에서도 함수 정의, 사용 가능\nconst parsed = parseInt(x, base); -\u0026gt; string을 int로 변환\nif (isNaN(parsed)) { return 0; } -\u0026gt; string이 \u0026rsquo;\u0026rsquo; 인 경우, NAN을 반환하는데, NAN을 0으로 치환\nreturn parsed; -\u0026gt; 치환한 결과를 반환\n}\nrouting 설정 router.post('/:category/:product', function(req, res, next) {\npost 명령으로 / \u0026hellip; / \u0026hellip; 주소로 명령이 내려올 경우 function을 수행한다. main.js에서 r_edit을 \u0026lsquo;SERVER_ADDRESS/edit\u0026rsquo; 주소로 왔을 때 실행하도록 매핑해 놓았으므로, \u0026lsquo;SERVER_ADDRESS/edit/AAA/BBB\u0026rsquo; 주소로 명령이 내려오면 해당 함수가 동작한다. AAA 자리에 들어가는 값은 req.params.category 로 참조 가능하며, BBB는 req.params.product로 참조 가능하다. router.get('/:TLV', function(req, res, next) { -\u0026gt; get 명령은 router.get으로 설정 가능하다.\nmodule.exports = router; -\u0026gt; 마지막에 router를 exports 해야 적용이 된다.\nsession 설정 if (req.session.user) {\nmain.js에서 session을 사용하였으므로 req.session으로 session에 담긴 변수들을 참조 가능하다. req.session.user 값이 있으면 아래 내용을 수행한다는 코드이다. 값을 집어넣을 때에도 req.session.val = 1 과 같이 사용 가능하다. DB 사용 var mysql = require('mysql'); -\u0026gt; mysql 모듈을 사용한다.\nvar db_config = require('../config/db_config.json'); -\u0026gt; config 폴더 안에 db 접속에 필요한 내용을 저장해 놓았다. js 파일과 해당 내용을 분리하여 보안을 강화시킬 수 있다. db_config.json파일은 json 데이터를 담고 있다.\nvar connection = mysql.createConnection({ -\u0026gt; mysql 연결 설정\nhost : db_config.host, -\u0026gt; db_config_json 파일의 key를 참조하여 value를 대입한다.\nuser : db_config.user,\npassword : db_config.password,\ndatabase : db_config.database -\u0026gt; 사용할 DB 이름\nconnection.connect(); -\u0026gt; 연결을 수행한다.\n});\nconnection.query('UPDATE mytable SET name = ?, description = ?, price = ? where number = ?',[inputs.name, inputs.description, inputs.price, req.params.category], function (error, results, fields) { -\u0026gt; 연결된 DB에 query를 날린다. error는 오류정보, results는 DB 결과(row)를 array형태로 반환한다.\nquery 안에 query를 넣으면 오류가 난다. 완료 후 다음 query를 진행하도록 하자. console.log(this.sql); -\u0026gt; 함수 안에서 this.sql을 호출하면 query 내용을 참조할 수 있다.\nif (error) { -\u0026gt; 에러가 발생한 경우\nconsole.log(error);\nres.status(500).json({\u0026quot;Error\u0026quot;: \u0026quot;DB Error\u0026quot;}); -\u0026gt; 결과 response에 status 500을 주고, json 메시지를 함께 던진다.(화면에는 Json 메시지가 출력 됨)\n}\n});\nconnection.end();-\u0026gt; DB 사용을 끝내고 연결을 해제한다.\nconnection.query(\u0026quot;SELECT * FROM user WHERE User=? AND authentication_string=PASSWORD(?)\u0026quot;, [id, pswd], function (error, results, fields) {\nPASSWORD() 함수는 mysql의 user DB에서 사용자의 비밀번호를 인코딩하여 authentication_string 컬럼에 해당하는 값으로 만드는 함수이다. 비밀번호를 넣으면 authentication_string값을 반환한다. html 페이지 연결 routing 함수에서 받은 요청에 대해 redirect를 할 수도 있고, render로 파일을 열 수도 있다. res.redirect('/edit/' + req.params.TLV); -\u0026gt; 설정한 주소로 페이지를 리다이렉트 한다.\nres.render('login.html', {url: target}); -\u0026gt; url이란 키로 target 이라는 변수에 담긴 data를 login.html에 전달한다. html 파일에서는 url 이란 변수로 target값을 사용 가능하다.\nhtml 페이지 연동 html 페이지에서 form에 넣어서 보낸 내용은 bodyParser 모듈로 파싱하면 \u0026lsquo;req.body.변수이름\u0026rsquo; 으로 참조 가능하다. var inputs = { -\u0026gt; 내용을 받아 json 형태로 저장\n\u0026quot;relation\u0026quot;: req.body.relation, -\u0026gt; html파일의 form 태그의 input 태그중 name=\u0026ldquo;relation\u0026quot;인 태그의 value 값을 참조\n\u0026quot;number\u0026quot;: req.body.name}\nindex.html ejs모듈을 사용하여 설정한 대로 view 폴더 내에 생성한다. static 설정을 마쳤기 때문에 js 파일이나 css 파일들은 미리 설정해둔 \u0026lsquo;/static\u0026rsquo; 폴더 내에서 참조 가능하다. \u0026lt;script type=\u0026quot;text/javascript\u0026quot; src=\u0026quot;/static/edit_func.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; -\u0026gt; static 파일 호출 방법\nhtml 안에서 nodejs 문법을 사용하려면 \u0026lt;% %\u0026gt; 안에서 사용하면 된다. 변수 값을 바로 반환하려면 \u0026lt;%= %\u0026gt; 를 사용한다. \u0026lt;% var ptr = 10 %\u0026gt; -\u0026gt; 변수 ptr 선언\n\u0026lt;% dataList.forEach(function(item, index) { %\u0026gt;-\u0026gt; dataList의 항목들에 대해 수행, dataList는 routing function(route/index.js 안의 routing 함수)에서 res.render('index.html', {dataList: data}); 로 전해준 데이터이다.\n\u0026lt;% if (dataList[ptr].number != item.number) { %\u0026gt; -\u0026gt; if 함수 사용 가능, if문이 false라면 아래 내용은 출력되지 않음\n\u0026lt;tr id=\u0026quot;lineTr\u0026quot;\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;a href=\u0026quot;edit/\u0026lt;%=item.number%\u0026gt;\u0026quot;\u0026gt;\u0026lt;%= item.number %\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.name %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.description %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.superSet %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;% ptr = index %\u0026gt;\n\u0026lt;% } else { %\u0026gt;\n\u0026lt;tr\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;% } %\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.relation %\u0026gt;\u0026lt;/td\u0026gt; -\u0026gt; item.relation의 값을 반환, 즉 해당 값의 내용이 안에 출력된다.\n\u0026lt;td\u0026gt;\u0026lt;%= item.etc %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.bit %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.byte %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.value %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.meaning %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.history %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;/tr\u0026gt;\n\u0026lt;% }); %\u0026gt;\n","permalink":"https://aswinblue.github.io/post/webserver/nodejs/","summary":"Node.js 기본 명령 npm init : 패키지 생성 npm install : 라이브러리 설치 -P : package.json에 저장, 기본옵션 -O : optionalDependencies에 저장 -D, --no-save : 기록없이 다운로드 -g : 글로벌 설치, 모든 프로젝트에 적용 MODULE_NAME@VERSION : 버전 설정, latest는 가장 최근 버전을 의미 node main.js : 실행(main.js) npx \u0026lt;package_name\u0026gt; : 설치하지 않고 일회만 실행 node main.js : 패키지 실행 (main.js파일) npm audit : 의존성 문제가 발생했을 때, npm audit fix : 의존성 문제를 자동으로 해결하는 명령어, 일부 해결을 할 수는 있지만 package.","title":"Nodejs"},{"content":"mysql 명령어 문법 참조 : http://tcpschool.com/mysql/mysql_basic_syntax\n명령어에서 대소문자는 상관없다. mysql에서 주석은 \u0026lsquo;#\u0026lsquo;을 사용한다. 실행 및 로그인 mysql mysql 실행, 기본으로 설정된 user로 로그인됨 mysql -u 아이디 -p -u: 특정 아이디로 로그인 -p: 로그인시 비밀번호 입력하도록 데이터베이스 관리 DB 생성 UTF8 로 문자열 저장하기 CREATE DATABASE 데이터베이스_이름 default CHARACTER SET UTF8 DB 목록확인 show databases DB 선택 use DB_NAME 종료 EXIT 로그인 \u0026amp; 데이터베이스 선택 $ mysql -p DB_NAME -u USER_NAME 사용자 이름과 USER_NAME으로 DB_NAME 데이터베이스 실행 USER_NAME이 비어있으면 현재 로그인한 계정과 동일한 이름으로 로그인 시도 -u DB_NAME 옵션은 로그인 후 $use DB_NAME 과 같은 효과 테이블 생성 및 관리 TABLE_NAME 테이블의 스키마 확인 desc TABLE_NAME\nCREATE : 테이블 생성\nCREATE TABLE 테이블이름 (\rid INT NOT NULL AUTO_INCREMENT,\r항목1 VARCHAR(255) NOT NULL DEFAULT \u0026#39;FOO\u0026#39;,\r항목2 DATE NOT NULL,\r항목3 DECIMAL(10 , 2 ) NULL,\rPRIMARY KEY (id)\r) ENGINE-; NOT NULL: 필수항목 AUTO_INCREMENT: 수동으로 설정 가능하지만, 따로 설정하지 않으면 테이블 내 해당 컬럼에서 가장 큰 값에 1을 증가하여 자동으로 설정됨. VARCHAR(#): 캐릭터형 #bit DEFAULT : 기본값, 따로 설정안할시 기본값은 NULL이 됨. ENGINE: 데이터 저장 구조 MyISAM row level locking이 아닌 table level locking을 사용하기에, 한 테이블에 많은 접근이 이루어지면 속도가 느려짐 select count(*) from TABLE 속도가 빠름 InnoDB 풀 텍스트 인덱스를 지원하지 않고 속도가 약간 느림 트랜잭션을 지원함 참조 DESC: 테이블 구조 확인 DESC 테이블 DESCRIBE 테이블\nSELECT : 테이블 검색 SELECT 필드 [,필드2 ...] FROM 테이블 [WHERE 조건] [ORDER BY 필드]\n필드를 \u0026lsquo;,\u0026lsquo;로 다중 선택 WHERE 문으로 특정 조건에 해당하는 레코드만 추출 LIKE : 뒤에 와일드 카드 사용 _ : 와일드카드로, \u0026lsquo;한 자리의 어떤 문자\u0026rsquo;를 의미한다. % : 와일드카드로, 정규식의 *과 같은 의미이다. NOT : 부정의 의미, !과 동일 \u0026lt;\u0026gt; : !=와 같은 의미 ORDER BY 문으로 검색 결과를 필드에 맞게 정렬 DELETE : 데이터 삭제 DELETE FROM 테이블 [WHERE 조건]\n조건을 생략하면 테이블의 모든 데이터 삭제 ALTER: 테이블 변경 참조 컬럼 추가 ALTER TABLE 테이블이름 ADD COLUMN 컬럼이름 데이터형 컬럼 타입 변경 ALTER TABLE 테이블이름 MODIFY COLUMN 컬럼이름 데이터형 컬럼 이름 변경 ALTER TABLE 테이블이름 CHANGE COLUMN 기존이름 새이름 데이터형 컬럼 삭제 ALTER TABLE 테이블이름 DROP COLUMN 컬럼이름 Primary Key 설정 ALTER TABLE 테이블이름 ADD PRIMARY KEY (설정할컬럼1, 설정할컬럼2, ...) Primary key 삭제 ALTER TABLE 테이블이름 DROP PRIMARY KEY 테이블명 변경 ALTER TABLE 테이블이름 RENAME 새테이블이름 DB구조 변경 ALTER TABLE 테이블 engine=InnoDB; DROP : 테이블 삭제 DROP DATABASE 데이터베이스 DROP TABLE 테이블\nINSERT : 행 추가\n원하는 필드만 설정, 설정 안한부분은 default값이 들어감 INSERT INTO 테이블(필드1, 필드2, ... ) VALUES (데이터1, 데이터2, ... ) 모든 필드를 설정할땐 컬럼 이름을 생략 가능 INSERT INTO 테이블 VALUES (데이터1, 데이터2, ... ) JOIN : 테이블 융합 내부Join\nSELECT 테이블1.*, 테이블2.* FROM 테이블1, 테이블2 WHERE 조건 SELECT 테이블1.*, 테이블2.* FROM 테이블1 INNER JOIN 테이블2 ON 조건 외부Join\nLEFT Join SELECT * FROM 테이블1 LEFT JOIN 테이블2 ON 조건 조건이 맞지 않으면 테이블2의 필드 값이 모두 null 상태로 표시된다. RIGHT Join SELECT * FROM 테이블1 LEFT JOIN 테이블2 ON 조건 조건이 맞지 않으면 테이블1의 필드값이 모두 null 상태로 표시된다. 유저 관리 GRANT : 데이터베이스에 권한 부여 GRANT ALL PRIVILEGES ON my_db.* TO new_user@localhost IDENTIFIED BY 'pswd'; ALL PRIVILEGES : 모든 권한 my_db.* : my_db의 모든 테이블 new_user : 사용권한을 받을 유저(없을시 자동생성), @localhost : 로컬환경에서만 접속 가능 IDENTIFIED BY 'pswd' : new_user의 비밀번호를 pswd로 설정 flush privileges 권한 즉시 적용 기타 명령어 현재 사용자 정보 확인 select user()\n현재 DB 정보 확인 select databases()\nCSV파일 DB에 적용 LOAD DATA LOCAL INFILE 'FILE_NAME' INTO TABLE TABLE_NAME FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\u0026quot;' LINES TERMINATED BY '\\n'; - FILE_NAME 파일을 TABLE_NAME 테이블에 넣는다. 필드는 \u0026lsquo;,\u0026lsquo;로 구분되어 있고, 줄바꿈은 \u0026lsquo;\\n\u0026rsquo;로 구분되어 있고, \u0026lsquo;\u0026quot;\u0026lsquo;로 싸인 내용은 한 덩어리로 인식한다.\n경고문 확인 SHOW WARNINGS\\G\n데이터 타입 문자형 데이터타입 데이터 타입 설명 CHAR(n) 고정 길이 데이터 타입(최대 255byte)- 지정된 길이보다 짦은 데이터 입력될 시 나머지 공간 공백으로 채워진다. VARCHAR(n) 가변 길이 데이터 타입(최대 65535byte)- 지정된 길이보다 짦은 데이터 입력될 시 나머지 공간은 채우지 않는다. TINYTEXT(n) 문자열 데이터 타입(최대 255byte) TEXT(n) 문자열 데이터 타입(최대 65535byte) MEDIUMTEXT(n) 문자열 데이터 타입(최대 16777215byte) LONGTEXT(n) 문자열 데이터 타입(최대 4294967295byte) 숫자형 데이터 타입 데이터 타입 설명 TINYINT(n) 정수형 데이터 타입(1byte) -128 ~ +127 또는 0 ~ 255수 표현 가능하다. SMALLINT(n) 정수형 데이터 타입(2byte) -32768 ~ 32767 또는 0 ~ 65536수 표현 가능하다. MEDIUMINT(n) 정수형 데이터 타입(3byte) -8388608 ~ +8388607 또는 0 ~ 16777215수 표현 가능하다. INT(n) 정수형 데이터 타입(4byte) -2147483648 ~ +2147483647 또는 0 ~ 4294967295수 표현 가능하다. BIGINT(n) 정수형 데이터 타입(8byte) - 무제한 수 표현 가능하다. FLOAT(길이,소수) 부동 소수형 데이터 타입(4byte) -고정 소수점을 사용 형태이다. DECIMAL(길이,소수) 고정 소수형 데이터 타입고정(길이+1byte) -소수점을 사용 형태이다. DOUBLE(길이,소수) 부동 소수형 데이터 타입(8byte) -DOUBLE을 문자열로 저장한다. 날짜형 데이터 타입 데이터 타입 설명 DATE 날짜(년도, 월, 일) 형태의 기간 표현 데이터 타입(3byte) TIME 시간(시, 분, 초) 형태의 기간 표현 데이터 타입(3byte) DATETIME 날짜와 시간 형태의 기간 표현 데이터 타입(8byte) TIMESTAMP 날짜와 시간 형태의 기간 표현 데이터 타입(4byte) -시스템 변경 시 자동으로 그 날짜와 시간이 저장된다. YEAR 년도 표현 데이터 타입(1byte) 이진 데이터 타입 데이터 타입 설명 BINARY(n) \u0026amp; BYTE(n) CHAR의 형태의 이진 데이터 타입 (최대 255byte) VARBINARY(n) VARCHAR의 형태의 이진 데이터 타입 (최대 65535byte) TINYBLOB(n) 이진 데이터 타입 (최대 255byte) BLOB(n) 이진 데이터 타입 (최대 65535byte) MEDIUMBLOB(n) 이진 데이터 타입 (최대 16777215byte) LONGBLOB(n) 이진 데이터 타입 (최대 4294967295byte) C++연동 SDK mysql cpp connector 라 불리는, C++ 코드로 mysql을 사용할 수 있는 SDK가 제공된다. mysql과 mysqlx가 있는데, 전자는 RDB, 후자는 NoSQL이다. 표준 docmument https://dev.mysql.com/doc/connector-cpp/8.0/en/connector-cpp-installation-source-distribution.html guthub https://github.com/mysql/mysql-connector-cpp 참조 데이터베이스 정규화 1NF, 2NF, 3NF, BCNF :: Deep Play\n[MySQL] csv 파일을 직접 MySQL 테이블로 Import 하는 방법 (대용량 파일 import 팁) 주경야근\nImport CSV File Into MySQL Table\nDB - 데이터 타입/MYSQL\n[MySQL] Warnings 발생 했을 때 경고 내용 보기 - Blog Goooood.net\nHow to import CSV into mysql if values contains comma - Stack Overflow\n[SQL] 테이블 합치기 (JOIN / UNION) : 네이버 블로그\nMySQL 계정 생성 관리 및 권한설정 :: 비실이의 개발공간\n[MySQL] ERROR 1044 (42000.. : 네이버블로그\nphp - How can I make a key pair primary? - Stack Overflow\nMySQL 계정 변경 및 간단한 사용법 : 네이버 블로그\nMySQL 소개 및 기본 사용법 - 생활코딩\n(MySQL) 1장 시작하기. (DB 생성, 테이블 생성, SELECT) - 미래학자\n","permalink":"https://aswinblue.github.io/post/database/mysql/","summary":"mysql 명령어 문법 참조 : http://tcpschool.com/mysql/mysql_basic_syntax\n명령어에서 대소문자는 상관없다. mysql에서 주석은 \u0026lsquo;#\u0026lsquo;을 사용한다. 실행 및 로그인 mysql mysql 실행, 기본으로 설정된 user로 로그인됨 mysql -u 아이디 -p -u: 특정 아이디로 로그인 -p: 로그인시 비밀번호 입력하도록 데이터베이스 관리 DB 생성 UTF8 로 문자열 저장하기 CREATE DATABASE 데이터베이스_이름 default CHARACTER SET UTF8 DB 목록확인 show databases DB 선택 use DB_NAME 종료 EXIT 로그인 \u0026amp; 데이터베이스 선택 $ mysql -p DB_NAME -u USER_NAME 사용자 이름과 USER_NAME으로 DB_NAME 데이터베이스 실행 USER_NAME이 비어있으면 현재 로그인한 계정과 동일한 이름으로 로그인 시도 -u DB_NAME 옵션은 로그인 후 $use DB_NAME 과 같은 효과 테이블 생성 및 관리 TABLE_NAME 테이블의 스키마 확인 desc TABLE_NAME","title":"Mysql"},{"content":"python CGI CGI는 Common Gateway Interface의 약자다. web application을 만들 수 있는 언어는 ruby, java, php 등 다양하지만 모두 CGI 규약을 따라 web server와 통신한다. web server는 사용자의 요청을 받으면 약속된 이름의 데이터를 환경변수로 web application에 전달하여 서로 교류한다. apache에서 python을 이용해 web application을 만들어 web server와 통신해 보자. $ a2enmod CGI 명령으로 apache의 CGI를 켜 주고, sudo service apache2 restart 로 설정 적용 /var/log/apache2/error.log 안에 apache 실행시 발생한 에러 로그가 담겨있다. 웹 브라우저가 웹 서버에 요청할 때 웹 서버는 응답으로 웹 페이지의 데이터 타입(헤더)와 함께 웹 페이지를 전송한다. python CGI로는 print(\u0026quot;content-type:text/html; charset=UTF-8\\n\u0026quot;) 와 같이 헤더를 표기낸다. 헤더를 출력한 다음 부터는 body 부분이 출력된다. 특정 주소로 Redirection을 할 때에는 print(\u0026quot;location : index.py?id=title\u0026quot;)을 이용한다. ( \u0026lsquo;:\u0026rsquo; 이후 부터 \u0026lsquo;\u0026quot;\u0026rsquo; 까지는 원하는대로 작성) formatting string에서 특정 문자열을 다른 문자로 치환하는 기능 ex) '{} {}'.format('one','tow') ex) '{a} {b}'.format(a='hello', b='world') python 파일에서 문자열과 format 함수를 이용하여 동적 html을 구현 가능하다. CGI 모듈 import cgi 로 모듈을 로드해 사용한다. form = cgi.FieldStorage() form은 jQuery와 같은 역할을 한다. ex) pageId = form['id'].value : page의 id를 가져온다. HTML 연동 input 태그의 name 속성 : input 태그를 특정 이름으로 CGI에 전달함 ex)\n\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;title\u0026#34; placeholder=\u0026#34;title\u0026#34;\u0026gt; \u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;textarea rows=\u0026#34;4\u0026#34; name=\u0026#34;description\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; form 태그 : 특정 파일로 form 태그 안의 태그들을 전송\naction 속성 : form 안의 내용을 처리할 파일(목적지)를 설정한다. ex)\n\u0026lt;form action=\u0026#34;create.py\u0026#34;\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;title\u0026#34; placeholder=\u0026#34;title\u0026#34;\u0026gt; \u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;textarea rows=\u0026#34;4\u0026#34; name=\u0026#34;description\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;/form\u0026gt; url 쿼리 스트링 생성자 역할을 한다.\nurl 쿼리 스트링은 form 안의 input 태그의 name 속성들과 목적지(처리할 파일)를 포함하고 있다.\nget 방식은 쿼리 스트링을 url에 넣어서 사용하는 것이 맞다. 하지만 post 방식은 url이 아닌 다른 곳에 내용을 담아 전송하게 된다.\nmethod 속성은 get과 post 방식을 설정할 수 있다. ex)\n\u0026lt;form action=\u0026#34;create.py\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;title\u0026#34; placeholder=\u0026#34;title\u0026#34;\u0026gt; \u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;textarea rows=\u0026#34;4\u0026#34; name=\u0026#34;description\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;/form\u0026gt; action 속성으로 연결한 python 파일에서 form 안의 내용들을 사용하려면 cgi.FieldStorage()을 사용한다. ex)\nimport cgi\rform = cgi.FieldStorage()\rtitle = form[\u0026#34;title\u0026#34;].value\rdescription = form[\u0026#34;description\u0026#34;].value form 안의 내용 중 사용자에게 노출이필요 없는 input 태그는 type=\u0026ldquo;hidden\u0026rdquo; 속성을 주어 숨긴다. ex) \u0026lt;input type=\u0026quot;hidden\u0026quot; name=\u0026quot;pageId\u0026quot; value={}\u0026gt; 이벤트를 이용하여 form 안의 내용들을 특정 python 파일로 전송시키면 python 파일에서 내용을 처리하고 다른 html로 redirection 시키는 방식으로 웹 구성이 가능하다.\ncross site scripting (xss) 웹 페이지의 script란을 임의로 작성하여 의도되지 않은 동작을 하도록 하는 행위\n컴퓨터가 html 파일을 해석할 때, \u0026lt;script\u0026gt;를 만나면 출력 대상이 아닌, javascript로 처리해야 할 태그로 인식한다. xml 문법에 사용되는 특수문자를 대체하여 이를 막을 수 있다.\n'\u0026lt;' : \u0026amp;lt; '\u0026gt;' : \u0026amp;gt; ex) ''.replace('\u0026lt;','\u0026amp;lt;') \u0026ldquo;python html sanitizer\u0026rdquo; 로 검색하면 관련 패키지 검색이 가능하다.\n정리 python package Index (PyPI): python 패키지들의 목록이 저장되어 있는 곳, 필요한 패키지를 활용하자. CGI는 느려서 최근에는 잘 쓰이지 않고, FastCGI, 파이썬 전용 WSGI 등이 쓰인다. web framework : 웹에서 사용되는 공통적 작업들만 잘 추려서 만든 APIdjango, flask 가 이에 해당. Database 연동 Crawling: 웹페이지를 다운로드, 분석이 필요 (urllib, beautiful Soup 패키지 활용 가능) github의 trending 탭을 보면 현재 가장 인기 있는 패키지를 볼 수 있다. ","permalink":"https://aswinblue.github.io/post/webapplication/pythoncgi/","summary":"python CGI CGI는 Common Gateway Interface의 약자다. web application을 만들 수 있는 언어는 ruby, java, php 등 다양하지만 모두 CGI 규약을 따라 web server와 통신한다. web server는 사용자의 요청을 받으면 약속된 이름의 데이터를 환경변수로 web application에 전달하여 서로 교류한다. apache에서 python을 이용해 web application을 만들어 web server와 통신해 보자. $ a2enmod CGI 명령으로 apache의 CGI를 켜 주고, sudo service apache2 restart 로 설정 적용 /var/log/apache2/error.log 안에 apache 실행시 발생한 에러 로그가 담겨있다.","title":"PythonCGI"},{"content":"JavaScript 기본적으로 HTML 위에서 돌아가는 코드 body 태그 안에 태그를 넣고 안에 작성\ndocument를 호출하고, .으로 함수를 호출한다.\nquerySelector(\u0026rsquo;\u0026rsquo;)로 원하는 element 선택 가능, \u0026lsquo;\u0026lsquo;안의 내용은 css 선택자 문법과 같음\nquerySelectorAll(\u0026rsquo;\u0026rsquo;)로 원하는 속성의 element들을 nodeList(배열과 유사)형태로 선택 가능\nex ) document.querySelector('body')\nex ) document.querySelector('#new')\nex ) document.write(\u0026quot;hello world\u0026quot;)\n태그 안에 javaScript를 사용하는 속성값으로 사용\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;hello\u0026quot; onclick=\u0026quot;alert('hello')\u0026quot;\u0026gt;\n특정 태그 안에서 자기자신을 호출할 때에는 querySelector를 호출하지 않고 this를 사용하면 된다.\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; id=\u0026quot;hello\u0026quot; onclick=\u0026quot;document.querySelector('#hello').style.color='black';\u0026quot;\u0026gt;\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; id=\u0026quot;hello\u0026quot; onclick=\u0026quot;this.style.color='black';\u0026quot;\u0026gt;\nvar 로 변수를 선언 가능하다. (var 이 없어도 된다)\n별도의 파일로 분리한 후 파일의 링크를 지정한다.\nex ) \u0026lt;script src=\u0026quot;script.js\u0026quot;\u0026gt; \u0026lt;/script\u0026gt;\n연산자 = : 대입 연산자\n== : 비교 연산자, 좌항과 우항이 같으면 true\n=== : 비교 연산자, 좌항과 우항의 type 까지 비교\nex ) null === undefined : false\nex ) null == undefined : true\nex ) 123 == \u0026quot;123\u0026quot; : true\nex ) 123 === \u0026quot;123\u0026quot; : false\n+ : 덧셈 연산자, 문자열 병합에도 사용 가능\n배열 var NAME = [] 형태로 선언 .length : 배열의 길이를 반환하는 메소드 함수 선언 function FUNCTION_NAME () {} 형태로 함수 선언, ()안에는 인자가, {}안에는 함수 body가 들어간다. 인자로 self를 넣으면 python의 함수가 호출된 객체를 지칭하도록 사용할 수 있다. return 예약어를 통해 함수 종료시 값을 반환 가능(return 필수 아님) 동일한 이름의 함수가 다시 정의되면 이전의 함수는 삭제된다. 객체 var NAME = {}; 형태로 선언 가능\nex ) var coworker = {\u0026quot;designer\u0026quot; : \u0026quot;A\u0026quot;, \u0026quot;programmer\u0026quot; : \u0026quot;B\u0026quot;, \u0026quot;data scientist\u0026quot; : \u0026quot;C\u0026quot;};\n객체의 값은 . 이나 [] 로 참조 가능, property라고 칭한다.\nex ) coworker.designer\nex ) coworker[\u0026quot;data scientist\u0026quot;]\n객체의 필드들은 ,로 구분해야 한다. 함수도 {} 다음에 ,를 찍어준다.\nex ) var coworker = { \u0026quot;designer\u0026quot;:\u0026quot;A\u0026quot;, showAll:function( ){ }, \u0026quot;programmer\u0026quot;:\u0026quot;B\u0026quot; }\n이미 선언된 객체에 새로운 값 추가 혹은 기존 값 변경 가능\nex ) coworker.new = \u0026quot;D\u0026quot;\nex ) coworker.programmer = \u0026quot;E\u0026quot;\nfor ( .. in ~~ ) {} : 객체 내부 순회, ..는 내부 원소를 지칭할 변수를 선언하고, ~~에는 객체를 넣어준다.\nex ) for (var key : coworker) {}\n객체 내부에 함수도 선언 가능, method라고 칭한다.\nex ) var body = { setColor:function( ){ } }\nex ) coworker.setColor = function() {}\n객체 내부의 메소드에서 객체를 칭할 때에는 this를 사용\nex ) funciton () { for (var key in this) {} }\n데이터 타입 primitive Boolean Null Undefined Number 연산으로 계산 가능 String \u0026rsquo; \u0026rsquo; 나 \u0026quot; \u0026quot; 로 묶어서 사용 + 으로 concatenate 가능 Symbol Object 문자열 (String) .startWith(STRING) : 문자열이 STRING 으로 시작하면(prefix) true를 반환, 아니면 false를 반환 .slice(VALUE) : 시작점으로 부터 VALUE만큼의 글자를 제거 (문자열 자르기) .substring(VALUE) : 시작점으로 부터 VALUE만큼의 글자를 제거 () .replace(\u0026quot;/^AB\u0026quot;, '') : 정규식을 이용, AB로 시작하는 prefix 제거 (문자열 치환) Json .hasOwnProperty(KEY) : json 데이터에 KEY 라는 key가 존재한다면 true를 반환, 아니면 false를 반환 이벤트 onclick : 클릭 이벤트가 일어났을 때 onchange : 텍스트 에디터의 내용이 변경되었을 경우 onkeydown : 키를 눌렀을 때 메소드 alert(\u0026rsquo; \u0026lsquo;) : 브라우저의 경고창에 \u0026rsquo;\u0026rsquo; 안의 내용을 띄움 .length : 문자열의 길이를 반환, 배열의 길이를 반환 .indexOf(\u0026rsquo; \u0026lsquo;) : 문자열 중 \u0026lsquo;\u0026lsquo;에 속하는 문자 혹은 문자열이 시작되는 index를 반환, 0부터 카운팅 .trim() : 문자열의 공백을 제거 .value : element의 값을 뜻하는 변수 호출 함수 var repeat = setInterval(function, time) : time 만큼 delay를 주고 function을 반복한다. 독립 thread로 동작한다. clearInterval(repeat) : 인자로 받은 interval 반복함수를 정지한다. var result = setTimeout(function, time) : time만큼 delay후 function을 실행한다. 실행후 result에는 \u0026rsquo;true\u0026rsquo;가 저장된다. Jquery javascript상에서 document를 대체하여 사용성을 높인 라이브러리\n$() 로 시작한다.\nex ) $('a').css('color','red') : 모든 \u0026lsquo;a\u0026rsquo; 태그의 css 속성 중 color을 red로 변경\n참조 document \u0026lt; DOM (Document Object Model) \u0026lt; window ajax : 웹페이지를 변경하지 않고 내용 변경 cookie : 사용자에게 개별화된 서비스 제공 offline web application : 인터넷이 끊겨도 동작하는 어플리케이션 webRTC : 화상통신 웹 speech(로 시작하는 API) : 사용자 음성 처리 webGL : 3차원 그래픽 webVR : 가상현실 ","permalink":"https://aswinblue.github.io/post/webapplication/javascript/","summary":"JavaScript 기본적으로 HTML 위에서 돌아가는 코드 body 태그 안에 태그를 넣고 안에 작성\ndocument를 호출하고, .으로 함수를 호출한다.\nquerySelector(\u0026rsquo;\u0026rsquo;)로 원하는 element 선택 가능, \u0026lsquo;\u0026lsquo;안의 내용은 css 선택자 문법과 같음\nquerySelectorAll(\u0026rsquo;\u0026rsquo;)로 원하는 속성의 element들을 nodeList(배열과 유사)형태로 선택 가능\nex ) document.querySelector('body')\nex ) document.querySelector('#new')\nex ) document.write(\u0026quot;hello world\u0026quot;)\n태그 안에 javaScript를 사용하는 속성값으로 사용\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;hello\u0026quot; onclick=\u0026quot;alert('hello')\u0026quot;\u0026gt;\n특정 태그 안에서 자기자신을 호출할 때에는 querySelector를 호출하지 않고 this를 사용하면 된다.","title":"JavaScript"},{"content":"CSS 특정 개체에 효과를 부과한다. 이를 declaration 이라 칭한다. 중복의 제거 가능, 유지보수 수월, 가독성 증가 위에서 부터 아래로 읽어가며 효과 적용, 중복 불가능한 효과에 대해서는 이전 효과가 사라짐 tag 선택자 \u0026lt; calss 선택자 \u0026lt; id 선택자 로 우선 순위가 높다. html 문서 안에 \u0026lt;style\u0026gt; 태그 안에 작성 가능\nex ) \u0026lt;style\u0026gt; a { color:black; } \u0026lt;/style\u0026gt;\n태그의 종류별로 속성 설정 가능\n여기서 태그 a 는 선택자(selector)라고 한다.\n선택자는 ,로 구별하여 함께 사용 가능\nex ) \u0026lt;style\u0026gt; a, h1 { color:black; } \u0026lt;/style\u0026gt;\n특정 태그의 자식태그 중 하나의 속성을 지정하고 싶다면 띄워쓰기로 구분한다. ex ) 중괄호{} 안에 declaration을 작성한다.\n하나의 declaration은 ;로 끝나서 다음 declaration과 구분된다.\n특정 태그 안에 style 속성을 넣어 작성 가능\nex ) \u0026lt;a style=\u0026quot;color:black\u0026quot;\u0026gt; \u0026lt;/a\u0026gt;\n다른 파일로 만들어 사용 가능\n재사용이 가능해 가장 효율적인 방법\n웹페이지 안에 직접 css를 넣는 것이 트래픽적 관점에서는 더 효율적이지만, 재사용성과 캐싱 기법에 의해 본 기법이 더 효율적이다.\nex ) \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;style.css\u0026quot;\u0026gt; 특정 태그(element)를 지정해 효과 설정이 가능하다.\nex ) \u0026lt;style\u0026gt; a { color:black; } \u0026lt;/style\u0026gt;\n특정 class를 지정해 효과 설정이 가능하다. class를 지칭할 때에는 이름 앞에 . 을 찍는다. 태그 선택자 보다 우선 순위가 높다.\nex ) \u0026lt;style\u0026gt; .saw{color:gray;} \u0026lt;/style\u0026gt;\n특정 id를 지정해 효과 설정이 가능하다. id를 지정할 때에는 이름 앞에 # 을 찍는다. class보다 우선 순위가 높다.\nex ) \u0026lt;style\u0026gt; #active{color:red;} \u0026lt;/style\u0026gt;\n스타일 PROPERTY:PROPERTY_VALUE; 형태로 존재한다. color:red : 색깔 변경(빨강) text-decoration:none : 꾸미기 없음 text-decoration:underline : 밑줄 font-size:45px : 글자 크기 설정 text-align:center : 글자 정렬 설정(가운데 정렬) border-width:5px : 테두리 굵기 설정 border-color:red : 테두리 색상 설정 border-style:solid : 테두리 모양 설정(직선) border 스타일 및 일부 스타일은 축약해서 사용 가능하다.\nex) \u0026lt;style\u0026gt; a{ border: 5px red solid;} \u0026lt;/style\u0026gt;\nborder-bottom: 1px solid gray : 아래쪽 테두리에만 설정 적용 display:inline : 태그의 레벨 속성(inline element - block element)을 변경 display:none : 화면에 표시 안함 display:grid : grid 형태로 표시 grid-template-colums: 150px 1fr : 그리드 형태를 열로 하고, 첫 열은 150, 둘째 열은 남은 공간을 사용하도록 설정 padding:20px : 테두리와 내용 사이의 버퍼 설정 margin:10px : 테두리 바깥과 다른 element 사이의 버퍼 설정 width:100px : element 폭 설정 단위 px : 픽셀 fr : 남은 자유공간으로 그 크기는 ((현재 fr 수치 / \u0026lt;총 사용된 fr\u0026gt;) * 남은 공간) 으로 계산된다. 미디어 쿼리 반응형 웹(responsive web) 을 위한 내용\n@media() {} 와 같이 표현되며, () 안에는 조건문이 들어가고, {} 안에는 적용 할 내용이 들어간다.\nex ) \u0026lt;style\u0026gt; @media(min-width:800px) {div {display:none;}} \u0026lt;/style\u0026gt;\nhttp://caniuse.com : 특정 스타일을 사용했을 때 몇 %의 브라우저가 해당 스타일을 지원하는지 확인 가능한 사이트\n","permalink":"https://aswinblue.github.io/post/webapplication/css/","summary":"CSS 특정 개체에 효과를 부과한다. 이를 declaration 이라 칭한다. 중복의 제거 가능, 유지보수 수월, 가독성 증가 위에서 부터 아래로 읽어가며 효과 적용, 중복 불가능한 효과에 대해서는 이전 효과가 사라짐 tag 선택자 \u0026lt; calss 선택자 \u0026lt; id 선택자 로 우선 순위가 높다. html 문서 안에 \u0026lt;style\u0026gt; 태그 안에 작성 가능\nex ) \u0026lt;style\u0026gt; a { color:black; } \u0026lt;/style\u0026gt;\n태그의 종류별로 속성 설정 가능\n여기서 태그 a 는 선택자(selector)라고 한다.\n선택자는 ,로 구별하여 함께 사용 가능","title":"Css"},{"content":"HTML W3C에서 HTML 규칙을 규정, 웹 브라우저 제작사들이 이를 참조하여 브라우저를 만든다. 태그 element라고 칭하기도 한다. 부모 자식 관계가 존재 \u0026lt;TAG_NAME\u0026gt; 로 시작하고 \u0026lt;/TAG_NAME\u0026gt;로 끝냄 태그별로 검색 엔진에서 노출되는 중요도가 다르다. 태그의 종류에 따라 줄 전체를 사용하거나(block level element), 내용의 크기 만큼의 공간만 사용하는 태그(lnline element)들이 있다. html : body와 head를 통틀어 묶은 최 고위 태그 관용적으로 \u0026lt;!doctype html\u0026gt; 을 붙여 쓴다. body : 본문을 묶는 태그 head : 본문을 설명하는 태그 속성(attribute) \u0026lt;TAG_NAME ATTRIBUTE\u0026gt; 와 같은 형태로 태그 이름 뒤에 붙음 body 속성 strong : 굵은 글씨\nu : 밑줄\nh1 : 제목 1\nh2 : 제목 2\nh6 : 제목 6\np : 단락 설정\nbr : 줄바꿈\nimg : 이미지\n\u0026lt;img src=\u0026quot;\u0026quot;\u0026gt; : src에 경로 지정\nli : 리스트\nul태그를 부모로 가짐 ul : 리스트 그루핑을 위한 태그\nli 태그를 자식으로 가짐 unordered-list ol : 넘버링 되는 리스트를 위한 태그\nordered-list a : 링크\nAnchor의 약자 href 속겅 필요 (hypertext reference) target : 창을 여는 방법, \u0026ldquo;_blank\u0026rdquo; : 새창 title : 마우스 오버레이시 툴팁 표시 input :\ntype=\u0026ldquo;checkbox\u0026rdquo; : 체크박스 type=\u0026ldquo;button\u0026rdquo; : 버튼 onclick=\u0026quot;\u0026quot; : \u0026quot;\u0026quot; 사이에는 javascript가 들어간다. 버튼 클릭 시 동작할 내용 \u0026lt;input\u0026gt; 으로 끝난다. \u0026lt;input/\u0026gt; 이나 \u0026lt;input\u0026gt; \u0026lt;/input\u0026gt; 으로 사용하지 않는다. font :\ncss가 등장하기 이전에 문자의 스타일을 설정하게 하기 위함 어껀 정보도 없는 태그, 기자인만을 위함 class : 태그들을 특정 그룹으로 묶기 위함\n하나의 태그에 두 개 이상의 class 지정 가능 id : 특정 태그에 명칭을 붙이기 위함\nclass 보다 높은 우선순위 단 한 번만 사용하도록 권장, 중복하여 사용하지 않도록 한다. div : 아무 의미 없이 디자인의 용도로만 사용하는 태그, block element\nspan : div와 같지만 inline element\nform : 폼 데이터 전송을 위한 태그, 하위\naction : 데이터를 어디로 전송할지 나타내는 속성 method : 데이터를 어떻게 전송할지 나타내는 속성. post/get을 사용 가능하다. head title : 제목 meta : 현재는 사용되자 않음 style : CSS 코드 삽입부 link 참조\nrel 참조 preload : href값에 선언된 리소스를 페이지 로드전에 요청해서 받아오게 지정한다. as 속성과 함께 사용된다. 상세설명 예시: \u0026lt;link rel=\u0026quot;preload\u0026quot; href=\u0026quot;style.css\u0026quot; as=\u0026quot;style\u0026quot; /\u0026gt; ","permalink":"https://aswinblue.github.io/post/webapplication/html/","summary":"HTML W3C에서 HTML 규칙을 규정, 웹 브라우저 제작사들이 이를 참조하여 브라우저를 만든다. 태그 element라고 칭하기도 한다. 부모 자식 관계가 존재 \u0026lt;TAG_NAME\u0026gt; 로 시작하고 \u0026lt;/TAG_NAME\u0026gt;로 끝냄 태그별로 검색 엔진에서 노출되는 중요도가 다르다. 태그의 종류에 따라 줄 전체를 사용하거나(block level element), 내용의 크기 만큼의 공간만 사용하는 태그(lnline element)들이 있다. html : body와 head를 통틀어 묶은 최 고위 태그 관용적으로 \u0026lt;!doctype html\u0026gt; 을 붙여 쓴다. body : 본문을 묶는 태그 head : 본문을 설명하는 태그 속성(attribute) \u0026lt;TAG_NAME ATTRIBUTE\u0026gt; 와 같은 형태로 태그 이름 뒤에 붙음 body 속성 strong : 굵은 글씨","title":"Html"},{"content":"Linux 서버에 개발 환경을 세팅하는데 뭔가 제대로 되지 않아 이미 환경설정을 해 본 다른 사람에게 원격으로 도움을 요청했다.\n하지만 그 사람이 리눅스에 익숙하지 않았는지, 우리 서버를 잘못 만져 apt가 먹통이 되는 현상이 발생했다.\n본 해프닝에 대해 서술하자면 아래와 같다.\n원인 /bin 디렉터리 안의 python bin파일을 강제로 삭제한 것이 원인으로 추정된다.\n환경 설정을 하는데 제대로 되지 않으니 sudo apt-get upgrade 명령도 남용하기도 했다.\n현상 apt를 이용해 install, remove를 하려 하면 py3compile, py3clean 등에서 오류가 발생하였다.\napt 명령을 수행하면\n/usr/bin/dpkg return an errorcode(1) 오류가 발생하며 정상 동작하지 않는다.\ninstall -f 명령도 먹히지 않았다.\n해결 python bin파일이 없어졌고, python이 없다는 내용이 떴으므로 python을 다시 설치해 봤다.\napt가 제대로 동작하지 않았으므로 git에서 python을 받아 빌드하여 설치했다.\ndpkg return an errorcode(1) 을 검색해보니 dpkg에 문제가 있을 수 있다는 내용이 많았다.\ndpkg를 재설정 해보라는 글들이 많아 내용대로 따라가 보았다.\n/var/lib/dpkg/info 에는 설치된 프로그램의 목록들이 저장되어 있는듯 하다.\napt 명령을 수행할 때 오류가 발생하는 프로그램들을 찾아 rm 명령으로 해당 프로그램의 내용을 삭제한다.\n삭제 후 dpkg --configure -a 명령을 사용하여 dpkg를 재설정 해준다.\n그 후 apt 명령을 사용하여 설치, 삭제를 해 보니 dpkg를 리셋한 내용들은 오류에 뜨지 않았다.\n오류가 나지 않을 때 까지 dpkg를 계속 재설정 해주니 정상 동작하게 되었다.\n결론 /bin 안의 파일들을 강제로 삭제하면 apt가 충돌이 일어나 동작하지 않을 수 있으므로 주의한다.\n/var/lib/dpkg/info 에서 설치된 패키지의 내용들을 확인 가능하다.\ndpkg --configure -a 명령으로 dpkg를 리셋할 수 있다.\n","permalink":"https://aswinblue.github.io/post/linux/linux_apt/","summary":"Linux 서버에 개발 환경을 세팅하는데 뭔가 제대로 되지 않아 이미 환경설정을 해 본 다른 사람에게 원격으로 도움을 요청했다.\n하지만 그 사람이 리눅스에 익숙하지 않았는지, 우리 서버를 잘못 만져 apt가 먹통이 되는 현상이 발생했다.\n본 해프닝에 대해 서술하자면 아래와 같다.\n원인 /bin 디렉터리 안의 python bin파일을 강제로 삭제한 것이 원인으로 추정된다.\n환경 설정을 하는데 제대로 되지 않으니 sudo apt-get upgrade 명령도 남용하기도 했다.\n현상 apt를 이용해 install, remove를 하려 하면 py3compile, py3clean 등에서 오류가 발생하였다.","title":"Linux_apt"},{"content":"Hugo를 이용해 블로그 만들기 Git과 markdown을 이용하여 git을 블로그처럼 이용하는 사람들이 있다는 것을 알았다.\n게다가 UI를 보기 좋게 꾸며줄 수 있는 툴들도 찾았는데, 그 중 Hugo를 사용해 보았다.\nHugo는 Go 언어로 짜여져 있어 apt-get으로도 설치가 가능하고, 소스 코드를 받아 빌드하여 쓸 수도 있다.\n내 컴퓨터에는 Go가 이미 설치되 있던 터라 apt-get으로 hugo를 받아서 사용해 보았다.\n설치는 정상적으로 되었고, 처음에는 잘 동작하는 듯 했는데, theme을 적용하니 ERROR들이 뜨기 시작했다.\n인터넷 검색을 아무리 해 봐도 해결책이 보이지 않고, 해당 git에 issue를 날려보기도 했는데 응답이 없어서 혼자 이것저것 뒤져 보았다.\n알고보니 내 hugo의 버전이 너무 낮아서 발생한 현상이었고, 덩달아 Go의 버전도 낮다는 것을 알아냈다.\nGo언어는 apt-get 대신 인터넷에서 tar파일을 받아서 압축을 풀어 사용했고, Hugo는 소스코드를 받아 Go 언어로 빌드하여 사용하였다.\n(brew를 이용해 보라고도 해서 brew를 설치 해 보기도 했는데, 잘 동작 하지 않아서 그만뒀다.)\n버전을 최신으로 맞추고 나니 모두 정상동작, git에 올려놓은 issue를 뻘쭘하게 혼자 close했다.\n링크 hugo 환경설정 및 사용방법 가이드\n아래 주소의 글쓴이도 hugo로 블로그를 만들어 관리하고 있다. 이분의 글을 토대로 환경을 세팅했다.\nhttps://github.com/Integerous/Integerous.github.io\nHugo git 사이트\nHugo의 소스파일을 다운받을 수 있다.\nhttps://github.com/gohugoio/hugo\n내가 사용한 theme의 git 주소\n설명대로 theme을 다운받고, config파일을 수정해 주어야 최종적으로 적용이 된다.\nhttps://github.com/cntrump/hugo-notepadium\nGo 언어 설치 가이드\nhttps://golang.org/doc/install\nHugo 설치 가이드\nhttps://gohugo.io/getting-started/installing/\n환경 세팅 (window) 리눅스 환경세팅은 apt, yum을 이용하면 간단하게 수행 가능하여 생략한다.\nGo 언어를 설치한다. 설치파일로 받아서 설치하면 간단하다. 리눅스에 설치할 경우, apt를 사용하면 낮은 버전이 설치될 수 있으니 코드를 받아 설치하는걸 추천한다. Hugo를 설치한다. 압축파일 형태로 제공되며, 압축을 푼 후 path 설정만 해주면 된다. 리눅스의 경우 코드를 이용해 설치할 수 있다. git 레퍼지토리를 2개 생성한다. 한개는 글 작성용, 한개는 publish용이다. (이 경우, \u0026lt;GITHUB_ID\u0026gt;.github.io 이름으로 repository를 생성한다. 그렇지 않으면 정상동작하지 않는다.)\nex) github.com/AswinBlue/AswinBlue.github.io 작성용은 소스코드에 해당하며 publish용은 컴파일된 바이너리에 해당한다고 보면 된다. 로컬PC에서 Hugo 프로젝트를 생성한다. hugo new site \u0026lt;SITE\u0026gt; 명령으로 새로운 hugo 프로젝트를 생성한다. 생성한 프로젝트를 git과 연동시킨다. 프로젝트 root디렉터리에 (3)에서 만든 소스용 git을 연동시킨다. /public 디렉터리에 (3)에서 만든 publish용 git을 연동시킨다. git 폴더 안에 git을 연동하려면 git submodule add \u0026lt;URL\u0026gt;명령어를 이용한다. 테마를 선택한다. 인터넷에서 hugo 테마를 검색하여, 원하는 테마의 git repository를 /themes 경로에 clone 한다. 이후, 해당 테마에서 지원하는 config 파일을 root 경로에 복사한다. config 파일은 toml, yaml, json 형태로 작성이 가능하며, hugo에서는 toml -\u0026gt; yaml -\u0026gt; json 순서대로 config파일을 찾아 적용한다. (즉, config.toml파일이 있으면 config.yml파일은 적용되지 않음) 기본 탬플릿을 설정한다. /archtypes/default.md 파일을 수정하면, hugo new NEW_POST.md 를 이용해 새로운 파일을 생성할 때 사용되는 기본 md파일 탬플릿을 정의할 수 있다. 파일 생성시 .md 확장자가 붙여야 정상 동작함에 주의한다. Quick Start 프로젝트 생성 새로운 Hugo 사이트를 생성하는 명령어, 폴더 안에 Hugo 구조에 맞게 폴더 및 파일이 자동 생성된다.\nhugo new site \u0026lt;NAME\u0026gt; 생성된 폴더에서 새로운 post를 생성하는 명령어, content 폴더 안에 archtype에 맞게 내용을 적어 파일을 생성한다.\nhugo new \u0026lt;POST\u0026gt;.md\rex) hugo new post/hugo.md 테마에 맞는 형식으로 content 폴더 안의 내용을 이용해 public 폴더 안에 내용을 생성한다. : hugo -t \u0026lt;THEME\u0026gt;\nconfig파일에 따라 hugo --config config.yml 와 같이 명령어를 사용할 수도 있다.\nconfig파일에서 baseURL 을 페이지 주소로 설정해야 css 및 javascript가 정상 동작 한다. html에서 hugo문법으로 config파일에 선언된 baseURL을 가져오는 것은 {{ .Page.Site.BaseURL }} 와 같이 사용하면 된다. 본 페이지는 hugo-PaperMod 테마를 사용했다.\n문서 최상단에 +++로 둘러쌓인 부분은 설정 부분이다. draft=false로 설정을 해야 화면에 표시됨에 주의한다.\ntoml을 사용한다면 +++로 formatter를 구성 하고, yaml은 ---, json은 {} 을 사용한다. public 폴더에 생성한 내용을 push 하기 전 테스트 해 본다.\nhugo server [--theme \u0026lt;THEME_PATH\u0026gt;] 서버 실행 후 http://localhost:1313 경로에서 웹 브라우저로 내용을 확인할 수 있다.\n내용이 완벽하다면 public 폴더 안의 git을 push 하면 \u0026lt;GIT_ID\u0026gt;.github.io 주소에서 방금 본 내용을 볼 수 있다. ex : aswinblue.github.io\nGo와 Hugo의 설치만 잘 하면 사용 가이드는 인터넷에 잘 정리된 글들이 많다. 참조하면 활용에 문제는 없을 것이다.\nAdsense 추가 구글 애드센스를 휴고 Blog에 넣고싶다면, 아래와 같은 절차를 거치면 된다.\nthemes/원하는_테마/layouts/partials/ 디렉터리 안에 adsense.html 파일을 만들고, 애드센스에 필요한 script를 붙여넣은 후 저장한다. themes/원하는_테마/layouts/partials/ 디렉터리 안에 head.html 파일을 열고, {{- partial \u0026quot;adsense.html\u0026quot; . -}} 한줄을 추가하고 저장한다. hugo -t 원하는_테마 명령으로 다시 빌드하고, 서버에 push한다. sidebar 형태의 구문을 넣고싶다면, baseof.html 파일을 수정해야 한다. \u0026lt;div class=\u0026quot;grid-container\u0026quot;\u0026gt; 태그로 main을 감싸고, main과 sidebar을 동일한 level에 배치한다.\n# before\r\u0026lt;main class=\u0026#34;main\u0026#34;\u0026gt;\r{{- block \u0026#34;main\u0026#34; . }}{{ end }}\r\u0026lt;/main\u0026gt; # after\r\u0026lt;div class=\u0026#34;grid-container\u0026#34;\u0026gt;\r{{ partial \u0026#34;sidebar.html\u0026#34; . }}\r\u0026lt;main class=\u0026#34;main\u0026#34;\u0026gt;\r{{- block \u0026#34;main\u0026#34; . }}{{ end }}\r\u0026lt;/main\u0026gt;\r\u0026lt;/div\u0026gt; github page 자동화 github에서 제공하는 CI/CD 인 github actions 를 사용하면 push시 자동으로 배포를 할 수 있다.\ngithub actions -\u0026gt; Categories:Pages -\u0026gt; Hugo 선택 템플릿 파일로 HugoBlog/.github/workflows/hugo.yml 파일을 제공한다. 본인의 상황에 맞게 작성한 후 remote branch에 반영한다. # Sample workflow for building and deploying a Hugo site to GitHub Pages\rname: Deploy Hugo site to Pages\ron:\r# Runs on pushes targeting the default branch\rpush:\rbranches: [\u0026#34;master\u0026#34;]\r# Allows you to run this workflow manually from the Actions tab\rworkflow_dispatch:\r# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\rpermissions:\rcontents: read\rpages: write\rid-token: write\r# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\r# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\rconcurrency:\rgroup: \u0026#34;pages\u0026#34;\rcancel-in-progress: false\r# Default to bash\rdefaults:\rrun:\rshell: bash\rjobs:\r# Build job\rbuild:\rruns-on: ubuntu-latest\renv:\rHUGO_VERSION: 0.108.0\rsteps:\r- name: Install Hugo CLI\rrun: |\rwget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\\r\u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb\r- name: Install Dart Sass Embedded\rrun: sudo snap install dart-sass-embedded\r- name: Checkout\ruses: actions/checkout@v3\rwith:\rsubmodules: recursive\r- name: Setup Pages\rid: pages\ruses: actions/configure-pages@v3\r- name: Install Node.js dependencies\rrun: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34;\r- name: Build with Hugo\renv:\r# For maximum backward compatibility with Hugo modules\rHUGO_ENVIRONMENT: production\rHUGO_ENV: production\rrun: |\rhugo --minify --config config.yml\r- name: Upload artifact\ruses: actions/upload-pages-artifact@v1\rwith:\rpath: ./public\r# Deployment job\rdeploy:\renvironment:\rname: github-pages\rurl: ${{ steps.deployment.outputs.page_url }}\rruns-on: ubuntu-latest\rneeds: build\rsteps:\r- name: Deploy to GitHub Pages\rid: deployment\ruses: actions/deploy-pages@v2 문법 Hugo 문법 hugo는 html 안에 {{ }} 형태로 hugo용 구문을 넣을 수 있다. {{ }}안에 --, %%, \u0026lt;\u0026gt; 를 넣어 용도에 따라 다양한 변형이 있을 수 있다. {{- }}, {{ -}}, {{- -}} 를 사용하면 앞/뒤쪽의 줄바꿈 및 빈 여백을 모두 제거해 준다. 변수 선언 변수는 site, page 에 따라 다르게 선언 할 수 있다. config.yml 파일에 선언하면 site 단위로 선언되며, 전역 변수처럼 모든 page에서 참조 가능하다. .Params 은 page 변수를 참조하며, site.Params 은 site 변수를 참조하는 방식이다. page 변수는 hugo new 를 사용하여 만든 각 페이지(.md파일) 최상단에 작성된 메타데이터(+++ 혹은 \u0026mdash; 로 감싸진 구역의 데이터)를 의미한다. {{- $isHidden := Params.cover.hidden | default site.Params.cover.hiddenInSingle | default site.Params.cover.hidden }} : page 변수로 \u0026lsquo;isHidden\u0026rsquo; 를 선언하는 예시 조건문 {{- if (.Param \u0026quot;ShowToc\u0026quot;) }} : page변수에서 ShotToc가 있는지 체크 RelPermalink vs Permalink\nYOUR_CUSTOM_PATH.RelPermalink : baseurl을 / 로 처리한 링크 (/YOUR_CUSTOM_PATAH) YOUR_CUSTOM_PATH.Permalink : baseurl을 앞에 붙인 링크 (https://localhost:1313/YOUR_CUSTOM_PATAH) 파일 import\n페이지 내부에서 다른 파일을 import 해오려면 {{template 파일명}} 혹은 {{partial 파일명}} 을 사용하면 된다. 이때 인자로 dictionary 데이터를 전달 할 수 있다. {{ template 파일명 dict (\u0026quot;Pages\u0026quot; .Site.RegularPages )}} 와 같이 사용하면 호출된다. 이런 방식으로 subpage들을 recursive하게 참조할 수 있다. {{ define \u0026#34;sample\u0026#34; }}\r...\r{{- $subSections := where .Site.Sections \u0026#34;Parent\u0026#34; .Sections }}\r{{ template sample dict (\u0026#34;Sections\u0026#34; $subSections) }}\r...\r{{ end }} define\n{{- define 이름 -}} {{ end }} 을 세트로 사용하여 사이에 있는 모든 구문을 \u0026ldquo;이름\u0026rdquo; 으로 정의한다. template이나 partial을 통해 define 된 구문을 호출할 수 있다. : {{ tempalte 이름 }} 반복문\n{{ range $itr := LIST}} {{ end }} : LIST 안의 내용을 하나씩 itr 에 담아서 반복한다. 이때, range 문 안에서는 \u0026lsquo;.\u0026rsquo; 문자는 $itr 을 의미하게 되므로, 주의한다. 구조 Scope . 혹은 $. 으로 변수를 호출하면 context 에 선언된 변수를 호출하는 것이다. context는 page를 생성할 때 전달해 줄 수 있다. {{ template FILE_NAME CONTEXT_NAME CONTEXT_VALUE}} 와 같이 사용하면 해당 파일 안에서 .은 CONTEXT_VALUE를 의미하게 된다. 여러 데이터를 주고 싶다면 dict() 함수를 사용해서 dictionary 형태를 전달할 수도 있다. {{ template FILE_NAME dict(\u0026quot;v1\u0026quot; v1 \u0026quot;v2\u0026quot; v2)}} Site \u0026amp; Page \u0026amp; Section Site는 전체 프로젝트, Page는 내용물을 담고 있는 파일, Section은 폴더(디렉터리) 로 이해하면 편하다. 각각 변수 scope를 갖고 있어서 .Site.변수이름, .Page.변수이름, Section.변수이름 으로 변수를 참조 및 선언할 수 있다. 하지만, config파일에서 선언하지 않는 한, 다른 파일에서 선언한 변수는 같은 page라도 참조가 되지 않는다. (필요시 전달할 수 있는 방법은 있다) Site (https://gohugo.io/variables/site/) Page (https://gohugo.io/variables/page/) Section (https://gohugo.io/content-management/sections/) Section이 되기위한 조건으로는 1) content 폴더의 직속 디렉터리 이거나, 2) 안에 _index.md 파일을 지녀야 한다. _index.md 파일을 지닌 디렉터리는 중간 가지 역할을 하고, index.md 파일을 지닌 디렉터리는 leaf node 역할을 하며, index.md 파일과 동일한 디렉터리에 들어있는 파일들은 각각의 페이지가 생성되지 않는다. 오류 해결 배포 페이지 CSS 동작 오류 hugo server로 로컬에서 동작시키면 css가 정상적으로 나오지만, 배포한 github page에서 css가 제대로 동작하지 않는다면 stylesheet를 선언하는 부분(보통 theme/선택한_테마/layouts/partials/head.html에 있음) 에서 baseurl이 정상적으로 설정되었는지 확인한다. stylesheet는 href=\u0026quot;{{ $stylesheet.RelPermalink }}\u0026quot; 와 같이 정상적으로 설정했는지 확인한다. (url을 직접 string으로 입력하기보다 url을 세팅해주는 함수를 사용하는것을 권장) Failed to find a valid digest in the \u0026lsquo;integrity\u0026rsquo; attribute for resource hugo에서 제공하는 .Data.Integrity 기능을 사용하여 html tag에 integrity 속성을 부여했을 경우 발생한다. config파일에서 minify 설정을 해 놓으면, 파일의 불필요한 줄바꿈, 공백을 제거하는데, minify 하기 전 값을 sha256으로 인코딩 하여, 결과가 틀려지는 것이다. # minify 설정\rminify:\rdisableXML: true\rminifyOutput: true 위와 같은 설정이 config파일에 있다면, fingerprint를 사용하기 전에 minify를 먼저 수행하라. {{- $stylesheet := $stylesheet | minify | fingerprint \u0026quot;sha256\u0026quot;}}. fingerprint의 default값은 sha256이므로, sha256은 제거해도 무관 github page 자동화 오류 fatal: remote error: upload-pack: not our ref 7821df1a10579b4a62917f0f07d3a5c482e872f6 github actions/checkout@v3 에서 submodule의 특정 commit으로 checkout 이 안되는 현상이다. render of \u0026quot;page\u0026quot; failed: \u0026quot;C:\\HugoBlog\\themes\\hugo-PaperMod\\layouts\\_default\\baseof.html:5:8\u0026quot;: execute of template failed: template: _default/single.html:5:8: executing \u0026quot;_default/single.html\u0026quot; at \u0026lt;partial \u0026quot;head.html\u0026quot; .\u0026gt;: error calling partial: execute of template failed: template: partials/templates/opengraph.html:5:14: executing \u0026quot;partials/templates/opengraph.html\u0026quot; at \u0026lt;.Params.cover.image\u0026gt;: can't evaluate field image in type string 빌드 했을 때 위와같은 오류가 발생 한다면, golang과 hugo 버전 차이에 따라 페이지가 파싱이 제대로 되지 않는 경우이다. hugo 문법에 따라 페이지를 수정하거나 golang, hugo 버전을 최신으로 업데이트 해 본다. ","permalink":"https://aswinblue.github.io/post/hugo/hugo_dev/","summary":"Hugo를 이용해 블로그 만들기 Git과 markdown을 이용하여 git을 블로그처럼 이용하는 사람들이 있다는 것을 알았다.\n게다가 UI를 보기 좋게 꾸며줄 수 있는 툴들도 찾았는데, 그 중 Hugo를 사용해 보았다.\nHugo는 Go 언어로 짜여져 있어 apt-get으로도 설치가 가능하고, 소스 코드를 받아 빌드하여 쓸 수도 있다.\n내 컴퓨터에는 Go가 이미 설치되 있던 터라 apt-get으로 hugo를 받아서 사용해 보았다.\n설치는 정상적으로 되었고, 처음에는 잘 동작하는 듯 했는데, theme을 적용하니 ERROR들이 뜨기 시작했다.\n인터넷 검색을 아무리 해 봐도 해결책이 보이지 않고, 해당 git에 issue를 날려보기도 했는데 응답이 없어서 혼자 이것저것 뒤져 보았다.","title":"Hugo 환경세팅"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 `` The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 ``\nParagraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\n`` Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\n``\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Inline Markdown In Table italics bold strikethrough code Code Blocks Code block with backticks html\r\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Item First Sub-item Second Sub-item Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nWelcome to StackEdit! Hi! I\u0026rsquo;m your first Markdown file in StackEdit. If you want to learn about StackEdit, you can read me. If you want to play with Markdown, you can edit me. Once you have finished with me, you can create new files by opening the file explorer on the left corner of the navigation bar.\nFiles StackEdit stores your files in your browser, which means all your files are automatically saved locally and are accessible offline!\nCreate files and folders The file explorer is accessible using the button in left corner of the navigation bar. You can create a new file by clicking the New file button in the file explorer. You can also create folders by clicking the New folder button.\nSwitch to another file All your files and folders are presented as a tree in the file explorer. You can switch from one to another by clicking a file in the tree.\nRename a file You can rename the current file by clicking the file name in the navigation bar or by clicking the Rename button in the file explorer.\nDelete a file You can delete the current file by clicking the Remove button in the file explorer. The file will be moved into the Trash folder and automatically deleted after 7 days of inactivity.\nExport a file You can export the current file by clicking Export to disk in the menu. You can choose to export the file as plain Markdown, as HTML using a Handlebars template or as a PDF.\nSynchronization Synchronization is one of the biggest features of StackEdit. It enables you to synchronize any file in your workspace with other files stored in your Google Drive, your Dropbox and your GitHub accounts. This allows you to keep writing on other devices, collaborate with people you share the file with, integrate easily into your workflow\u0026hellip; The synchronization mechanism takes place every minute in the background, downloading, merging, and uploading file modifications.\nThere are two types of synchronization and they can complement each other:\nThe workspace synchronization will sync all your files, folders and settings automatically. This will allow you to fetch your workspace on any other device.\nTo start syncing your workspace, just sign in with Google in the menu.\nThe file synchronization will keep one file of the workspace synced with one or multiple files in Google Drive, Dropbox or GitHub. Before starting to sync files, you must link an account in the Synchronize sub-menu.\nOpen a file You can open a file from Google Drive, Dropbox or GitHub by opening the Synchronize sub-menu and clicking Open from. Once opened in the workspace, any modification in the file will be automatically synced.\nSave a file You can save any file of the workspace to Google Drive, Dropbox or GitHub by opening the Synchronize sub-menu and clicking Save on. Even if a file in the workspace is already synced, you can save it to another location. StackEdit can sync one file with multiple locations and accounts.\nSynchronize a file Once your file is linked to a synchronized location, StackEdit will periodically synchronize it by downloading/uploading any modification. A merge will be performed if necessary and conflicts will be resolved.\nIf you just have modified your file and you want to force syncing, click the Synchronize now button in the navigation bar.\nNote: The Synchronize now button is disabled if you have no file to synchronize.\nManage file synchronization Since one file can be synced with multiple locations, you can list and manage synchronized locations by clicking File synchronization in the Synchronize sub-menu. This allows you to list and remove synchronized locations that are linked to your file.\nPublication Publishing in StackEdit makes it simple for you to publish online your files. Once you\u0026rsquo;re happy with a file, you can publish it to different hosting platforms like Blogger, Dropbox, Gist, GitHub, Google Drive, WordPress and Zendesk. With Handlebars templates, you have full control over what you export.\nBefore starting to publish, you must link an account in the Publish sub-menu.\nPublish a File You can publish your file by opening the Publish sub-menu and by clicking Publish to. For some locations, you can choose between the following formats:\nMarkdown: publish the Markdown text on a website that can interpret it (GitHub for instance), HTML: publish the file converted to HTML via a Handlebars template (on a blog for example). Update a publication After publishing, StackEdit keeps your file linked to that publication which makes it easy for you to re-publish it. Once you have modified your file and you want to update your publication, click on the Publish now button in the navigation bar.\nNote: The Publish now button is disabled if your file has not been published yet.\nManage file publication Since one file can be published to multiple locations, you can list and manage publish locations by clicking File publication in the Publish sub-menu. This allows you to list and remove publication locations that are linked to your file.\nMarkdown extensions StackEdit extends the standard Markdown syntax by adding extra Markdown extensions, providing you with some nice features.\nProTip: You can disable any Markdown extension in the File properties dialog.\nSmartyPants SmartyPants converts ASCII punctuation characters into \u0026ldquo;smart\u0026rdquo; typographic punctuation HTML entities. For example:\nASCII HTML Single backticks 'Isn't this fun?' \u0026lsquo;Isn\u0026rsquo;t this fun?\u0026rsquo; Quotes \u0026quot;Isn't this fun?\u0026quot; \u0026ldquo;Isn\u0026rsquo;t this fun?\u0026rdquo; Dashes -- is en-dash, --- is em-dash \u0026ndash; is en-dash, \u0026mdash; is em-dash KaTeX You can render LaTeX mathematical expressions using KaTeX:\nThe Gamma function satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral\n$$ \\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt,. $$\nYou can find more information about LaTeX mathematical expressions here.\nUML diagrams You can render UML diagrams using Mermaid. For example, this will produce a sequence diagram:\nsequenceDiagram\rAlice -\u0026gt;\u0026gt; Bob: Hello Bob, how are you?\rBob--\u0026gt;\u0026gt;John: How about you John?\rBob--x Alice: I am good thanks!\rBob-x John: I am good thanks!\rNote right of John: Bob thinks a long\u0026lt;br/\u0026gt;long time, so long\u0026lt;br/\u0026gt;that the text does\u0026lt;br/\u0026gt;not fit on a row.\rBob--\u0026gt;Alice: Checking with John...\rAlice-\u0026gt;John: Yes... John, how are you? And this will produce a flow chart:\ngraph LR\rA[Square Rect] -- Link text --\u0026gt; B((Circle))\rA --\u0026gt; C(Round Rect)\rB --\u0026gt; D{Rhombus}\rC --\u0026gt; D The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://aswinblue.github.io/post/hugo/sample/","summary":"\u003cp\u003eThis article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\u003c/p\u003e","title":"Markdown Syntax Guide"},{"content":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\nhttps://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n","permalink":"https://aswinblue.github.io/about/","summary":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\nhttps://github.com/russross/blackfriday https://github.","title":"About"}]